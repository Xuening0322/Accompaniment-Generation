{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "In this file we train SketchNet\n",
    "'''\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from SketchVAE.sketchvae import SketchVAE\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.distributions import Normal\n",
    "from SketchNet.sketchnet import SketchNet\n",
    "from utils.helpers import *\n",
    "import time\n",
    "###############################\n",
    "# initial parameters\n",
    "s_dir = \"\" # folder address\n",
    "zp_dims = 128\n",
    "zr_dims = 128\n",
    "pf_dims = 512\n",
    "gen_dims = 1024\n",
    "combine_dims = 512\n",
    "combine_head = 4\n",
    "combine_num = 4\n",
    "pf_num = 2\n",
    "inpaint_len = 4\n",
    "seq_len = 16\n",
    "total_len = 16\n",
    "batch_size = 32\n",
    "n_epochs = 15 \n",
    "save_path = \"model_backup\"\n",
    "save_period = 5 # save every 5 epochs\n",
    "data_path = [\n",
    "    \"data/irish-dis-measure-vae-train-whole.npy\",\n",
    "    \"data/irish-dis-measure-vae-validate-whole.npy\",\n",
    "    \"data/irish-dis-measure-vae-test-whole.npy\"\n",
    "]\n",
    "lr = 1e-4\n",
    "decay = 0.9999\n",
    "##############################\n",
    "##############  for vae init ##############\n",
    "vae_hidden_dims = 1024\n",
    "vae_zp_dims = 128\n",
    "vae_zr_dims = 128\n",
    "vae_beta = 0.1\n",
    "vae_input_dims = 130\n",
    "vae_pitch_dims = 129\n",
    "vae_rhythm_dims = 3\n",
    "vae_seq_len = 6 * 4\n",
    "vae_beat_num = 4\n",
    "vae_tick_num = 6\n",
    "############################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Warmup schedule\n",
    "class CustomSchedule:\n",
    "    def __init__(self, d_model, warmup_steps=4000, optimizer=None):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.optimizer = optimizer\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "        self._step = 0\n",
    "        self._rate = 0\n",
    "\n",
    "    def step(self):\n",
    "        \"Update parameters and rate\"\n",
    "        self._step += 1\n",
    "        rate = self.rate()\n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = rate\n",
    "        self._rate = rate\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def rate(self, step=None):\n",
    "        if step is None:\n",
    "            step = self._step\n",
    "        arg1 = step ** (-0.5)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return self.d_model ** (-0.5) * min(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed data:\n",
      "processed finish! zeros: 256\n",
      "torch.Size([39798, 16, 24]) torch.Size([39798, 16, 24]) torch.Size([39798, 16, 24]) torch.Size([39798, 16]) torch.Size([39798, 16, 24, 3])\n",
      "processed data:\n",
      "processed finish! zeros: 1\n",
      "torch.Size([2927, 16, 24]) torch.Size([2927, 16, 24]) torch.Size([2927, 16, 24]) torch.Size([2927, 16]) torch.Size([2927, 16, 24, 3])\n",
      "91\n"
     ]
    }
   ],
   "source": [
    "# input data dis-measure-vae\n",
    "def processed_data_tensor(data):\n",
    "    print(\"processed data:\")\n",
    "    gd = [] \n",
    "    px = []\n",
    "    rx = []\n",
    "    len_x = []\n",
    "    nrx = []\n",
    "    total = 0\n",
    "    for i, d in enumerate(data):\n",
    "        gd.append([list(dd[0]) for dd in d])\n",
    "        px.append([list(dd[1]) for dd in d])\n",
    "        rx.append([list(dd[2]) for dd in d])\n",
    "        len_x.append([dd[3] for dd in d])\n",
    "        if len(gd[-1][-1]) != vae_seq_len:\n",
    "            gd[-1][-1].extend([128] * (vae_seq_len - len(gd[-1][-1])))\n",
    "            px[-1][-1].extend([128] * (vae_seq_len - len(px[-1][-1])))\n",
    "            rx[-1][-1].extend([2] * (vae_seq_len - len(rx[-1][-1])))\n",
    "    for i,d in enumerate(len_x):\n",
    "        for j,dd in enumerate(d):\n",
    "            if len_x[i][j] == 0:\n",
    "                gd[i][j][0] = 60\n",
    "                px[i][j][0] = 60\n",
    "                rx[i][j][0] = 1\n",
    "                len_x[i][j] = 1\n",
    "                total += 1\n",
    "    gd = np.array(gd)\n",
    "    px = np.array(px)\n",
    "    rx = np.array(rx)\n",
    "    len_x = np.array(len_x)\n",
    "    for d in rx:\n",
    "        nnrx = []\n",
    "        for dd in d:\n",
    "            temp = np.zeros((vae_seq_len, vae_rhythm_dims))\n",
    "            lins = np.arange(0, len(dd))\n",
    "            temp[lins, dd - 1] = 1\n",
    "            nnrx.append(temp)\n",
    "        nrx.append(nnrx)\n",
    "    nrx = np.array(nrx)\n",
    "    gd = torch.from_numpy(gd).long()\n",
    "    px = torch.from_numpy(px).long()\n",
    "    rx = torch.from_numpy(rx).float()\n",
    "    len_x = torch.from_numpy(len_x).long()\n",
    "    nrx = torch.from_numpy(nrx).float()\n",
    "    print(\"processed finish! zeros:\", total)\n",
    "    print(gd.size(),px.size(),rx.size(),len_x.size(),nrx.size())\n",
    "    return TensorDataset(px, rx, len_x, nrx, gd)\n",
    "\n",
    "train_set = np.load(os.path.join(s_dir,data_path[0]),allow_pickle = True)\n",
    "train_loader = DataLoader(\n",
    "    dataset = processed_data_tensor(train_set),\n",
    "    batch_size = batch_size, \n",
    "    shuffle = True, \n",
    "    num_workers = 8, \n",
    "    pin_memory = True, \n",
    "    drop_last = True\n",
    ")\n",
    "\n",
    "validate_set = np.load(os.path.join(s_dir,data_path[1]),allow_pickle = True)\n",
    "validate_loader = DataLoader(\n",
    "    dataset = processed_data_tensor(validate_set),\n",
    "    batch_size = batch_size, \n",
    "    shuffle = False, \n",
    "    num_workers = 8, \n",
    "    pin_memory = True, \n",
    "    drop_last = True\n",
    ")\n",
    "validate_data = []\n",
    "for i,d in enumerate(validate_loader):\n",
    "    validate_data.append(d)\n",
    "print(len(validate_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using:  NVIDIA GeForce RTX 2080 Ti\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# load VAE model\n",
    "vae_model = SketchVAE(\n",
    "    vae_input_dims, vae_pitch_dims, vae_rhythm_dims, vae_hidden_dims, \n",
    "    vae_zp_dims, vae_zr_dims, vae_seq_len, vae_beat_num, vae_tick_num, 4000)\n",
    "dic = torch.load(os.path.join(save_path, \"sketchvae-loss_0.04435703124001108_acc_0.9970518388541095_epoch_22_it_147928.pt\"))\n",
    "\n",
    "for name in list(dic.keys()):\n",
    "    dic[name.replace('module.', '')] = dic.pop(name)\n",
    "vae_model.load_state_dict(dic)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('Using: ', torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "    vae_model.cuda()\n",
    "else:\n",
    "    print('Using: CPU')\n",
    "vae_model.eval()\n",
    "print(vae_model.training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using:  NVIDIA GeForce RTX 2080 Ti\n",
      "SketchNet(\n",
      "  (past_p_gru): GRU(128, 512, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (past_r_gru): GRU(128, 512, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (future_p_gru): GRU(128, 512, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (future_r_gru): GRU(128, 512, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (gen_p_gru): GRU(128, 1024, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (gen_r_gru): GRU(128, 1024, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (gen_p_out): Linear(in_features=2048, out_features=128, bias=True)\n",
      "  (gen_r_out): Linear(in_features=2048, out_features=128, bias=True)\n",
      "  (combine_in): Linear(in_features=256, out_features=512, bias=True)\n",
      "  (combine_posenc): PositionalEncoding()\n",
      "  (combine_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (combine_nn): ModuleList(\n",
      "    (0): CombineLayer(\n",
      "      (slf_attn): MultiHeadAttention(\n",
      "        (w_qs): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (w_ks): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (w_vs): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (fc): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (attention): ScaledDotProductAttention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (pos_ffn): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (1): CombineLayer(\n",
      "      (slf_attn): MultiHeadAttention(\n",
      "        (w_qs): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (w_ks): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (w_vs): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (fc): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (attention): ScaledDotProductAttention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (pos_ffn): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (2): CombineLayer(\n",
      "      (slf_attn): MultiHeadAttention(\n",
      "        (w_qs): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (w_ks): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (w_vs): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (fc): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (attention): ScaledDotProductAttention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (pos_ffn): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (3): CombineLayer(\n",
      "      (slf_attn): MultiHeadAttention(\n",
      "        (w_qs): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (w_ks): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (w_vs): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (fc): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (attention): ScaledDotProductAttention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (pos_ffn): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (combine_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "  (combine_out): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (vae_model): SketchVAE(\n",
      "    (p_embedding): Embedding(130, 10)\n",
      "    (p_encoder_gru): GRU(10, 1024, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "    (p_linear_mu): Linear(in_features=4096, out_features=128, bias=True)\n",
      "    (p_linear_var): Linear(in_features=4096, out_features=128, bias=True)\n",
      "    (r_encoder_gru): GRU(3, 1024, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "    (r_linear_mu): Linear(in_features=4096, out_features=128, bias=True)\n",
      "    (r_linear_var): Linear(in_features=4096, out_features=128, bias=True)\n",
      "    (z_to_beat_hidden): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=2048, bias=True)\n",
      "      (1): SELU()\n",
      "    )\n",
      "    (beat_gru): GRU(1, 1024, num_layers=2, batch_first=True, dropout=0.2)\n",
      "    (beat_to_tick_hidden): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
      "      (1): SELU()\n",
      "    )\n",
      "    (beat_to_tick_input): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (1): SELU()\n",
      "    )\n",
      "    (d_embedding): Embedding(130, 10)\n",
      "    (tick_gru): GRU(1034, 1024, num_layers=2, batch_first=True, dropout=0.2)\n",
      "    (tick_to_note): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=130, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# import model\n",
    "\n",
    "# think about traning with mse\n",
    "model = SketchNet(\n",
    "    zp_dims, zr_dims, \n",
    "    pf_dims, gen_dims, combine_dims,\n",
    "    pf_num, combine_num, combine_head,\n",
    "    inpaint_len, total_len, \n",
    "    vae_model, True\n",
    ")\n",
    "# stage-1 traning result\n",
    "dic = torch.load(os.path.join(save_path,\"sketchNet-stage-1loss_0.7491441772814633_acc_0.7700165195930545_epoch_10_it_12430.pt\"))\n",
    "for name in list(dic.keys()):\n",
    "    dic[name.replace('module.', '')] = dic.pop(name)\n",
    "model.load_state_dict(dic)\n",
    "model.set_stage(\"sketch\")\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),lr=lr)\n",
    "scheduler = CustomSchedule(combine_dims, optimizer=optimizer)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('Using: ', torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "    model.cuda()\n",
    "else:\n",
    "    print('Using: CPU')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "epoch: 0\n",
      "__________________________________________\n",
      "batch 0 loss: 5.47479 acc: 0.59505 | v_loss: 6.64137 v_acc: 0.54264 |  iteration: 1 teacher: 0 stage: sketch lr: 0.000000\n",
      "batch 1 loss: 5.46798 acc: 0.61068 | v_loss: 6.14511 v_acc: 0.55046 |  iteration: 2 teacher: 1 stage: sketch lr: 0.000000\n",
      "batch 2 loss: 6.24513 acc: 0.56738 | v_loss: 6.45180 v_acc: 0.56543 |  iteration: 3 teacher: 1 stage: sketch lr: 0.000001\n",
      "batch 3 loss: 5.85714 acc: 0.57617 | v_loss: 6.03933 v_acc: 0.57389 |  iteration: 4 teacher: 0 stage: sketch lr: 0.000001\n",
      "batch 4 loss: 5.33090 acc: 0.60124 | v_loss: 5.46206 v_acc: 0.58919 |  iteration: 5 teacher: 1 stage: sketch lr: 0.000001\n",
      "batch 5 loss: 5.83259 acc: 0.58301 | v_loss: 6.43918 v_acc: 0.54850 |  iteration: 6 teacher: 0 stage: sketch lr: 0.000001\n",
      "batch 6 loss: 6.03222 acc: 0.56445 | v_loss: 5.92277 v_acc: 0.56478 |  iteration: 7 teacher: 1 stage: sketch lr: 0.000001\n",
      "batch 7 loss: 5.40070 acc: 0.60091 | v_loss: 6.04820 v_acc: 0.56999 |  iteration: 8 teacher: 0 stage: sketch lr: 0.000001\n",
      "batch 8 loss: 5.83002 acc: 0.57520 | v_loss: 5.63724 v_acc: 0.57552 |  iteration: 9 teacher: 1 stage: sketch lr: 0.000002\n",
      "batch 9 loss: 4.93514 acc: 0.61328 | v_loss: 5.31582 v_acc: 0.58919 |  iteration: 10 teacher: 0 stage: sketch lr: 0.000002\n",
      "batch 10 loss: 4.90288 acc: 0.62793 | v_loss: 5.06200 v_acc: 0.61133 |  iteration: 11 teacher: 1 stage: sketch lr: 0.000002\n",
      "batch 11 loss: 5.04043 acc: 0.61491 | v_loss: 4.99379 v_acc: 0.62435 |  iteration: 12 teacher: 0 stage: sketch lr: 0.000002\n",
      "batch 12 loss: 5.04744 acc: 0.61263 | v_loss: 3.67633 v_acc: 0.67285 |  iteration: 13 teacher: 1 stage: sketch lr: 0.000002\n",
      "batch 13 loss: 4.58656 acc: 0.63281 | v_loss: 4.32656 v_acc: 0.64616 |  iteration: 14 teacher: 0 stage: sketch lr: 0.000002\n",
      "batch 14 loss: 4.85879 acc: 0.62630 | v_loss: 4.22073 v_acc: 0.65007 |  iteration: 15 teacher: 0 stage: sketch lr: 0.000003\n",
      "batch 15 loss: 4.71589 acc: 0.63249 | v_loss: 3.78555 v_acc: 0.66309 |  iteration: 16 teacher: 1 stage: sketch lr: 0.000003\n",
      "batch 16 loss: 4.35266 acc: 0.64193 | v_loss: 3.64421 v_acc: 0.66309 |  iteration: 17 teacher: 0 stage: sketch lr: 0.000003\n",
      "batch 17 loss: 4.35794 acc: 0.64486 | v_loss: 3.96286 v_acc: 0.66569 |  iteration: 18 teacher: 0 stage: sketch lr: 0.000003\n",
      "batch 18 loss: 4.52547 acc: 0.63639 | v_loss: 3.79048 v_acc: 0.65951 |  iteration: 19 teacher: 0 stage: sketch lr: 0.000003\n",
      "batch 19 loss: 4.75584 acc: 0.64030 | v_loss: 4.26886 v_acc: 0.64909 |  iteration: 20 teacher: 1 stage: sketch lr: 0.000003\n",
      "batch 20 loss: 4.18244 acc: 0.65690 | v_loss: 3.81874 v_acc: 0.65755 |  iteration: 21 teacher: 1 stage: sketch lr: 0.000004\n",
      "batch 21 loss: 3.89835 acc: 0.66602 | v_loss: 3.50219 v_acc: 0.67741 |  iteration: 22 teacher: 0 stage: sketch lr: 0.000004\n",
      "batch 22 loss: 3.97303 acc: 0.65853 | v_loss: 3.95774 v_acc: 0.65853 |  iteration: 23 teacher: 1 stage: sketch lr: 0.000004\n",
      "batch 23 loss: 3.92047 acc: 0.65299 | v_loss: 3.96876 v_acc: 0.65397 |  iteration: 24 teacher: 1 stage: sketch lr: 0.000004\n",
      "batch 24 loss: 4.19539 acc: 0.65885 | v_loss: 3.86472 v_acc: 0.66536 |  iteration: 25 teacher: 1 stage: sketch lr: 0.000004\n",
      "batch 25 loss: 4.49960 acc: 0.63574 | v_loss: 3.84530 v_acc: 0.65853 |  iteration: 26 teacher: 1 stage: sketch lr: 0.000005\n",
      "batch 26 loss: 3.65793 acc: 0.66895 | v_loss: 3.54432 v_acc: 0.66276 |  iteration: 27 teacher: 0 stage: sketch lr: 0.000005\n",
      "batch 27 loss: 4.20632 acc: 0.64551 | v_loss: 3.66145 v_acc: 0.66276 |  iteration: 28 teacher: 1 stage: sketch lr: 0.000005\n",
      "batch 28 loss: 4.33017 acc: 0.63704 | v_loss: 3.86824 v_acc: 0.64909 |  iteration: 29 teacher: 1 stage: sketch lr: 0.000005\n",
      "batch 29 loss: 3.57018 acc: 0.66341 | v_loss: 3.25494 v_acc: 0.66081 |  iteration: 30 teacher: 0 stage: sketch lr: 0.000005\n",
      "batch 30 loss: 3.91680 acc: 0.64844 | v_loss: 3.66181 v_acc: 0.65527 |  iteration: 31 teacher: 1 stage: sketch lr: 0.000005\n",
      "batch 31 loss: 3.69048 acc: 0.65397 | v_loss: 3.49443 v_acc: 0.66341 |  iteration: 32 teacher: 0 stage: sketch lr: 0.000006\n",
      "batch 32 loss: 3.94603 acc: 0.64648 | v_loss: 3.59489 v_acc: 0.65137 |  iteration: 33 teacher: 0 stage: sketch lr: 0.000006\n",
      "batch 33 loss: 3.91259 acc: 0.63542 | v_loss: 2.81828 v_acc: 0.68587 |  iteration: 34 teacher: 0 stage: sketch lr: 0.000006\n",
      "batch 34 loss: 3.45147 acc: 0.65755 | v_loss: 3.66240 v_acc: 0.63574 |  iteration: 35 teacher: 0 stage: sketch lr: 0.000006\n",
      "batch 35 loss: 3.66209 acc: 0.64616 | v_loss: 3.06715 v_acc: 0.66797 |  iteration: 36 teacher: 1 stage: sketch lr: 0.000006\n",
      "batch 36 loss: 3.41331 acc: 0.65234 | v_loss: 3.38348 v_acc: 0.64876 |  iteration: 37 teacher: 0 stage: sketch lr: 0.000006\n",
      "batch 37 loss: 3.35735 acc: 0.65234 | v_loss: 3.49578 v_acc: 0.63216 |  iteration: 38 teacher: 0 stage: sketch lr: 0.000007\n",
      "batch 38 loss: 3.35084 acc: 0.64225 | v_loss: 3.11186 v_acc: 0.63770 |  iteration: 39 teacher: 0 stage: sketch lr: 0.000007\n",
      "batch 39 loss: 3.20526 acc: 0.65137 | v_loss: 3.04424 v_acc: 0.65299 |  iteration: 40 teacher: 0 stage: sketch lr: 0.000007\n",
      "batch 40 loss: 3.54456 acc: 0.65397 | v_loss: 2.87906 v_acc: 0.65723 |  iteration: 41 teacher: 1 stage: sketch lr: 0.000007\n",
      "batch 41 loss: 3.19718 acc: 0.63737 | v_loss: 2.77522 v_acc: 0.65690 |  iteration: 42 teacher: 0 stage: sketch lr: 0.000007\n",
      "batch 42 loss: 3.63261 acc: 0.61523 | v_loss: 2.71228 v_acc: 0.64876 |  iteration: 43 teacher: 1 stage: sketch lr: 0.000008\n",
      "batch 43 loss: 3.58978 acc: 0.61686 | v_loss: 3.39515 v_acc: 0.62044 |  iteration: 44 teacher: 1 stage: sketch lr: 0.000008\n",
      "batch 44 loss: 3.50703 acc: 0.62142 | v_loss: 2.92331 v_acc: 0.64225 |  iteration: 45 teacher: 0 stage: sketch lr: 0.000008\n",
      "batch 45 loss: 3.36435 acc: 0.62760 | v_loss: 2.68410 v_acc: 0.65983 |  iteration: 46 teacher: 1 stage: sketch lr: 0.000008\n",
      "batch 46 loss: 3.19242 acc: 0.63542 | v_loss: 2.79912 v_acc: 0.64258 |  iteration: 47 teacher: 0 stage: sketch lr: 0.000008\n",
      "batch 47 loss: 3.11720 acc: 0.63770 | v_loss: 2.52662 v_acc: 0.66113 |  iteration: 48 teacher: 0 stage: sketch lr: 0.000008\n",
      "batch 48 loss: 3.27677 acc: 0.63249 | v_loss: 2.60760 v_acc: 0.64583 |  iteration: 49 teacher: 1 stage: sketch lr: 0.000009\n",
      "batch 49 loss: 3.26742 acc: 0.62402 | v_loss: 2.54683 v_acc: 0.64355 |  iteration: 50 teacher: 1 stage: sketch lr: 0.000009\n",
      "batch 50 loss: 2.98481 acc: 0.64258 | v_loss: 2.30612 v_acc: 0.67350 |  iteration: 51 teacher: 1 stage: sketch lr: 0.000009\n",
      "batch 51 loss: 2.98828 acc: 0.64323 | v_loss: 2.36418 v_acc: 0.66276 |  iteration: 52 teacher: 0 stage: sketch lr: 0.000009\n",
      "batch 52 loss: 2.81557 acc: 0.64551 | v_loss: 2.43181 v_acc: 0.65592 |  iteration: 53 teacher: 1 stage: sketch lr: 0.000009\n",
      "batch 53 loss: 2.89958 acc: 0.65299 | v_loss: 2.39866 v_acc: 0.66341 |  iteration: 54 teacher: 1 stage: sketch lr: 0.000009\n",
      "batch 54 loss: 2.83282 acc: 0.64258 | v_loss: 2.37859 v_acc: 0.65918 |  iteration: 55 teacher: 1 stage: sketch lr: 0.000010\n",
      "batch 55 loss: 2.75557 acc: 0.65527 | v_loss: 2.25610 v_acc: 0.67025 |  iteration: 56 teacher: 0 stage: sketch lr: 0.000010\n",
      "batch 56 loss: 2.59151 acc: 0.65951 | v_loss: 2.30468 v_acc: 0.66634 |  iteration: 57 teacher: 0 stage: sketch lr: 0.000010\n",
      "batch 57 loss: 2.62300 acc: 0.65951 | v_loss: 2.33646 v_acc: 0.65658 |  iteration: 58 teacher: 0 stage: sketch lr: 0.000010\n",
      "batch 58 loss: 2.89919 acc: 0.63216 | v_loss: 2.27781 v_acc: 0.66374 |  iteration: 59 teacher: 1 stage: sketch lr: 0.000010\n",
      "batch 59 loss: 2.86031 acc: 0.63542 | v_loss: 2.14889 v_acc: 0.67025 |  iteration: 60 teacher: 1 stage: sketch lr: 0.000010\n",
      "batch 60 loss: 2.64823 acc: 0.64876 | v_loss: 1.95925 v_acc: 0.68587 |  iteration: 61 teacher: 0 stage: sketch lr: 0.000011\n",
      "batch 61 loss: 2.59662 acc: 0.65267 | v_loss: 1.89576 v_acc: 0.67415 |  iteration: 62 teacher: 0 stage: sketch lr: 0.000011\n",
      "batch 62 loss: 2.54991 acc: 0.65234 | v_loss: 2.01659 v_acc: 0.67448 |  iteration: 63 teacher: 0 stage: sketch lr: 0.000011\n",
      "batch 63 loss: 2.47162 acc: 0.65625 | v_loss: 2.12780 v_acc: 0.66016 |  iteration: 64 teacher: 0 stage: sketch lr: 0.000011\n",
      "batch 64 loss: 2.45089 acc: 0.65007 | v_loss: 2.03596 v_acc: 0.67155 |  iteration: 65 teacher: 0 stage: sketch lr: 0.000011\n",
      "batch 65 loss: 2.38664 acc: 0.64583 | v_loss: 2.38252 v_acc: 0.64941 |  iteration: 66 teacher: 1 stage: sketch lr: 0.000012\n",
      "batch 66 loss: 2.30909 acc: 0.65690 | v_loss: 2.49441 v_acc: 0.63672 |  iteration: 67 teacher: 0 stage: sketch lr: 0.000012\n",
      "batch 67 loss: 2.62986 acc: 0.64030 | v_loss: 2.21356 v_acc: 0.64616 |  iteration: 68 teacher: 1 stage: sketch lr: 0.000012\n",
      "batch 68 loss: 2.46056 acc: 0.64746 | v_loss: 1.98758 v_acc: 0.66178 |  iteration: 69 teacher: 1 stage: sketch lr: 0.000012\n",
      "batch 69 loss: 2.32139 acc: 0.65723 | v_loss: 1.99985 v_acc: 0.65397 |  iteration: 70 teacher: 1 stage: sketch lr: 0.000012\n",
      "batch 70 loss: 2.59520 acc: 0.63411 | v_loss: 1.82925 v_acc: 0.66699 |  iteration: 71 teacher: 1 stage: sketch lr: 0.000012\n",
      "batch 71 loss: 2.47676 acc: 0.63867 | v_loss: 2.00339 v_acc: 0.65495 |  iteration: 72 teacher: 1 stage: sketch lr: 0.000013\n",
      "batch 72 loss: 2.30858 acc: 0.64909 | v_loss: 1.92517 v_acc: 0.66732 |  iteration: 73 teacher: 0 stage: sketch lr: 0.000013\n",
      "batch 73 loss: 2.14302 acc: 0.66016 | v_loss: 1.88432 v_acc: 0.66829 |  iteration: 74 teacher: 1 stage: sketch lr: 0.000013\n",
      "batch 74 loss: 2.08709 acc: 0.65885 | v_loss: 1.95850 v_acc: 0.66276 |  iteration: 75 teacher: 1 stage: sketch lr: 0.000013\n",
      "batch 75 loss: 2.16095 acc: 0.65690 | v_loss: 1.92250 v_acc: 0.65983 |  iteration: 76 teacher: 0 stage: sketch lr: 0.000013\n",
      "batch 76 loss: 2.13204 acc: 0.65690 | v_loss: 1.94308 v_acc: 0.65462 |  iteration: 77 teacher: 0 stage: sketch lr: 0.000013\n",
      "batch 77 loss: 2.08915 acc: 0.65918 | v_loss: 1.78037 v_acc: 0.66569 |  iteration: 78 teacher: 0 stage: sketch lr: 0.000014\n",
      "batch 78 loss: 2.03636 acc: 0.65820 | v_loss: 2.05161 v_acc: 0.64583 |  iteration: 79 teacher: 0 stage: sketch lr: 0.000014\n",
      "batch 79 loss: 2.17235 acc: 0.64616 | v_loss: 1.83093 v_acc: 0.65527 |  iteration: 80 teacher: 1 stage: sketch lr: 0.000014\n",
      "batch 80 loss: 2.13161 acc: 0.65885 | v_loss: 1.82946 v_acc: 0.66732 |  iteration: 81 teacher: 1 stage: sketch lr: 0.000014\n",
      "batch 81 loss: 2.27578 acc: 0.65039 | v_loss: 2.01810 v_acc: 0.65820 |  iteration: 82 teacher: 1 stage: sketch lr: 0.000014\n",
      "batch 82 loss: 2.14113 acc: 0.65690 | v_loss: 2.01691 v_acc: 0.64941 |  iteration: 83 teacher: 1 stage: sketch lr: 0.000014\n",
      "batch 83 loss: 2.15734 acc: 0.65332 | v_loss: 1.74348 v_acc: 0.67253 |  iteration: 84 teacher: 1 stage: sketch lr: 0.000015\n",
      "batch 84 loss: 2.16831 acc: 0.64844 | v_loss: 2.01204 v_acc: 0.65072 |  iteration: 85 teacher: 0 stage: sketch lr: 0.000015\n",
      "batch 85 loss: 2.05072 acc: 0.65658 | v_loss: 1.88516 v_acc: 0.65137 |  iteration: 86 teacher: 0 stage: sketch lr: 0.000015\n",
      "batch 86 loss: 2.02718 acc: 0.65983 | v_loss: 1.85893 v_acc: 0.65527 |  iteration: 87 teacher: 1 stage: sketch lr: 0.000015\n",
      "batch 87 loss: 2.00691 acc: 0.65723 | v_loss: 1.77878 v_acc: 0.66048 |  iteration: 88 teacher: 1 stage: sketch lr: 0.000015\n",
      "batch 88 loss: 1.92282 acc: 0.66113 | v_loss: 1.83201 v_acc: 0.66243 |  iteration: 89 teacher: 0 stage: sketch lr: 0.000016\n",
      "batch 89 loss: 2.01901 acc: 0.65560 | v_loss: 1.89425 v_acc: 0.65267 |  iteration: 90 teacher: 0 stage: sketch lr: 0.000016\n",
      "batch 90 loss: 2.06660 acc: 0.65267 | v_loss: 1.79998 v_acc: 0.67480 |  iteration: 91 teacher: 1 stage: sketch lr: 0.000016\n",
      "batch 91 loss: 2.04036 acc: 0.65690 | v_loss: 1.81184 v_acc: 0.65983 |  iteration: 92 teacher: 0 stage: sketch lr: 0.000016\n",
      "batch 92 loss: 1.87394 acc: 0.66895 | v_loss: 1.78610 v_acc: 0.66471 |  iteration: 93 teacher: 1 stage: sketch lr: 0.000016\n",
      "batch 93 loss: 2.00798 acc: 0.65560 | v_loss: 1.85773 v_acc: 0.67318 |  iteration: 94 teacher: 0 stage: sketch lr: 0.000016\n",
      "batch 94 loss: 1.80743 acc: 0.67383 | v_loss: 1.72304 v_acc: 0.67611 |  iteration: 95 teacher: 0 stage: sketch lr: 0.000017\n",
      "batch 95 loss: 1.89328 acc: 0.66992 | v_loss: 1.79048 v_acc: 0.67513 |  iteration: 96 teacher: 1 stage: sketch lr: 0.000017\n",
      "batch 96 loss: 1.99526 acc: 0.65951 | v_loss: 1.71566 v_acc: 0.66927 |  iteration: 97 teacher: 1 stage: sketch lr: 0.000017\n",
      "batch 97 loss: 1.83892 acc: 0.67188 | v_loss: 1.77493 v_acc: 0.66829 |  iteration: 98 teacher: 0 stage: sketch lr: 0.000017\n",
      "batch 98 loss: 1.79787 acc: 0.67220 | v_loss: 2.02042 v_acc: 0.65104 |  iteration: 99 teacher: 0 stage: sketch lr: 0.000017\n",
      "batch 99 loss: 1.94572 acc: 0.65820 | v_loss: 1.72531 v_acc: 0.66960 |  iteration: 100 teacher: 1 stage: sketch lr: 0.000017\n",
      "batch 100 loss: 1.84367 acc: 0.66927 | v_loss: 1.76111 v_acc: 0.66439 |  iteration: 101 teacher: 0 stage: sketch lr: 0.000018\n",
      "batch 101 loss: 1.81702 acc: 0.67253 | v_loss: 1.75288 v_acc: 0.67025 |  iteration: 102 teacher: 0 stage: sketch lr: 0.000018\n",
      "batch 102 loss: 1.85396 acc: 0.66927 | v_loss: 1.68309 v_acc: 0.67513 |  iteration: 103 teacher: 0 stage: sketch lr: 0.000018\n",
      "batch 103 loss: 1.79476 acc: 0.67350 | v_loss: 1.64686 v_acc: 0.68229 |  iteration: 104 teacher: 0 stage: sketch lr: 0.000018\n",
      "batch 104 loss: 1.95441 acc: 0.66667 | v_loss: 1.68917 v_acc: 0.67448 |  iteration: 105 teacher: 0 stage: sketch lr: 0.000018\n",
      "batch 105 loss: 1.85672 acc: 0.67480 | v_loss: 1.68575 v_acc: 0.67611 |  iteration: 106 teacher: 0 stage: sketch lr: 0.000019\n",
      "batch 106 loss: 1.80772 acc: 0.67220 | v_loss: 1.68893 v_acc: 0.67708 |  iteration: 107 teacher: 0 stage: sketch lr: 0.000019\n",
      "batch 107 loss: 1.81632 acc: 0.67708 | v_loss: 1.78984 v_acc: 0.66602 |  iteration: 108 teacher: 0 stage: sketch lr: 0.000019\n",
      "batch 108 loss: 1.86756 acc: 0.67415 | v_loss: 1.66122 v_acc: 0.68066 |  iteration: 109 teacher: 0 stage: sketch lr: 0.000019\n",
      "batch 109 loss: 1.85835 acc: 0.66764 | v_loss: 1.65851 v_acc: 0.69206 |  iteration: 110 teacher: 0 stage: sketch lr: 0.000019\n",
      "batch 110 loss: 1.93335 acc: 0.66667 | v_loss: 1.77101 v_acc: 0.67480 |  iteration: 111 teacher: 0 stage: sketch lr: 0.000019\n",
      "batch 111 loss: 1.81754 acc: 0.67969 | v_loss: 1.69135 v_acc: 0.68490 |  iteration: 112 teacher: 0 stage: sketch lr: 0.000020\n",
      "batch 112 loss: 1.77302 acc: 0.68066 | v_loss: 1.53312 v_acc: 0.70833 |  iteration: 113 teacher: 0 stage: sketch lr: 0.000020\n",
      "batch 113 loss: 2.00125 acc: 0.65462 | v_loss: 1.78852 v_acc: 0.67969 |  iteration: 114 teacher: 1 stage: sketch lr: 0.000020\n",
      "batch 114 loss: 1.99707 acc: 0.66406 | v_loss: 1.77917 v_acc: 0.67090 |  iteration: 115 teacher: 1 stage: sketch lr: 0.000020\n",
      "batch 115 loss: 1.94884 acc: 0.66341 | v_loss: 1.79131 v_acc: 0.67513 |  iteration: 116 teacher: 1 stage: sketch lr: 0.000020\n",
      "batch 116 loss: 1.78775 acc: 0.67546 | v_loss: 1.68483 v_acc: 0.67741 |  iteration: 117 teacher: 1 stage: sketch lr: 0.000020\n",
      "batch 117 loss: 1.83373 acc: 0.67708 | v_loss: 1.87011 v_acc: 0.66016 |  iteration: 118 teacher: 0 stage: sketch lr: 0.000021\n",
      "batch 118 loss: 1.92539 acc: 0.66113 | v_loss: 1.69871 v_acc: 0.67546 |  iteration: 119 teacher: 1 stage: sketch lr: 0.000021\n",
      "batch 119 loss: 1.80743 acc: 0.67285 | v_loss: 1.87144 v_acc: 0.65788 |  iteration: 120 teacher: 1 stage: sketch lr: 0.000021\n",
      "batch 120 loss: 1.83605 acc: 0.66439 | v_loss: 1.71123 v_acc: 0.67611 |  iteration: 121 teacher: 1 stage: sketch lr: 0.000021\n",
      "batch 121 loss: 1.77035 acc: 0.66992 | v_loss: 1.68081 v_acc: 0.68652 |  iteration: 122 teacher: 1 stage: sketch lr: 0.000021\n",
      "batch 122 loss: 1.67697 acc: 0.68359 | v_loss: 1.73172 v_acc: 0.66797 |  iteration: 123 teacher: 0 stage: sketch lr: 0.000021\n",
      "batch 123 loss: 1.91745 acc: 0.66113 | v_loss: 1.89551 v_acc: 0.65690 |  iteration: 124 teacher: 1 stage: sketch lr: 0.000022\n",
      "batch 124 loss: 1.81110 acc: 0.67546 | v_loss: 1.63269 v_acc: 0.67415 |  iteration: 125 teacher: 0 stage: sketch lr: 0.000022\n",
      "batch 125 loss: 1.87385 acc: 0.66374 | v_loss: 1.95417 v_acc: 0.64746 |  iteration: 126 teacher: 1 stage: sketch lr: 0.000022\n",
      "batch 126 loss: 1.81533 acc: 0.67025 | v_loss: 1.70525 v_acc: 0.69141 |  iteration: 127 teacher: 0 stage: sketch lr: 0.000022\n",
      "batch 127 loss: 1.76344 acc: 0.67936 | v_loss: 1.92991 v_acc: 0.65592 |  iteration: 128 teacher: 0 stage: sketch lr: 0.000022\n",
      "batch 128 loss: 1.83629 acc: 0.67969 | v_loss: 1.94688 v_acc: 0.66016 |  iteration: 129 teacher: 0 stage: sketch lr: 0.000023\n",
      "batch 129 loss: 1.82115 acc: 0.67285 | v_loss: 1.83058 v_acc: 0.67025 |  iteration: 130 teacher: 1 stage: sketch lr: 0.000023\n",
      "batch 130 loss: 1.75609 acc: 0.67741 | v_loss: 1.69886 v_acc: 0.67773 |  iteration: 131 teacher: 1 stage: sketch lr: 0.000023\n",
      "batch 131 loss: 1.80731 acc: 0.67904 | v_loss: 1.62216 v_acc: 0.68555 |  iteration: 132 teacher: 0 stage: sketch lr: 0.000023\n",
      "batch 132 loss: 1.72159 acc: 0.68750 | v_loss: 1.76538 v_acc: 0.67741 |  iteration: 133 teacher: 0 stage: sketch lr: 0.000023\n",
      "batch 133 loss: 1.82725 acc: 0.66797 | v_loss: 1.61926 v_acc: 0.69499 |  iteration: 134 teacher: 1 stage: sketch lr: 0.000023\n",
      "batch 134 loss: 1.77624 acc: 0.67969 | v_loss: 2.01240 v_acc: 0.66536 |  iteration: 135 teacher: 0 stage: sketch lr: 0.000024\n",
      "batch 135 loss: 1.90211 acc: 0.67415 | v_loss: 1.74284 v_acc: 0.68262 |  iteration: 136 teacher: 0 stage: sketch lr: 0.000024\n",
      "batch 136 loss: 1.91439 acc: 0.66536 | v_loss: 1.60782 v_acc: 0.69759 |  iteration: 137 teacher: 1 stage: sketch lr: 0.000024\n",
      "batch 137 loss: 1.72901 acc: 0.68164 | v_loss: 1.72238 v_acc: 0.69629 |  iteration: 138 teacher: 0 stage: sketch lr: 0.000024\n",
      "batch 138 loss: 1.84334 acc: 0.66829 | v_loss: 1.68580 v_acc: 0.68034 |  iteration: 139 teacher: 1 stage: sketch lr: 0.000024\n",
      "batch 139 loss: 1.89413 acc: 0.68034 | v_loss: 1.72048 v_acc: 0.67188 |  iteration: 140 teacher: 1 stage: sketch lr: 0.000024\n",
      "batch 140 loss: 1.87746 acc: 0.66406 | v_loss: 1.63960 v_acc: 0.69792 |  iteration: 141 teacher: 1 stage: sketch lr: 0.000025\n",
      "batch 141 loss: 1.81791 acc: 0.67839 | v_loss: 1.55456 v_acc: 0.68815 |  iteration: 142 teacher: 0 stage: sketch lr: 0.000025\n",
      "batch 142 loss: 1.80016 acc: 0.67839 | v_loss: 1.53140 v_acc: 0.70898 |  iteration: 143 teacher: 0 stage: sketch lr: 0.000025\n",
      "batch 143 loss: 1.80342 acc: 0.68392 | v_loss: 1.65917 v_acc: 0.69206 |  iteration: 144 teacher: 0 stage: sketch lr: 0.000025\n",
      "batch 144 loss: 1.97097 acc: 0.65918 | v_loss: 1.72569 v_acc: 0.68587 |  iteration: 145 teacher: 1 stage: sketch lr: 0.000025\n",
      "batch 145 loss: 1.85347 acc: 0.67415 | v_loss: 1.66774 v_acc: 0.68457 |  iteration: 146 teacher: 0 stage: sketch lr: 0.000026\n",
      "batch 146 loss: 1.82292 acc: 0.67188 | v_loss: 1.60697 v_acc: 0.69531 |  iteration: 147 teacher: 0 stage: sketch lr: 0.000026\n",
      "batch 147 loss: 1.80410 acc: 0.67253 | v_loss: 1.67417 v_acc: 0.71159 |  iteration: 148 teacher: 0 stage: sketch lr: 0.000026\n",
      "batch 148 loss: 1.79220 acc: 0.67969 | v_loss: 1.69719 v_acc: 0.67904 |  iteration: 149 teacher: 0 stage: sketch lr: 0.000026\n",
      "batch 149 loss: 1.73835 acc: 0.67773 | v_loss: 1.65015 v_acc: 0.70312 |  iteration: 150 teacher: 1 stage: sketch lr: 0.000026\n",
      "batch 150 loss: 1.67197 acc: 0.69661 | v_loss: 1.58020 v_acc: 0.69238 |  iteration: 151 teacher: 0 stage: sketch lr: 0.000026\n",
      "batch 151 loss: 1.84293 acc: 0.67090 | v_loss: 1.49920 v_acc: 0.71842 |  iteration: 152 teacher: 1 stage: sketch lr: 0.000027\n",
      "batch 152 loss: 1.81010 acc: 0.66960 | v_loss: 1.54532 v_acc: 0.70215 |  iteration: 153 teacher: 1 stage: sketch lr: 0.000027\n",
      "batch 153 loss: 1.83617 acc: 0.67057 | v_loss: 1.58024 v_acc: 0.69368 |  iteration: 154 teacher: 1 stage: sketch lr: 0.000027\n",
      "batch 154 loss: 1.79208 acc: 0.67285 | v_loss: 1.70165 v_acc: 0.68522 |  iteration: 155 teacher: 1 stage: sketch lr: 0.000027\n",
      "batch 155 loss: 1.82924 acc: 0.67936 | v_loss: 1.64275 v_acc: 0.69987 |  iteration: 156 teacher: 0 stage: sketch lr: 0.000027\n",
      "batch 156 loss: 1.71463 acc: 0.68587 | v_loss: 1.88102 v_acc: 0.69401 |  iteration: 157 teacher: 0 stage: sketch lr: 0.000027\n",
      "batch 157 loss: 1.69757 acc: 0.69401 | v_loss: 1.92834 v_acc: 0.67969 |  iteration: 158 teacher: 1 stage: sketch lr: 0.000028\n",
      "batch 158 loss: 1.76147 acc: 0.69401 | v_loss: 1.83754 v_acc: 0.67871 |  iteration: 159 teacher: 1 stage: sketch lr: 0.000028\n",
      "batch 159 loss: 1.79722 acc: 0.67741 | v_loss: 1.65207 v_acc: 0.70671 |  iteration: 160 teacher: 0 stage: sketch lr: 0.000028\n",
      "batch 160 loss: 1.82226 acc: 0.67936 | v_loss: 1.71899 v_acc: 0.69336 |  iteration: 161 teacher: 1 stage: sketch lr: 0.000028\n",
      "batch 161 loss: 1.76212 acc: 0.68783 | v_loss: 1.55047 v_acc: 0.70378 |  iteration: 162 teacher: 1 stage: sketch lr: 0.000028\n",
      "batch 162 loss: 1.83953 acc: 0.68034 | v_loss: 1.72627 v_acc: 0.68034 |  iteration: 163 teacher: 0 stage: sketch lr: 0.000028\n",
      "batch 163 loss: 1.71749 acc: 0.67643 | v_loss: 1.62873 v_acc: 0.68685 |  iteration: 164 teacher: 0 stage: sketch lr: 0.000029\n",
      "batch 164 loss: 1.85977 acc: 0.66927 | v_loss: 1.55852 v_acc: 0.70312 |  iteration: 165 teacher: 0 stage: sketch lr: 0.000029\n",
      "batch 165 loss: 1.77821 acc: 0.67220 | v_loss: 1.61173 v_acc: 0.70280 |  iteration: 166 teacher: 1 stage: sketch lr: 0.000029\n",
      "batch 166 loss: 1.74902 acc: 0.67806 | v_loss: 1.67591 v_acc: 0.67806 |  iteration: 167 teacher: 1 stage: sketch lr: 0.000029\n",
      "batch 167 loss: 1.79326 acc: 0.67643 | v_loss: 1.61315 v_acc: 0.70443 |  iteration: 168 teacher: 1 stage: sketch lr: 0.000029\n",
      "batch 168 loss: 1.81615 acc: 0.67546 | v_loss: 1.52291 v_acc: 0.71191 |  iteration: 169 teacher: 1 stage: sketch lr: 0.000030\n",
      "batch 169 loss: 1.71104 acc: 0.69434 | v_loss: 1.77501 v_acc: 0.68392 |  iteration: 170 teacher: 1 stage: sketch lr: 0.000030\n",
      "batch 170 loss: 1.72423 acc: 0.69238 | v_loss: 1.58840 v_acc: 0.70345 |  iteration: 171 teacher: 0 stage: sketch lr: 0.000030\n",
      "batch 171 loss: 1.79156 acc: 0.68034 | v_loss: 1.60504 v_acc: 0.70215 |  iteration: 172 teacher: 1 stage: sketch lr: 0.000030\n",
      "batch 172 loss: 1.74547 acc: 0.68848 | v_loss: 1.72028 v_acc: 0.69889 |  iteration: 173 teacher: 0 stage: sketch lr: 0.000030\n",
      "batch 173 loss: 1.68714 acc: 0.68717 | v_loss: 1.79307 v_acc: 0.68685 |  iteration: 174 teacher: 1 stage: sketch lr: 0.000030\n",
      "batch 174 loss: 1.74788 acc: 0.68327 | v_loss: 1.53501 v_acc: 0.71810 |  iteration: 175 teacher: 1 stage: sketch lr: 0.000031\n",
      "batch 175 loss: 1.67848 acc: 0.69108 | v_loss: 1.71549 v_acc: 0.70247 |  iteration: 176 teacher: 0 stage: sketch lr: 0.000031\n",
      "batch 176 loss: 1.81361 acc: 0.67643 | v_loss: 1.64189 v_acc: 0.69076 |  iteration: 177 teacher: 1 stage: sketch lr: 0.000031\n",
      "batch 177 loss: 1.72064 acc: 0.67904 | v_loss: 1.64115 v_acc: 0.69759 |  iteration: 178 teacher: 0 stage: sketch lr: 0.000031\n",
      "batch 178 loss: 1.70705 acc: 0.68587 | v_loss: 1.61090 v_acc: 0.69401 |  iteration: 179 teacher: 0 stage: sketch lr: 0.000031\n",
      "batch 179 loss: 1.74421 acc: 0.68327 | v_loss: 1.67006 v_acc: 0.69694 |  iteration: 180 teacher: 0 stage: sketch lr: 0.000031\n",
      "batch 180 loss: 1.70832 acc: 0.69336 | v_loss: 1.74092 v_acc: 0.68132 |  iteration: 181 teacher: 1 stage: sketch lr: 0.000032\n",
      "batch 181 loss: 1.61942 acc: 0.70898 | v_loss: 1.62834 v_acc: 0.69857 |  iteration: 182 teacher: 0 stage: sketch lr: 0.000032\n",
      "batch 182 loss: 1.69383 acc: 0.69108 | v_loss: 1.61166 v_acc: 0.69792 |  iteration: 183 teacher: 0 stage: sketch lr: 0.000032\n",
      "batch 183 loss: 1.79091 acc: 0.68522 | v_loss: 1.61196 v_acc: 0.70410 |  iteration: 184 teacher: 0 stage: sketch lr: 0.000032\n",
      "batch 184 loss: 1.61960 acc: 0.70117 | v_loss: 1.62499 v_acc: 0.70085 |  iteration: 185 teacher: 0 stage: sketch lr: 0.000032\n",
      "batch 185 loss: 1.83731 acc: 0.68424 | v_loss: 1.53739 v_acc: 0.70703 |  iteration: 186 teacher: 1 stage: sketch lr: 0.000032\n",
      "batch 186 loss: 1.67552 acc: 0.69824 | v_loss: 1.59206 v_acc: 0.71615 |  iteration: 187 teacher: 0 stage: sketch lr: 0.000033\n",
      "batch 187 loss: 1.75052 acc: 0.68587 | v_loss: 1.54481 v_acc: 0.70182 |  iteration: 188 teacher: 1 stage: sketch lr: 0.000033\n",
      "batch 188 loss: 1.65742 acc: 0.69661 | v_loss: 1.61188 v_acc: 0.69694 |  iteration: 189 teacher: 0 stage: sketch lr: 0.000033\n",
      "batch 189 loss: 1.67490 acc: 0.69564 | v_loss: 1.87359 v_acc: 0.68880 |  iteration: 190 teacher: 1 stage: sketch lr: 0.000033\n",
      "batch 190 loss: 1.79324 acc: 0.68132 | v_loss: 1.59794 v_acc: 0.70020 |  iteration: 191 teacher: 1 stage: sketch lr: 0.000033\n",
      "batch 191 loss: 1.71799 acc: 0.69010 | v_loss: 1.60732 v_acc: 0.69629 |  iteration: 192 teacher: 1 stage: sketch lr: 0.000034\n",
      "batch 192 loss: 1.71996 acc: 0.68457 | v_loss: 1.61192 v_acc: 0.70540 |  iteration: 193 teacher: 1 stage: sketch lr: 0.000034\n",
      "batch 193 loss: 1.71640 acc: 0.69173 | v_loss: 1.54797 v_acc: 0.70280 |  iteration: 194 teacher: 0 stage: sketch lr: 0.000034\n",
      "batch 194 loss: 1.70727 acc: 0.69596 | v_loss: 1.46401 v_acc: 0.73145 |  iteration: 195 teacher: 0 stage: sketch lr: 0.000034\n",
      "batch 195 loss: 1.70325 acc: 0.69727 | v_loss: 1.53626 v_acc: 0.71354 |  iteration: 196 teacher: 0 stage: sketch lr: 0.000034\n",
      "batch 196 loss: 1.80269 acc: 0.68034 | v_loss: 1.54433 v_acc: 0.72852 |  iteration: 197 teacher: 1 stage: sketch lr: 0.000034\n",
      "batch 197 loss: 1.77894 acc: 0.68717 | v_loss: 1.52978 v_acc: 0.71484 |  iteration: 198 teacher: 1 stage: sketch lr: 0.000035\n",
      "batch 198 loss: 1.75376 acc: 0.68359 | v_loss: 1.60780 v_acc: 0.71191 |  iteration: 199 teacher: 1 stage: sketch lr: 0.000035\n",
      "batch 199 loss: 1.68494 acc: 0.69141 | v_loss: 1.54946 v_acc: 0.70964 |  iteration: 200 teacher: 1 stage: sketch lr: 0.000035\n",
      "batch 200 loss: 1.70585 acc: 0.69401 | v_loss: 1.53900 v_acc: 0.71908 |  iteration: 201 teacher: 1 stage: sketch lr: 0.000035\n",
      "batch 201 loss: 1.64612 acc: 0.69434 | v_loss: 1.65784 v_acc: 0.69531 |  iteration: 202 teacher: 1 stage: sketch lr: 0.000035\n",
      "batch 202 loss: 1.66504 acc: 0.69596 | v_loss: 1.56792 v_acc: 0.71777 |  iteration: 203 teacher: 0 stage: sketch lr: 0.000035\n",
      "batch 203 loss: 1.70948 acc: 0.69368 | v_loss: 1.38792 v_acc: 0.74219 |  iteration: 204 teacher: 0 stage: sketch lr: 0.000036\n",
      "batch 204 loss: 1.67819 acc: 0.69531 | v_loss: 1.65744 v_acc: 0.70085 |  iteration: 205 teacher: 0 stage: sketch lr: 0.000036\n",
      "batch 205 loss: 1.75578 acc: 0.69824 | v_loss: 1.67052 v_acc: 0.70085 |  iteration: 206 teacher: 1 stage: sketch lr: 0.000036\n",
      "batch 206 loss: 1.78374 acc: 0.68913 | v_loss: 1.61164 v_acc: 0.71875 |  iteration: 207 teacher: 0 stage: sketch lr: 0.000036\n",
      "batch 207 loss: 1.66352 acc: 0.69076 | v_loss: 1.51984 v_acc: 0.71647 |  iteration: 208 teacher: 1 stage: sketch lr: 0.000036\n",
      "batch 208 loss: 1.75175 acc: 0.68457 | v_loss: 1.72527 v_acc: 0.69238 |  iteration: 209 teacher: 1 stage: sketch lr: 0.000037\n",
      "batch 209 loss: 1.66737 acc: 0.69596 | v_loss: 1.57299 v_acc: 0.70605 |  iteration: 210 teacher: 1 stage: sketch lr: 0.000037\n",
      "batch 210 loss: 1.59968 acc: 0.69629 | v_loss: 1.74218 v_acc: 0.69173 |  iteration: 211 teacher: 0 stage: sketch lr: 0.000037\n",
      "batch 211 loss: 1.63887 acc: 0.70475 | v_loss: 1.58269 v_acc: 0.70410 |  iteration: 212 teacher: 1 stage: sketch lr: 0.000037\n",
      "batch 212 loss: 1.65813 acc: 0.69434 | v_loss: 1.53590 v_acc: 0.72266 |  iteration: 213 teacher: 0 stage: sketch lr: 0.000037\n",
      "batch 213 loss: 1.66853 acc: 0.69043 | v_loss: 1.58318 v_acc: 0.70898 |  iteration: 214 teacher: 1 stage: sketch lr: 0.000037\n",
      "batch 214 loss: 1.69218 acc: 0.69596 | v_loss: 1.71092 v_acc: 0.70638 |  iteration: 215 teacher: 0 stage: sketch lr: 0.000038\n",
      "batch 215 loss: 1.67200 acc: 0.69824 | v_loss: 1.54361 v_acc: 0.70150 |  iteration: 216 teacher: 1 stage: sketch lr: 0.000038\n",
      "batch 216 loss: 1.67664 acc: 0.70443 | v_loss: 1.77919 v_acc: 0.68945 |  iteration: 217 teacher: 0 stage: sketch lr: 0.000038\n",
      "batch 217 loss: 1.56622 acc: 0.70768 | v_loss: 1.57776 v_acc: 0.72428 |  iteration: 218 teacher: 1 stage: sketch lr: 0.000038\n",
      "batch 218 loss: 1.59729 acc: 0.70085 | v_loss: 1.84338 v_acc: 0.68164 |  iteration: 219 teacher: 0 stage: sketch lr: 0.000038\n",
      "batch 219 loss: 1.60295 acc: 0.70150 | v_loss: 1.81648 v_acc: 0.68848 |  iteration: 220 teacher: 0 stage: sketch lr: 0.000038\n",
      "batch 220 loss: 1.75097 acc: 0.67969 | v_loss: 1.73671 v_acc: 0.68848 |  iteration: 221 teacher: 0 stage: sketch lr: 0.000039\n",
      "batch 221 loss: 1.73310 acc: 0.69076 | v_loss: 1.58403 v_acc: 0.69596 |  iteration: 222 teacher: 0 stage: sketch lr: 0.000039\n",
      "batch 222 loss: 1.71389 acc: 0.68750 | v_loss: 1.52405 v_acc: 0.70280 |  iteration: 223 teacher: 1 stage: sketch lr: 0.000039\n",
      "batch 223 loss: 1.61450 acc: 0.69531 | v_loss: 1.70018 v_acc: 0.69564 |  iteration: 224 teacher: 0 stage: sketch lr: 0.000039\n",
      "batch 224 loss: 1.61403 acc: 0.70378 | v_loss: 1.49943 v_acc: 0.71777 |  iteration: 225 teacher: 1 stage: sketch lr: 0.000039\n",
      "batch 225 loss: 1.62262 acc: 0.70182 | v_loss: 1.87198 v_acc: 0.68783 |  iteration: 226 teacher: 0 stage: sketch lr: 0.000039\n",
      "batch 226 loss: 1.68993 acc: 0.70573 | v_loss: 1.65925 v_acc: 0.69303 |  iteration: 227 teacher: 1 stage: sketch lr: 0.000040\n",
      "batch 227 loss: 1.76441 acc: 0.68164 | v_loss: 1.54934 v_acc: 0.71191 |  iteration: 228 teacher: 1 stage: sketch lr: 0.000040\n",
      "batch 228 loss: 1.75985 acc: 0.68001 | v_loss: 1.65731 v_acc: 0.70736 |  iteration: 229 teacher: 1 stage: sketch lr: 0.000040\n",
      "batch 229 loss: 1.61256 acc: 0.69531 | v_loss: 1.61640 v_acc: 0.68978 |  iteration: 230 teacher: 0 stage: sketch lr: 0.000040\n",
      "batch 230 loss: 1.74828 acc: 0.67969 | v_loss: 1.66426 v_acc: 0.68978 |  iteration: 231 teacher: 1 stage: sketch lr: 0.000040\n",
      "batch 231 loss: 1.63112 acc: 0.69629 | v_loss: 1.55220 v_acc: 0.71647 |  iteration: 232 teacher: 0 stage: sketch lr: 0.000041\n",
      "batch 232 loss: 1.69545 acc: 0.69303 | v_loss: 1.45960 v_acc: 0.71354 |  iteration: 233 teacher: 1 stage: sketch lr: 0.000041\n",
      "batch 233 loss: 1.69342 acc: 0.69108 | v_loss: 1.45342 v_acc: 0.71875 |  iteration: 234 teacher: 1 stage: sketch lr: 0.000041\n",
      "batch 234 loss: 1.72283 acc: 0.69629 | v_loss: 1.57710 v_acc: 0.71094 |  iteration: 235 teacher: 1 stage: sketch lr: 0.000041\n",
      "batch 235 loss: 1.64985 acc: 0.70052 | v_loss: 1.66216 v_acc: 0.69889 |  iteration: 236 teacher: 0 stage: sketch lr: 0.000041\n",
      "batch 236 loss: 1.68514 acc: 0.70996 | v_loss: 1.58424 v_acc: 0.70410 |  iteration: 237 teacher: 1 stage: sketch lr: 0.000041\n",
      "batch 237 loss: 1.66124 acc: 0.69857 | v_loss: 1.55875 v_acc: 0.70410 |  iteration: 238 teacher: 1 stage: sketch lr: 0.000042\n",
      "batch 238 loss: 1.52580 acc: 0.70996 | v_loss: 1.64445 v_acc: 0.71940 |  iteration: 239 teacher: 0 stage: sketch lr: 0.000042\n",
      "batch 239 loss: 1.64298 acc: 0.69889 | v_loss: 1.59790 v_acc: 0.69629 |  iteration: 240 teacher: 0 stage: sketch lr: 0.000042\n",
      "batch 240 loss: 1.69803 acc: 0.68359 | v_loss: 1.51092 v_acc: 0.72168 |  iteration: 241 teacher: 0 stage: sketch lr: 0.000042\n",
      "batch 241 loss: 1.51129 acc: 0.70312 | v_loss: 1.47237 v_acc: 0.70736 |  iteration: 242 teacher: 0 stage: sketch lr: 0.000042\n",
      "batch 242 loss: 1.58946 acc: 0.70312 | v_loss: 1.44069 v_acc: 0.72852 |  iteration: 243 teacher: 0 stage: sketch lr: 0.000042\n",
      "batch 243 loss: 1.59725 acc: 0.70085 | v_loss: 1.47252 v_acc: 0.72070 |  iteration: 244 teacher: 1 stage: sketch lr: 0.000043\n",
      "batch 244 loss: 1.69777 acc: 0.69076 | v_loss: 1.52244 v_acc: 0.70964 |  iteration: 245 teacher: 1 stage: sketch lr: 0.000043\n",
      "batch 245 loss: 1.66888 acc: 0.69759 | v_loss: 1.60946 v_acc: 0.69629 |  iteration: 246 teacher: 1 stage: sketch lr: 0.000043\n",
      "batch 246 loss: 1.69605 acc: 0.69141 | v_loss: 1.57133 v_acc: 0.71452 |  iteration: 247 teacher: 0 stage: sketch lr: 0.000043\n",
      "batch 247 loss: 1.72816 acc: 0.69368 | v_loss: 1.72614 v_acc: 0.72917 |  iteration: 248 teacher: 1 stage: sketch lr: 0.000043\n",
      "batch 248 loss: 1.57718 acc: 0.71126 | v_loss: 1.85966 v_acc: 0.68750 |  iteration: 249 teacher: 0 stage: sketch lr: 0.000043\n",
      "batch 249 loss: 1.64895 acc: 0.70182 | v_loss: 1.73454 v_acc: 0.69499 |  iteration: 250 teacher: 0 stage: sketch lr: 0.000044\n",
      "batch 250 loss: 1.63707 acc: 0.70150 | v_loss: 1.57184 v_acc: 0.71387 |  iteration: 251 teacher: 1 stage: sketch lr: 0.000044\n",
      "batch 251 loss: 1.78822 acc: 0.68685 | v_loss: 1.72182 v_acc: 0.69043 |  iteration: 252 teacher: 1 stage: sketch lr: 0.000044\n",
      "batch 252 loss: 1.67597 acc: 0.68717 | v_loss: 1.49303 v_acc: 0.70475 |  iteration: 253 teacher: 0 stage: sketch lr: 0.000044\n",
      "batch 253 loss: 1.65759 acc: 0.68880 | v_loss: 1.66543 v_acc: 0.69629 |  iteration: 254 teacher: 0 stage: sketch lr: 0.000044\n",
      "batch 254 loss: 1.69067 acc: 0.69141 | v_loss: 1.58659 v_acc: 0.70833 |  iteration: 255 teacher: 0 stage: sketch lr: 0.000045\n",
      "batch 255 loss: 1.65929 acc: 0.69954 | v_loss: 1.47210 v_acc: 0.72754 |  iteration: 256 teacher: 1 stage: sketch lr: 0.000045\n",
      "batch 256 loss: 1.64036 acc: 0.70182 | v_loss: 1.54479 v_acc: 0.71289 |  iteration: 257 teacher: 1 stage: sketch lr: 0.000045\n",
      "batch 257 loss: 1.78376 acc: 0.69596 | v_loss: 1.59328 v_acc: 0.70312 |  iteration: 258 teacher: 1 stage: sketch lr: 0.000045\n",
      "batch 258 loss: 1.69526 acc: 0.69271 | v_loss: 1.52935 v_acc: 0.72363 |  iteration: 259 teacher: 0 stage: sketch lr: 0.000045\n",
      "batch 259 loss: 1.63747 acc: 0.70247 | v_loss: 1.47349 v_acc: 0.72135 |  iteration: 260 teacher: 0 stage: sketch lr: 0.000045\n",
      "batch 260 loss: 1.71248 acc: 0.68880 | v_loss: 1.75366 v_acc: 0.68522 |  iteration: 261 teacher: 0 stage: sketch lr: 0.000046\n",
      "batch 261 loss: 1.72508 acc: 0.69076 | v_loss: 1.54090 v_acc: 0.70605 |  iteration: 262 teacher: 0 stage: sketch lr: 0.000046\n",
      "batch 262 loss: 1.62173 acc: 0.69466 | v_loss: 1.58002 v_acc: 0.69531 |  iteration: 263 teacher: 1 stage: sketch lr: 0.000046\n",
      "batch 263 loss: 1.69355 acc: 0.69629 | v_loss: 1.59342 v_acc: 0.70736 |  iteration: 264 teacher: 0 stage: sketch lr: 0.000046\n",
      "batch 264 loss: 1.78075 acc: 0.68522 | v_loss: 1.71979 v_acc: 0.70020 |  iteration: 265 teacher: 1 stage: sketch lr: 0.000046\n",
      "batch 265 loss: 1.63843 acc: 0.69824 | v_loss: 1.49585 v_acc: 0.72331 |  iteration: 266 teacher: 1 stage: sketch lr: 0.000046\n",
      "batch 266 loss: 1.63054 acc: 0.69531 | v_loss: 1.61049 v_acc: 0.71061 |  iteration: 267 teacher: 0 stage: sketch lr: 0.000047\n",
      "batch 267 loss: 1.59441 acc: 0.70312 | v_loss: 1.56022 v_acc: 0.70312 |  iteration: 268 teacher: 0 stage: sketch lr: 0.000047\n",
      "batch 268 loss: 1.50163 acc: 0.72038 | v_loss: 1.58711 v_acc: 0.70736 |  iteration: 269 teacher: 0 stage: sketch lr: 0.000047\n",
      "batch 269 loss: 1.66502 acc: 0.70150 | v_loss: 1.56892 v_acc: 0.70671 |  iteration: 270 teacher: 1 stage: sketch lr: 0.000047\n",
      "batch 270 loss: 1.76748 acc: 0.68522 | v_loss: 1.62582 v_acc: 0.70247 |  iteration: 271 teacher: 1 stage: sketch lr: 0.000047\n",
      "batch 271 loss: 1.56452 acc: 0.70703 | v_loss: 1.70620 v_acc: 0.68392 |  iteration: 272 teacher: 0 stage: sketch lr: 0.000048\n",
      "batch 272 loss: 1.70409 acc: 0.69759 | v_loss: 1.54569 v_acc: 0.70345 |  iteration: 273 teacher: 1 stage: sketch lr: 0.000048\n",
      "batch 273 loss: 1.65417 acc: 0.69368 | v_loss: 1.54117 v_acc: 0.70638 |  iteration: 274 teacher: 0 stage: sketch lr: 0.000048\n",
      "batch 274 loss: 1.61658 acc: 0.69238 | v_loss: 1.58176 v_acc: 0.70215 |  iteration: 275 teacher: 0 stage: sketch lr: 0.000048\n",
      "batch 275 loss: 1.65807 acc: 0.69857 | v_loss: 1.55858 v_acc: 0.70638 |  iteration: 276 teacher: 1 stage: sketch lr: 0.000048\n",
      "batch 276 loss: 1.64300 acc: 0.69727 | v_loss: 1.46829 v_acc: 0.71484 |  iteration: 277 teacher: 1 stage: sketch lr: 0.000048\n",
      "batch 277 loss: 1.75395 acc: 0.68555 | v_loss: 1.51913 v_acc: 0.72591 |  iteration: 278 teacher: 0 stage: sketch lr: 0.000049\n",
      "batch 278 loss: 1.67200 acc: 0.68945 | v_loss: 1.49098 v_acc: 0.70508 |  iteration: 279 teacher: 1 stage: sketch lr: 0.000049\n",
      "batch 279 loss: 1.68550 acc: 0.69727 | v_loss: 1.52626 v_acc: 0.70443 |  iteration: 280 teacher: 0 stage: sketch lr: 0.000049\n",
      "batch 280 loss: 1.59296 acc: 0.71029 | v_loss: 1.79683 v_acc: 0.68685 |  iteration: 281 teacher: 0 stage: sketch lr: 0.000049\n",
      "batch 281 loss: 1.62427 acc: 0.70638 | v_loss: 1.56763 v_acc: 0.69889 |  iteration: 282 teacher: 0 stage: sketch lr: 0.000049\n",
      "batch 282 loss: 1.59309 acc: 0.70866 | v_loss: 1.57207 v_acc: 0.69173 |  iteration: 283 teacher: 1 stage: sketch lr: 0.000049\n",
      "batch 283 loss: 1.66141 acc: 0.69629 | v_loss: 1.58783 v_acc: 0.70345 |  iteration: 284 teacher: 0 stage: sketch lr: 0.000050\n",
      "batch 284 loss: 1.73657 acc: 0.68880 | v_loss: 1.48683 v_acc: 0.69857 |  iteration: 285 teacher: 0 stage: sketch lr: 0.000050\n",
      "batch 285 loss: 1.62893 acc: 0.69824 | v_loss: 1.41429 v_acc: 0.73730 |  iteration: 286 teacher: 1 stage: sketch lr: 0.000050\n",
      "batch 286 loss: 1.56739 acc: 0.71191 | v_loss: 1.49650 v_acc: 0.71680 |  iteration: 287 teacher: 0 stage: sketch lr: 0.000050\n",
      "batch 287 loss: 1.60933 acc: 0.70475 | v_loss: 1.49467 v_acc: 0.73796 |  iteration: 288 teacher: 0 stage: sketch lr: 0.000050\n",
      "batch 288 loss: 1.60375 acc: 0.70052 | v_loss: 1.47026 v_acc: 0.71810 |  iteration: 289 teacher: 0 stage: sketch lr: 0.000050\n",
      "batch 289 loss: 1.62766 acc: 0.69954 | v_loss: 1.55021 v_acc: 0.71875 |  iteration: 290 teacher: 1 stage: sketch lr: 0.000051\n",
      "batch 290 loss: 1.62315 acc: 0.69661 | v_loss: 1.46883 v_acc: 0.72135 |  iteration: 291 teacher: 0 stage: sketch lr: 0.000051\n",
      "batch 291 loss: 1.64585 acc: 0.70312 | v_loss: 1.50148 v_acc: 0.72201 |  iteration: 292 teacher: 0 stage: sketch lr: 0.000051\n",
      "batch 292 loss: 1.66494 acc: 0.68750 | v_loss: 1.60823 v_acc: 0.69596 |  iteration: 293 teacher: 0 stage: sketch lr: 0.000051\n",
      "batch 293 loss: 1.56243 acc: 0.70020 | v_loss: 1.53689 v_acc: 0.71875 |  iteration: 294 teacher: 0 stage: sketch lr: 0.000051\n",
      "batch 294 loss: 1.55465 acc: 0.70866 | v_loss: 1.35538 v_acc: 0.74414 |  iteration: 295 teacher: 1 stage: sketch lr: 0.000052\n",
      "batch 295 loss: 1.67823 acc: 0.69271 | v_loss: 1.60424 v_acc: 0.69987 |  iteration: 296 teacher: 1 stage: sketch lr: 0.000052\n",
      "batch 296 loss: 1.56387 acc: 0.70996 | v_loss: 1.62684 v_acc: 0.69824 |  iteration: 297 teacher: 0 stage: sketch lr: 0.000052\n",
      "batch 297 loss: 1.69424 acc: 0.69303 | v_loss: 1.53719 v_acc: 0.72363 |  iteration: 298 teacher: 0 stage: sketch lr: 0.000052\n",
      "batch 298 loss: 1.69141 acc: 0.70215 | v_loss: 1.45415 v_acc: 0.71875 |  iteration: 299 teacher: 1 stage: sketch lr: 0.000052\n",
      "batch 299 loss: 1.62041 acc: 0.70833 | v_loss: 1.66420 v_acc: 0.68913 |  iteration: 300 teacher: 1 stage: sketch lr: 0.000052\n",
      "batch 300 loss: 1.65457 acc: 0.70443 | v_loss: 1.52703 v_acc: 0.71029 |  iteration: 301 teacher: 1 stage: sketch lr: 0.000053\n",
      "batch 301 loss: 1.62227 acc: 0.69629 | v_loss: 1.70475 v_acc: 0.68880 |  iteration: 302 teacher: 1 stage: sketch lr: 0.000053\n",
      "batch 302 loss: 1.48455 acc: 0.71549 | v_loss: 1.54964 v_acc: 0.70931 |  iteration: 303 teacher: 0 stage: sketch lr: 0.000053\n",
      "batch 303 loss: 1.70171 acc: 0.69303 | v_loss: 1.46656 v_acc: 0.72298 |  iteration: 304 teacher: 1 stage: sketch lr: 0.000053\n",
      "batch 304 loss: 1.62939 acc: 0.69824 | v_loss: 1.56411 v_acc: 0.70703 |  iteration: 305 teacher: 0 stage: sketch lr: 0.000053\n",
      "batch 305 loss: 1.73359 acc: 0.68848 | v_loss: 1.63743 v_acc: 0.70312 |  iteration: 306 teacher: 1 stage: sketch lr: 0.000053\n",
      "batch 306 loss: 1.57824 acc: 0.70996 | v_loss: 1.50148 v_acc: 0.70833 |  iteration: 307 teacher: 1 stage: sketch lr: 0.000054\n",
      "batch 307 loss: 1.67204 acc: 0.70117 | v_loss: 1.72232 v_acc: 0.69238 |  iteration: 308 teacher: 0 stage: sketch lr: 0.000054\n",
      "batch 308 loss: 1.67975 acc: 0.70085 | v_loss: 1.53107 v_acc: 0.72786 |  iteration: 309 teacher: 1 stage: sketch lr: 0.000054\n",
      "batch 309 loss: 1.62814 acc: 0.70020 | v_loss: 1.79633 v_acc: 0.68327 |  iteration: 310 teacher: 0 stage: sketch lr: 0.000054\n",
      "batch 310 loss: 1.56129 acc: 0.70280 | v_loss: 1.73636 v_acc: 0.68945 |  iteration: 311 teacher: 0 stage: sketch lr: 0.000054\n",
      "batch 311 loss: 1.80683 acc: 0.68783 | v_loss: 1.69527 v_acc: 0.68945 |  iteration: 312 teacher: 1 stage: sketch lr: 0.000055\n",
      "batch 312 loss: 1.56320 acc: 0.70378 | v_loss: 1.54430 v_acc: 0.69727 |  iteration: 313 teacher: 0 stage: sketch lr: 0.000055\n",
      "batch 313 loss: 1.73321 acc: 0.68783 | v_loss: 1.48018 v_acc: 0.70573 |  iteration: 314 teacher: 1 stage: sketch lr: 0.000055\n",
      "batch 314 loss: 1.61786 acc: 0.71094 | v_loss: 1.65425 v_acc: 0.69629 |  iteration: 315 teacher: 0 stage: sketch lr: 0.000055\n",
      "batch 315 loss: 1.62750 acc: 0.70605 | v_loss: 1.47336 v_acc: 0.72135 |  iteration: 316 teacher: 1 stage: sketch lr: 0.000055\n",
      "batch 316 loss: 1.68034 acc: 0.69889 | v_loss: 1.80885 v_acc: 0.68978 |  iteration: 317 teacher: 1 stage: sketch lr: 0.000055\n",
      "batch 317 loss: 1.67141 acc: 0.69661 | v_loss: 1.62011 v_acc: 0.69629 |  iteration: 318 teacher: 0 stage: sketch lr: 0.000056\n",
      "batch 318 loss: 1.60550 acc: 0.70443 | v_loss: 1.50407 v_acc: 0.71582 |  iteration: 319 teacher: 1 stage: sketch lr: 0.000056\n",
      "batch 319 loss: 1.62406 acc: 0.70540 | v_loss: 1.59596 v_acc: 0.70964 |  iteration: 320 teacher: 0 stage: sketch lr: 0.000056\n",
      "batch 320 loss: 1.60161 acc: 0.70475 | v_loss: 1.57419 v_acc: 0.69434 |  iteration: 321 teacher: 0 stage: sketch lr: 0.000056\n",
      "batch 321 loss: 1.67559 acc: 0.69531 | v_loss: 1.62264 v_acc: 0.69564 |  iteration: 322 teacher: 0 stage: sketch lr: 0.000056\n",
      "batch 322 loss: 1.71171 acc: 0.69303 | v_loss: 1.51752 v_acc: 0.71842 |  iteration: 323 teacher: 0 stage: sketch lr: 0.000056\n",
      "batch 323 loss: 1.51158 acc: 0.71387 | v_loss: 1.43669 v_acc: 0.71224 |  iteration: 324 teacher: 0 stage: sketch lr: 0.000057\n",
      "batch 324 loss: 1.70054 acc: 0.68880 | v_loss: 1.42663 v_acc: 0.72396 |  iteration: 325 teacher: 0 stage: sketch lr: 0.000057\n",
      "batch 325 loss: 1.60495 acc: 0.71257 | v_loss: 1.52610 v_acc: 0.70931 |  iteration: 326 teacher: 0 stage: sketch lr: 0.000057\n",
      "batch 326 loss: 1.54359 acc: 0.71094 | v_loss: 1.61736 v_acc: 0.70410 |  iteration: 327 teacher: 1 stage: sketch lr: 0.000057\n",
      "batch 327 loss: 1.69806 acc: 0.70410 | v_loss: 1.51542 v_acc: 0.71517 |  iteration: 328 teacher: 0 stage: sketch lr: 0.000057\n",
      "batch 328 loss: 1.60716 acc: 0.71680 | v_loss: 1.50672 v_acc: 0.71289 |  iteration: 329 teacher: 1 stage: sketch lr: 0.000057\n",
      "batch 329 loss: 1.68414 acc: 0.69499 | v_loss: 1.53448 v_acc: 0.73145 |  iteration: 330 teacher: 0 stage: sketch lr: 0.000058\n",
      "batch 330 loss: 1.61452 acc: 0.69987 | v_loss: 1.53064 v_acc: 0.70410 |  iteration: 331 teacher: 0 stage: sketch lr: 0.000058\n",
      "batch 331 loss: 1.70857 acc: 0.68587 | v_loss: 1.44147 v_acc: 0.73991 |  iteration: 332 teacher: 0 stage: sketch lr: 0.000058\n",
      "batch 332 loss: 1.62474 acc: 0.69336 | v_loss: 1.43126 v_acc: 0.71191 |  iteration: 333 teacher: 0 stage: sketch lr: 0.000058\n",
      "batch 333 loss: 1.58197 acc: 0.70638 | v_loss: 1.42296 v_acc: 0.72721 |  iteration: 334 teacher: 1 stage: sketch lr: 0.000058\n",
      "batch 334 loss: 1.72173 acc: 0.68587 | v_loss: 1.44072 v_acc: 0.72624 |  iteration: 335 teacher: 1 stage: sketch lr: 0.000059\n",
      "batch 335 loss: 1.57817 acc: 0.70573 | v_loss: 1.50009 v_acc: 0.70703 |  iteration: 336 teacher: 0 stage: sketch lr: 0.000059\n",
      "batch 336 loss: 1.63430 acc: 0.69596 | v_loss: 1.57454 v_acc: 0.70052 |  iteration: 337 teacher: 0 stage: sketch lr: 0.000059\n",
      "batch 337 loss: 1.57140 acc: 0.70638 | v_loss: 1.50837 v_acc: 0.71745 |  iteration: 338 teacher: 0 stage: sketch lr: 0.000059\n",
      "batch 338 loss: 1.66448 acc: 0.69629 | v_loss: 1.60787 v_acc: 0.73796 |  iteration: 339 teacher: 0 stage: sketch lr: 0.000059\n",
      "batch 339 loss: 1.60805 acc: 0.69954 | v_loss: 1.78000 v_acc: 0.69727 |  iteration: 340 teacher: 0 stage: sketch lr: 0.000059\n",
      "batch 340 loss: 1.67587 acc: 0.69238 | v_loss: 1.69136 v_acc: 0.70247 |  iteration: 341 teacher: 0 stage: sketch lr: 0.000060\n",
      "batch 341 loss: 1.61373 acc: 0.69531 | v_loss: 1.53584 v_acc: 0.71549 |  iteration: 342 teacher: 1 stage: sketch lr: 0.000060\n",
      "batch 342 loss: 1.60284 acc: 0.70671 | v_loss: 1.65978 v_acc: 0.70247 |  iteration: 343 teacher: 1 stage: sketch lr: 0.000060\n",
      "batch 343 loss: 1.62766 acc: 0.69694 | v_loss: 1.46007 v_acc: 0.71549 |  iteration: 344 teacher: 0 stage: sketch lr: 0.000060\n",
      "batch 344 loss: 1.55811 acc: 0.70573 | v_loss: 1.59568 v_acc: 0.70475 |  iteration: 345 teacher: 0 stage: sketch lr: 0.000060\n",
      "batch 345 loss: 1.60985 acc: 0.69954 | v_loss: 1.56969 v_acc: 0.70247 |  iteration: 346 teacher: 1 stage: sketch lr: 0.000060\n",
      "batch 346 loss: 1.56710 acc: 0.71061 | v_loss: 1.45286 v_acc: 0.72656 |  iteration: 347 teacher: 0 stage: sketch lr: 0.000061\n",
      "batch 347 loss: 1.56200 acc: 0.70378 | v_loss: 1.46032 v_acc: 0.71777 |  iteration: 348 teacher: 1 stage: sketch lr: 0.000061\n",
      "batch 348 loss: 1.60627 acc: 0.69922 | v_loss: 1.53519 v_acc: 0.70215 |  iteration: 349 teacher: 0 stage: sketch lr: 0.000061\n",
      "batch 349 loss: 1.62749 acc: 0.70638 | v_loss: 1.52132 v_acc: 0.71615 |  iteration: 350 teacher: 1 stage: sketch lr: 0.000061\n",
      "batch 350 loss: 1.53346 acc: 0.71029 | v_loss: 1.45676 v_acc: 0.72591 |  iteration: 351 teacher: 0 stage: sketch lr: 0.000061\n",
      "batch 351 loss: 1.65706 acc: 0.69922 | v_loss: 1.74247 v_acc: 0.68327 |  iteration: 352 teacher: 1 stage: sketch lr: 0.000061\n",
      "batch 352 loss: 1.61657 acc: 0.69987 | v_loss: 1.49526 v_acc: 0.70833 |  iteration: 353 teacher: 1 stage: sketch lr: 0.000062\n",
      "batch 353 loss: 1.60456 acc: 0.70573 | v_loss: 1.50775 v_acc: 0.70671 |  iteration: 354 teacher: 1 stage: sketch lr: 0.000062\n",
      "batch 354 loss: 1.60914 acc: 0.70443 | v_loss: 1.54653 v_acc: 0.71419 |  iteration: 355 teacher: 1 stage: sketch lr: 0.000062\n",
      "batch 355 loss: 1.58655 acc: 0.70866 | v_loss: 1.67173 v_acc: 0.70703 |  iteration: 356 teacher: 0 stage: sketch lr: 0.000062\n",
      "batch 356 loss: 1.52940 acc: 0.71452 | v_loss: 1.46871 v_acc: 0.72852 |  iteration: 357 teacher: 0 stage: sketch lr: 0.000062\n",
      "batch 357 loss: 1.67379 acc: 0.70215 | v_loss: 1.58348 v_acc: 0.71387 |  iteration: 358 teacher: 1 stage: sketch lr: 0.000063\n",
      "batch 358 loss: 1.69462 acc: 0.69076 | v_loss: 1.53657 v_acc: 0.70020 |  iteration: 359 teacher: 0 stage: sketch lr: 0.000063\n",
      "batch 359 loss: 1.65673 acc: 0.69303 | v_loss: 1.55903 v_acc: 0.70150 |  iteration: 360 teacher: 0 stage: sketch lr: 0.000063\n",
      "batch 360 loss: 1.58947 acc: 0.70605 | v_loss: 1.56065 v_acc: 0.70605 |  iteration: 361 teacher: 0 stage: sketch lr: 0.000063\n",
      "batch 361 loss: 1.58522 acc: 0.70736 | v_loss: 1.59251 v_acc: 0.70312 |  iteration: 362 teacher: 1 stage: sketch lr: 0.000063\n",
      "batch 362 loss: 1.56097 acc: 0.71094 | v_loss: 1.66827 v_acc: 0.68750 |  iteration: 363 teacher: 1 stage: sketch lr: 0.000063\n",
      "batch 363 loss: 1.62667 acc: 0.70345 | v_loss: 1.51560 v_acc: 0.70898 |  iteration: 364 teacher: 0 stage: sketch lr: 0.000064\n",
      "batch 364 loss: 1.57731 acc: 0.70475 | v_loss: 1.51141 v_acc: 0.70801 |  iteration: 365 teacher: 0 stage: sketch lr: 0.000064\n",
      "batch 365 loss: 1.57657 acc: 0.70996 | v_loss: 1.53892 v_acc: 0.70964 |  iteration: 366 teacher: 0 stage: sketch lr: 0.000064\n",
      "batch 366 loss: 1.62217 acc: 0.70150 | v_loss: 1.56782 v_acc: 0.70540 |  iteration: 367 teacher: 0 stage: sketch lr: 0.000064\n",
      "batch 367 loss: 1.49750 acc: 0.72168 | v_loss: 1.42615 v_acc: 0.71875 |  iteration: 368 teacher: 0 stage: sketch lr: 0.000064\n",
      "batch 368 loss: 1.62588 acc: 0.70182 | v_loss: 1.49420 v_acc: 0.72624 |  iteration: 369 teacher: 0 stage: sketch lr: 0.000064\n",
      "batch 369 loss: 1.63722 acc: 0.70020 | v_loss: 1.47603 v_acc: 0.70443 |  iteration: 370 teacher: 0 stage: sketch lr: 0.000065\n",
      "batch 370 loss: 1.58038 acc: 0.70540 | v_loss: 1.50376 v_acc: 0.70475 |  iteration: 371 teacher: 0 stage: sketch lr: 0.000065\n",
      "batch 371 loss: 1.55760 acc: 0.70703 | v_loss: 1.75755 v_acc: 0.68848 |  iteration: 372 teacher: 1 stage: sketch lr: 0.000065\n",
      "batch 372 loss: 1.57366 acc: 0.70312 | v_loss: 1.54867 v_acc: 0.70052 |  iteration: 373 teacher: 1 stage: sketch lr: 0.000065\n",
      "batch 373 loss: 1.61950 acc: 0.69759 | v_loss: 1.55783 v_acc: 0.69564 |  iteration: 374 teacher: 0 stage: sketch lr: 0.000065\n",
      "batch 374 loss: 1.57177 acc: 0.70345 | v_loss: 1.54882 v_acc: 0.70475 |  iteration: 375 teacher: 0 stage: sketch lr: 0.000066\n",
      "batch 375 loss: 1.60496 acc: 0.70573 | v_loss: 1.45183 v_acc: 0.70573 |  iteration: 376 teacher: 1 stage: sketch lr: 0.000066\n",
      "batch 376 loss: 1.61217 acc: 0.70182 | v_loss: 1.38856 v_acc: 0.73600 |  iteration: 377 teacher: 1 stage: sketch lr: 0.000066\n",
      "batch 377 loss: 1.60031 acc: 0.70671 | v_loss: 1.48051 v_acc: 0.71387 |  iteration: 378 teacher: 1 stage: sketch lr: 0.000066\n",
      "batch 378 loss: 1.56969 acc: 0.70605 | v_loss: 1.43668 v_acc: 0.74023 |  iteration: 379 teacher: 0 stage: sketch lr: 0.000066\n",
      "batch 379 loss: 1.66965 acc: 0.70638 | v_loss: 1.44034 v_acc: 0.72461 |  iteration: 380 teacher: 1 stage: sketch lr: 0.000066\n",
      "batch 380 loss: 1.63582 acc: 0.69531 | v_loss: 1.54614 v_acc: 0.71094 |  iteration: 381 teacher: 1 stage: sketch lr: 0.000067\n",
      "batch 381 loss: 1.55369 acc: 0.70312 | v_loss: 1.45859 v_acc: 0.71322 |  iteration: 382 teacher: 1 stage: sketch lr: 0.000067\n",
      "batch 382 loss: 1.56590 acc: 0.70312 | v_loss: 1.47973 v_acc: 0.72135 |  iteration: 383 teacher: 1 stage: sketch lr: 0.000067\n",
      "batch 383 loss: 1.49800 acc: 0.70801 | v_loss: 1.55328 v_acc: 0.69889 |  iteration: 384 teacher: 0 stage: sketch lr: 0.000067\n",
      "batch 384 loss: 1.60820 acc: 0.70443 | v_loss: 1.50882 v_acc: 0.72363 |  iteration: 385 teacher: 0 stage: sketch lr: 0.000067\n",
      "batch 385 loss: 1.55204 acc: 0.70996 | v_loss: 1.33650 v_acc: 0.74674 |  iteration: 386 teacher: 1 stage: sketch lr: 0.000067\n",
      "batch 386 loss: 1.56233 acc: 0.70312 | v_loss: 1.58184 v_acc: 0.70020 |  iteration: 387 teacher: 0 stage: sketch lr: 0.000068\n",
      "batch 387 loss: 1.54115 acc: 0.71452 | v_loss: 1.58247 v_acc: 0.70866 |  iteration: 388 teacher: 0 stage: sketch lr: 0.000068\n",
      "batch 388 loss: 1.61508 acc: 0.69987 | v_loss: 1.50803 v_acc: 0.72949 |  iteration: 389 teacher: 0 stage: sketch lr: 0.000068\n",
      "batch 389 loss: 1.65297 acc: 0.69173 | v_loss: 1.43091 v_acc: 0.72298 |  iteration: 390 teacher: 1 stage: sketch lr: 0.000068\n",
      "batch 390 loss: 1.60785 acc: 0.70443 | v_loss: 1.64751 v_acc: 0.69792 |  iteration: 391 teacher: 1 stage: sketch lr: 0.000068\n",
      "batch 391 loss: 1.49085 acc: 0.70996 | v_loss: 1.50485 v_acc: 0.71354 |  iteration: 392 teacher: 0 stage: sketch lr: 0.000068\n",
      "batch 392 loss: 1.56905 acc: 0.70345 | v_loss: 1.65932 v_acc: 0.69434 |  iteration: 393 teacher: 0 stage: sketch lr: 0.000069\n",
      "batch 393 loss: 1.55577 acc: 0.70085 | v_loss: 1.51102 v_acc: 0.71452 |  iteration: 394 teacher: 0 stage: sketch lr: 0.000069\n",
      "batch 394 loss: 1.59928 acc: 0.70312 | v_loss: 1.44163 v_acc: 0.72559 |  iteration: 395 teacher: 1 stage: sketch lr: 0.000069\n",
      "batch 395 loss: 1.59527 acc: 0.70768 | v_loss: 1.55677 v_acc: 0.71126 |  iteration: 396 teacher: 1 stage: sketch lr: 0.000069\n",
      "batch 396 loss: 1.57886 acc: 0.70605 | v_loss: 1.61972 v_acc: 0.69499 |  iteration: 397 teacher: 0 stage: sketch lr: 0.000069\n",
      "batch 397 loss: 1.47160 acc: 0.71647 | v_loss: 1.49067 v_acc: 0.70378 |  iteration: 398 teacher: 0 stage: sketch lr: 0.000070\n",
      "batch 398 loss: 1.54227 acc: 0.71517 | v_loss: 1.70017 v_acc: 0.68424 |  iteration: 399 teacher: 0 stage: sketch lr: 0.000070\n",
      "batch 399 loss: 1.64134 acc: 0.69336 | v_loss: 1.52571 v_acc: 0.72201 |  iteration: 400 teacher: 0 stage: sketch lr: 0.000070\n",
      "batch 400 loss: 1.66096 acc: 0.69010 | v_loss: 1.74625 v_acc: 0.68750 |  iteration: 401 teacher: 1 stage: sketch lr: 0.000070\n",
      "batch 401 loss: 1.63664 acc: 0.70150 | v_loss: 1.66151 v_acc: 0.70573 |  iteration: 402 teacher: 1 stage: sketch lr: 0.000070\n",
      "batch 402 loss: 1.63149 acc: 0.69954 | v_loss: 1.66390 v_acc: 0.69564 |  iteration: 403 teacher: 1 stage: sketch lr: 0.000070\n",
      "batch 403 loss: 1.61434 acc: 0.69792 | v_loss: 1.50756 v_acc: 0.70085 |  iteration: 404 teacher: 0 stage: sketch lr: 0.000071\n",
      "batch 404 loss: 1.55424 acc: 0.71094 | v_loss: 1.46465 v_acc: 0.70898 |  iteration: 405 teacher: 1 stage: sketch lr: 0.000071\n",
      "batch 405 loss: 1.61836 acc: 0.70475 | v_loss: 1.63568 v_acc: 0.69661 |  iteration: 406 teacher: 1 stage: sketch lr: 0.000071\n",
      "batch 406 loss: 1.61937 acc: 0.70182 | v_loss: 1.44036 v_acc: 0.72070 |  iteration: 407 teacher: 1 stage: sketch lr: 0.000071\n",
      "batch 407 loss: 1.56601 acc: 0.71061 | v_loss: 1.76753 v_acc: 0.69466 |  iteration: 408 teacher: 0 stage: sketch lr: 0.000071\n",
      "batch 408 loss: 1.54795 acc: 0.70996 | v_loss: 1.60153 v_acc: 0.69857 |  iteration: 409 teacher: 1 stage: sketch lr: 0.000071\n",
      "batch 409 loss: 1.53454 acc: 0.71126 | v_loss: 1.48855 v_acc: 0.71712 |  iteration: 410 teacher: 1 stage: sketch lr: 0.000072\n",
      "batch 410 loss: 1.61031 acc: 0.70540 | v_loss: 1.57331 v_acc: 0.71517 |  iteration: 411 teacher: 0 stage: sketch lr: 0.000072\n",
      "batch 411 loss: 1.56918 acc: 0.69954 | v_loss: 1.55960 v_acc: 0.70215 |  iteration: 412 teacher: 0 stage: sketch lr: 0.000072\n",
      "batch 412 loss: 1.71730 acc: 0.69792 | v_loss: 1.58786 v_acc: 0.70443 |  iteration: 413 teacher: 1 stage: sketch lr: 0.000072\n",
      "batch 413 loss: 1.61310 acc: 0.70280 | v_loss: 1.49371 v_acc: 0.71647 |  iteration: 414 teacher: 1 stage: sketch lr: 0.000072\n",
      "batch 414 loss: 1.63320 acc: 0.69857 | v_loss: 1.41358 v_acc: 0.71322 |  iteration: 415 teacher: 0 stage: sketch lr: 0.000072\n",
      "batch 415 loss: 1.60824 acc: 0.69401 | v_loss: 1.41405 v_acc: 0.72070 |  iteration: 416 teacher: 0 stage: sketch lr: 0.000073\n",
      "batch 416 loss: 1.59304 acc: 0.70540 | v_loss: 1.50659 v_acc: 0.70768 |  iteration: 417 teacher: 0 stage: sketch lr: 0.000073\n",
      "batch 417 loss: 1.56171 acc: 0.70378 | v_loss: 1.61513 v_acc: 0.70768 |  iteration: 418 teacher: 0 stage: sketch lr: 0.000073\n",
      "batch 418 loss: 1.58354 acc: 0.70280 | v_loss: 1.49514 v_acc: 0.71582 |  iteration: 419 teacher: 0 stage: sketch lr: 0.000073\n",
      "batch 419 loss: 1.54903 acc: 0.71061 | v_loss: 1.49755 v_acc: 0.71908 |  iteration: 420 teacher: 1 stage: sketch lr: 0.000073\n",
      "batch 420 loss: 1.63944 acc: 0.69661 | v_loss: 1.51672 v_acc: 0.73470 |  iteration: 421 teacher: 0 stage: sketch lr: 0.000074\n",
      "batch 421 loss: 1.61557 acc: 0.70736 | v_loss: 1.51492 v_acc: 0.70703 |  iteration: 422 teacher: 1 stage: sketch lr: 0.000074\n",
      "batch 422 loss: 1.61802 acc: 0.70605 | v_loss: 1.38104 v_acc: 0.73991 |  iteration: 423 teacher: 0 stage: sketch lr: 0.000074\n",
      "batch 423 loss: 1.57934 acc: 0.70508 | v_loss: 1.41552 v_acc: 0.71810 |  iteration: 424 teacher: 0 stage: sketch lr: 0.000074\n",
      "batch 424 loss: 1.64613 acc: 0.69531 | v_loss: 1.40348 v_acc: 0.73079 |  iteration: 425 teacher: 0 stage: sketch lr: 0.000074\n",
      "batch 425 loss: 1.55782 acc: 0.70801 | v_loss: 1.43303 v_acc: 0.72852 |  iteration: 426 teacher: 0 stage: sketch lr: 0.000074\n",
      "batch 426 loss: 1.56609 acc: 0.70410 | v_loss: 1.49399 v_acc: 0.70866 |  iteration: 427 teacher: 1 stage: sketch lr: 0.000075\n",
      "batch 427 loss: 1.60698 acc: 0.70280 | v_loss: 1.55351 v_acc: 0.69954 |  iteration: 428 teacher: 1 stage: sketch lr: 0.000075\n",
      "batch 428 loss: 1.66141 acc: 0.69564 | v_loss: 1.50190 v_acc: 0.71745 |  iteration: 429 teacher: 1 stage: sketch lr: 0.000075\n",
      "batch 429 loss: 1.62007 acc: 0.69401 | v_loss: 1.56496 v_acc: 0.73763 |  iteration: 430 teacher: 1 stage: sketch lr: 0.000075\n",
      "batch 430 loss: 1.61902 acc: 0.69271 | v_loss: 1.75357 v_acc: 0.69499 |  iteration: 431 teacher: 0 stage: sketch lr: 0.000075\n",
      "batch 431 loss: 1.51131 acc: 0.71517 | v_loss: 1.66962 v_acc: 0.69759 |  iteration: 432 teacher: 0 stage: sketch lr: 0.000075\n",
      "batch 432 loss: 1.59261 acc: 0.70540 | v_loss: 1.50508 v_acc: 0.71842 |  iteration: 433 teacher: 1 stage: sketch lr: 0.000076\n",
      "batch 433 loss: 1.50664 acc: 0.71582 | v_loss: 1.62804 v_acc: 0.70443 |  iteration: 434 teacher: 0 stage: sketch lr: 0.000076\n",
      "batch 434 loss: 1.54535 acc: 0.71159 | v_loss: 1.43268 v_acc: 0.72331 |  iteration: 435 teacher: 0 stage: sketch lr: 0.000076\n",
      "batch 435 loss: 1.56777 acc: 0.71289 | v_loss: 1.58294 v_acc: 0.70182 |  iteration: 436 teacher: 0 stage: sketch lr: 0.000076\n",
      "batch 436 loss: 1.55231 acc: 0.70931 | v_loss: 1.55005 v_acc: 0.70736 |  iteration: 437 teacher: 1 stage: sketch lr: 0.000076\n",
      "batch 437 loss: 1.62276 acc: 0.69857 | v_loss: 1.43541 v_acc: 0.72754 |  iteration: 438 teacher: 1 stage: sketch lr: 0.000077\n",
      "batch 438 loss: 1.53470 acc: 0.71354 | v_loss: 1.43011 v_acc: 0.72135 |  iteration: 439 teacher: 1 stage: sketch lr: 0.000077\n",
      "batch 439 loss: 1.48814 acc: 0.71484 | v_loss: 1.49959 v_acc: 0.71126 |  iteration: 440 teacher: 0 stage: sketch lr: 0.000077\n",
      "batch 440 loss: 1.58000 acc: 0.71257 | v_loss: 1.49344 v_acc: 0.72461 |  iteration: 441 teacher: 0 stage: sketch lr: 0.000077\n",
      "batch 441 loss: 1.62195 acc: 0.69531 | v_loss: 1.43664 v_acc: 0.72591 |  iteration: 442 teacher: 1 stage: sketch lr: 0.000077\n",
      "batch 442 loss: 1.59121 acc: 0.70020 | v_loss: 1.73357 v_acc: 0.68490 |  iteration: 443 teacher: 0 stage: sketch lr: 0.000077\n",
      "batch 443 loss: 1.55200 acc: 0.70964 | v_loss: 1.46981 v_acc: 0.71712 |  iteration: 444 teacher: 0 stage: sketch lr: 0.000078\n",
      "batch 444 loss: 1.62312 acc: 0.69824 | v_loss: 1.48431 v_acc: 0.71126 |  iteration: 445 teacher: 0 stage: sketch lr: 0.000078\n",
      "batch 445 loss: 1.51814 acc: 0.71126 | v_loss: 1.53680 v_acc: 0.70671 |  iteration: 446 teacher: 1 stage: sketch lr: 0.000078\n",
      "batch 446 loss: 1.56121 acc: 0.71615 | v_loss: 1.63628 v_acc: 0.70736 |  iteration: 447 teacher: 1 stage: sketch lr: 0.000078\n",
      "batch 447 loss: 1.55238 acc: 0.71289 | v_loss: 1.44488 v_acc: 0.72721 |  iteration: 448 teacher: 0 stage: sketch lr: 0.000078\n",
      "batch 448 loss: 1.59816 acc: 0.70312 | v_loss: 1.55523 v_acc: 0.71484 |  iteration: 449 teacher: 1 stage: sketch lr: 0.000078\n",
      "batch 449 loss: 1.61672 acc: 0.70312 | v_loss: 1.50966 v_acc: 0.70182 |  iteration: 450 teacher: 1 stage: sketch lr: 0.000079\n",
      "batch 450 loss: 1.61321 acc: 0.69922 | v_loss: 1.54289 v_acc: 0.70866 |  iteration: 451 teacher: 0 stage: sketch lr: 0.000079\n",
      "batch 451 loss: 1.58307 acc: 0.69857 | v_loss: 1.53049 v_acc: 0.70931 |  iteration: 452 teacher: 1 stage: sketch lr: 0.000079\n",
      "batch 452 loss: 1.54884 acc: 0.70540 | v_loss: 1.55018 v_acc: 0.70703 |  iteration: 453 teacher: 0 stage: sketch lr: 0.000079\n",
      "batch 453 loss: 1.62408 acc: 0.69824 | v_loss: 1.64847 v_acc: 0.69238 |  iteration: 454 teacher: 0 stage: sketch lr: 0.000079\n",
      "batch 454 loss: 1.61757 acc: 0.69629 | v_loss: 1.49900 v_acc: 0.71387 |  iteration: 455 teacher: 0 stage: sketch lr: 0.000079\n",
      "batch 455 loss: 1.62900 acc: 0.69792 | v_loss: 1.49074 v_acc: 0.70833 |  iteration: 456 teacher: 0 stage: sketch lr: 0.000080\n",
      "batch 456 loss: 1.50292 acc: 0.71549 | v_loss: 1.51166 v_acc: 0.71159 |  iteration: 457 teacher: 0 stage: sketch lr: 0.000080\n",
      "batch 457 loss: 1.48957 acc: 0.72331 | v_loss: 1.52733 v_acc: 0.70964 |  iteration: 458 teacher: 1 stage: sketch lr: 0.000080\n",
      "batch 458 loss: 1.55906 acc: 0.70703 | v_loss: 1.40454 v_acc: 0.72233 |  iteration: 459 teacher: 1 stage: sketch lr: 0.000080\n",
      "batch 459 loss: 1.56665 acc: 0.70736 | v_loss: 1.46192 v_acc: 0.72982 |  iteration: 460 teacher: 0 stage: sketch lr: 0.000080\n",
      "batch 460 loss: 1.48750 acc: 0.71777 | v_loss: 1.46177 v_acc: 0.70996 |  iteration: 461 teacher: 1 stage: sketch lr: 0.000081\n",
      "batch 461 loss: 1.65539 acc: 0.71061 | v_loss: 1.45958 v_acc: 0.71224 |  iteration: 462 teacher: 0 stage: sketch lr: 0.000081\n",
      "batch 462 loss: 1.53942 acc: 0.71094 | v_loss: 1.68896 v_acc: 0.70280 |  iteration: 463 teacher: 1 stage: sketch lr: 0.000081\n",
      "batch 463 loss: 1.57660 acc: 0.70410 | v_loss: 1.52955 v_acc: 0.70768 |  iteration: 464 teacher: 0 stage: sketch lr: 0.000081\n",
      "batch 464 loss: 1.55071 acc: 0.70801 | v_loss: 1.52394 v_acc: 0.69987 |  iteration: 465 teacher: 1 stage: sketch lr: 0.000081\n",
      "batch 465 loss: 1.58289 acc: 0.69954 | v_loss: 1.52043 v_acc: 0.71029 |  iteration: 466 teacher: 1 stage: sketch lr: 0.000081\n",
      "batch 466 loss: 1.54219 acc: 0.70182 | v_loss: 1.43621 v_acc: 0.71289 |  iteration: 467 teacher: 0 stage: sketch lr: 0.000082\n",
      "batch 467 loss: 1.51886 acc: 0.70703 | v_loss: 1.37592 v_acc: 0.73958 |  iteration: 468 teacher: 0 stage: sketch lr: 0.000082\n",
      "batch 468 loss: 1.56166 acc: 0.70898 | v_loss: 1.47423 v_acc: 0.71549 |  iteration: 469 teacher: 1 stage: sketch lr: 0.000082\n",
      "batch 469 loss: 1.59623 acc: 0.70117 | v_loss: 1.42049 v_acc: 0.73600 |  iteration: 470 teacher: 1 stage: sketch lr: 0.000082\n",
      "batch 470 loss: 1.54336 acc: 0.70671 | v_loss: 1.41187 v_acc: 0.72656 |  iteration: 471 teacher: 0 stage: sketch lr: 0.000082\n",
      "batch 471 loss: 1.51016 acc: 0.71159 | v_loss: 1.51688 v_acc: 0.71582 |  iteration: 472 teacher: 1 stage: sketch lr: 0.000082\n",
      "batch 472 loss: 1.50585 acc: 0.71061 | v_loss: 1.41637 v_acc: 0.72428 |  iteration: 473 teacher: 0 stage: sketch lr: 0.000083\n",
      "batch 473 loss: 1.54530 acc: 0.70410 | v_loss: 1.44560 v_acc: 0.72493 |  iteration: 474 teacher: 0 stage: sketch lr: 0.000083\n",
      "batch 474 loss: 1.62507 acc: 0.69694 | v_loss: 1.50843 v_acc: 0.70508 |  iteration: 475 teacher: 0 stage: sketch lr: 0.000083\n",
      "batch 475 loss: 1.59728 acc: 0.70215 | v_loss: 1.50814 v_acc: 0.72135 |  iteration: 476 teacher: 1 stage: sketch lr: 0.000083\n",
      "batch 476 loss: 1.51179 acc: 0.72103 | v_loss: 1.32688 v_acc: 0.74740 |  iteration: 477 teacher: 1 stage: sketch lr: 0.000083\n",
      "batch 477 loss: 1.58126 acc: 0.70703 | v_loss: 1.55274 v_acc: 0.70345 |  iteration: 478 teacher: 0 stage: sketch lr: 0.000084\n",
      "batch 478 loss: 1.57619 acc: 0.70833 | v_loss: 1.56588 v_acc: 0.70573 |  iteration: 479 teacher: 0 stage: sketch lr: 0.000084\n",
      "batch 479 loss: 1.60105 acc: 0.70215 | v_loss: 1.50943 v_acc: 0.72201 |  iteration: 480 teacher: 1 stage: sketch lr: 0.000084\n",
      "batch 480 loss: 1.50975 acc: 0.70996 | v_loss: 1.39300 v_acc: 0.72201 |  iteration: 481 teacher: 1 stage: sketch lr: 0.000084\n",
      "batch 481 loss: 1.58568 acc: 0.70443 | v_loss: 1.63060 v_acc: 0.70182 |  iteration: 482 teacher: 0 stage: sketch lr: 0.000084\n",
      "batch 482 loss: 1.47632 acc: 0.71126 | v_loss: 1.48569 v_acc: 0.71582 |  iteration: 483 teacher: 0 stage: sketch lr: 0.000084\n",
      "batch 483 loss: 1.58633 acc: 0.69889 | v_loss: 1.65303 v_acc: 0.69434 |  iteration: 484 teacher: 1 stage: sketch lr: 0.000085\n",
      "batch 484 loss: 1.63372 acc: 0.69661 | v_loss: 1.48380 v_acc: 0.71484 |  iteration: 485 teacher: 1 stage: sketch lr: 0.000085\n",
      "batch 485 loss: 1.58830 acc: 0.70378 | v_loss: 1.41016 v_acc: 0.73307 |  iteration: 486 teacher: 1 stage: sketch lr: 0.000085\n",
      "batch 486 loss: 1.55229 acc: 0.70964 | v_loss: 1.52732 v_acc: 0.70540 |  iteration: 487 teacher: 1 stage: sketch lr: 0.000085\n",
      "batch 487 loss: 1.47986 acc: 0.71159 | v_loss: 1.64417 v_acc: 0.68978 |  iteration: 488 teacher: 1 stage: sketch lr: 0.000085\n",
      "batch 488 loss: 1.57039 acc: 0.69987 | v_loss: 1.48233 v_acc: 0.70475 |  iteration: 489 teacher: 0 stage: sketch lr: 0.000085\n",
      "batch 489 loss: 1.51925 acc: 0.70898 | v_loss: 1.64447 v_acc: 0.69303 |  iteration: 490 teacher: 1 stage: sketch lr: 0.000086\n",
      "batch 490 loss: 1.52951 acc: 0.70736 | v_loss: 1.48809 v_acc: 0.73079 |  iteration: 491 teacher: 1 stage: sketch lr: 0.000086\n",
      "batch 491 loss: 1.51476 acc: 0.71484 | v_loss: 1.71298 v_acc: 0.69987 |  iteration: 492 teacher: 0 stage: sketch lr: 0.000086\n",
      "batch 492 loss: 1.59768 acc: 0.70345 | v_loss: 1.63683 v_acc: 0.71029 |  iteration: 493 teacher: 0 stage: sketch lr: 0.000086\n",
      "batch 493 loss: 1.46496 acc: 0.73177 | v_loss: 1.62506 v_acc: 0.69401 |  iteration: 494 teacher: 0 stage: sketch lr: 0.000086\n",
      "batch 494 loss: 1.56634 acc: 0.70345 | v_loss: 1.46955 v_acc: 0.70150 |  iteration: 495 teacher: 1 stage: sketch lr: 0.000086\n",
      "batch 495 loss: 1.47530 acc: 0.71322 | v_loss: 1.44733 v_acc: 0.70833 |  iteration: 496 teacher: 0 stage: sketch lr: 0.000087\n",
      "batch 496 loss: 1.66375 acc: 0.68652 | v_loss: 1.63695 v_acc: 0.69564 |  iteration: 497 teacher: 1 stage: sketch lr: 0.000087\n",
      "batch 497 loss: 1.49188 acc: 0.70378 | v_loss: 1.44040 v_acc: 0.71973 |  iteration: 498 teacher: 1 stage: sketch lr: 0.000087\n",
      "batch 498 loss: 1.59140 acc: 0.70312 | v_loss: 1.72423 v_acc: 0.69336 |  iteration: 499 teacher: 1 stage: sketch lr: 0.000087\n",
      "batch 499 loss: 1.49926 acc: 0.71094 | v_loss: 1.57130 v_acc: 0.69922 |  iteration: 500 teacher: 0 stage: sketch lr: 0.000087\n",
      "batch 500 loss: 1.58412 acc: 0.70605 | v_loss: 1.45859 v_acc: 0.71615 |  iteration: 501 teacher: 1 stage: sketch lr: 0.000088\n",
      "batch 501 loss: 1.66038 acc: 0.70182 | v_loss: 1.53522 v_acc: 0.71191 |  iteration: 502 teacher: 1 stage: sketch lr: 0.000088\n",
      "batch 502 loss: 1.55944 acc: 0.70898 | v_loss: 1.53905 v_acc: 0.69824 |  iteration: 503 teacher: 1 stage: sketch lr: 0.000088\n",
      "batch 503 loss: 1.54291 acc: 0.70964 | v_loss: 1.58163 v_acc: 0.70247 |  iteration: 504 teacher: 1 stage: sketch lr: 0.000088\n",
      "batch 504 loss: 1.64622 acc: 0.69694 | v_loss: 1.46575 v_acc: 0.72005 |  iteration: 505 teacher: 0 stage: sketch lr: 0.000088\n",
      "batch 505 loss: 1.60880 acc: 0.69271 | v_loss: 1.37299 v_acc: 0.71810 |  iteration: 506 teacher: 0 stage: sketch lr: 0.000088\n",
      "batch 506 loss: 1.51271 acc: 0.70736 | v_loss: 1.38611 v_acc: 0.72721 |  iteration: 507 teacher: 1 stage: sketch lr: 0.000089\n",
      "batch 507 loss: 1.61463 acc: 0.69694 | v_loss: 1.47738 v_acc: 0.71582 |  iteration: 508 teacher: 1 stage: sketch lr: 0.000089\n",
      "batch 508 loss: 1.58864 acc: 0.70638 | v_loss: 1.57092 v_acc: 0.70573 |  iteration: 509 teacher: 0 stage: sketch lr: 0.000089\n",
      "batch 509 loss: 1.57899 acc: 0.70410 | v_loss: 1.46364 v_acc: 0.71940 |  iteration: 510 teacher: 1 stage: sketch lr: 0.000089\n",
      "batch 510 loss: 1.65100 acc: 0.69499 | v_loss: 1.45757 v_acc: 0.71224 |  iteration: 511 teacher: 1 stage: sketch lr: 0.000089\n",
      "batch 511 loss: 1.61021 acc: 0.69401 | v_loss: 1.49113 v_acc: 0.73372 |  iteration: 512 teacher: 0 stage: sketch lr: 0.000089\n",
      "batch 512 loss: 1.61731 acc: 0.69987 | v_loss: 1.48274 v_acc: 0.70540 |  iteration: 513 teacher: 1 stage: sketch lr: 0.000090\n",
      "batch 513 loss: 1.51412 acc: 0.70996 | v_loss: 1.35183 v_acc: 0.73535 |  iteration: 514 teacher: 1 stage: sketch lr: 0.000090\n",
      "batch 514 loss: 1.50809 acc: 0.71712 | v_loss: 1.37671 v_acc: 0.72070 |  iteration: 515 teacher: 0 stage: sketch lr: 0.000090\n",
      "batch 515 loss: 1.55476 acc: 0.70866 | v_loss: 1.39302 v_acc: 0.73177 |  iteration: 516 teacher: 1 stage: sketch lr: 0.000090\n",
      "batch 516 loss: 1.52469 acc: 0.71224 | v_loss: 1.41611 v_acc: 0.72819 |  iteration: 517 teacher: 0 stage: sketch lr: 0.000090\n",
      "batch 517 loss: 1.52760 acc: 0.70736 | v_loss: 1.48140 v_acc: 0.70671 |  iteration: 518 teacher: 1 stage: sketch lr: 0.000090\n",
      "batch 518 loss: 1.52585 acc: 0.71777 | v_loss: 1.51494 v_acc: 0.70540 |  iteration: 519 teacher: 0 stage: sketch lr: 0.000091\n",
      "batch 519 loss: 1.67459 acc: 0.69889 | v_loss: 1.46604 v_acc: 0.72428 |  iteration: 520 teacher: 1 stage: sketch lr: 0.000091\n",
      "batch 520 loss: 1.46819 acc: 0.71094 | v_loss: 1.53542 v_acc: 0.74382 |  iteration: 521 teacher: 0 stage: sketch lr: 0.000091\n",
      "batch 521 loss: 1.56474 acc: 0.69954 | v_loss: 1.70053 v_acc: 0.69889 |  iteration: 522 teacher: 1 stage: sketch lr: 0.000091\n",
      "batch 522 loss: 1.51294 acc: 0.70410 | v_loss: 1.63114 v_acc: 0.70117 |  iteration: 523 teacher: 1 stage: sketch lr: 0.000091\n",
      "batch 523 loss: 1.50990 acc: 0.71549 | v_loss: 1.45631 v_acc: 0.71940 |  iteration: 524 teacher: 0 stage: sketch lr: 0.000092\n",
      "batch 524 loss: 1.46430 acc: 0.71712 | v_loss: 1.58739 v_acc: 0.70898 |  iteration: 525 teacher: 0 stage: sketch lr: 0.000092\n",
      "batch 525 loss: 1.54813 acc: 0.70736 | v_loss: 1.40596 v_acc: 0.72559 |  iteration: 526 teacher: 1 stage: sketch lr: 0.000092\n",
      "batch 526 loss: 1.48911 acc: 0.71615 | v_loss: 1.56014 v_acc: 0.70671 |  iteration: 527 teacher: 1 stage: sketch lr: 0.000092\n",
      "batch 527 loss: 1.59700 acc: 0.70345 | v_loss: 1.53374 v_acc: 0.71094 |  iteration: 528 teacher: 0 stage: sketch lr: 0.000092\n",
      "batch 528 loss: 1.53934 acc: 0.71582 | v_loss: 1.40646 v_acc: 0.72949 |  iteration: 529 teacher: 0 stage: sketch lr: 0.000092\n",
      "batch 529 loss: 1.44997 acc: 0.71354 | v_loss: 1.39070 v_acc: 0.72656 |  iteration: 530 teacher: 1 stage: sketch lr: 0.000093\n",
      "batch 530 loss: 1.51347 acc: 0.70996 | v_loss: 1.47312 v_acc: 0.70964 |  iteration: 531 teacher: 1 stage: sketch lr: 0.000093\n",
      "batch 531 loss: 1.48170 acc: 0.71322 | v_loss: 1.47417 v_acc: 0.72331 |  iteration: 532 teacher: 1 stage: sketch lr: 0.000093\n",
      "batch 532 loss: 1.44674 acc: 0.72070 | v_loss: 1.43290 v_acc: 0.72298 |  iteration: 533 teacher: 0 stage: sketch lr: 0.000093\n",
      "batch 533 loss: 1.45249 acc: 0.71322 | v_loss: 1.71289 v_acc: 0.68587 |  iteration: 534 teacher: 0 stage: sketch lr: 0.000093\n",
      "batch 534 loss: 1.51096 acc: 0.71452 | v_loss: 1.43231 v_acc: 0.72103 |  iteration: 535 teacher: 0 stage: sketch lr: 0.000093\n",
      "batch 535 loss: 1.55991 acc: 0.70215 | v_loss: 1.46023 v_acc: 0.70996 |  iteration: 536 teacher: 0 stage: sketch lr: 0.000094\n",
      "batch 536 loss: 1.52200 acc: 0.71061 | v_loss: 1.48171 v_acc: 0.72005 |  iteration: 537 teacher: 1 stage: sketch lr: 0.000094\n",
      "batch 537 loss: 1.54951 acc: 0.70215 | v_loss: 1.60151 v_acc: 0.70964 |  iteration: 538 teacher: 0 stage: sketch lr: 0.000094\n",
      "batch 538 loss: 1.55099 acc: 0.70508 | v_loss: 1.39471 v_acc: 0.73145 |  iteration: 539 teacher: 0 stage: sketch lr: 0.000094\n",
      "batch 539 loss: 1.59071 acc: 0.70117 | v_loss: 1.51588 v_acc: 0.72103 |  iteration: 540 teacher: 0 stage: sketch lr: 0.000094\n",
      "batch 540 loss: 1.66361 acc: 0.69368 | v_loss: 1.47428 v_acc: 0.70671 |  iteration: 541 teacher: 1 stage: sketch lr: 0.000095\n",
      "batch 541 loss: 1.51104 acc: 0.71159 | v_loss: 1.53823 v_acc: 0.70443 |  iteration: 542 teacher: 0 stage: sketch lr: 0.000095\n",
      "batch 542 loss: 1.60926 acc: 0.70085 | v_loss: 1.51619 v_acc: 0.70638 |  iteration: 543 teacher: 1 stage: sketch lr: 0.000095\n",
      "batch 543 loss: 1.56880 acc: 0.69759 | v_loss: 1.52841 v_acc: 0.69954 |  iteration: 544 teacher: 1 stage: sketch lr: 0.000095\n",
      "batch 544 loss: 1.57314 acc: 0.70052 | v_loss: 1.61907 v_acc: 0.69336 |  iteration: 545 teacher: 1 stage: sketch lr: 0.000095\n",
      "batch 545 loss: 1.55502 acc: 0.70736 | v_loss: 1.47176 v_acc: 0.70801 |  iteration: 546 teacher: 1 stage: sketch lr: 0.000095\n",
      "batch 546 loss: 1.52754 acc: 0.70312 | v_loss: 1.46111 v_acc: 0.71094 |  iteration: 547 teacher: 0 stage: sketch lr: 0.000096\n",
      "batch 547 loss: 1.66087 acc: 0.69661 | v_loss: 1.47559 v_acc: 0.71126 |  iteration: 548 teacher: 1 stage: sketch lr: 0.000096\n",
      "batch 548 loss: 1.42011 acc: 0.71712 | v_loss: 1.53665 v_acc: 0.70247 |  iteration: 549 teacher: 0 stage: sketch lr: 0.000096\n",
      "batch 549 loss: 1.61980 acc: 0.69694 | v_loss: 1.39066 v_acc: 0.72233 |  iteration: 550 teacher: 0 stage: sketch lr: 0.000096\n",
      "batch 550 loss: 1.50143 acc: 0.70703 | v_loss: 1.42248 v_acc: 0.72884 |  iteration: 551 teacher: 0 stage: sketch lr: 0.000096\n",
      "batch 551 loss: 1.54873 acc: 0.70020 | v_loss: 1.44800 v_acc: 0.70410 |  iteration: 552 teacher: 0 stage: sketch lr: 0.000096\n",
      "batch 552 loss: 1.53720 acc: 0.70475 | v_loss: 1.44031 v_acc: 0.71126 |  iteration: 553 teacher: 0 stage: sketch lr: 0.000097\n",
      "batch 553 loss: 1.47863 acc: 0.71908 | v_loss: 1.65818 v_acc: 0.70085 |  iteration: 554 teacher: 1 stage: sketch lr: 0.000097\n",
      "batch 554 loss: 1.62371 acc: 0.69922 | v_loss: 1.49130 v_acc: 0.70833 |  iteration: 555 teacher: 1 stage: sketch lr: 0.000097\n",
      "batch 555 loss: 1.45971 acc: 0.71029 | v_loss: 1.49706 v_acc: 0.70768 |  iteration: 556 teacher: 0 stage: sketch lr: 0.000097\n",
      "batch 556 loss: 1.53334 acc: 0.70312 | v_loss: 1.48577 v_acc: 0.71094 |  iteration: 557 teacher: 0 stage: sketch lr: 0.000097\n",
      "batch 557 loss: 1.61199 acc: 0.69531 | v_loss: 1.39640 v_acc: 0.70898 |  iteration: 558 teacher: 0 stage: sketch lr: 0.000097\n",
      "batch 558 loss: 1.61443 acc: 0.70833 | v_loss: 1.34862 v_acc: 0.74056 |  iteration: 559 teacher: 1 stage: sketch lr: 0.000098\n",
      "batch 559 loss: 1.47010 acc: 0.70931 | v_loss: 1.43599 v_acc: 0.71712 |  iteration: 560 teacher: 0 stage: sketch lr: 0.000098\n",
      "batch 560 loss: 1.50539 acc: 0.70801 | v_loss: 1.35825 v_acc: 0.74056 |  iteration: 561 teacher: 1 stage: sketch lr: 0.000098\n",
      "batch 561 loss: 1.51620 acc: 0.70410 | v_loss: 1.38303 v_acc: 0.72689 |  iteration: 562 teacher: 1 stage: sketch lr: 0.000098\n",
      "batch 562 loss: 1.45611 acc: 0.71973 | v_loss: 1.47383 v_acc: 0.71582 |  iteration: 563 teacher: 0 stage: sketch lr: 0.000098\n",
      "batch 563 loss: 1.40527 acc: 0.72526 | v_loss: 1.35191 v_acc: 0.72233 |  iteration: 564 teacher: 1 stage: sketch lr: 0.000099\n",
      "batch 564 loss: 1.49812 acc: 0.71582 | v_loss: 1.41205 v_acc: 0.72624 |  iteration: 565 teacher: 1 stage: sketch lr: 0.000099\n",
      "batch 565 loss: 1.59576 acc: 0.69987 | v_loss: 1.49546 v_acc: 0.70280 |  iteration: 566 teacher: 1 stage: sketch lr: 0.000099\n",
      "batch 566 loss: 1.55527 acc: 0.70052 | v_loss: 1.48347 v_acc: 0.72233 |  iteration: 567 teacher: 0 stage: sketch lr: 0.000099\n",
      "batch 567 loss: 1.54092 acc: 0.70605 | v_loss: 1.28776 v_acc: 0.74805 |  iteration: 568 teacher: 1 stage: sketch lr: 0.000099\n",
      "batch 568 loss: 1.48396 acc: 0.70573 | v_loss: 1.53448 v_acc: 0.70020 |  iteration: 569 teacher: 1 stage: sketch lr: 0.000099\n",
      "batch 569 loss: 1.58317 acc: 0.70475 | v_loss: 1.51690 v_acc: 0.71745 |  iteration: 570 teacher: 0 stage: sketch lr: 0.000100\n",
      "batch 570 loss: 1.48042 acc: 0.71061 | v_loss: 1.48071 v_acc: 0.71615 |  iteration: 571 teacher: 1 stage: sketch lr: 0.000100\n",
      "batch 571 loss: 1.45750 acc: 0.70996 | v_loss: 1.34472 v_acc: 0.72038 |  iteration: 572 teacher: 1 stage: sketch lr: 0.000100\n",
      "batch 572 loss: 1.48676 acc: 0.71680 | v_loss: 1.58885 v_acc: 0.70410 |  iteration: 573 teacher: 1 stage: sketch lr: 0.000100\n",
      "batch 573 loss: 1.50990 acc: 0.69629 | v_loss: 1.44771 v_acc: 0.70866 |  iteration: 574 teacher: 0 stage: sketch lr: 0.000100\n",
      "batch 574 loss: 1.62663 acc: 0.69661 | v_loss: 1.60810 v_acc: 0.69401 |  iteration: 575 teacher: 1 stage: sketch lr: 0.000100\n",
      "batch 575 loss: 1.53710 acc: 0.69564 | v_loss: 1.43375 v_acc: 0.72070 |  iteration: 576 teacher: 1 stage: sketch lr: 0.000101\n",
      "batch 576 loss: 1.60759 acc: 0.69531 | v_loss: 1.37617 v_acc: 0.73210 |  iteration: 577 teacher: 0 stage: sketch lr: 0.000101\n",
      "batch 577 loss: 1.53421 acc: 0.69954 | v_loss: 1.46640 v_acc: 0.71126 |  iteration: 578 teacher: 1 stage: sketch lr: 0.000101\n",
      "batch 578 loss: 1.48511 acc: 0.71647 | v_loss: 1.53668 v_acc: 0.71029 |  iteration: 579 teacher: 1 stage: sketch lr: 0.000101\n",
      "batch 579 loss: 1.55066 acc: 0.70150 | v_loss: 1.43638 v_acc: 0.70768 |  iteration: 580 teacher: 1 stage: sketch lr: 0.000101\n",
      "batch 580 loss: 1.50859 acc: 0.70605 | v_loss: 1.61315 v_acc: 0.70085 |  iteration: 581 teacher: 0 stage: sketch lr: 0.000101\n",
      "batch 581 loss: 1.42699 acc: 0.71777 | v_loss: 1.44657 v_acc: 0.73242 |  iteration: 582 teacher: 1 stage: sketch lr: 0.000102\n",
      "batch 582 loss: 1.40423 acc: 0.72363 | v_loss: 1.64992 v_acc: 0.70312 |  iteration: 583 teacher: 0 stage: sketch lr: 0.000102\n",
      "batch 583 loss: 1.48624 acc: 0.71191 | v_loss: 1.58040 v_acc: 0.70801 |  iteration: 584 teacher: 0 stage: sketch lr: 0.000102\n",
      "batch 584 loss: 1.47701 acc: 0.70931 | v_loss: 1.60077 v_acc: 0.69629 |  iteration: 585 teacher: 1 stage: sketch lr: 0.000102\n",
      "batch 585 loss: 1.51130 acc: 0.70638 | v_loss: 1.42304 v_acc: 0.70475 |  iteration: 586 teacher: 0 stage: sketch lr: 0.000102\n",
      "batch 586 loss: 1.55588 acc: 0.70215 | v_loss: 1.40494 v_acc: 0.71615 |  iteration: 587 teacher: 1 stage: sketch lr: 0.000103\n",
      "batch 587 loss: 1.47103 acc: 0.71549 | v_loss: 1.56725 v_acc: 0.70475 |  iteration: 588 teacher: 0 stage: sketch lr: 0.000103\n",
      "batch 588 loss: 1.55715 acc: 0.70312 | v_loss: 1.38505 v_acc: 0.72624 |  iteration: 589 teacher: 1 stage: sketch lr: 0.000103\n",
      "batch 589 loss: 1.49333 acc: 0.70866 | v_loss: 1.64763 v_acc: 0.70052 |  iteration: 590 teacher: 1 stage: sketch lr: 0.000103\n",
      "batch 590 loss: 1.45598 acc: 0.71484 | v_loss: 1.53162 v_acc: 0.70020 |  iteration: 591 teacher: 1 stage: sketch lr: 0.000103\n",
      "batch 591 loss: 1.50063 acc: 0.71452 | v_loss: 1.39695 v_acc: 0.72233 |  iteration: 592 teacher: 1 stage: sketch lr: 0.000103\n",
      "batch 592 loss: 1.49535 acc: 0.71094 | v_loss: 1.49590 v_acc: 0.71680 |  iteration: 593 teacher: 0 stage: sketch lr: 0.000104\n",
      "batch 593 loss: 1.46616 acc: 0.71647 | v_loss: 1.48199 v_acc: 0.70540 |  iteration: 594 teacher: 0 stage: sketch lr: 0.000104\n",
      "batch 594 loss: 1.52471 acc: 0.70280 | v_loss: 1.53309 v_acc: 0.70573 |  iteration: 595 teacher: 1 stage: sketch lr: 0.000104\n",
      "batch 595 loss: 1.52116 acc: 0.70443 | v_loss: 1.44662 v_acc: 0.72168 |  iteration: 596 teacher: 1 stage: sketch lr: 0.000104\n",
      "batch 596 loss: 1.39280 acc: 0.72298 | v_loss: 1.33540 v_acc: 0.72591 |  iteration: 597 teacher: 0 stage: sketch lr: 0.000104\n",
      "batch 597 loss: 1.53251 acc: 0.70085 | v_loss: 1.33964 v_acc: 0.72428 |  iteration: 598 teacher: 0 stage: sketch lr: 0.000104\n",
      "batch 598 loss: 1.34912 acc: 0.71973 | v_loss: 1.42124 v_acc: 0.71680 |  iteration: 599 teacher: 0 stage: sketch lr: 0.000105\n",
      "batch 599 loss: 1.59329 acc: 0.69824 | v_loss: 1.51771 v_acc: 0.70150 |  iteration: 600 teacher: 0 stage: sketch lr: 0.000105\n",
      "batch 600 loss: 1.52163 acc: 0.70280 | v_loss: 1.41393 v_acc: 0.71549 |  iteration: 601 teacher: 1 stage: sketch lr: 0.000105\n",
      "batch 601 loss: 1.48733 acc: 0.70671 | v_loss: 1.39650 v_acc: 0.72396 |  iteration: 602 teacher: 1 stage: sketch lr: 0.000105\n",
      "batch 602 loss: 1.43700 acc: 0.71517 | v_loss: 1.47573 v_acc: 0.73047 |  iteration: 603 teacher: 1 stage: sketch lr: 0.000105\n",
      "batch 603 loss: 1.48305 acc: 0.70768 | v_loss: 1.44660 v_acc: 0.70736 |  iteration: 604 teacher: 0 stage: sketch lr: 0.000106\n",
      "batch 604 loss: 1.56036 acc: 0.70150 | v_loss: 1.31864 v_acc: 0.73438 |  iteration: 605 teacher: 0 stage: sketch lr: 0.000106\n",
      "batch 605 loss: 1.52860 acc: 0.70638 | v_loss: 1.32400 v_acc: 0.72298 |  iteration: 606 teacher: 1 stage: sketch lr: 0.000106\n",
      "batch 606 loss: 1.57006 acc: 0.70182 | v_loss: 1.35490 v_acc: 0.73340 |  iteration: 607 teacher: 0 stage: sketch lr: 0.000106\n",
      "batch 607 loss: 1.55647 acc: 0.70020 | v_loss: 1.38098 v_acc: 0.73047 |  iteration: 608 teacher: 1 stage: sketch lr: 0.000106\n",
      "batch 608 loss: 1.48233 acc: 0.71289 | v_loss: 1.45360 v_acc: 0.70833 |  iteration: 609 teacher: 0 stage: sketch lr: 0.000106\n",
      "batch 609 loss: 1.52665 acc: 0.70508 | v_loss: 1.49205 v_acc: 0.69661 |  iteration: 610 teacher: 0 stage: sketch lr: 0.000107\n",
      "batch 610 loss: 1.46381 acc: 0.70443 | v_loss: 1.41587 v_acc: 0.71224 |  iteration: 611 teacher: 1 stage: sketch lr: 0.000107\n",
      "batch 611 loss: 1.42968 acc: 0.70768 | v_loss: 1.44282 v_acc: 0.74284 |  iteration: 612 teacher: 0 stage: sketch lr: 0.000107\n",
      "batch 612 loss: 1.53283 acc: 0.70345 | v_loss: 1.64128 v_acc: 0.69661 |  iteration: 613 teacher: 0 stage: sketch lr: 0.000107\n",
      "batch 613 loss: 1.52127 acc: 0.70280 | v_loss: 1.58843 v_acc: 0.69954 |  iteration: 614 teacher: 1 stage: sketch lr: 0.000107\n",
      "batch 614 loss: 1.61633 acc: 0.69824 | v_loss: 1.43117 v_acc: 0.71322 |  iteration: 615 teacher: 1 stage: sketch lr: 0.000107\n",
      "batch 615 loss: 1.53609 acc: 0.71029 | v_loss: 1.50901 v_acc: 0.70964 |  iteration: 616 teacher: 1 stage: sketch lr: 0.000108\n",
      "batch 616 loss: 1.61456 acc: 0.69043 | v_loss: 1.33184 v_acc: 0.72949 |  iteration: 617 teacher: 1 stage: sketch lr: 0.000108\n",
      "batch 617 loss: 1.51059 acc: 0.71029 | v_loss: 1.51574 v_acc: 0.70638 |  iteration: 618 teacher: 1 stage: sketch lr: 0.000108\n",
      "batch 618 loss: 1.51820 acc: 0.71191 | v_loss: 1.45527 v_acc: 0.70866 |  iteration: 619 teacher: 1 stage: sketch lr: 0.000108\n",
      "batch 619 loss: 1.55187 acc: 0.70020 | v_loss: 1.36580 v_acc: 0.72949 |  iteration: 620 teacher: 1 stage: sketch lr: 0.000108\n",
      "batch 620 loss: 1.46233 acc: 0.70247 | v_loss: 1.36563 v_acc: 0.72591 |  iteration: 621 teacher: 1 stage: sketch lr: 0.000108\n",
      "batch 621 loss: 1.44651 acc: 0.71159 | v_loss: 1.41821 v_acc: 0.70378 |  iteration: 622 teacher: 1 stage: sketch lr: 0.000109\n",
      "batch 622 loss: 1.53813 acc: 0.70052 | v_loss: 1.43172 v_acc: 0.72493 |  iteration: 623 teacher: 0 stage: sketch lr: 0.000109\n",
      "batch 623 loss: 1.50114 acc: 0.71029 | v_loss: 1.39463 v_acc: 0.72135 |  iteration: 624 teacher: 0 stage: sketch lr: 0.000109\n",
      "batch 624 loss: 1.45360 acc: 0.70671 | v_loss: 1.66965 v_acc: 0.68750 |  iteration: 625 teacher: 1 stage: sketch lr: 0.000109\n",
      "batch 625 loss: 1.43849 acc: 0.72493 | v_loss: 1.38890 v_acc: 0.72103 |  iteration: 626 teacher: 1 stage: sketch lr: 0.000109\n",
      "batch 626 loss: 1.55508 acc: 0.70768 | v_loss: 1.41142 v_acc: 0.71484 |  iteration: 627 teacher: 0 stage: sketch lr: 0.000110\n",
      "batch 627 loss: 1.45287 acc: 0.71322 | v_loss: 1.44177 v_acc: 0.71973 |  iteration: 628 teacher: 0 stage: sketch lr: 0.000110\n",
      "batch 628 loss: 1.53710 acc: 0.69954 | v_loss: 1.54084 v_acc: 0.70801 |  iteration: 629 teacher: 0 stage: sketch lr: 0.000110\n",
      "batch 629 loss: 1.41298 acc: 0.70801 | v_loss: 1.31785 v_acc: 0.73438 |  iteration: 630 teacher: 1 stage: sketch lr: 0.000110\n",
      "batch 630 loss: 1.45700 acc: 0.71061 | v_loss: 1.49583 v_acc: 0.70996 |  iteration: 631 teacher: 1 stage: sketch lr: 0.000110\n",
      "batch 631 loss: 1.56565 acc: 0.70410 | v_loss: 1.38538 v_acc: 0.70931 |  iteration: 632 teacher: 1 stage: sketch lr: 0.000110\n",
      "batch 632 loss: 1.48524 acc: 0.71745 | v_loss: 1.47436 v_acc: 0.70540 |  iteration: 633 teacher: 0 stage: sketch lr: 0.000111\n",
      "batch 633 loss: 1.54435 acc: 0.69922 | v_loss: 1.48948 v_acc: 0.71061 |  iteration: 634 teacher: 1 stage: sketch lr: 0.000111\n",
      "batch 634 loss: 1.46939 acc: 0.70964 | v_loss: 1.47413 v_acc: 0.71159 |  iteration: 635 teacher: 1 stage: sketch lr: 0.000111\n",
      "batch 635 loss: 1.42744 acc: 0.71387 | v_loss: 1.58790 v_acc: 0.69499 |  iteration: 636 teacher: 1 stage: sketch lr: 0.000111\n",
      "batch 636 loss: 1.46051 acc: 0.71289 | v_loss: 1.42568 v_acc: 0.71419 |  iteration: 637 teacher: 0 stage: sketch lr: 0.000111\n",
      "batch 637 loss: 1.35437 acc: 0.72396 | v_loss: 1.41295 v_acc: 0.70508 |  iteration: 638 teacher: 0 stage: sketch lr: 0.000111\n",
      "batch 638 loss: 1.52776 acc: 0.70475 | v_loss: 1.41417 v_acc: 0.71126 |  iteration: 639 teacher: 1 stage: sketch lr: 0.000112\n",
      "batch 639 loss: 1.46599 acc: 0.71094 | v_loss: 1.45897 v_acc: 0.71224 |  iteration: 640 teacher: 1 stage: sketch lr: 0.000112\n",
      "batch 640 loss: 1.52208 acc: 0.70312 | v_loss: 1.35418 v_acc: 0.72168 |  iteration: 641 teacher: 1 stage: sketch lr: 0.000112\n",
      "batch 641 loss: 1.42104 acc: 0.71712 | v_loss: 1.38362 v_acc: 0.73210 |  iteration: 642 teacher: 0 stage: sketch lr: 0.000112\n",
      "batch 642 loss: 1.53479 acc: 0.70280 | v_loss: 1.41048 v_acc: 0.71191 |  iteration: 643 teacher: 0 stage: sketch lr: 0.000112\n",
      "batch 643 loss: 1.55854 acc: 0.70508 | v_loss: 1.41024 v_acc: 0.70964 |  iteration: 644 teacher: 0 stage: sketch lr: 0.000113\n",
      "batch 644 loss: 1.44537 acc: 0.72266 | v_loss: 1.56259 v_acc: 0.70508 |  iteration: 645 teacher: 1 stage: sketch lr: 0.000113\n",
      "batch 645 loss: 1.38202 acc: 0.71940 | v_loss: 1.43445 v_acc: 0.71517 |  iteration: 646 teacher: 0 stage: sketch lr: 0.000113\n",
      "batch 646 loss: 1.45997 acc: 0.71159 | v_loss: 1.47288 v_acc: 0.70410 |  iteration: 647 teacher: 0 stage: sketch lr: 0.000113\n",
      "batch 647 loss: 1.44698 acc: 0.70117 | v_loss: 1.42608 v_acc: 0.71094 |  iteration: 648 teacher: 0 stage: sketch lr: 0.000113\n",
      "batch 648 loss: 1.50223 acc: 0.70833 | v_loss: 1.33368 v_acc: 0.71387 |  iteration: 649 teacher: 1 stage: sketch lr: 0.000113\n",
      "batch 649 loss: 1.47567 acc: 0.71419 | v_loss: 1.31763 v_acc: 0.74251 |  iteration: 650 teacher: 1 stage: sketch lr: 0.000114\n",
      "batch 650 loss: 1.36002 acc: 0.71842 | v_loss: 1.40779 v_acc: 0.72624 |  iteration: 651 teacher: 0 stage: sketch lr: 0.000114\n",
      "batch 651 loss: 1.50237 acc: 0.70736 | v_loss: 1.34726 v_acc: 0.73958 |  iteration: 652 teacher: 1 stage: sketch lr: 0.000114\n",
      "batch 652 loss: 1.57017 acc: 0.70703 | v_loss: 1.33677 v_acc: 0.72917 |  iteration: 653 teacher: 1 stage: sketch lr: 0.000114\n",
      "batch 653 loss: 1.52167 acc: 0.71419 | v_loss: 1.43351 v_acc: 0.70833 |  iteration: 654 teacher: 1 stage: sketch lr: 0.000114\n",
      "batch 654 loss: 1.50724 acc: 0.70573 | v_loss: 1.33124 v_acc: 0.71973 |  iteration: 655 teacher: 0 stage: sketch lr: 0.000114\n",
      "batch 655 loss: 1.44749 acc: 0.70150 | v_loss: 1.37529 v_acc: 0.71777 |  iteration: 656 teacher: 1 stage: sketch lr: 0.000115\n",
      "batch 656 loss: 1.39582 acc: 0.71387 | v_loss: 1.45939 v_acc: 0.70410 |  iteration: 657 teacher: 1 stage: sketch lr: 0.000115\n",
      "batch 657 loss: 1.55981 acc: 0.69629 | v_loss: 1.44886 v_acc: 0.72135 |  iteration: 658 teacher: 1 stage: sketch lr: 0.000115\n",
      "batch 658 loss: 1.46044 acc: 0.70378 | v_loss: 1.23967 v_acc: 0.74772 |  iteration: 659 teacher: 0 stage: sketch lr: 0.000115\n",
      "batch 659 loss: 1.41706 acc: 0.71289 | v_loss: 1.43533 v_acc: 0.70768 |  iteration: 660 teacher: 0 stage: sketch lr: 0.000115\n",
      "batch 660 loss: 1.47625 acc: 0.71419 | v_loss: 1.48963 v_acc: 0.72135 |  iteration: 661 teacher: 0 stage: sketch lr: 0.000115\n",
      "batch 661 loss: 1.47643 acc: 0.71061 | v_loss: 1.41614 v_acc: 0.72624 |  iteration: 662 teacher: 0 stage: sketch lr: 0.000116\n",
      "batch 662 loss: 1.61324 acc: 0.69401 | v_loss: 1.29347 v_acc: 0.72591 |  iteration: 663 teacher: 1 stage: sketch lr: 0.000116\n",
      "batch 663 loss: 1.44996 acc: 0.70410 | v_loss: 1.53577 v_acc: 0.70020 |  iteration: 664 teacher: 1 stage: sketch lr: 0.000116\n",
      "batch 664 loss: 1.44985 acc: 0.71191 | v_loss: 1.39617 v_acc: 0.70540 |  iteration: 665 teacher: 1 stage: sketch lr: 0.000116\n",
      "batch 665 loss: 1.37821 acc: 0.71940 | v_loss: 1.51866 v_acc: 0.69564 |  iteration: 666 teacher: 0 stage: sketch lr: 0.000116\n",
      "batch 666 loss: 1.49014 acc: 0.70378 | v_loss: 1.41099 v_acc: 0.72461 |  iteration: 667 teacher: 1 stage: sketch lr: 0.000117\n",
      "batch 667 loss: 1.48798 acc: 0.71094 | v_loss: 1.33164 v_acc: 0.72331 |  iteration: 668 teacher: 1 stage: sketch lr: 0.000117\n",
      "batch 668 loss: 1.47126 acc: 0.70573 | v_loss: 1.39927 v_acc: 0.71419 |  iteration: 669 teacher: 0 stage: sketch lr: 0.000117\n",
      "batch 669 loss: 1.50475 acc: 0.71029 | v_loss: 1.45803 v_acc: 0.71029 |  iteration: 670 teacher: 1 stage: sketch lr: 0.000117\n",
      "batch 670 loss: 1.42379 acc: 0.70833 | v_loss: 1.35119 v_acc: 0.71322 |  iteration: 671 teacher: 0 stage: sketch lr: 0.000117\n",
      "batch 671 loss: 1.43582 acc: 0.71029 | v_loss: 1.50049 v_acc: 0.70703 |  iteration: 672 teacher: 0 stage: sketch lr: 0.000117\n",
      "batch 672 loss: 1.44797 acc: 0.71322 | v_loss: 1.38719 v_acc: 0.72819 |  iteration: 673 teacher: 0 stage: sketch lr: 0.000118\n",
      "batch 673 loss: 1.45298 acc: 0.71810 | v_loss: 1.57834 v_acc: 0.70736 |  iteration: 674 teacher: 0 stage: sketch lr: 0.000118\n",
      "batch 674 loss: 1.43891 acc: 0.71191 | v_loss: 1.49569 v_acc: 0.70768 |  iteration: 675 teacher: 0 stage: sketch lr: 0.000118\n",
      "batch 675 loss: 1.39196 acc: 0.72754 | v_loss: 1.53875 v_acc: 0.69694 |  iteration: 676 teacher: 1 stage: sketch lr: 0.000118\n",
      "batch 676 loss: 1.41428 acc: 0.71549 | v_loss: 1.35664 v_acc: 0.70540 |  iteration: 677 teacher: 1 stage: sketch lr: 0.000118\n",
      "batch 677 loss: 1.57243 acc: 0.70052 | v_loss: 1.33602 v_acc: 0.71647 |  iteration: 678 teacher: 0 stage: sketch lr: 0.000118\n",
      "batch 678 loss: 1.54430 acc: 0.69857 | v_loss: 1.45077 v_acc: 0.71224 |  iteration: 679 teacher: 0 stage: sketch lr: 0.000119\n",
      "batch 679 loss: 1.44232 acc: 0.71191 | v_loss: 1.32963 v_acc: 0.72168 |  iteration: 680 teacher: 0 stage: sketch lr: 0.000119\n",
      "batch 680 loss: 1.42743 acc: 0.71419 | v_loss: 1.57306 v_acc: 0.69889 |  iteration: 681 teacher: 0 stage: sketch lr: 0.000119\n",
      "batch 681 loss: 1.41452 acc: 0.71484 | v_loss: 1.46972 v_acc: 0.69889 |  iteration: 682 teacher: 1 stage: sketch lr: 0.000119\n",
      "batch 682 loss: 1.48710 acc: 0.70150 | v_loss: 1.37060 v_acc: 0.71973 |  iteration: 683 teacher: 0 stage: sketch lr: 0.000119\n",
      "batch 683 loss: 1.46510 acc: 0.70964 | v_loss: 1.42289 v_acc: 0.71908 |  iteration: 684 teacher: 1 stage: sketch lr: 0.000119\n",
      "batch 684 loss: 1.43378 acc: 0.70475 | v_loss: 1.40071 v_acc: 0.70931 |  iteration: 685 teacher: 1 stage: sketch lr: 0.000120\n",
      "batch 685 loss: 1.42103 acc: 0.71257 | v_loss: 1.49667 v_acc: 0.69010 |  iteration: 686 teacher: 0 stage: sketch lr: 0.000120\n",
      "batch 686 loss: 1.45806 acc: 0.70703 | v_loss: 1.36527 v_acc: 0.72331 |  iteration: 687 teacher: 0 stage: sketch lr: 0.000120\n",
      "batch 687 loss: 1.49240 acc: 0.70638 | v_loss: 1.27792 v_acc: 0.72917 |  iteration: 688 teacher: 1 stage: sketch lr: 0.000120\n",
      "batch 688 loss: 1.44369 acc: 0.70833 | v_loss: 1.29015 v_acc: 0.73145 |  iteration: 689 teacher: 0 stage: sketch lr: 0.000120\n",
      "batch 689 loss: 1.39199 acc: 0.72526 | v_loss: 1.35971 v_acc: 0.72266 |  iteration: 690 teacher: 0 stage: sketch lr: 0.000121\n",
      "batch 690 loss: 1.51214 acc: 0.70312 | v_loss: 1.44522 v_acc: 0.71354 |  iteration: 691 teacher: 1 stage: sketch lr: 0.000121\n",
      "batch 691 loss: 1.38736 acc: 0.71615 | v_loss: 1.38231 v_acc: 0.70898 |  iteration: 692 teacher: 1 stage: sketch lr: 0.000121\n",
      "batch 692 loss: 1.42172 acc: 0.70964 | v_loss: 1.34805 v_acc: 0.72461 |  iteration: 693 teacher: 0 stage: sketch lr: 0.000121\n",
      "batch 693 loss: 1.43518 acc: 0.71517 | v_loss: 1.44656 v_acc: 0.72819 |  iteration: 694 teacher: 0 stage: sketch lr: 0.000121\n",
      "batch 694 loss: 1.55290 acc: 0.69564 | v_loss: 1.40305 v_acc: 0.70280 |  iteration: 695 teacher: 1 stage: sketch lr: 0.000121\n",
      "batch 695 loss: 1.37455 acc: 0.71549 | v_loss: 1.27761 v_acc: 0.72005 |  iteration: 696 teacher: 0 stage: sketch lr: 0.000122\n",
      "batch 696 loss: 1.43001 acc: 0.71029 | v_loss: 1.27773 v_acc: 0.72689 |  iteration: 697 teacher: 0 stage: sketch lr: 0.000122\n",
      "batch 697 loss: 1.51379 acc: 0.69857 | v_loss: 1.34335 v_acc: 0.73210 |  iteration: 698 teacher: 1 stage: sketch lr: 0.000122\n",
      "batch 698 loss: 1.39526 acc: 0.71159 | v_loss: 1.35220 v_acc: 0.73047 |  iteration: 699 teacher: 1 stage: sketch lr: 0.000122\n",
      "batch 699 loss: 1.40414 acc: 0.71582 | v_loss: 1.43622 v_acc: 0.70768 |  iteration: 700 teacher: 1 stage: sketch lr: 0.000122\n",
      "batch 700 loss: 1.39042 acc: 0.71484 | v_loss: 1.44861 v_acc: 0.69954 |  iteration: 701 teacher: 1 stage: sketch lr: 0.000122\n",
      "batch 701 loss: 1.39845 acc: 0.72266 | v_loss: 1.37228 v_acc: 0.72233 |  iteration: 702 teacher: 0 stage: sketch lr: 0.000123\n",
      "batch 702 loss: 1.40166 acc: 0.71647 | v_loss: 1.39080 v_acc: 0.75033 |  iteration: 703 teacher: 1 stage: sketch lr: 0.000123\n",
      "batch 703 loss: 1.46877 acc: 0.71484 | v_loss: 1.55974 v_acc: 0.70182 |  iteration: 704 teacher: 1 stage: sketch lr: 0.000123\n",
      "batch 704 loss: 1.44545 acc: 0.70703 | v_loss: 1.52943 v_acc: 0.70345 |  iteration: 705 teacher: 1 stage: sketch lr: 0.000123\n",
      "batch 705 loss: 1.40846 acc: 0.71973 | v_loss: 1.36653 v_acc: 0.72493 |  iteration: 706 teacher: 0 stage: sketch lr: 0.000123\n",
      "batch 706 loss: 1.38677 acc: 0.72005 | v_loss: 1.45277 v_acc: 0.70866 |  iteration: 707 teacher: 0 stage: sketch lr: 0.000124\n",
      "batch 707 loss: 1.57759 acc: 0.70117 | v_loss: 1.26761 v_acc: 0.73372 |  iteration: 708 teacher: 1 stage: sketch lr: 0.000124\n",
      "batch 708 loss: 1.42022 acc: 0.71094 | v_loss: 1.45611 v_acc: 0.70638 |  iteration: 709 teacher: 0 stage: sketch lr: 0.000124\n",
      "batch 709 loss: 1.48017 acc: 0.70150 | v_loss: 1.39366 v_acc: 0.71875 |  iteration: 710 teacher: 0 stage: sketch lr: 0.000124\n",
      "batch 710 loss: 1.43847 acc: 0.71582 | v_loss: 1.30035 v_acc: 0.73535 |  iteration: 711 teacher: 1 stage: sketch lr: 0.000124\n",
      "batch 711 loss: 1.36054 acc: 0.72624 | v_loss: 1.31113 v_acc: 0.73177 |  iteration: 712 teacher: 1 stage: sketch lr: 0.000124\n",
      "batch 712 loss: 1.44166 acc: 0.71484 | v_loss: 1.35417 v_acc: 0.71842 |  iteration: 713 teacher: 1 stage: sketch lr: 0.000125\n",
      "batch 713 loss: 1.49637 acc: 0.70280 | v_loss: 1.38755 v_acc: 0.72070 |  iteration: 714 teacher: 1 stage: sketch lr: 0.000125\n",
      "batch 714 loss: 1.41305 acc: 0.71875 | v_loss: 1.37608 v_acc: 0.72689 |  iteration: 715 teacher: 0 stage: sketch lr: 0.000125\n",
      "batch 715 loss: 1.42965 acc: 0.71289 | v_loss: 1.64995 v_acc: 0.69173 |  iteration: 716 teacher: 0 stage: sketch lr: 0.000125\n",
      "batch 716 loss: 1.45218 acc: 0.70801 | v_loss: 1.33514 v_acc: 0.71940 |  iteration: 717 teacher: 0 stage: sketch lr: 0.000125\n",
      "batch 717 loss: 1.38968 acc: 0.71745 | v_loss: 1.36698 v_acc: 0.71387 |  iteration: 718 teacher: 0 stage: sketch lr: 0.000125\n",
      "batch 718 loss: 1.42335 acc: 0.71094 | v_loss: 1.42537 v_acc: 0.71257 |  iteration: 719 teacher: 1 stage: sketch lr: 0.000126\n",
      "batch 719 loss: 1.36684 acc: 0.71680 | v_loss: 1.48903 v_acc: 0.71680 |  iteration: 720 teacher: 0 stage: sketch lr: 0.000126\n",
      "batch 720 loss: 1.38646 acc: 0.71973 | v_loss: 1.26359 v_acc: 0.74447 |  iteration: 721 teacher: 1 stage: sketch lr: 0.000126\n",
      "batch 721 loss: 1.45117 acc: 0.71126 | v_loss: 1.43438 v_acc: 0.71908 |  iteration: 722 teacher: 1 stage: sketch lr: 0.000126\n",
      "batch 722 loss: 1.44086 acc: 0.71159 | v_loss: 1.31326 v_acc: 0.70801 |  iteration: 723 teacher: 0 stage: sketch lr: 0.000126\n",
      "batch 723 loss: 1.42958 acc: 0.71582 | v_loss: 1.41994 v_acc: 0.71745 |  iteration: 724 teacher: 1 stage: sketch lr: 0.000126\n",
      "batch 724 loss: 1.45810 acc: 0.70768 | v_loss: 1.43430 v_acc: 0.70996 |  iteration: 725 teacher: 0 stage: sketch lr: 0.000127\n",
      "batch 725 loss: 1.35865 acc: 0.72038 | v_loss: 1.41397 v_acc: 0.70703 |  iteration: 726 teacher: 1 stage: sketch lr: 0.000127\n",
      "batch 726 loss: 1.37077 acc: 0.72070 | v_loss: 1.54698 v_acc: 0.69922 |  iteration: 727 teacher: 1 stage: sketch lr: 0.000127\n",
      "batch 727 loss: 1.51313 acc: 0.69759 | v_loss: 1.38690 v_acc: 0.71810 |  iteration: 728 teacher: 0 stage: sketch lr: 0.000127\n",
      "batch 728 loss: 1.45020 acc: 0.70833 | v_loss: 1.37395 v_acc: 0.71973 |  iteration: 729 teacher: 0 stage: sketch lr: 0.000127\n",
      "batch 729 loss: 1.43898 acc: 0.71159 | v_loss: 1.33797 v_acc: 0.71973 |  iteration: 730 teacher: 0 stage: sketch lr: 0.000128\n",
      "batch 730 loss: 1.35469 acc: 0.72168 | v_loss: 1.39992 v_acc: 0.72331 |  iteration: 731 teacher: 0 stage: sketch lr: 0.000128\n",
      "batch 731 loss: 1.36568 acc: 0.72135 | v_loss: 1.30948 v_acc: 0.72949 |  iteration: 732 teacher: 0 stage: sketch lr: 0.000128\n",
      "batch 732 loss: 1.49858 acc: 0.70215 | v_loss: 1.33053 v_acc: 0.73275 |  iteration: 733 teacher: 0 stage: sketch lr: 0.000128\n",
      "batch 733 loss: 1.41679 acc: 0.71452 | v_loss: 1.34190 v_acc: 0.72070 |  iteration: 734 teacher: 0 stage: sketch lr: 0.000128\n",
      "batch 734 loss: 1.37427 acc: 0.71615 | v_loss: 1.33027 v_acc: 0.71224 |  iteration: 735 teacher: 1 stage: sketch lr: 0.000128\n",
      "batch 735 loss: 1.40869 acc: 0.71842 | v_loss: 1.45371 v_acc: 0.70833 |  iteration: 736 teacher: 1 stage: sketch lr: 0.000129\n",
      "batch 736 loss: 1.36936 acc: 0.71712 | v_loss: 1.39936 v_acc: 0.71549 |  iteration: 737 teacher: 0 stage: sketch lr: 0.000129\n",
      "batch 737 loss: 1.42279 acc: 0.71289 | v_loss: 1.44241 v_acc: 0.70215 |  iteration: 738 teacher: 0 stage: sketch lr: 0.000129\n",
      "batch 738 loss: 1.42109 acc: 0.70833 | v_loss: 1.35505 v_acc: 0.71875 |  iteration: 739 teacher: 0 stage: sketch lr: 0.000129\n",
      "batch 739 loss: 1.50105 acc: 0.70247 | v_loss: 1.28487 v_acc: 0.72233 |  iteration: 740 teacher: 1 stage: sketch lr: 0.000129\n",
      "batch 740 loss: 1.49146 acc: 0.70312 | v_loss: 1.27807 v_acc: 0.74414 |  iteration: 741 teacher: 1 stage: sketch lr: 0.000129\n",
      "batch 741 loss: 1.42525 acc: 0.71484 | v_loss: 1.37095 v_acc: 0.72363 |  iteration: 742 teacher: 1 stage: sketch lr: 0.000130\n",
      "batch 742 loss: 1.48176 acc: 0.69499 | v_loss: 1.32667 v_acc: 0.74707 |  iteration: 743 teacher: 0 stage: sketch lr: 0.000130\n",
      "batch 743 loss: 1.31458 acc: 0.72624 | v_loss: 1.31743 v_acc: 0.72363 |  iteration: 744 teacher: 0 stage: sketch lr: 0.000130\n",
      "batch 744 loss: 1.45765 acc: 0.70768 | v_loss: 1.38783 v_acc: 0.72038 |  iteration: 745 teacher: 1 stage: sketch lr: 0.000130\n",
      "batch 745 loss: 1.47816 acc: 0.69987 | v_loss: 1.26543 v_acc: 0.73665 |  iteration: 746 teacher: 0 stage: sketch lr: 0.000130\n",
      "batch 746 loss: 1.36064 acc: 0.72266 | v_loss: 1.32602 v_acc: 0.72819 |  iteration: 747 teacher: 0 stage: sketch lr: 0.000130\n",
      "batch 747 loss: 1.36227 acc: 0.71517 | v_loss: 1.41707 v_acc: 0.70931 |  iteration: 748 teacher: 0 stage: sketch lr: 0.000131\n",
      "batch 748 loss: 1.47131 acc: 0.70443 | v_loss: 1.42568 v_acc: 0.72428 |  iteration: 749 teacher: 0 stage: sketch lr: 0.000131\n",
      "batch 749 loss: 1.47881 acc: 0.70215 | v_loss: 1.20538 v_acc: 0.75456 |  iteration: 750 teacher: 1 stage: sketch lr: 0.000131\n",
      "batch 750 loss: 1.49549 acc: 0.70573 | v_loss: 1.35906 v_acc: 0.71322 |  iteration: 751 teacher: 1 stage: sketch lr: 0.000131\n",
      "batch 751 loss: 1.33083 acc: 0.72168 | v_loss: 1.43532 v_acc: 0.72201 |  iteration: 752 teacher: 0 stage: sketch lr: 0.000131\n",
      "batch 752 loss: 1.45345 acc: 0.71419 | v_loss: 1.38431 v_acc: 0.72754 |  iteration: 753 teacher: 0 stage: sketch lr: 0.000132\n",
      "batch 753 loss: 1.36179 acc: 0.72298 | v_loss: 1.23651 v_acc: 0.72949 |  iteration: 754 teacher: 1 stage: sketch lr: 0.000132\n",
      "batch 754 loss: 1.44859 acc: 0.71647 | v_loss: 1.47894 v_acc: 0.71191 |  iteration: 755 teacher: 0 stage: sketch lr: 0.000132\n",
      "batch 755 loss: 1.46583 acc: 0.70508 | v_loss: 1.33295 v_acc: 0.71712 |  iteration: 756 teacher: 1 stage: sketch lr: 0.000132\n",
      "batch 756 loss: 1.42674 acc: 0.71094 | v_loss: 1.44716 v_acc: 0.70085 |  iteration: 757 teacher: 1 stage: sketch lr: 0.000132\n",
      "batch 757 loss: 1.31921 acc: 0.72005 | v_loss: 1.36523 v_acc: 0.72428 |  iteration: 758 teacher: 0 stage: sketch lr: 0.000132\n",
      "batch 758 loss: 1.50320 acc: 0.69141 | v_loss: 1.28399 v_acc: 0.72917 |  iteration: 759 teacher: 0 stage: sketch lr: 0.000133\n",
      "batch 759 loss: 1.42272 acc: 0.70736 | v_loss: 1.31889 v_acc: 0.72070 |  iteration: 760 teacher: 1 stage: sketch lr: 0.000133\n",
      "batch 760 loss: 1.37556 acc: 0.70703 | v_loss: 1.44771 v_acc: 0.69759 |  iteration: 761 teacher: 0 stage: sketch lr: 0.000133\n",
      "batch 761 loss: 1.40318 acc: 0.71419 | v_loss: 1.31052 v_acc: 0.71908 |  iteration: 762 teacher: 0 stage: sketch lr: 0.000133\n",
      "batch 762 loss: 1.48687 acc: 0.71289 | v_loss: 1.42923 v_acc: 0.71029 |  iteration: 763 teacher: 1 stage: sketch lr: 0.000133\n",
      "batch 763 loss: 1.35720 acc: 0.71126 | v_loss: 1.33419 v_acc: 0.73470 |  iteration: 764 teacher: 0 stage: sketch lr: 0.000133\n",
      "batch 764 loss: 1.40956 acc: 0.71517 | v_loss: 1.52220 v_acc: 0.71322 |  iteration: 765 teacher: 1 stage: sketch lr: 0.000134\n",
      "batch 765 loss: 1.38788 acc: 0.71094 | v_loss: 1.44481 v_acc: 0.71126 |  iteration: 766 teacher: 0 stage: sketch lr: 0.000134\n",
      "batch 766 loss: 1.39767 acc: 0.70931 | v_loss: 1.50135 v_acc: 0.70312 |  iteration: 767 teacher: 0 stage: sketch lr: 0.000134\n",
      "batch 767 loss: 1.38820 acc: 0.71257 | v_loss: 1.32979 v_acc: 0.70996 |  iteration: 768 teacher: 1 stage: sketch lr: 0.000134\n",
      "batch 768 loss: 1.34482 acc: 0.72038 | v_loss: 1.28778 v_acc: 0.72526 |  iteration: 769 teacher: 1 stage: sketch lr: 0.000134\n",
      "batch 769 loss: 1.35635 acc: 0.71973 | v_loss: 1.39128 v_acc: 0.71745 |  iteration: 770 teacher: 0 stage: sketch lr: 0.000135\n",
      "batch 770 loss: 1.41420 acc: 0.71094 | v_loss: 1.28004 v_acc: 0.73665 |  iteration: 771 teacher: 1 stage: sketch lr: 0.000135\n",
      "batch 771 loss: 1.51259 acc: 0.70768 | v_loss: 1.49120 v_acc: 0.70052 |  iteration: 772 teacher: 0 stage: sketch lr: 0.000135\n",
      "batch 772 loss: 1.32267 acc: 0.72298 | v_loss: 1.43874 v_acc: 0.70312 |  iteration: 773 teacher: 1 stage: sketch lr: 0.000135\n",
      "batch 773 loss: 1.47193 acc: 0.70801 | v_loss: 1.30424 v_acc: 0.72884 |  iteration: 774 teacher: 1 stage: sketch lr: 0.000135\n",
      "batch 774 loss: 1.42613 acc: 0.70931 | v_loss: 1.40665 v_acc: 0.71289 |  iteration: 775 teacher: 1 stage: sketch lr: 0.000135\n",
      "batch 775 loss: 1.40065 acc: 0.70898 | v_loss: 1.35014 v_acc: 0.70964 |  iteration: 776 teacher: 0 stage: sketch lr: 0.000136\n",
      "batch 776 loss: 1.36309 acc: 0.71094 | v_loss: 1.47502 v_acc: 0.70378 |  iteration: 777 teacher: 1 stage: sketch lr: 0.000136\n",
      "batch 777 loss: 1.42776 acc: 0.70964 | v_loss: 1.32867 v_acc: 0.73796 |  iteration: 778 teacher: 1 stage: sketch lr: 0.000136\n",
      "batch 778 loss: 1.34478 acc: 0.71712 | v_loss: 1.26305 v_acc: 0.73079 |  iteration: 779 teacher: 0 stage: sketch lr: 0.000136\n",
      "batch 779 loss: 1.38552 acc: 0.71419 | v_loss: 1.23847 v_acc: 0.73242 |  iteration: 780 teacher: 0 stage: sketch lr: 0.000136\n",
      "batch 780 loss: 1.37034 acc: 0.72135 | v_loss: 1.32766 v_acc: 0.72786 |  iteration: 781 teacher: 0 stage: sketch lr: 0.000136\n",
      "batch 781 loss: 1.38985 acc: 0.71191 | v_loss: 1.42478 v_acc: 0.71322 |  iteration: 782 teacher: 1 stage: sketch lr: 0.000137\n",
      "batch 782 loss: 1.37895 acc: 0.71159 | v_loss: 1.34665 v_acc: 0.71582 |  iteration: 783 teacher: 0 stage: sketch lr: 0.000137\n",
      "batch 783 loss: 1.44199 acc: 0.70443 | v_loss: 1.30909 v_acc: 0.73014 |  iteration: 784 teacher: 1 stage: sketch lr: 0.000137\n",
      "batch 784 loss: 1.31478 acc: 0.72591 | v_loss: 1.42103 v_acc: 0.73796 |  iteration: 785 teacher: 0 stage: sketch lr: 0.000137\n",
      "batch 785 loss: 1.44933 acc: 0.70508 | v_loss: 1.36445 v_acc: 0.70671 |  iteration: 786 teacher: 1 stage: sketch lr: 0.000137\n",
      "batch 786 loss: 1.41810 acc: 0.70996 | v_loss: 1.25719 v_acc: 0.73112 |  iteration: 787 teacher: 1 stage: sketch lr: 0.000137\n",
      "batch 787 loss: 1.44355 acc: 0.71159 | v_loss: 1.25013 v_acc: 0.73568 |  iteration: 788 teacher: 1 stage: sketch lr: 0.000138\n",
      "batch 788 loss: 1.49824 acc: 0.70378 | v_loss: 1.29703 v_acc: 0.73568 |  iteration: 789 teacher: 1 stage: sketch lr: 0.000138\n",
      "batch 789 loss: 1.27165 acc: 0.73079 | v_loss: 1.32573 v_acc: 0.72689 |  iteration: 790 teacher: 1 stage: sketch lr: 0.000138\n",
      "batch 790 loss: 1.41533 acc: 0.72103 | v_loss: 1.41096 v_acc: 0.71842 |  iteration: 791 teacher: 1 stage: sketch lr: 0.000138\n",
      "batch 791 loss: 1.49351 acc: 0.71029 | v_loss: 1.40528 v_acc: 0.71159 |  iteration: 792 teacher: 1 stage: sketch lr: 0.000138\n",
      "batch 792 loss: 1.31300 acc: 0.72721 | v_loss: 1.34395 v_acc: 0.72103 |  iteration: 793 teacher: 0 stage: sketch lr: 0.000139\n",
      "batch 793 loss: 1.44961 acc: 0.70345 | v_loss: 1.33206 v_acc: 0.74609 |  iteration: 794 teacher: 1 stage: sketch lr: 0.000139\n",
      "batch 794 loss: 1.36515 acc: 0.72852 | v_loss: 1.52241 v_acc: 0.70638 |  iteration: 795 teacher: 1 stage: sketch lr: 0.000139\n",
      "batch 795 loss: 1.45832 acc: 0.70638 | v_loss: 1.49517 v_acc: 0.70736 |  iteration: 796 teacher: 1 stage: sketch lr: 0.000139\n",
      "batch 796 loss: 1.40383 acc: 0.71712 | v_loss: 1.30043 v_acc: 0.72786 |  iteration: 797 teacher: 1 stage: sketch lr: 0.000139\n",
      "batch 797 loss: 1.41571 acc: 0.71419 | v_loss: 1.43475 v_acc: 0.71484 |  iteration: 798 teacher: 1 stage: sketch lr: 0.000139\n",
      "batch 798 loss: 1.46007 acc: 0.71452 | v_loss: 1.25985 v_acc: 0.73503 |  iteration: 799 teacher: 1 stage: sketch lr: 0.000140\n",
      "batch 799 loss: 1.35181 acc: 0.72266 | v_loss: 1.43778 v_acc: 0.70736 |  iteration: 800 teacher: 0 stage: sketch lr: 0.000140\n",
      "batch 800 loss: 1.41101 acc: 0.71712 | v_loss: 1.36685 v_acc: 0.72038 |  iteration: 801 teacher: 1 stage: sketch lr: 0.000140\n",
      "batch 801 loss: 1.46429 acc: 0.69922 | v_loss: 1.28433 v_acc: 0.73535 |  iteration: 802 teacher: 1 stage: sketch lr: 0.000140\n",
      "batch 802 loss: 1.44136 acc: 0.71159 | v_loss: 1.28014 v_acc: 0.73307 |  iteration: 803 teacher: 1 stage: sketch lr: 0.000140\n",
      "batch 803 loss: 1.39278 acc: 0.71191 | v_loss: 1.31302 v_acc: 0.71712 |  iteration: 804 teacher: 0 stage: sketch lr: 0.000140\n",
      "batch 804 loss: 1.48239 acc: 0.70931 | v_loss: 1.34943 v_acc: 0.72949 |  iteration: 805 teacher: 1 stage: sketch lr: 0.000141\n",
      "batch 805 loss: 1.37096 acc: 0.72168 | v_loss: 1.33603 v_acc: 0.73079 |  iteration: 806 teacher: 0 stage: sketch lr: 0.000141\n",
      "batch 806 loss: 1.32461 acc: 0.71582 | v_loss: 1.64700 v_acc: 0.68620 |  iteration: 807 teacher: 0 stage: sketch lr: 0.000141\n",
      "batch 807 loss: 1.44002 acc: 0.70931 | v_loss: 1.30659 v_acc: 0.72689 |  iteration: 808 teacher: 1 stage: sketch lr: 0.000141\n",
      "batch 808 loss: 1.36310 acc: 0.71484 | v_loss: 1.36081 v_acc: 0.72656 |  iteration: 809 teacher: 1 stage: sketch lr: 0.000141\n",
      "batch 809 loss: 1.47107 acc: 0.70671 | v_loss: 1.41593 v_acc: 0.71842 |  iteration: 810 teacher: 1 stage: sketch lr: 0.000142\n",
      "batch 810 loss: 1.38890 acc: 0.70996 | v_loss: 1.47186 v_acc: 0.71549 |  iteration: 811 teacher: 1 stage: sketch lr: 0.000142\n",
      "batch 811 loss: 1.39511 acc: 0.71517 | v_loss: 1.26555 v_acc: 0.73893 |  iteration: 812 teacher: 0 stage: sketch lr: 0.000142\n",
      "batch 812 loss: 1.32814 acc: 0.71289 | v_loss: 1.42003 v_acc: 0.71224 |  iteration: 813 teacher: 0 stage: sketch lr: 0.000142\n",
      "batch 813 loss: 1.40451 acc: 0.71680 | v_loss: 1.28751 v_acc: 0.72135 |  iteration: 814 teacher: 1 stage: sketch lr: 0.000142\n",
      "batch 814 loss: 1.33139 acc: 0.71810 | v_loss: 1.40626 v_acc: 0.72070 |  iteration: 815 teacher: 0 stage: sketch lr: 0.000142\n",
      "batch 815 loss: 1.47570 acc: 0.69987 | v_loss: 1.42563 v_acc: 0.70996 |  iteration: 816 teacher: 0 stage: sketch lr: 0.000143\n",
      "batch 816 loss: 1.51504 acc: 0.69206 | v_loss: 1.42118 v_acc: 0.70833 |  iteration: 817 teacher: 1 stage: sketch lr: 0.000143\n",
      "batch 817 loss: 1.44765 acc: 0.70540 | v_loss: 1.54245 v_acc: 0.69727 |  iteration: 818 teacher: 0 stage: sketch lr: 0.000143\n",
      "batch 818 loss: 1.44540 acc: 0.70768 | v_loss: 1.40152 v_acc: 0.71224 |  iteration: 819 teacher: 0 stage: sketch lr: 0.000143\n",
      "batch 819 loss: 1.40929 acc: 0.70931 | v_loss: 1.37126 v_acc: 0.71354 |  iteration: 820 teacher: 1 stage: sketch lr: 0.000143\n",
      "batch 820 loss: 1.37258 acc: 0.71257 | v_loss: 1.30070 v_acc: 0.72884 |  iteration: 821 teacher: 1 stage: sketch lr: 0.000143\n",
      "batch 821 loss: 1.32745 acc: 0.72363 | v_loss: 1.36769 v_acc: 0.72591 |  iteration: 822 teacher: 0 stage: sketch lr: 0.000144\n",
      "batch 822 loss: 1.33695 acc: 0.71419 | v_loss: 1.30258 v_acc: 0.72949 |  iteration: 823 teacher: 0 stage: sketch lr: 0.000144\n",
      "batch 823 loss: 1.42070 acc: 0.71745 | v_loss: 1.31042 v_acc: 0.73210 |  iteration: 824 teacher: 0 stage: sketch lr: 0.000144\n",
      "batch 824 loss: 1.51340 acc: 0.70540 | v_loss: 1.33474 v_acc: 0.72103 |  iteration: 825 teacher: 1 stage: sketch lr: 0.000144\n",
      "batch 825 loss: 1.35295 acc: 0.71452 | v_loss: 1.30853 v_acc: 0.72038 |  iteration: 826 teacher: 0 stage: sketch lr: 0.000144\n",
      "batch 826 loss: 1.31559 acc: 0.73014 | v_loss: 1.45391 v_acc: 0.70443 |  iteration: 827 teacher: 1 stage: sketch lr: 0.000144\n",
      "batch 827 loss: 1.42868 acc: 0.70052 | v_loss: 1.37146 v_acc: 0.71908 |  iteration: 828 teacher: 0 stage: sketch lr: 0.000145\n",
      "batch 828 loss: 1.27963 acc: 0.72689 | v_loss: 1.42626 v_acc: 0.70801 |  iteration: 829 teacher: 0 stage: sketch lr: 0.000145\n",
      "batch 829 loss: 1.39601 acc: 0.71159 | v_loss: 1.33858 v_acc: 0.72591 |  iteration: 830 teacher: 1 stage: sketch lr: 0.000145\n",
      "batch 830 loss: 1.40399 acc: 0.71615 | v_loss: 1.27333 v_acc: 0.72233 |  iteration: 831 teacher: 1 stage: sketch lr: 0.000145\n",
      "batch 831 loss: 1.37154 acc: 0.72461 | v_loss: 1.25665 v_acc: 0.74707 |  iteration: 832 teacher: 0 stage: sketch lr: 0.000145\n",
      "batch 832 loss: 1.34778 acc: 0.72201 | v_loss: 1.34400 v_acc: 0.72493 |  iteration: 833 teacher: 1 stage: sketch lr: 0.000146\n",
      "batch 833 loss: 1.42230 acc: 0.71549 | v_loss: 1.31095 v_acc: 0.73503 |  iteration: 834 teacher: 0 stage: sketch lr: 0.000146\n",
      "batch 834 loss: 1.48125 acc: 0.70150 | v_loss: 1.29313 v_acc: 0.73145 |  iteration: 835 teacher: 0 stage: sketch lr: 0.000146\n",
      "batch 835 loss: 1.43837 acc: 0.70410 | v_loss: 1.35864 v_acc: 0.71842 |  iteration: 836 teacher: 1 stage: sketch lr: 0.000146\n",
      "batch 836 loss: 1.35856 acc: 0.72233 | v_loss: 1.23688 v_acc: 0.73438 |  iteration: 837 teacher: 1 stage: sketch lr: 0.000146\n",
      "batch 837 loss: 1.30612 acc: 0.72135 | v_loss: 1.32603 v_acc: 0.73242 |  iteration: 838 teacher: 1 stage: sketch lr: 0.000146\n",
      "batch 838 loss: 1.47837 acc: 0.69857 | v_loss: 1.41655 v_acc: 0.71289 |  iteration: 839 teacher: 1 stage: sketch lr: 0.000147\n",
      "batch 839 loss: 1.42759 acc: 0.70475 | v_loss: 1.37762 v_acc: 0.73307 |  iteration: 840 teacher: 1 stage: sketch lr: 0.000147\n",
      "batch 840 loss: 1.28854 acc: 0.72559 | v_loss: 1.17312 v_acc: 0.75358 |  iteration: 841 teacher: 1 stage: sketch lr: 0.000147\n",
      "batch 841 loss: 1.33904 acc: 0.71810 | v_loss: 1.33875 v_acc: 0.72005 |  iteration: 842 teacher: 1 stage: sketch lr: 0.000147\n",
      "batch 842 loss: 1.47550 acc: 0.70801 | v_loss: 1.39993 v_acc: 0.72461 |  iteration: 843 teacher: 1 stage: sketch lr: 0.000147\n",
      "batch 843 loss: 1.35343 acc: 0.72233 | v_loss: 1.36898 v_acc: 0.72852 |  iteration: 844 teacher: 0 stage: sketch lr: 0.000147\n",
      "batch 844 loss: 1.41652 acc: 0.71810 | v_loss: 1.19585 v_acc: 0.73893 |  iteration: 845 teacher: 1 stage: sketch lr: 0.000148\n",
      "batch 845 loss: 1.45748 acc: 0.70312 | v_loss: 1.42549 v_acc: 0.71745 |  iteration: 846 teacher: 0 stage: sketch lr: 0.000148\n",
      "batch 846 loss: 1.35927 acc: 0.71289 | v_loss: 1.31496 v_acc: 0.71680 |  iteration: 847 teacher: 1 stage: sketch lr: 0.000148\n",
      "batch 847 loss: 1.39847 acc: 0.71712 | v_loss: 1.41992 v_acc: 0.70996 |  iteration: 848 teacher: 1 stage: sketch lr: 0.000148\n",
      "batch 848 loss: 1.32124 acc: 0.71908 | v_loss: 1.32142 v_acc: 0.73340 |  iteration: 849 teacher: 0 stage: sketch lr: 0.000148\n",
      "batch 849 loss: 1.41332 acc: 0.70671 | v_loss: 1.24034 v_acc: 0.73470 |  iteration: 850 teacher: 0 stage: sketch lr: 0.000148\n",
      "batch 850 loss: 1.30405 acc: 0.72949 | v_loss: 1.26745 v_acc: 0.72786 |  iteration: 851 teacher: 1 stage: sketch lr: 0.000149\n",
      "batch 851 loss: 1.42722 acc: 0.70671 | v_loss: 1.41590 v_acc: 0.71094 |  iteration: 852 teacher: 1 stage: sketch lr: 0.000149\n",
      "batch 852 loss: 1.35588 acc: 0.72038 | v_loss: 1.28203 v_acc: 0.72201 |  iteration: 853 teacher: 1 stage: sketch lr: 0.000149\n",
      "batch 853 loss: 1.39367 acc: 0.71322 | v_loss: 1.41271 v_acc: 0.71387 |  iteration: 854 teacher: 0 stage: sketch lr: 0.000149\n",
      "batch 854 loss: 1.42684 acc: 0.71191 | v_loss: 1.32022 v_acc: 0.73210 |  iteration: 855 teacher: 0 stage: sketch lr: 0.000149\n",
      "batch 855 loss: 1.35117 acc: 0.72852 | v_loss: 1.47962 v_acc: 0.71257 |  iteration: 856 teacher: 1 stage: sketch lr: 0.000150\n",
      "batch 856 loss: 1.37940 acc: 0.71745 | v_loss: 1.41170 v_acc: 0.70964 |  iteration: 857 teacher: 0 stage: sketch lr: 0.000150\n",
      "batch 857 loss: 1.38572 acc: 0.71549 | v_loss: 1.47237 v_acc: 0.70378 |  iteration: 858 teacher: 1 stage: sketch lr: 0.000150\n",
      "batch 858 loss: 1.42126 acc: 0.71615 | v_loss: 1.30904 v_acc: 0.71061 |  iteration: 859 teacher: 1 stage: sketch lr: 0.000150\n",
      "batch 859 loss: 1.37450 acc: 0.71094 | v_loss: 1.26119 v_acc: 0.73112 |  iteration: 860 teacher: 0 stage: sketch lr: 0.000150\n",
      "batch 860 loss: 1.41178 acc: 0.71517 | v_loss: 1.39337 v_acc: 0.71029 |  iteration: 861 teacher: 0 stage: sketch lr: 0.000150\n",
      "batch 861 loss: 1.34149 acc: 0.72331 | v_loss: 1.25624 v_acc: 0.74447 |  iteration: 862 teacher: 0 stage: sketch lr: 0.000151\n",
      "batch 862 loss: 1.39366 acc: 0.71582 | v_loss: 1.46124 v_acc: 0.70475 |  iteration: 863 teacher: 1 stage: sketch lr: 0.000151\n",
      "batch 863 loss: 1.39812 acc: 0.71387 | v_loss: 1.41062 v_acc: 0.70931 |  iteration: 864 teacher: 0 stage: sketch lr: 0.000151\n",
      "batch 864 loss: 1.39237 acc: 0.71257 | v_loss: 1.28031 v_acc: 0.73242 |  iteration: 865 teacher: 0 stage: sketch lr: 0.000151\n",
      "batch 865 loss: 1.45898 acc: 0.70182 | v_loss: 1.33261 v_acc: 0.72201 |  iteration: 866 teacher: 1 stage: sketch lr: 0.000151\n",
      "batch 866 loss: 1.33579 acc: 0.72331 | v_loss: 1.33066 v_acc: 0.71842 |  iteration: 867 teacher: 1 stage: sketch lr: 0.000151\n",
      "batch 867 loss: 1.33574 acc: 0.72005 | v_loss: 1.44913 v_acc: 0.71680 |  iteration: 868 teacher: 0 stage: sketch lr: 0.000152\n",
      "batch 868 loss: 1.33987 acc: 0.72331 | v_loss: 1.29446 v_acc: 0.74316 |  iteration: 869 teacher: 1 stage: sketch lr: 0.000152\n",
      "batch 869 loss: 1.42906 acc: 0.71387 | v_loss: 1.22207 v_acc: 0.73991 |  iteration: 870 teacher: 1 stage: sketch lr: 0.000152\n",
      "batch 870 loss: 1.44904 acc: 0.71029 | v_loss: 1.19889 v_acc: 0.73698 |  iteration: 871 teacher: 0 stage: sketch lr: 0.000152\n",
      "batch 871 loss: 1.44977 acc: 0.70475 | v_loss: 1.30521 v_acc: 0.72819 |  iteration: 872 teacher: 1 stage: sketch lr: 0.000152\n",
      "batch 872 loss: 1.37458 acc: 0.70703 | v_loss: 1.37192 v_acc: 0.71387 |  iteration: 873 teacher: 1 stage: sketch lr: 0.000153\n",
      "batch 873 loss: 1.38305 acc: 0.70964 | v_loss: 1.32160 v_acc: 0.71484 |  iteration: 874 teacher: 0 stage: sketch lr: 0.000153\n",
      "batch 874 loss: 1.34850 acc: 0.71940 | v_loss: 1.29492 v_acc: 0.72852 |  iteration: 875 teacher: 0 stage: sketch lr: 0.000153\n",
      "batch 875 loss: 1.40101 acc: 0.71354 | v_loss: 1.39172 v_acc: 0.73470 |  iteration: 876 teacher: 1 stage: sketch lr: 0.000153\n",
      "batch 876 loss: 1.44817 acc: 0.71257 | v_loss: 1.32633 v_acc: 0.71029 |  iteration: 877 teacher: 1 stage: sketch lr: 0.000153\n",
      "batch 877 loss: 1.37192 acc: 0.70931 | v_loss: 1.23986 v_acc: 0.73275 |  iteration: 878 teacher: 1 stage: sketch lr: 0.000153\n",
      "batch 878 loss: 1.41676 acc: 0.71973 | v_loss: 1.23095 v_acc: 0.73470 |  iteration: 879 teacher: 0 stage: sketch lr: 0.000154\n",
      "batch 879 loss: 1.39599 acc: 0.72233 | v_loss: 1.26970 v_acc: 0.73470 |  iteration: 880 teacher: 0 stage: sketch lr: 0.000154\n",
      "batch 880 loss: 1.33244 acc: 0.72135 | v_loss: 1.29151 v_acc: 0.73210 |  iteration: 881 teacher: 1 stage: sketch lr: 0.000154\n",
      "batch 881 loss: 1.39354 acc: 0.70931 | v_loss: 1.38084 v_acc: 0.71615 |  iteration: 882 teacher: 1 stage: sketch lr: 0.000154\n",
      "batch 882 loss: 1.43368 acc: 0.70996 | v_loss: 1.36988 v_acc: 0.71322 |  iteration: 883 teacher: 0 stage: sketch lr: 0.000154\n",
      "batch 883 loss: 1.38310 acc: 0.72005 | v_loss: 1.31646 v_acc: 0.72982 |  iteration: 884 teacher: 1 stage: sketch lr: 0.000154\n",
      "batch 884 loss: 1.33088 acc: 0.71810 | v_loss: 1.27385 v_acc: 0.75553 |  iteration: 885 teacher: 1 stage: sketch lr: 0.000155\n",
      "batch 885 loss: 1.35107 acc: 0.71940 | v_loss: 1.47311 v_acc: 0.71191 |  iteration: 886 teacher: 0 stage: sketch lr: 0.000155\n",
      "batch 886 loss: 1.28753 acc: 0.72526 | v_loss: 1.48376 v_acc: 0.70866 |  iteration: 887 teacher: 1 stage: sketch lr: 0.000155\n",
      "batch 887 loss: 1.36302 acc: 0.71419 | v_loss: 1.27214 v_acc: 0.73307 |  iteration: 888 teacher: 0 stage: sketch lr: 0.000155\n",
      "batch 888 loss: 1.37514 acc: 0.71387 | v_loss: 1.41427 v_acc: 0.72038 |  iteration: 889 teacher: 1 stage: sketch lr: 0.000155\n",
      "batch 889 loss: 1.42357 acc: 0.71029 | v_loss: 1.22470 v_acc: 0.73600 |  iteration: 890 teacher: 0 stage: sketch lr: 0.000155\n",
      "batch 890 loss: 1.45923 acc: 0.70996 | v_loss: 1.39782 v_acc: 0.71094 |  iteration: 891 teacher: 0 stage: sketch lr: 0.000156\n",
      "batch 891 loss: 1.29135 acc: 0.73145 | v_loss: 1.33754 v_acc: 0.72135 |  iteration: 892 teacher: 0 stage: sketch lr: 0.000156\n",
      "batch 892 loss: 1.36803 acc: 0.71452 | v_loss: 1.25343 v_acc: 0.73665 |  iteration: 893 teacher: 0 stage: sketch lr: 0.000156\n",
      "batch 893 loss: 1.38586 acc: 0.71224 | v_loss: 1.24513 v_acc: 0.73958 |  iteration: 894 teacher: 1 stage: sketch lr: 0.000156\n",
      "batch 894 loss: 1.39056 acc: 0.71354 | v_loss: 1.29338 v_acc: 0.71745 |  iteration: 895 teacher: 1 stage: sketch lr: 0.000156\n",
      "batch 895 loss: 1.35078 acc: 0.71582 | v_loss: 1.32172 v_acc: 0.73470 |  iteration: 896 teacher: 1 stage: sketch lr: 0.000157\n",
      "batch 896 loss: 1.27235 acc: 0.73047 | v_loss: 1.30629 v_acc: 0.73600 |  iteration: 897 teacher: 0 stage: sketch lr: 0.000157\n",
      "batch 897 loss: 1.28306 acc: 0.72005 | v_loss: 1.63631 v_acc: 0.67904 |  iteration: 898 teacher: 0 stage: sketch lr: 0.000157\n",
      "batch 898 loss: 1.30502 acc: 0.72168 | v_loss: 1.28437 v_acc: 0.73210 |  iteration: 899 teacher: 0 stage: sketch lr: 0.000157\n",
      "batch 899 loss: 1.42374 acc: 0.70931 | v_loss: 1.32292 v_acc: 0.72656 |  iteration: 900 teacher: 0 stage: sketch lr: 0.000157\n",
      "batch 900 loss: 1.34405 acc: 0.72526 | v_loss: 1.33834 v_acc: 0.73503 |  iteration: 901 teacher: 0 stage: sketch lr: 0.000157\n",
      "batch 901 loss: 1.35101 acc: 0.71777 | v_loss: 1.41509 v_acc: 0.71973 |  iteration: 902 teacher: 0 stage: sketch lr: 0.000158\n",
      "batch 902 loss: 1.39944 acc: 0.70866 | v_loss: 1.22573 v_acc: 0.74772 |  iteration: 903 teacher: 0 stage: sketch lr: 0.000158\n",
      "batch 903 loss: 1.39841 acc: 0.71224 | v_loss: 1.37572 v_acc: 0.71875 |  iteration: 904 teacher: 1 stage: sketch lr: 0.000158\n",
      "batch 904 loss: 1.42335 acc: 0.70605 | v_loss: 1.25868 v_acc: 0.71810 |  iteration: 905 teacher: 0 stage: sketch lr: 0.000158\n",
      "batch 905 loss: 1.35641 acc: 0.71419 | v_loss: 1.37466 v_acc: 0.72363 |  iteration: 906 teacher: 1 stage: sketch lr: 0.000158\n",
      "batch 906 loss: 1.26903 acc: 0.72949 | v_loss: 1.38651 v_acc: 0.71257 |  iteration: 907 teacher: 0 stage: sketch lr: 0.000158\n",
      "batch 907 loss: 1.35386 acc: 0.72201 | v_loss: 1.34068 v_acc: 0.71582 |  iteration: 908 teacher: 1 stage: sketch lr: 0.000159\n",
      "batch 908 loss: 1.31425 acc: 0.71875 | v_loss: 1.49631 v_acc: 0.70020 |  iteration: 909 teacher: 0 stage: sketch lr: 0.000159\n",
      "batch 909 loss: 1.43050 acc: 0.70605 | v_loss: 1.33450 v_acc: 0.72819 |  iteration: 910 teacher: 1 stage: sketch lr: 0.000159\n",
      "batch 910 loss: 1.30136 acc: 0.71875 | v_loss: 1.32427 v_acc: 0.72135 |  iteration: 911 teacher: 0 stage: sketch lr: 0.000159\n",
      "batch 911 loss: 1.48801 acc: 0.70117 | v_loss: 1.27761 v_acc: 0.73047 |  iteration: 912 teacher: 0 stage: sketch lr: 0.000159\n",
      "batch 912 loss: 1.35643 acc: 0.71582 | v_loss: 1.34117 v_acc: 0.73112 |  iteration: 913 teacher: 1 stage: sketch lr: 0.000159\n",
      "batch 913 loss: 1.28460 acc: 0.72689 | v_loss: 1.26566 v_acc: 0.73503 |  iteration: 914 teacher: 0 stage: sketch lr: 0.000160\n",
      "batch 914 loss: 1.37785 acc: 0.71289 | v_loss: 1.25932 v_acc: 0.74089 |  iteration: 915 teacher: 0 stage: sketch lr: 0.000160\n",
      "batch 915 loss: 1.35988 acc: 0.72005 | v_loss: 1.31229 v_acc: 0.72526 |  iteration: 916 teacher: 0 stage: sketch lr: 0.000160\n",
      "batch 916 loss: 1.42861 acc: 0.71029 | v_loss: 1.28838 v_acc: 0.72298 |  iteration: 917 teacher: 0 stage: sketch lr: 0.000160\n",
      "batch 917 loss: 1.37341 acc: 0.70964 | v_loss: 1.40223 v_acc: 0.71159 |  iteration: 918 teacher: 0 stage: sketch lr: 0.000160\n",
      "batch 918 loss: 1.44443 acc: 0.70833 | v_loss: 1.33982 v_acc: 0.72331 |  iteration: 919 teacher: 1 stage: sketch lr: 0.000161\n",
      "batch 919 loss: 1.36443 acc: 0.71159 | v_loss: 1.40371 v_acc: 0.71908 |  iteration: 920 teacher: 1 stage: sketch lr: 0.000161\n",
      "batch 920 loss: 1.38804 acc: 0.71452 | v_loss: 1.33357 v_acc: 0.72493 |  iteration: 921 teacher: 1 stage: sketch lr: 0.000161\n",
      "batch 921 loss: 1.33446 acc: 0.72754 | v_loss: 1.25400 v_acc: 0.72591 |  iteration: 922 teacher: 1 stage: sketch lr: 0.000161\n",
      "batch 922 loss: 1.33767 acc: 0.72070 | v_loss: 1.23937 v_acc: 0.74870 |  iteration: 923 teacher: 0 stage: sketch lr: 0.000161\n",
      "batch 923 loss: 1.43737 acc: 0.70508 | v_loss: 1.31654 v_acc: 0.73079 |  iteration: 924 teacher: 1 stage: sketch lr: 0.000161\n",
      "batch 924 loss: 1.36905 acc: 0.70703 | v_loss: 1.28067 v_acc: 0.74219 |  iteration: 925 teacher: 1 stage: sketch lr: 0.000162\n",
      "batch 925 loss: 1.43209 acc: 0.70475 | v_loss: 1.28416 v_acc: 0.72819 |  iteration: 926 teacher: 1 stage: sketch lr: 0.000162\n",
      "batch 926 loss: 1.33999 acc: 0.71549 | v_loss: 1.34357 v_acc: 0.72526 |  iteration: 927 teacher: 0 stage: sketch lr: 0.000162\n",
      "batch 927 loss: 1.45796 acc: 0.70931 | v_loss: 1.20545 v_acc: 0.73926 |  iteration: 928 teacher: 1 stage: sketch lr: 0.000162\n",
      "batch 928 loss: 1.31336 acc: 0.72233 | v_loss: 1.28793 v_acc: 0.73503 |  iteration: 929 teacher: 0 stage: sketch lr: 0.000162\n",
      "batch 929 loss: 1.40648 acc: 0.71094 | v_loss: 1.38308 v_acc: 0.71745 |  iteration: 930 teacher: 0 stage: sketch lr: 0.000162\n",
      "batch 930 loss: 1.32690 acc: 0.72103 | v_loss: 1.35723 v_acc: 0.73340 |  iteration: 931 teacher: 0 stage: sketch lr: 0.000163\n",
      "batch 931 loss: 1.31172 acc: 0.72982 | v_loss: 1.16574 v_acc: 0.75423 |  iteration: 932 teacher: 0 stage: sketch lr: 0.000163\n",
      "batch 932 loss: 1.46179 acc: 0.70833 | v_loss: 1.31800 v_acc: 0.71615 |  iteration: 933 teacher: 0 stage: sketch lr: 0.000163\n",
      "batch 933 loss: 1.40271 acc: 0.71745 | v_loss: 1.37483 v_acc: 0.72526 |  iteration: 934 teacher: 0 stage: sketch lr: 0.000163\n",
      "batch 934 loss: 1.39415 acc: 0.71615 | v_loss: 1.34214 v_acc: 0.73405 |  iteration: 935 teacher: 0 stage: sketch lr: 0.000163\n",
      "batch 935 loss: 1.35151 acc: 0.72135 | v_loss: 1.18118 v_acc: 0.74251 |  iteration: 936 teacher: 1 stage: sketch lr: 0.000164\n",
      "batch 936 loss: 1.46424 acc: 0.70150 | v_loss: 1.39961 v_acc: 0.71517 |  iteration: 937 teacher: 1 stage: sketch lr: 0.000164\n",
      "batch 937 loss: 1.34397 acc: 0.71484 | v_loss: 1.30455 v_acc: 0.72103 |  iteration: 938 teacher: 1 stage: sketch lr: 0.000164\n",
      "batch 938 loss: 1.52846 acc: 0.70020 | v_loss: 1.40941 v_acc: 0.70703 |  iteration: 939 teacher: 1 stage: sketch lr: 0.000164\n",
      "batch 939 loss: 1.29422 acc: 0.72363 | v_loss: 1.30387 v_acc: 0.73796 |  iteration: 940 teacher: 1 stage: sketch lr: 0.000164\n",
      "batch 940 loss: 1.36032 acc: 0.72689 | v_loss: 1.22618 v_acc: 0.73730 |  iteration: 941 teacher: 1 stage: sketch lr: 0.000164\n",
      "batch 941 loss: 1.51614 acc: 0.69954 | v_loss: 1.26116 v_acc: 0.73014 |  iteration: 942 teacher: 1 stage: sketch lr: 0.000165\n",
      "batch 942 loss: 1.37328 acc: 0.71842 | v_loss: 1.38566 v_acc: 0.70964 |  iteration: 943 teacher: 1 stage: sketch lr: 0.000165\n",
      "batch 943 loss: 1.46345 acc: 0.70833 | v_loss: 1.27289 v_acc: 0.72201 |  iteration: 944 teacher: 1 stage: sketch lr: 0.000165\n",
      "batch 944 loss: 1.40889 acc: 0.70964 | v_loss: 1.36113 v_acc: 0.71549 |  iteration: 945 teacher: 0 stage: sketch lr: 0.000165\n",
      "batch 945 loss: 1.36569 acc: 0.71647 | v_loss: 1.28796 v_acc: 0.73730 |  iteration: 946 teacher: 1 stage: sketch lr: 0.000165\n",
      "batch 946 loss: 1.37720 acc: 0.71745 | v_loss: 1.45047 v_acc: 0.71387 |  iteration: 947 teacher: 1 stage: sketch lr: 0.000165\n",
      "batch 947 loss: 1.43599 acc: 0.71680 | v_loss: 1.38513 v_acc: 0.70247 |  iteration: 948 teacher: 1 stage: sketch lr: 0.000166\n",
      "batch 948 loss: 1.32418 acc: 0.72559 | v_loss: 1.46349 v_acc: 0.70182 |  iteration: 949 teacher: 0 stage: sketch lr: 0.000166\n",
      "batch 949 loss: 1.28690 acc: 0.72201 | v_loss: 1.30462 v_acc: 0.71061 |  iteration: 950 teacher: 0 stage: sketch lr: 0.000166\n",
      "batch 950 loss: 1.43833 acc: 0.70508 | v_loss: 1.24240 v_acc: 0.72982 |  iteration: 951 teacher: 1 stage: sketch lr: 0.000166\n",
      "batch 951 loss: 1.27333 acc: 0.71875 | v_loss: 1.37216 v_acc: 0.71582 |  iteration: 952 teacher: 0 stage: sketch lr: 0.000166\n",
      "batch 952 loss: 1.37157 acc: 0.72103 | v_loss: 1.24868 v_acc: 0.74577 |  iteration: 953 teacher: 1 stage: sketch lr: 0.000166\n",
      "batch 953 loss: 1.26295 acc: 0.73438 | v_loss: 1.41348 v_acc: 0.71549 |  iteration: 954 teacher: 0 stage: sketch lr: 0.000167\n",
      "batch 954 loss: 1.36735 acc: 0.71680 | v_loss: 1.37939 v_acc: 0.71517 |  iteration: 955 teacher: 0 stage: sketch lr: 0.000167\n",
      "batch 955 loss: 1.36496 acc: 0.70898 | v_loss: 1.26532 v_acc: 0.73307 |  iteration: 956 teacher: 1 stage: sketch lr: 0.000167\n",
      "batch 956 loss: 1.36492 acc: 0.71875 | v_loss: 1.30704 v_acc: 0.73047 |  iteration: 957 teacher: 0 stage: sketch lr: 0.000167\n",
      "batch 957 loss: 1.34874 acc: 0.71484 | v_loss: 1.30599 v_acc: 0.72298 |  iteration: 958 teacher: 0 stage: sketch lr: 0.000167\n",
      "batch 958 loss: 1.36349 acc: 0.72363 | v_loss: 1.40637 v_acc: 0.72038 |  iteration: 959 teacher: 0 stage: sketch lr: 0.000168\n",
      "batch 959 loss: 1.31952 acc: 0.71973 | v_loss: 1.28466 v_acc: 0.73763 |  iteration: 960 teacher: 1 stage: sketch lr: 0.000168\n",
      "batch 960 loss: 1.43009 acc: 0.70378 | v_loss: 1.20702 v_acc: 0.73958 |  iteration: 961 teacher: 0 stage: sketch lr: 0.000168\n",
      "batch 961 loss: 1.33269 acc: 0.71712 | v_loss: 1.18461 v_acc: 0.74447 |  iteration: 962 teacher: 0 stage: sketch lr: 0.000168\n",
      "batch 962 loss: 1.31202 acc: 0.71419 | v_loss: 1.28683 v_acc: 0.73470 |  iteration: 963 teacher: 0 stage: sketch lr: 0.000168\n",
      "batch 963 loss: 1.31905 acc: 0.71940 | v_loss: 1.33946 v_acc: 0.72949 |  iteration: 964 teacher: 1 stage: sketch lr: 0.000168\n",
      "batch 964 loss: 1.36770 acc: 0.71257 | v_loss: 1.26883 v_acc: 0.72721 |  iteration: 965 teacher: 0 stage: sketch lr: 0.000169\n",
      "batch 965 loss: 1.34595 acc: 0.72396 | v_loss: 1.26526 v_acc: 0.73763 |  iteration: 966 teacher: 1 stage: sketch lr: 0.000169\n",
      "batch 966 loss: 1.38031 acc: 0.71647 | v_loss: 1.36065 v_acc: 0.73926 |  iteration: 967 teacher: 0 stage: sketch lr: 0.000169\n",
      "batch 967 loss: 1.46782 acc: 0.70475 | v_loss: 1.32053 v_acc: 0.71387 |  iteration: 968 teacher: 1 stage: sketch lr: 0.000169\n",
      "batch 968 loss: 1.34764 acc: 0.72038 | v_loss: 1.21521 v_acc: 0.73275 |  iteration: 969 teacher: 0 stage: sketch lr: 0.000169\n",
      "batch 969 loss: 1.41601 acc: 0.70671 | v_loss: 1.21555 v_acc: 0.73600 |  iteration: 970 teacher: 1 stage: sketch lr: 0.000169\n",
      "batch 970 loss: 1.40249 acc: 0.71810 | v_loss: 1.24328 v_acc: 0.75163 |  iteration: 971 teacher: 1 stage: sketch lr: 0.000170\n",
      "batch 971 loss: 1.36385 acc: 0.72168 | v_loss: 1.29312 v_acc: 0.73307 |  iteration: 972 teacher: 1 stage: sketch lr: 0.000170\n",
      "batch 972 loss: 1.33455 acc: 0.72266 | v_loss: 1.38697 v_acc: 0.71712 |  iteration: 973 teacher: 0 stage: sketch lr: 0.000170\n",
      "batch 973 loss: 1.37365 acc: 0.71224 | v_loss: 1.35482 v_acc: 0.71354 |  iteration: 974 teacher: 0 stage: sketch lr: 0.000170\n",
      "batch 974 loss: 1.35616 acc: 0.71940 | v_loss: 1.29542 v_acc: 0.73340 |  iteration: 975 teacher: 0 stage: sketch lr: 0.000170\n",
      "batch 975 loss: 1.37595 acc: 0.71094 | v_loss: 1.25455 v_acc: 0.75586 |  iteration: 976 teacher: 0 stage: sketch lr: 0.000171\n",
      "batch 976 loss: 1.39071 acc: 0.71517 | v_loss: 1.48032 v_acc: 0.70671 |  iteration: 977 teacher: 0 stage: sketch lr: 0.000171\n",
      "batch 977 loss: 1.45478 acc: 0.70671 | v_loss: 1.44455 v_acc: 0.71452 |  iteration: 978 teacher: 1 stage: sketch lr: 0.000171\n",
      "batch 978 loss: 1.36936 acc: 0.70996 | v_loss: 1.27321 v_acc: 0.73405 |  iteration: 979 teacher: 0 stage: sketch lr: 0.000171\n",
      "batch 979 loss: 1.32728 acc: 0.72721 | v_loss: 1.39720 v_acc: 0.71875 |  iteration: 980 teacher: 0 stage: sketch lr: 0.000171\n",
      "batch 980 loss: 1.34740 acc: 0.72526 | v_loss: 1.21051 v_acc: 0.74154 |  iteration: 981 teacher: 1 stage: sketch lr: 0.000171\n",
      "batch 981 loss: 1.39067 acc: 0.72168 | v_loss: 1.36527 v_acc: 0.71875 |  iteration: 982 teacher: 0 stage: sketch lr: 0.000172\n",
      "batch 982 loss: 1.33346 acc: 0.71745 | v_loss: 1.32387 v_acc: 0.73112 |  iteration: 983 teacher: 0 stage: sketch lr: 0.000172\n",
      "batch 983 loss: 1.41132 acc: 0.71615 | v_loss: 1.24573 v_acc: 0.74121 |  iteration: 984 teacher: 1 stage: sketch lr: 0.000172\n",
      "batch 984 loss: 1.34389 acc: 0.72819 | v_loss: 1.23950 v_acc: 0.73893 |  iteration: 985 teacher: 1 stage: sketch lr: 0.000172\n",
      "batch 985 loss: 1.34103 acc: 0.72266 | v_loss: 1.27671 v_acc: 0.72103 |  iteration: 986 teacher: 0 stage: sketch lr: 0.000172\n",
      "batch 986 loss: 1.38966 acc: 0.72135 | v_loss: 1.34322 v_acc: 0.73145 |  iteration: 987 teacher: 1 stage: sketch lr: 0.000172\n",
      "batch 987 loss: 1.41926 acc: 0.71517 | v_loss: 1.31375 v_acc: 0.72591 |  iteration: 988 teacher: 0 stage: sketch lr: 0.000173\n",
      "batch 988 loss: 1.37855 acc: 0.70378 | v_loss: 1.62211 v_acc: 0.68099 |  iteration: 989 teacher: 1 stage: sketch lr: 0.000173\n",
      "batch 989 loss: 1.32553 acc: 0.72038 | v_loss: 1.27713 v_acc: 0.72884 |  iteration: 990 teacher: 1 stage: sketch lr: 0.000173\n",
      "batch 990 loss: 1.34716 acc: 0.72298 | v_loss: 1.30772 v_acc: 0.72949 |  iteration: 991 teacher: 0 stage: sketch lr: 0.000173\n",
      "batch 991 loss: 1.34036 acc: 0.72884 | v_loss: 1.32667 v_acc: 0.73503 |  iteration: 992 teacher: 0 stage: sketch lr: 0.000173\n",
      "batch 992 loss: 1.31981 acc: 0.72005 | v_loss: 1.40382 v_acc: 0.72721 |  iteration: 993 teacher: 0 stage: sketch lr: 0.000173\n",
      "batch 993 loss: 1.28943 acc: 0.73242 | v_loss: 1.23543 v_acc: 0.74447 |  iteration: 994 teacher: 1 stage: sketch lr: 0.000174\n",
      "batch 994 loss: 1.42200 acc: 0.71159 | v_loss: 1.37822 v_acc: 0.71745 |  iteration: 995 teacher: 0 stage: sketch lr: 0.000174\n",
      "batch 995 loss: 1.40991 acc: 0.72103 | v_loss: 1.26197 v_acc: 0.72135 |  iteration: 996 teacher: 1 stage: sketch lr: 0.000174\n",
      "batch 996 loss: 1.48679 acc: 0.69954 | v_loss: 1.37973 v_acc: 0.71777 |  iteration: 997 teacher: 1 stage: sketch lr: 0.000174\n",
      "batch 997 loss: 1.33735 acc: 0.71647 | v_loss: 1.44471 v_acc: 0.69954 |  iteration: 998 teacher: 0 stage: sketch lr: 0.000174\n",
      "batch 998 loss: 1.47120 acc: 0.69922 | v_loss: 1.39028 v_acc: 0.71061 |  iteration: 999 teacher: 0 stage: sketch lr: 0.000175\n",
      "batch 999 loss: 1.38388 acc: 0.71615 | v_loss: 1.47063 v_acc: 0.70215 |  iteration: 1000 teacher: 1 stage: sketch lr: 0.000175\n",
      "batch 1000 loss: 1.40589 acc: 0.71745 | v_loss: 1.33508 v_acc: 0.72396 |  iteration: 1001 teacher: 0 stage: sketch lr: 0.000175\n",
      "batch 1001 loss: 1.37198 acc: 0.72331 | v_loss: 1.34765 v_acc: 0.71517 |  iteration: 1002 teacher: 1 stage: sketch lr: 0.000175\n",
      "batch 1002 loss: 1.43603 acc: 0.71517 | v_loss: 1.25835 v_acc: 0.73210 |  iteration: 1003 teacher: 0 stage: sketch lr: 0.000175\n",
      "batch 1003 loss: 1.31148 acc: 0.72786 | v_loss: 1.33444 v_acc: 0.72884 |  iteration: 1004 teacher: 1 stage: sketch lr: 0.000175\n",
      "batch 1004 loss: 1.37751 acc: 0.71680 | v_loss: 1.25598 v_acc: 0.73503 |  iteration: 1005 teacher: 0 stage: sketch lr: 0.000176\n",
      "batch 1005 loss: 1.44193 acc: 0.70898 | v_loss: 1.28940 v_acc: 0.73242 |  iteration: 1006 teacher: 1 stage: sketch lr: 0.000176\n",
      "batch 1006 loss: 1.37150 acc: 0.71029 | v_loss: 1.30299 v_acc: 0.72233 |  iteration: 1007 teacher: 0 stage: sketch lr: 0.000176\n",
      "batch 1007 loss: 1.34547 acc: 0.71061 | v_loss: 1.26997 v_acc: 0.72461 |  iteration: 1008 teacher: 0 stage: sketch lr: 0.000176\n",
      "batch 1008 loss: 1.42762 acc: 0.71191 | v_loss: 1.40278 v_acc: 0.71159 |  iteration: 1009 teacher: 0 stage: sketch lr: 0.000176\n",
      "batch 1009 loss: 1.32591 acc: 0.72461 | v_loss: 1.33665 v_acc: 0.72103 |  iteration: 1010 teacher: 0 stage: sketch lr: 0.000176\n",
      "batch 1010 loss: 1.42355 acc: 0.70898 | v_loss: 1.40260 v_acc: 0.72135 |  iteration: 1011 teacher: 1 stage: sketch lr: 0.000177\n",
      "batch 1011 loss: 1.35341 acc: 0.71191 | v_loss: 1.31156 v_acc: 0.72917 |  iteration: 1012 teacher: 0 stage: sketch lr: 0.000177\n",
      "batch 1012 loss: 1.32766 acc: 0.72331 | v_loss: 1.23754 v_acc: 0.72754 |  iteration: 1013 teacher: 0 stage: sketch lr: 0.000177\n",
      "batch 1013 loss: 1.34936 acc: 0.72884 | v_loss: 1.24239 v_acc: 0.75098 |  iteration: 1014 teacher: 1 stage: sketch lr: 0.000177\n",
      "batch 1014 loss: 1.32936 acc: 0.71419 | v_loss: 1.30854 v_acc: 0.73047 |  iteration: 1015 teacher: 1 stage: sketch lr: 0.000177\n",
      "batch 1015 loss: 1.36345 acc: 0.71549 | v_loss: 1.31443 v_acc: 0.74056 |  iteration: 1016 teacher: 0 stage: sketch lr: 0.000177\n",
      "batch 1016 loss: 1.34266 acc: 0.71973 | v_loss: 1.26248 v_acc: 0.73242 |  iteration: 1017 teacher: 0 stage: sketch lr: 0.000178\n",
      "batch 1017 loss: 1.30092 acc: 0.71745 | v_loss: 1.32776 v_acc: 0.72493 |  iteration: 1018 teacher: 1 stage: sketch lr: 0.000178\n",
      "batch 1018 loss: 1.29773 acc: 0.72819 | v_loss: 1.19558 v_acc: 0.74219 |  iteration: 1019 teacher: 1 stage: sketch lr: 0.000178\n",
      "batch 1019 loss: 1.26081 acc: 0.72786 | v_loss: 1.27287 v_acc: 0.74089 |  iteration: 1020 teacher: 0 stage: sketch lr: 0.000178\n",
      "batch 1020 loss: 1.36214 acc: 0.72103 | v_loss: 1.36532 v_acc: 0.72201 |  iteration: 1021 teacher: 0 stage: sketch lr: 0.000178\n",
      "batch 1021 loss: 1.37909 acc: 0.70931 | v_loss: 1.32421 v_acc: 0.73665 |  iteration: 1022 teacher: 0 stage: sketch lr: 0.000179\n",
      "batch 1022 loss: 1.32475 acc: 0.71940 | v_loss: 1.15395 v_acc: 0.75260 |  iteration: 1023 teacher: 1 stage: sketch lr: 0.000179\n",
      "batch 1023 loss: 1.39176 acc: 0.71191 | v_loss: 1.30567 v_acc: 0.72363 |  iteration: 1024 teacher: 1 stage: sketch lr: 0.000179\n",
      "batch 1024 loss: 1.40900 acc: 0.70605 | v_loss: 1.35623 v_acc: 0.73307 |  iteration: 1025 teacher: 1 stage: sketch lr: 0.000179\n",
      "batch 1025 loss: 1.30623 acc: 0.72201 | v_loss: 1.33600 v_acc: 0.73763 |  iteration: 1026 teacher: 0 stage: sketch lr: 0.000179\n",
      "batch 1026 loss: 1.28931 acc: 0.72884 | v_loss: 1.17250 v_acc: 0.74447 |  iteration: 1027 teacher: 0 stage: sketch lr: 0.000179\n",
      "batch 1027 loss: 1.36504 acc: 0.71712 | v_loss: 1.37669 v_acc: 0.71875 |  iteration: 1028 teacher: 1 stage: sketch lr: 0.000180\n",
      "batch 1028 loss: 1.37152 acc: 0.71517 | v_loss: 1.30155 v_acc: 0.71875 |  iteration: 1029 teacher: 1 stage: sketch lr: 0.000180\n",
      "batch 1029 loss: 1.29165 acc: 0.72396 | v_loss: 1.39093 v_acc: 0.70866 |  iteration: 1030 teacher: 0 stage: sketch lr: 0.000180\n",
      "batch 1030 loss: 1.28784 acc: 0.72852 | v_loss: 1.30946 v_acc: 0.73568 |  iteration: 1031 teacher: 1 stage: sketch lr: 0.000180\n",
      "batch 1031 loss: 1.33073 acc: 0.72689 | v_loss: 1.22135 v_acc: 0.74447 |  iteration: 1032 teacher: 0 stage: sketch lr: 0.000180\n",
      "batch 1032 loss: 1.34053 acc: 0.71582 | v_loss: 1.24770 v_acc: 0.73665 |  iteration: 1033 teacher: 1 stage: sketch lr: 0.000180\n",
      "batch 1033 loss: 1.37305 acc: 0.72233 | v_loss: 1.35304 v_acc: 0.73275 |  iteration: 1034 teacher: 0 stage: sketch lr: 0.000181\n",
      "batch 1034 loss: 1.28020 acc: 0.73079 | v_loss: 1.25894 v_acc: 0.72526 |  iteration: 1035 teacher: 0 stage: sketch lr: 0.000181\n",
      "batch 1035 loss: 1.33320 acc: 0.72103 | v_loss: 1.35605 v_acc: 0.71419 |  iteration: 1036 teacher: 0 stage: sketch lr: 0.000181\n",
      "batch 1036 loss: 1.41645 acc: 0.70996 | v_loss: 1.28047 v_acc: 0.73926 |  iteration: 1037 teacher: 0 stage: sketch lr: 0.000181\n",
      "batch 1037 loss: 1.36230 acc: 0.73047 | v_loss: 1.44817 v_acc: 0.70573 |  iteration: 1038 teacher: 1 stage: sketch lr: 0.000181\n",
      "batch 1038 loss: 1.29665 acc: 0.71908 | v_loss: 1.36727 v_acc: 0.71484 |  iteration: 1039 teacher: 0 stage: sketch lr: 0.000182\n",
      "batch 1039 loss: 1.37570 acc: 0.71745 | v_loss: 1.43534 v_acc: 0.70768 |  iteration: 1040 teacher: 1 stage: sketch lr: 0.000182\n",
      "batch 1040 loss: 1.44476 acc: 0.70996 | v_loss: 1.28983 v_acc: 0.71419 |  iteration: 1041 teacher: 1 stage: sketch lr: 0.000182\n",
      "batch 1041 loss: 1.39652 acc: 0.72135 | v_loss: 1.23391 v_acc: 0.72852 |  iteration: 1042 teacher: 0 stage: sketch lr: 0.000182\n",
      "batch 1042 loss: 1.35279 acc: 0.71712 | v_loss: 1.34058 v_acc: 0.72624 |  iteration: 1043 teacher: 0 stage: sketch lr: 0.000182\n",
      "batch 1043 loss: 1.37338 acc: 0.71842 | v_loss: 1.23244 v_acc: 0.74674 |  iteration: 1044 teacher: 0 stage: sketch lr: 0.000182\n",
      "batch 1044 loss: 1.30576 acc: 0.73047 | v_loss: 1.40143 v_acc: 0.71354 |  iteration: 1045 teacher: 0 stage: sketch lr: 0.000183\n",
      "batch 1045 loss: 1.33828 acc: 0.72266 | v_loss: 1.38207 v_acc: 0.71647 |  iteration: 1046 teacher: 0 stage: sketch lr: 0.000183\n",
      "batch 1046 loss: 1.25738 acc: 0.72493 | v_loss: 1.26208 v_acc: 0.73307 |  iteration: 1047 teacher: 1 stage: sketch lr: 0.000183\n",
      "batch 1047 loss: 1.32401 acc: 0.73177 | v_loss: 1.29567 v_acc: 0.72396 |  iteration: 1048 teacher: 1 stage: sketch lr: 0.000183\n",
      "batch 1048 loss: 1.34628 acc: 0.72005 | v_loss: 1.29254 v_acc: 0.73079 |  iteration: 1049 teacher: 1 stage: sketch lr: 0.000183\n",
      "batch 1049 loss: 1.33741 acc: 0.72038 | v_loss: 1.38879 v_acc: 0.72266 |  iteration: 1050 teacher: 0 stage: sketch lr: 0.000183\n",
      "batch 1050 loss: 1.34669 acc: 0.71712 | v_loss: 1.26460 v_acc: 0.74219 |  iteration: 1051 teacher: 0 stage: sketch lr: 0.000184\n",
      "batch 1051 loss: 1.36086 acc: 0.71810 | v_loss: 1.19245 v_acc: 0.74284 |  iteration: 1052 teacher: 0 stage: sketch lr: 0.000184\n",
      "batch 1052 loss: 1.41947 acc: 0.71061 | v_loss: 1.17220 v_acc: 0.74121 |  iteration: 1053 teacher: 1 stage: sketch lr: 0.000184\n",
      "batch 1053 loss: 1.36073 acc: 0.71973 | v_loss: 1.27715 v_acc: 0.73340 |  iteration: 1054 teacher: 0 stage: sketch lr: 0.000184\n",
      "batch 1054 loss: 1.43357 acc: 0.71354 | v_loss: 1.32996 v_acc: 0.72298 |  iteration: 1055 teacher: 1 stage: sketch lr: 0.000184\n",
      "batch 1055 loss: 1.36794 acc: 0.71615 | v_loss: 1.26939 v_acc: 0.72461 |  iteration: 1056 teacher: 1 stage: sketch lr: 0.000184\n",
      "batch 1056 loss: 1.35107 acc: 0.71387 | v_loss: 1.25467 v_acc: 0.73926 |  iteration: 1057 teacher: 1 stage: sketch lr: 0.000185\n",
      "batch 1057 loss: 1.32042 acc: 0.72721 | v_loss: 1.34938 v_acc: 0.74154 |  iteration: 1058 teacher: 1 stage: sketch lr: 0.000185\n",
      "batch 1058 loss: 1.40475 acc: 0.71419 | v_loss: 1.31521 v_acc: 0.71126 |  iteration: 1059 teacher: 0 stage: sketch lr: 0.000185\n",
      "batch 1059 loss: 1.31829 acc: 0.73047 | v_loss: 1.20345 v_acc: 0.74349 |  iteration: 1060 teacher: 0 stage: sketch lr: 0.000185\n",
      "batch 1060 loss: 1.37151 acc: 0.71159 | v_loss: 1.20397 v_acc: 0.74056 |  iteration: 1061 teacher: 0 stage: sketch lr: 0.000185\n",
      "batch 1061 loss: 1.36143 acc: 0.72103 | v_loss: 1.23008 v_acc: 0.75098 |  iteration: 1062 teacher: 0 stage: sketch lr: 0.000186\n",
      "batch 1062 loss: 1.33881 acc: 0.72266 | v_loss: 1.27853 v_acc: 0.73958 |  iteration: 1063 teacher: 0 stage: sketch lr: 0.000186\n",
      "batch 1063 loss: 1.29767 acc: 0.72982 | v_loss: 1.36733 v_acc: 0.71875 |  iteration: 1064 teacher: 0 stage: sketch lr: 0.000186\n",
      "batch 1064 loss: 1.26083 acc: 0.74512 | v_loss: 1.34014 v_acc: 0.71810 |  iteration: 1065 teacher: 0 stage: sketch lr: 0.000186\n",
      "batch 1065 loss: 1.31868 acc: 0.71940 | v_loss: 1.28711 v_acc: 0.73535 |  iteration: 1066 teacher: 0 stage: sketch lr: 0.000186\n",
      "batch 1066 loss: 1.29157 acc: 0.72721 | v_loss: 1.23859 v_acc: 0.76172 |  iteration: 1067 teacher: 1 stage: sketch lr: 0.000186\n",
      "batch 1067 loss: 1.31248 acc: 0.73535 | v_loss: 1.41172 v_acc: 0.71745 |  iteration: 1068 teacher: 0 stage: sketch lr: 0.000187\n",
      "batch 1068 loss: 1.35078 acc: 0.72135 | v_loss: 1.41983 v_acc: 0.71680 |  iteration: 1069 teacher: 1 stage: sketch lr: 0.000187\n",
      "batch 1069 loss: 1.39033 acc: 0.71289 | v_loss: 1.25181 v_acc: 0.73470 |  iteration: 1070 teacher: 0 stage: sketch lr: 0.000187\n",
      "batch 1070 loss: 1.41793 acc: 0.71745 | v_loss: 1.39332 v_acc: 0.72038 |  iteration: 1071 teacher: 0 stage: sketch lr: 0.000187\n",
      "batch 1071 loss: 1.43553 acc: 0.70996 | v_loss: 1.19361 v_acc: 0.73926 |  iteration: 1072 teacher: 1 stage: sketch lr: 0.000187\n",
      "batch 1072 loss: 1.28573 acc: 0.73438 | v_loss: 1.34111 v_acc: 0.72038 |  iteration: 1073 teacher: 1 stage: sketch lr: 0.000187\n",
      "batch 1073 loss: 1.31305 acc: 0.71712 | v_loss: 1.30588 v_acc: 0.72884 |  iteration: 1074 teacher: 1 stage: sketch lr: 0.000188\n",
      "batch 1074 loss: 1.39776 acc: 0.71126 | v_loss: 1.24981 v_acc: 0.73438 |  iteration: 1075 teacher: 1 stage: sketch lr: 0.000188\n",
      "batch 1075 loss: 1.44099 acc: 0.70540 | v_loss: 1.21200 v_acc: 0.74186 |  iteration: 1076 teacher: 1 stage: sketch lr: 0.000188\n",
      "batch 1076 loss: 1.28865 acc: 0.73145 | v_loss: 1.26461 v_acc: 0.72005 |  iteration: 1077 teacher: 0 stage: sketch lr: 0.000188\n",
      "batch 1077 loss: 1.24627 acc: 0.73535 | v_loss: 1.29225 v_acc: 0.73372 |  iteration: 1078 teacher: 1 stage: sketch lr: 0.000188\n",
      "batch 1078 loss: 1.32060 acc: 0.72428 | v_loss: 1.28901 v_acc: 0.73893 |  iteration: 1079 teacher: 1 stage: sketch lr: 0.000188\n",
      "batch 1079 loss: 1.35336 acc: 0.72233 | v_loss: 1.58825 v_acc: 0.68945 |  iteration: 1080 teacher: 1 stage: sketch lr: 0.000189\n",
      "batch 1080 loss: 1.36786 acc: 0.71322 | v_loss: 1.25053 v_acc: 0.73014 |  iteration: 1081 teacher: 0 stage: sketch lr: 0.000189\n",
      "batch 1081 loss: 1.31373 acc: 0.72689 | v_loss: 1.29824 v_acc: 0.73307 |  iteration: 1082 teacher: 1 stage: sketch lr: 0.000189\n",
      "batch 1082 loss: 1.34014 acc: 0.71387 | v_loss: 1.29090 v_acc: 0.73763 |  iteration: 1083 teacher: 0 stage: sketch lr: 0.000189\n",
      "batch 1083 loss: 1.37133 acc: 0.71582 | v_loss: 1.38126 v_acc: 0.73014 |  iteration: 1084 teacher: 0 stage: sketch lr: 0.000189\n",
      "batch 1084 loss: 1.33494 acc: 0.72135 | v_loss: 1.19559 v_acc: 0.75195 |  iteration: 1085 teacher: 0 stage: sketch lr: 0.000190\n",
      "batch 1085 loss: 1.36358 acc: 0.71940 | v_loss: 1.35277 v_acc: 0.72266 |  iteration: 1086 teacher: 0 stage: sketch lr: 0.000190\n",
      "batch 1086 loss: 1.35251 acc: 0.71322 | v_loss: 1.23214 v_acc: 0.72819 |  iteration: 1087 teacher: 1 stage: sketch lr: 0.000190\n",
      "batch 1087 loss: 1.36974 acc: 0.70768 | v_loss: 1.35749 v_acc: 0.72852 |  iteration: 1088 teacher: 1 stage: sketch lr: 0.000190\n",
      "batch 1088 loss: 1.39936 acc: 0.71875 | v_loss: 1.35444 v_acc: 0.72005 |  iteration: 1089 teacher: 1 stage: sketch lr: 0.000190\n",
      "batch 1089 loss: 1.41596 acc: 0.72363 | v_loss: 1.30017 v_acc: 0.71940 |  iteration: 1090 teacher: 1 stage: sketch lr: 0.000190\n",
      "batch 1090 loss: 1.32725 acc: 0.72168 | v_loss: 1.46694 v_acc: 0.70866 |  iteration: 1091 teacher: 0 stage: sketch lr: 0.000191\n",
      "batch 1091 loss: 1.29404 acc: 0.72135 | v_loss: 1.31718 v_acc: 0.72786 |  iteration: 1092 teacher: 0 stage: sketch lr: 0.000191\n",
      "batch 1092 loss: 1.36643 acc: 0.71549 | v_loss: 1.30902 v_acc: 0.71875 |  iteration: 1093 teacher: 0 stage: sketch lr: 0.000191\n",
      "batch 1093 loss: 1.31862 acc: 0.71973 | v_loss: 1.25674 v_acc: 0.72591 |  iteration: 1094 teacher: 0 stage: sketch lr: 0.000191\n",
      "batch 1094 loss: 1.30915 acc: 0.71875 | v_loss: 1.32817 v_acc: 0.73307 |  iteration: 1095 teacher: 0 stage: sketch lr: 0.000191\n",
      "batch 1095 loss: 1.25638 acc: 0.72233 | v_loss: 1.23333 v_acc: 0.73861 |  iteration: 1096 teacher: 1 stage: sketch lr: 0.000191\n",
      "batch 1096 loss: 1.35256 acc: 0.71810 | v_loss: 1.24570 v_acc: 0.74023 |  iteration: 1097 teacher: 0 stage: sketch lr: 0.000192\n",
      "batch 1097 loss: 1.36588 acc: 0.71484 | v_loss: 1.29466 v_acc: 0.73079 |  iteration: 1098 teacher: 0 stage: sketch lr: 0.000192\n",
      "batch 1098 loss: 1.31157 acc: 0.72396 | v_loss: 1.26483 v_acc: 0.72819 |  iteration: 1099 teacher: 1 stage: sketch lr: 0.000192\n",
      "batch 1099 loss: 1.35293 acc: 0.72461 | v_loss: 1.36837 v_acc: 0.72493 |  iteration: 1100 teacher: 0 stage: sketch lr: 0.000192\n",
      "batch 1100 loss: 1.36369 acc: 0.72168 | v_loss: 1.32167 v_acc: 0.72168 |  iteration: 1101 teacher: 0 stage: sketch lr: 0.000192\n",
      "batch 1101 loss: 1.36429 acc: 0.72396 | v_loss: 1.37233 v_acc: 0.72298 |  iteration: 1102 teacher: 1 stage: sketch lr: 0.000193\n",
      "batch 1102 loss: 1.32539 acc: 0.73665 | v_loss: 1.30479 v_acc: 0.73014 |  iteration: 1103 teacher: 0 stage: sketch lr: 0.000193\n",
      "batch 1103 loss: 1.27922 acc: 0.73991 | v_loss: 1.23113 v_acc: 0.72461 |  iteration: 1104 teacher: 1 stage: sketch lr: 0.000193\n",
      "batch 1104 loss: 1.31116 acc: 0.71745 | v_loss: 1.21794 v_acc: 0.75293 |  iteration: 1105 teacher: 1 stage: sketch lr: 0.000193\n",
      "batch 1105 loss: 1.30636 acc: 0.73210 | v_loss: 1.29333 v_acc: 0.73177 |  iteration: 1106 teacher: 0 stage: sketch lr: 0.000193\n",
      "batch 1106 loss: 1.39339 acc: 0.72298 | v_loss: 1.26156 v_acc: 0.73665 |  iteration: 1107 teacher: 0 stage: sketch lr: 0.000193\n",
      "batch 1107 loss: 1.39232 acc: 0.71680 | v_loss: 1.25277 v_acc: 0.73535 |  iteration: 1108 teacher: 1 stage: sketch lr: 0.000194\n",
      "batch 1108 loss: 1.31239 acc: 0.72396 | v_loss: 1.30227 v_acc: 0.73047 |  iteration: 1109 teacher: 1 stage: sketch lr: 0.000194\n",
      "batch 1109 loss: 1.36360 acc: 0.72331 | v_loss: 1.19138 v_acc: 0.74186 |  iteration: 1110 teacher: 1 stage: sketch lr: 0.000194\n",
      "batch 1110 loss: 1.37486 acc: 0.72168 | v_loss: 1.27130 v_acc: 0.74251 |  iteration: 1111 teacher: 1 stage: sketch lr: 0.000194\n",
      "batch 1111 loss: 1.33465 acc: 0.72363 | v_loss: 1.36757 v_acc: 0.71549 |  iteration: 1112 teacher: 0 stage: sketch lr: 0.000194\n",
      "batch 1112 loss: 1.23106 acc: 0.74089 | v_loss: 1.29716 v_acc: 0.73796 |  iteration: 1113 teacher: 0 stage: sketch lr: 0.000194\n",
      "batch 1113 loss: 1.37045 acc: 0.72038 | v_loss: 1.12884 v_acc: 0.76042 |  iteration: 1114 teacher: 1 stage: sketch lr: 0.000195\n",
      "batch 1114 loss: 1.38486 acc: 0.71419 | v_loss: 1.30115 v_acc: 0.71940 |  iteration: 1115 teacher: 1 stage: sketch lr: 0.000195\n",
      "batch 1115 loss: 1.33261 acc: 0.71582 | v_loss: 1.32412 v_acc: 0.73600 |  iteration: 1116 teacher: 1 stage: sketch lr: 0.000195\n",
      "batch 1116 loss: 1.28285 acc: 0.73307 | v_loss: 1.33387 v_acc: 0.73242 |  iteration: 1117 teacher: 1 stage: sketch lr: 0.000195\n",
      "batch 1117 loss: 1.27597 acc: 0.73405 | v_loss: 1.16589 v_acc: 0.74023 |  iteration: 1118 teacher: 0 stage: sketch lr: 0.000195\n",
      "batch 1118 loss: 1.37812 acc: 0.71615 | v_loss: 1.35812 v_acc: 0.71940 |  iteration: 1119 teacher: 0 stage: sketch lr: 0.000195\n",
      "batch 1119 loss: 1.40274 acc: 0.70703 | v_loss: 1.26682 v_acc: 0.72624 |  iteration: 1120 teacher: 0 stage: sketch lr: 0.000196\n",
      "batch 1120 loss: 1.33190 acc: 0.71484 | v_loss: 1.37134 v_acc: 0.71680 |  iteration: 1121 teacher: 0 stage: sketch lr: 0.000196\n",
      "batch 1121 loss: 1.32992 acc: 0.71810 | v_loss: 1.28910 v_acc: 0.73698 |  iteration: 1122 teacher: 0 stage: sketch lr: 0.000196\n",
      "batch 1122 loss: 1.25642 acc: 0.72884 | v_loss: 1.19849 v_acc: 0.74414 |  iteration: 1123 teacher: 1 stage: sketch lr: 0.000196\n",
      "batch 1123 loss: 1.29479 acc: 0.72949 | v_loss: 1.21957 v_acc: 0.73438 |  iteration: 1124 teacher: 0 stage: sketch lr: 0.000196\n",
      "batch 1124 loss: 1.32151 acc: 0.72754 | v_loss: 1.34384 v_acc: 0.72526 |  iteration: 1125 teacher: 1 stage: sketch lr: 0.000197\n",
      "batch 1125 loss: 1.42249 acc: 0.70410 | v_loss: 1.25179 v_acc: 0.72689 |  iteration: 1126 teacher: 1 stage: sketch lr: 0.000197\n",
      "batch 1126 loss: 1.28719 acc: 0.73796 | v_loss: 1.31110 v_acc: 0.72135 |  iteration: 1127 teacher: 0 stage: sketch lr: 0.000197\n",
      "batch 1127 loss: 1.33133 acc: 0.72168 | v_loss: 1.28686 v_acc: 0.73991 |  iteration: 1128 teacher: 1 stage: sketch lr: 0.000197\n",
      "batch 1128 loss: 1.34358 acc: 0.72005 | v_loss: 1.38602 v_acc: 0.72298 |  iteration: 1129 teacher: 1 stage: sketch lr: 0.000197\n",
      "batch 1129 loss: 1.27221 acc: 0.73275 | v_loss: 1.33858 v_acc: 0.71549 |  iteration: 1130 teacher: 0 stage: sketch lr: 0.000197\n",
      "batch 1130 loss: 1.28550 acc: 0.72559 | v_loss: 1.41879 v_acc: 0.71159 |  iteration: 1131 teacher: 1 stage: sketch lr: 0.000198\n",
      "batch 1131 loss: 1.34045 acc: 0.71940 | v_loss: 1.27045 v_acc: 0.72070 |  iteration: 1132 teacher: 0 stage: sketch lr: 0.000198\n",
      "batch 1132 loss: 1.37265 acc: 0.71908 | v_loss: 1.20869 v_acc: 0.73210 |  iteration: 1133 teacher: 0 stage: sketch lr: 0.000198\n",
      "batch 1133 loss: 1.33107 acc: 0.72396 | v_loss: 1.33554 v_acc: 0.72526 |  iteration: 1134 teacher: 0 stage: sketch lr: 0.000198\n",
      "batch 1134 loss: 1.25252 acc: 0.72754 | v_loss: 1.22131 v_acc: 0.74740 |  iteration: 1135 teacher: 0 stage: sketch lr: 0.000198\n",
      "batch 1135 loss: 1.33926 acc: 0.72819 | v_loss: 1.37115 v_acc: 0.71615 |  iteration: 1136 teacher: 0 stage: sketch lr: 0.000198\n",
      "batch 1136 loss: 1.39107 acc: 0.71647 | v_loss: 1.34836 v_acc: 0.72591 |  iteration: 1137 teacher: 1 stage: sketch lr: 0.000199\n",
      "batch 1137 loss: 1.46865 acc: 0.70768 | v_loss: 1.24080 v_acc: 0.73861 |  iteration: 1138 teacher: 0 stage: sketch lr: 0.000199\n",
      "batch 1138 loss: 1.33286 acc: 0.72070 | v_loss: 1.27883 v_acc: 0.73145 |  iteration: 1139 teacher: 1 stage: sketch lr: 0.000199\n",
      "batch 1139 loss: 1.37698 acc: 0.72135 | v_loss: 1.29871 v_acc: 0.72266 |  iteration: 1140 teacher: 1 stage: sketch lr: 0.000199\n",
      "batch 1140 loss: 1.30960 acc: 0.72884 | v_loss: 1.39096 v_acc: 0.72493 |  iteration: 1141 teacher: 1 stage: sketch lr: 0.000199\n",
      "batch 1141 loss: 1.30947 acc: 0.72624 | v_loss: 1.25970 v_acc: 0.73861 |  iteration: 1142 teacher: 1 stage: sketch lr: 0.000199\n",
      "batch 1142 loss: 1.30138 acc: 0.72233 | v_loss: 1.18781 v_acc: 0.73893 |  iteration: 1143 teacher: 1 stage: sketch lr: 0.000200\n",
      "batch 1143 loss: 1.27195 acc: 0.73112 | v_loss: 1.16544 v_acc: 0.74284 |  iteration: 1144 teacher: 1 stage: sketch lr: 0.000200\n",
      "batch 1144 loss: 1.37360 acc: 0.70736 | v_loss: 1.27872 v_acc: 0.73275 |  iteration: 1145 teacher: 1 stage: sketch lr: 0.000200\n",
      "batch 1145 loss: 1.30544 acc: 0.72949 | v_loss: 1.32987 v_acc: 0.72982 |  iteration: 1146 teacher: 0 stage: sketch lr: 0.000200\n",
      "batch 1146 loss: 1.30842 acc: 0.71973 | v_loss: 1.26692 v_acc: 0.72624 |  iteration: 1147 teacher: 0 stage: sketch lr: 0.000200\n",
      "batch 1147 loss: 1.42100 acc: 0.71549 | v_loss: 1.24306 v_acc: 0.73991 |  iteration: 1148 teacher: 0 stage: sketch lr: 0.000201\n",
      "batch 1148 loss: 1.25138 acc: 0.72721 | v_loss: 1.34628 v_acc: 0.74089 |  iteration: 1149 teacher: 1 stage: sketch lr: 0.000201\n",
      "batch 1149 loss: 1.39598 acc: 0.70508 | v_loss: 1.29892 v_acc: 0.71159 |  iteration: 1150 teacher: 0 stage: sketch lr: 0.000201\n",
      "batch 1150 loss: 1.35422 acc: 0.71745 | v_loss: 1.20396 v_acc: 0.73633 |  iteration: 1151 teacher: 1 stage: sketch lr: 0.000201\n",
      "batch 1151 loss: 1.23911 acc: 0.72201 | v_loss: 1.20292 v_acc: 0.73047 |  iteration: 1152 teacher: 1 stage: sketch lr: 0.000201\n",
      "batch 1152 loss: 1.36287 acc: 0.71387 | v_loss: 1.20719 v_acc: 0.75879 |  iteration: 1153 teacher: 1 stage: sketch lr: 0.000201\n",
      "batch 1153 loss: 1.41009 acc: 0.70866 | v_loss: 1.25953 v_acc: 0.73665 |  iteration: 1154 teacher: 1 stage: sketch lr: 0.000202\n",
      "batch 1154 loss: 1.35268 acc: 0.71777 | v_loss: 1.35414 v_acc: 0.72233 |  iteration: 1155 teacher: 1 stage: sketch lr: 0.000202\n",
      "batch 1155 loss: 1.27915 acc: 0.72982 | v_loss: 1.34175 v_acc: 0.71484 |  iteration: 1156 teacher: 1 stage: sketch lr: 0.000202\n",
      "batch 1156 loss: 1.33025 acc: 0.71842 | v_loss: 1.29144 v_acc: 0.72526 |  iteration: 1157 teacher: 1 stage: sketch lr: 0.000202\n",
      "batch 1157 loss: 1.47059 acc: 0.70443 | v_loss: 1.22938 v_acc: 0.75260 |  iteration: 1158 teacher: 0 stage: sketch lr: 0.000202\n",
      "batch 1158 loss: 1.32460 acc: 0.70996 | v_loss: 1.40366 v_acc: 0.71387 |  iteration: 1159 teacher: 1 stage: sketch lr: 0.000202\n",
      "batch 1159 loss: 1.39342 acc: 0.70736 | v_loss: 1.42166 v_acc: 0.70703 |  iteration: 1160 teacher: 0 stage: sketch lr: 0.000203\n",
      "batch 1160 loss: 1.26568 acc: 0.73763 | v_loss: 1.23161 v_acc: 0.73796 |  iteration: 1161 teacher: 1 stage: sketch lr: 0.000203\n",
      "batch 1161 loss: 1.45821 acc: 0.70736 | v_loss: 1.36023 v_acc: 0.72884 |  iteration: 1162 teacher: 1 stage: sketch lr: 0.000203\n",
      "batch 1162 loss: 1.37931 acc: 0.70638 | v_loss: 1.17525 v_acc: 0.74414 |  iteration: 1163 teacher: 1 stage: sketch lr: 0.000203\n",
      "batch 1163 loss: 1.26653 acc: 0.73047 | v_loss: 1.32181 v_acc: 0.72038 |  iteration: 1164 teacher: 0 stage: sketch lr: 0.000203\n",
      "batch 1164 loss: 1.28532 acc: 0.72103 | v_loss: 1.29449 v_acc: 0.73470 |  iteration: 1165 teacher: 0 stage: sketch lr: 0.000204\n",
      "batch 1165 loss: 1.34520 acc: 0.71549 | v_loss: 1.22624 v_acc: 0.74479 |  iteration: 1166 teacher: 0 stage: sketch lr: 0.000204\n",
      "batch 1166 loss: 1.40522 acc: 0.71712 | v_loss: 1.21118 v_acc: 0.74870 |  iteration: 1167 teacher: 1 stage: sketch lr: 0.000204\n",
      "batch 1167 loss: 1.41366 acc: 0.71094 | v_loss: 1.24924 v_acc: 0.72559 |  iteration: 1168 teacher: 1 stage: sketch lr: 0.000204\n",
      "batch 1168 loss: 1.36635 acc: 0.71680 | v_loss: 1.26662 v_acc: 0.73926 |  iteration: 1169 teacher: 0 stage: sketch lr: 0.000204\n",
      "batch 1169 loss: 1.28874 acc: 0.72982 | v_loss: 1.26332 v_acc: 0.74447 |  iteration: 1170 teacher: 1 stage: sketch lr: 0.000204\n",
      "batch 1170 loss: 1.35516 acc: 0.71973 | v_loss: 1.59004 v_acc: 0.68685 |  iteration: 1171 teacher: 1 stage: sketch lr: 0.000205\n",
      "batch 1171 loss: 1.30709 acc: 0.73112 | v_loss: 1.24246 v_acc: 0.73079 |  iteration: 1172 teacher: 0 stage: sketch lr: 0.000205\n",
      "batch 1172 loss: 1.27171 acc: 0.73438 | v_loss: 1.28899 v_acc: 0.73340 |  iteration: 1173 teacher: 1 stage: sketch lr: 0.000205\n",
      "batch 1173 loss: 1.31389 acc: 0.72005 | v_loss: 1.27595 v_acc: 0.74023 |  iteration: 1174 teacher: 0 stage: sketch lr: 0.000205\n",
      "batch 1174 loss: 1.36339 acc: 0.70410 | v_loss: 1.36435 v_acc: 0.73112 |  iteration: 1175 teacher: 1 stage: sketch lr: 0.000205\n",
      "batch 1175 loss: 1.32037 acc: 0.72624 | v_loss: 1.17283 v_acc: 0.75684 |  iteration: 1176 teacher: 0 stage: sketch lr: 0.000205\n",
      "batch 1176 loss: 1.30348 acc: 0.72005 | v_loss: 1.32694 v_acc: 0.72754 |  iteration: 1177 teacher: 1 stage: sketch lr: 0.000206\n",
      "batch 1177 loss: 1.59367 acc: 0.69922 | v_loss: 1.22757 v_acc: 0.73210 |  iteration: 1178 teacher: 1 stage: sketch lr: 0.000206\n",
      "batch 1178 loss: 1.39497 acc: 0.71452 | v_loss: 1.37420 v_acc: 0.72786 |  iteration: 1179 teacher: 1 stage: sketch lr: 0.000206\n",
      "batch 1179 loss: 1.36454 acc: 0.72233 | v_loss: 1.36626 v_acc: 0.72201 |  iteration: 1180 teacher: 1 stage: sketch lr: 0.000206\n",
      "batch 1180 loss: 1.28316 acc: 0.73991 | v_loss: 1.29450 v_acc: 0.72201 |  iteration: 1181 teacher: 0 stage: sketch lr: 0.000206\n",
      "batch 1181 loss: 1.29984 acc: 0.73112 | v_loss: 1.43844 v_acc: 0.71322 |  iteration: 1182 teacher: 0 stage: sketch lr: 0.000206\n",
      "batch 1182 loss: 1.30296 acc: 0.73210 | v_loss: 1.30785 v_acc: 0.72852 |  iteration: 1183 teacher: 1 stage: sketch lr: 0.000207\n",
      "batch 1183 loss: 1.31358 acc: 0.72624 | v_loss: 1.30330 v_acc: 0.72428 |  iteration: 1184 teacher: 1 stage: sketch lr: 0.000207\n",
      "batch 1184 loss: 1.27348 acc: 0.72201 | v_loss: 1.25646 v_acc: 0.72721 |  iteration: 1185 teacher: 0 stage: sketch lr: 0.000207\n",
      "batch 1185 loss: 1.32719 acc: 0.71712 | v_loss: 1.31850 v_acc: 0.73340 |  iteration: 1186 teacher: 0 stage: sketch lr: 0.000207\n",
      "batch 1186 loss: 1.27629 acc: 0.73698 | v_loss: 1.22578 v_acc: 0.74023 |  iteration: 1187 teacher: 1 stage: sketch lr: 0.000207\n",
      "batch 1187 loss: 1.29898 acc: 0.72786 | v_loss: 1.23027 v_acc: 0.73991 |  iteration: 1188 teacher: 1 stage: sketch lr: 0.000208\n",
      "batch 1188 loss: 1.41317 acc: 0.71777 | v_loss: 1.27737 v_acc: 0.73340 |  iteration: 1189 teacher: 0 stage: sketch lr: 0.000208\n",
      "batch 1189 loss: 1.31731 acc: 0.71745 | v_loss: 1.24617 v_acc: 0.72038 |  iteration: 1190 teacher: 1 stage: sketch lr: 0.000208\n",
      "batch 1190 loss: 1.39245 acc: 0.70931 | v_loss: 1.35889 v_acc: 0.72461 |  iteration: 1191 teacher: 0 stage: sketch lr: 0.000208\n",
      "batch 1191 loss: 1.34049 acc: 0.72038 | v_loss: 1.30582 v_acc: 0.72005 |  iteration: 1192 teacher: 0 stage: sketch lr: 0.000208\n",
      "batch 1192 loss: 1.24400 acc: 0.72493 | v_loss: 1.36707 v_acc: 0.72689 |  iteration: 1193 teacher: 0 stage: sketch lr: 0.000208\n",
      "batch 1193 loss: 1.33251 acc: 0.72298 | v_loss: 1.29119 v_acc: 0.73242 |  iteration: 1194 teacher: 0 stage: sketch lr: 0.000209\n",
      "batch 1194 loss: 1.32608 acc: 0.71745 | v_loss: 1.22704 v_acc: 0.72949 |  iteration: 1195 teacher: 1 stage: sketch lr: 0.000209\n",
      "batch 1195 loss: 1.40092 acc: 0.72005 | v_loss: 1.20606 v_acc: 0.75326 |  iteration: 1196 teacher: 1 stage: sketch lr: 0.000209\n",
      "batch 1196 loss: 1.39312 acc: 0.71159 | v_loss: 1.28595 v_acc: 0.73503 |  iteration: 1197 teacher: 0 stage: sketch lr: 0.000209\n",
      "batch 1197 loss: 1.35149 acc: 0.73079 | v_loss: 1.24057 v_acc: 0.76367 |  iteration: 1198 teacher: 1 stage: sketch lr: 0.000209\n",
      "batch 1198 loss: 1.32312 acc: 0.73307 | v_loss: 1.25660 v_acc: 0.72559 |  iteration: 1199 teacher: 1 stage: sketch lr: 0.000209\n",
      "batch 1199 loss: 1.33079 acc: 0.72070 | v_loss: 1.34440 v_acc: 0.71712 |  iteration: 1200 teacher: 1 stage: sketch lr: 0.000210\n",
      "batch 1200 loss: 1.32181 acc: 0.71419 | v_loss: 1.17773 v_acc: 0.73763 |  iteration: 1201 teacher: 1 stage: sketch lr: 0.000210\n",
      "batch 1201 loss: 1.35515 acc: 0.71842 | v_loss: 1.24605 v_acc: 0.74316 |  iteration: 1202 teacher: 1 stage: sketch lr: 0.000210\n",
      "batch 1202 loss: 1.42938 acc: 0.71842 | v_loss: 1.37210 v_acc: 0.71842 |  iteration: 1203 teacher: 1 stage: sketch lr: 0.000210\n",
      "batch 1203 loss: 1.34434 acc: 0.71680 | v_loss: 1.29236 v_acc: 0.74023 |  iteration: 1204 teacher: 1 stage: sketch lr: 0.000210\n",
      "batch 1204 loss: 1.36720 acc: 0.71126 | v_loss: 1.12942 v_acc: 0.75684 |  iteration: 1205 teacher: 1 stage: sketch lr: 0.000211\n",
      "batch 1205 loss: 1.41041 acc: 0.71191 | v_loss: 1.30394 v_acc: 0.71810 |  iteration: 1206 teacher: 0 stage: sketch lr: 0.000211\n",
      "batch 1206 loss: 1.35950 acc: 0.71484 | v_loss: 1.32421 v_acc: 0.73372 |  iteration: 1207 teacher: 1 stage: sketch lr: 0.000211\n",
      "batch 1207 loss: 1.36964 acc: 0.72005 | v_loss: 1.31218 v_acc: 0.73893 |  iteration: 1208 teacher: 1 stage: sketch lr: 0.000211\n",
      "batch 1208 loss: 1.34562 acc: 0.72331 | v_loss: 1.15320 v_acc: 0.74544 |  iteration: 1209 teacher: 1 stage: sketch lr: 0.000211\n",
      "batch 1209 loss: 1.29322 acc: 0.72266 | v_loss: 1.36435 v_acc: 0.71973 |  iteration: 1210 teacher: 0 stage: sketch lr: 0.000211\n",
      "batch 1210 loss: 1.36597 acc: 0.70931 | v_loss: 1.27003 v_acc: 0.72819 |  iteration: 1211 teacher: 1 stage: sketch lr: 0.000212\n",
      "batch 1211 loss: 1.24358 acc: 0.72721 | v_loss: 1.37344 v_acc: 0.71712 |  iteration: 1212 teacher: 1 stage: sketch lr: 0.000212\n",
      "batch 1212 loss: 1.36983 acc: 0.72135 | v_loss: 1.29278 v_acc: 0.73275 |  iteration: 1213 teacher: 0 stage: sketch lr: 0.000212\n",
      "batch 1213 loss: 1.33269 acc: 0.72103 | v_loss: 1.21039 v_acc: 0.74349 |  iteration: 1214 teacher: 1 stage: sketch lr: 0.000212\n",
      "batch 1214 loss: 1.36760 acc: 0.71680 | v_loss: 1.21536 v_acc: 0.73861 |  iteration: 1215 teacher: 0 stage: sketch lr: 0.000212\n",
      "batch 1215 loss: 1.39467 acc: 0.71419 | v_loss: 1.30498 v_acc: 0.72884 |  iteration: 1216 teacher: 1 stage: sketch lr: 0.000212\n",
      "batch 1216 loss: 1.30391 acc: 0.73340 | v_loss: 1.23683 v_acc: 0.73242 |  iteration: 1217 teacher: 0 stage: sketch lr: 0.000213\n",
      "batch 1217 loss: 1.36795 acc: 0.72168 | v_loss: 1.28784 v_acc: 0.72591 |  iteration: 1218 teacher: 0 stage: sketch lr: 0.000213\n",
      "batch 1218 loss: 1.25527 acc: 0.72982 | v_loss: 1.27282 v_acc: 0.73991 |  iteration: 1219 teacher: 1 stage: sketch lr: 0.000213\n",
      "batch 1219 loss: 1.37633 acc: 0.72005 | v_loss: 1.38295 v_acc: 0.72721 |  iteration: 1220 teacher: 1 stage: sketch lr: 0.000213\n",
      "batch 1220 loss: 1.31110 acc: 0.71940 | v_loss: 1.32217 v_acc: 0.71549 |  iteration: 1221 teacher: 0 stage: sketch lr: 0.000213\n",
      "batch 1221 loss: 1.30157 acc: 0.72493 | v_loss: 1.40631 v_acc: 0.70866 |  iteration: 1222 teacher: 1 stage: sketch lr: 0.000213\n",
      "batch 1222 loss: 1.27140 acc: 0.72819 | v_loss: 1.25938 v_acc: 0.71875 |  iteration: 1223 teacher: 0 stage: sketch lr: 0.000214\n",
      "batch 1223 loss: 1.33101 acc: 0.71387 | v_loss: 1.20230 v_acc: 0.73047 |  iteration: 1224 teacher: 0 stage: sketch lr: 0.000214\n",
      "batch 1224 loss: 1.47518 acc: 0.69954 | v_loss: 1.31640 v_acc: 0.72819 |  iteration: 1225 teacher: 0 stage: sketch lr: 0.000214\n",
      "batch 1225 loss: 1.28828 acc: 0.72656 | v_loss: 1.21489 v_acc: 0.74544 |  iteration: 1226 teacher: 1 stage: sketch lr: 0.000214\n",
      "batch 1226 loss: 1.24722 acc: 0.74186 | v_loss: 1.36022 v_acc: 0.71875 |  iteration: 1227 teacher: 0 stage: sketch lr: 0.000214\n",
      "batch 1227 loss: 1.31104 acc: 0.72070 | v_loss: 1.33626 v_acc: 0.72103 |  iteration: 1228 teacher: 0 stage: sketch lr: 0.000215\n",
      "batch 1228 loss: 1.28027 acc: 0.72917 | v_loss: 1.22971 v_acc: 0.73958 |  iteration: 1229 teacher: 1 stage: sketch lr: 0.000215\n",
      "batch 1229 loss: 1.23273 acc: 0.73340 | v_loss: 1.29701 v_acc: 0.72591 |  iteration: 1230 teacher: 0 stage: sketch lr: 0.000215\n",
      "batch 1230 loss: 1.31673 acc: 0.72982 | v_loss: 1.28253 v_acc: 0.73014 |  iteration: 1231 teacher: 0 stage: sketch lr: 0.000215\n",
      "batch 1231 loss: 1.33513 acc: 0.72266 | v_loss: 1.38644 v_acc: 0.73079 |  iteration: 1232 teacher: 0 stage: sketch lr: 0.000215\n",
      "batch 1232 loss: 1.34098 acc: 0.72559 | v_loss: 1.25186 v_acc: 0.74382 |  iteration: 1233 teacher: 1 stage: sketch lr: 0.000215\n",
      "batch 1233 loss: 1.35154 acc: 0.72038 | v_loss: 1.17837 v_acc: 0.74121 |  iteration: 1234 teacher: 1 stage: sketch lr: 0.000216\n",
      "batch 1234 loss: 1.26175 acc: 0.73210 | v_loss: 1.15575 v_acc: 0.74870 |  iteration: 1235 teacher: 0 stage: sketch lr: 0.000216\n",
      "batch 1235 loss: 1.28057 acc: 0.73014 | v_loss: 1.27326 v_acc: 0.73958 |  iteration: 1236 teacher: 1 stage: sketch lr: 0.000216\n",
      "batch 1236 loss: 1.32787 acc: 0.72721 | v_loss: 1.31267 v_acc: 0.72982 |  iteration: 1237 teacher: 1 stage: sketch lr: 0.000216\n",
      "batch 1237 loss: 1.39028 acc: 0.71842 | v_loss: 1.25204 v_acc: 0.72721 |  iteration: 1238 teacher: 0 stage: sketch lr: 0.000216\n",
      "batch 1238 loss: 1.30973 acc: 0.73014 | v_loss: 1.23715 v_acc: 0.74284 |  iteration: 1239 teacher: 0 stage: sketch lr: 0.000216\n",
      "batch 1239 loss: 1.37768 acc: 0.71191 | v_loss: 1.34214 v_acc: 0.73698 |  iteration: 1240 teacher: 1 stage: sketch lr: 0.000217\n",
      "batch 1240 loss: 1.36117 acc: 0.71712 | v_loss: 1.27790 v_acc: 0.71647 |  iteration: 1241 teacher: 0 stage: sketch lr: 0.000217\n",
      "batch 1241 loss: 1.38524 acc: 0.71712 | v_loss: 1.19081 v_acc: 0.74544 |  iteration: 1242 teacher: 1 stage: sketch lr: 0.000217\n",
      "batch 1242 loss: 1.30421 acc: 0.72884 | v_loss: 1.19900 v_acc: 0.73861 |  iteration: 1243 teacher: 0 stage: sketch lr: 0.000217\n",
      "epoch 0 loss: 1.63921 acc: 0.70294 | v_loss: 1.56319 v_acc: 0.71144 \n",
      "epoch: 1\n",
      "__________________________________________\n",
      "batch 0 loss: 1.29710 acc: 0.73307 | v_loss: 1.29817 v_acc: 0.72070 |  iteration: 1244 teacher: 0 stage: sketch lr: 0.000217\n",
      "batch 1 loss: 1.32758 acc: 0.71810 | v_loss: 1.21630 v_acc: 0.73893 |  iteration: 1245 teacher: 0 stage: sketch lr: 0.000217\n",
      "batch 2 loss: 1.43084 acc: 0.72005 | v_loss: 1.30624 v_acc: 0.73470 |  iteration: 1246 teacher: 1 stage: sketch lr: 0.000218\n",
      "batch 3 loss: 1.23609 acc: 0.73958 | v_loss: 1.22902 v_acc: 0.74089 |  iteration: 1247 teacher: 0 stage: sketch lr: 0.000218\n",
      "batch 4 loss: 1.31099 acc: 0.72884 | v_loss: 1.23436 v_acc: 0.74284 |  iteration: 1248 teacher: 1 stage: sketch lr: 0.000218\n",
      "batch 5 loss: 1.30031 acc: 0.72982 | v_loss: 1.31699 v_acc: 0.73568 |  iteration: 1249 teacher: 0 stage: sketch lr: 0.000218\n",
      "batch 6 loss: 1.30174 acc: 0.72754 | v_loss: 1.24135 v_acc: 0.72852 |  iteration: 1250 teacher: 0 stage: sketch lr: 0.000218\n",
      "batch 7 loss: 1.29023 acc: 0.72917 | v_loss: 1.37655 v_acc: 0.71354 |  iteration: 1251 teacher: 1 stage: sketch lr: 0.000219\n",
      "batch 8 loss: 1.33127 acc: 0.72852 | v_loss: 1.33973 v_acc: 0.71159 |  iteration: 1252 teacher: 0 stage: sketch lr: 0.000219\n",
      "batch 9 loss: 1.33265 acc: 0.72233 | v_loss: 1.36724 v_acc: 0.73047 |  iteration: 1253 teacher: 1 stage: sketch lr: 0.000219\n",
      "batch 10 loss: 1.28854 acc: 0.72786 | v_loss: 1.28862 v_acc: 0.73665 |  iteration: 1254 teacher: 1 stage: sketch lr: 0.000219\n",
      "batch 11 loss: 1.31139 acc: 0.72754 | v_loss: 1.21211 v_acc: 0.72917 |  iteration: 1255 teacher: 1 stage: sketch lr: 0.000219\n",
      "batch 12 loss: 1.33346 acc: 0.72266 | v_loss: 1.21837 v_acc: 0.75130 |  iteration: 1256 teacher: 0 stage: sketch lr: 0.000219\n",
      "batch 13 loss: 1.38942 acc: 0.71126 | v_loss: 1.29051 v_acc: 0.73861 |  iteration: 1257 teacher: 1 stage: sketch lr: 0.000220\n",
      "batch 14 loss: 1.29802 acc: 0.73372 | v_loss: 1.26773 v_acc: 0.75391 |  iteration: 1258 teacher: 0 stage: sketch lr: 0.000220\n",
      "batch 15 loss: 1.32161 acc: 0.71810 | v_loss: 1.23481 v_acc: 0.73796 |  iteration: 1259 teacher: 0 stage: sketch lr: 0.000220\n",
      "batch 16 loss: 1.23785 acc: 0.73730 | v_loss: 1.28682 v_acc: 0.73470 |  iteration: 1260 teacher: 0 stage: sketch lr: 0.000220\n",
      "batch 17 loss: 1.39023 acc: 0.70866 | v_loss: 1.16782 v_acc: 0.74349 |  iteration: 1261 teacher: 1 stage: sketch lr: 0.000220\n",
      "batch 18 loss: 1.42846 acc: 0.71452 | v_loss: 1.24814 v_acc: 0.74251 |  iteration: 1262 teacher: 1 stage: sketch lr: 0.000220\n",
      "batch 19 loss: 1.34358 acc: 0.72298 | v_loss: 1.36013 v_acc: 0.71973 |  iteration: 1263 teacher: 0 stage: sketch lr: 0.000221\n",
      "batch 20 loss: 1.22385 acc: 0.73730 | v_loss: 1.28397 v_acc: 0.74121 |  iteration: 1264 teacher: 0 stage: sketch lr: 0.000221\n",
      "batch 21 loss: 1.39996 acc: 0.71517 | v_loss: 1.12633 v_acc: 0.75879 |  iteration: 1265 teacher: 0 stage: sketch lr: 0.000221\n",
      "batch 22 loss: 1.23263 acc: 0.73698 | v_loss: 1.28520 v_acc: 0.72363 |  iteration: 1266 teacher: 1 stage: sketch lr: 0.000221\n",
      "batch 23 loss: 1.27885 acc: 0.72331 | v_loss: 1.30662 v_acc: 0.73568 |  iteration: 1267 teacher: 1 stage: sketch lr: 0.000221\n",
      "batch 24 loss: 1.30401 acc: 0.71322 | v_loss: 1.31803 v_acc: 0.74056 |  iteration: 1268 teacher: 0 stage: sketch lr: 0.000222\n",
      "batch 25 loss: 1.28223 acc: 0.72852 | v_loss: 1.14211 v_acc: 0.74512 |  iteration: 1269 teacher: 1 stage: sketch lr: 0.000222\n",
      "batch 26 loss: 1.33102 acc: 0.72201 | v_loss: 1.33555 v_acc: 0.72591 |  iteration: 1270 teacher: 1 stage: sketch lr: 0.000222\n",
      "batch 27 loss: 1.31157 acc: 0.72266 | v_loss: 1.25494 v_acc: 0.73600 |  iteration: 1271 teacher: 0 stage: sketch lr: 0.000222\n",
      "batch 28 loss: 1.37066 acc: 0.71908 | v_loss: 1.35145 v_acc: 0.72233 |  iteration: 1272 teacher: 0 stage: sketch lr: 0.000222\n",
      "batch 29 loss: 1.34775 acc: 0.72754 | v_loss: 1.27390 v_acc: 0.74121 |  iteration: 1273 teacher: 1 stage: sketch lr: 0.000222\n",
      "batch 30 loss: 1.27703 acc: 0.73438 | v_loss: 1.22049 v_acc: 0.74479 |  iteration: 1274 teacher: 1 stage: sketch lr: 0.000223\n",
      "batch 31 loss: 1.33305 acc: 0.71745 | v_loss: 1.22806 v_acc: 0.73112 |  iteration: 1275 teacher: 1 stage: sketch lr: 0.000223\n",
      "batch 32 loss: 1.40267 acc: 0.72038 | v_loss: 1.29149 v_acc: 0.72135 |  iteration: 1276 teacher: 0 stage: sketch lr: 0.000223\n",
      "batch 33 loss: 1.33195 acc: 0.72103 | v_loss: 1.22932 v_acc: 0.73014 |  iteration: 1277 teacher: 0 stage: sketch lr: 0.000223\n",
      "batch 34 loss: 1.27454 acc: 0.72917 | v_loss: 1.28735 v_acc: 0.71419 |  iteration: 1278 teacher: 0 stage: sketch lr: 0.000223\n",
      "batch 35 loss: 1.30174 acc: 0.73438 | v_loss: 1.26505 v_acc: 0.73796 |  iteration: 1279 teacher: 1 stage: sketch lr: 0.000223\n",
      "batch 36 loss: 1.40176 acc: 0.72493 | v_loss: 1.34692 v_acc: 0.72754 |  iteration: 1280 teacher: 1 stage: sketch lr: 0.000224\n",
      "batch 37 loss: 1.24768 acc: 0.72233 | v_loss: 1.31118 v_acc: 0.71908 |  iteration: 1281 teacher: 1 stage: sketch lr: 0.000224\n",
      "batch 38 loss: 1.24164 acc: 0.73242 | v_loss: 1.39067 v_acc: 0.71517 |  iteration: 1282 teacher: 0 stage: sketch lr: 0.000224\n",
      "batch 39 loss: 1.30684 acc: 0.72689 | v_loss: 1.26621 v_acc: 0.71940 |  iteration: 1283 teacher: 1 stage: sketch lr: 0.000224\n",
      "batch 40 loss: 1.43442 acc: 0.71354 | v_loss: 1.19379 v_acc: 0.72721 |  iteration: 1284 teacher: 1 stage: sketch lr: 0.000224\n",
      "batch 41 loss: 1.22641 acc: 0.74089 | v_loss: 1.31087 v_acc: 0.72559 |  iteration: 1285 teacher: 1 stage: sketch lr: 0.000224\n",
      "batch 42 loss: 1.33011 acc: 0.72005 | v_loss: 1.21097 v_acc: 0.74512 |  iteration: 1286 teacher: 1 stage: sketch lr: 0.000225\n",
      "batch 43 loss: 1.35161 acc: 0.72754 | v_loss: 1.36181 v_acc: 0.72396 |  iteration: 1287 teacher: 1 stage: sketch lr: 0.000225\n",
      "batch 44 loss: 1.38764 acc: 0.72070 | v_loss: 1.32725 v_acc: 0.72493 |  iteration: 1288 teacher: 1 stage: sketch lr: 0.000225\n",
      "batch 45 loss: 1.38676 acc: 0.71908 | v_loss: 1.24468 v_acc: 0.73763 |  iteration: 1289 teacher: 0 stage: sketch lr: 0.000225\n",
      "batch 46 loss: 1.31067 acc: 0.72559 | v_loss: 1.27426 v_acc: 0.73177 |  iteration: 1290 teacher: 0 stage: sketch lr: 0.000225\n",
      "batch 47 loss: 1.26056 acc: 0.73340 | v_loss: 1.27894 v_acc: 0.72786 |  iteration: 1291 teacher: 1 stage: sketch lr: 0.000226\n",
      "batch 48 loss: 1.31350 acc: 0.72493 | v_loss: 1.35718 v_acc: 0.72624 |  iteration: 1292 teacher: 1 stage: sketch lr: 0.000226\n",
      "batch 49 loss: 1.30992 acc: 0.72005 | v_loss: 1.23359 v_acc: 0.75065 |  iteration: 1293 teacher: 1 stage: sketch lr: 0.000226\n",
      "batch 50 loss: 1.26703 acc: 0.73698 | v_loss: 1.17687 v_acc: 0.74121 |  iteration: 1294 teacher: 0 stage: sketch lr: 0.000226\n",
      "batch 51 loss: 1.28521 acc: 0.72266 | v_loss: 1.14509 v_acc: 0.74740 |  iteration: 1295 teacher: 0 stage: sketch lr: 0.000226\n",
      "batch 52 loss: 1.29596 acc: 0.73568 | v_loss: 1.26027 v_acc: 0.73763 |  iteration: 1296 teacher: 0 stage: sketch lr: 0.000226\n",
      "batch 53 loss: 1.24851 acc: 0.73405 | v_loss: 1.29834 v_acc: 0.73438 |  iteration: 1297 teacher: 0 stage: sketch lr: 0.000227\n",
      "batch 54 loss: 1.28614 acc: 0.73177 | v_loss: 1.25260 v_acc: 0.72754 |  iteration: 1298 teacher: 1 stage: sketch lr: 0.000227\n",
      "batch 55 loss: 1.25929 acc: 0.73503 | v_loss: 1.23770 v_acc: 0.73828 |  iteration: 1299 teacher: 1 stage: sketch lr: 0.000227\n",
      "batch 56 loss: 1.37853 acc: 0.71257 | v_loss: 1.32058 v_acc: 0.74414 |  iteration: 1300 teacher: 1 stage: sketch lr: 0.000227\n",
      "batch 57 loss: 1.43642 acc: 0.71126 | v_loss: 1.29491 v_acc: 0.71419 |  iteration: 1301 teacher: 1 stage: sketch lr: 0.000227\n",
      "batch 58 loss: 1.34168 acc: 0.72363 | v_loss: 1.20304 v_acc: 0.74121 |  iteration: 1302 teacher: 0 stage: sketch lr: 0.000227\n",
      "batch 59 loss: 1.39974 acc: 0.71517 | v_loss: 1.18306 v_acc: 0.74284 |  iteration: 1303 teacher: 0 stage: sketch lr: 0.000228\n",
      "batch 60 loss: 1.32715 acc: 0.73210 | v_loss: 1.18356 v_acc: 0.75846 |  iteration: 1304 teacher: 1 stage: sketch lr: 0.000228\n",
      "batch 61 loss: 1.27125 acc: 0.72754 | v_loss: 1.22700 v_acc: 0.74349 |  iteration: 1305 teacher: 1 stage: sketch lr: 0.000228\n",
      "batch 62 loss: 1.32205 acc: 0.72428 | v_loss: 1.33299 v_acc: 0.72591 |  iteration: 1306 teacher: 0 stage: sketch lr: 0.000228\n",
      "batch 63 loss: 1.30178 acc: 0.72786 | v_loss: 1.34378 v_acc: 0.71126 |  iteration: 1307 teacher: 0 stage: sketch lr: 0.000228\n",
      "batch 64 loss: 1.20604 acc: 0.73958 | v_loss: 1.27263 v_acc: 0.73340 |  iteration: 1308 teacher: 1 stage: sketch lr: 0.000228\n",
      "batch 65 loss: 1.25590 acc: 0.72396 | v_loss: 1.20188 v_acc: 0.75586 |  iteration: 1309 teacher: 0 stage: sketch lr: 0.000229\n",
      "batch 66 loss: 1.27026 acc: 0.73307 | v_loss: 1.36600 v_acc: 0.71777 |  iteration: 1310 teacher: 0 stage: sketch lr: 0.000229\n",
      "batch 67 loss: 1.32699 acc: 0.72493 | v_loss: 1.39464 v_acc: 0.71875 |  iteration: 1311 teacher: 0 stage: sketch lr: 0.000229\n",
      "batch 68 loss: 1.37956 acc: 0.71745 | v_loss: 1.21112 v_acc: 0.74023 |  iteration: 1312 teacher: 1 stage: sketch lr: 0.000229\n",
      "batch 69 loss: 1.35993 acc: 0.72363 | v_loss: 1.38496 v_acc: 0.71582 |  iteration: 1313 teacher: 0 stage: sketch lr: 0.000229\n",
      "batch 70 loss: 1.32499 acc: 0.72721 | v_loss: 1.16600 v_acc: 0.74089 |  iteration: 1314 teacher: 1 stage: sketch lr: 0.000230\n",
      "batch 71 loss: 1.37783 acc: 0.71387 | v_loss: 1.31374 v_acc: 0.72233 |  iteration: 1315 teacher: 0 stage: sketch lr: 0.000230\n",
      "batch 72 loss: 1.25039 acc: 0.72624 | v_loss: 1.26519 v_acc: 0.73470 |  iteration: 1316 teacher: 0 stage: sketch lr: 0.000230\n",
      "batch 73 loss: 1.35398 acc: 0.71029 | v_loss: 1.20696 v_acc: 0.74219 |  iteration: 1317 teacher: 0 stage: sketch lr: 0.000230\n",
      "batch 74 loss: 1.41311 acc: 0.71712 | v_loss: 1.20001 v_acc: 0.74935 |  iteration: 1318 teacher: 0 stage: sketch lr: 0.000230\n",
      "batch 75 loss: 1.34201 acc: 0.71908 | v_loss: 1.23443 v_acc: 0.73079 |  iteration: 1319 teacher: 1 stage: sketch lr: 0.000230\n",
      "batch 76 loss: 1.43266 acc: 0.71517 | v_loss: 1.27114 v_acc: 0.73958 |  iteration: 1320 teacher: 1 stage: sketch lr: 0.000231\n",
      "batch 77 loss: 1.29852 acc: 0.72852 | v_loss: 1.24668 v_acc: 0.74382 |  iteration: 1321 teacher: 0 stage: sketch lr: 0.000231\n",
      "batch 78 loss: 1.42569 acc: 0.71387 | v_loss: 1.60695 v_acc: 0.68620 |  iteration: 1322 teacher: 1 stage: sketch lr: 0.000231\n",
      "batch 79 loss: 1.29264 acc: 0.71354 | v_loss: 1.23594 v_acc: 0.72754 |  iteration: 1323 teacher: 0 stage: sketch lr: 0.000231\n",
      "batch 80 loss: 1.28243 acc: 0.73340 | v_loss: 1.27661 v_acc: 0.72982 |  iteration: 1324 teacher: 1 stage: sketch lr: 0.000231\n",
      "batch 81 loss: 1.32797 acc: 0.71973 | v_loss: 1.27157 v_acc: 0.74316 |  iteration: 1325 teacher: 0 stage: sketch lr: 0.000231\n",
      "batch 82 loss: 1.28633 acc: 0.72461 | v_loss: 1.34423 v_acc: 0.73470 |  iteration: 1326 teacher: 1 stage: sketch lr: 0.000232\n",
      "batch 83 loss: 1.38693 acc: 0.70605 | v_loss: 1.15979 v_acc: 0.76042 |  iteration: 1327 teacher: 0 stage: sketch lr: 0.000232\n",
      "batch 84 loss: 1.26989 acc: 0.72754 | v_loss: 1.32977 v_acc: 0.72493 |  iteration: 1328 teacher: 1 stage: sketch lr: 0.000232\n",
      "batch 85 loss: 1.31375 acc: 0.72917 | v_loss: 1.20835 v_acc: 0.73014 |  iteration: 1329 teacher: 0 stage: sketch lr: 0.000232\n",
      "batch 86 loss: 1.26421 acc: 0.73014 | v_loss: 1.33228 v_acc: 0.72884 |  iteration: 1330 teacher: 1 stage: sketch lr: 0.000232\n",
      "batch 87 loss: 1.30036 acc: 0.72819 | v_loss: 1.32889 v_acc: 0.72786 |  iteration: 1331 teacher: 0 stage: sketch lr: 0.000233\n",
      "batch 88 loss: 1.30603 acc: 0.72591 | v_loss: 1.28390 v_acc: 0.72005 |  iteration: 1332 teacher: 1 stage: sketch lr: 0.000233\n",
      "batch 89 loss: 1.25870 acc: 0.72233 | v_loss: 1.42665 v_acc: 0.71094 |  iteration: 1333 teacher: 0 stage: sketch lr: 0.000233\n",
      "batch 90 loss: 1.26057 acc: 0.72949 | v_loss: 1.29170 v_acc: 0.72786 |  iteration: 1334 teacher: 0 stage: sketch lr: 0.000233\n",
      "batch 91 loss: 1.24585 acc: 0.72461 | v_loss: 1.27503 v_acc: 0.72819 |  iteration: 1335 teacher: 1 stage: sketch lr: 0.000233\n",
      "batch 92 loss: 1.31385 acc: 0.73242 | v_loss: 1.20463 v_acc: 0.74056 |  iteration: 1336 teacher: 0 stage: sketch lr: 0.000233\n",
      "batch 93 loss: 1.25002 acc: 0.73340 | v_loss: 1.29382 v_acc: 0.73600 |  iteration: 1337 teacher: 0 stage: sketch lr: 0.000234\n",
      "batch 94 loss: 1.28116 acc: 0.72526 | v_loss: 1.22574 v_acc: 0.73926 |  iteration: 1338 teacher: 1 stage: sketch lr: 0.000234\n",
      "batch 95 loss: 1.29440 acc: 0.72331 | v_loss: 1.21916 v_acc: 0.74219 |  iteration: 1339 teacher: 0 stage: sketch lr: 0.000234\n",
      "batch 96 loss: 1.33353 acc: 0.71842 | v_loss: 1.26745 v_acc: 0.73665 |  iteration: 1340 teacher: 1 stage: sketch lr: 0.000234\n",
      "batch 97 loss: 1.27369 acc: 0.72493 | v_loss: 1.23318 v_acc: 0.72982 |  iteration: 1341 teacher: 1 stage: sketch lr: 0.000234\n",
      "batch 98 loss: 1.31746 acc: 0.71777 | v_loss: 1.36809 v_acc: 0.71940 |  iteration: 1342 teacher: 0 stage: sketch lr: 0.000234\n",
      "batch 99 loss: 1.44886 acc: 0.70931 | v_loss: 1.29294 v_acc: 0.72396 |  iteration: 1343 teacher: 1 stage: sketch lr: 0.000235\n",
      "batch 100 loss: 1.35014 acc: 0.72721 | v_loss: 1.34900 v_acc: 0.72884 |  iteration: 1344 teacher: 1 stage: sketch lr: 0.000235\n",
      "batch 101 loss: 1.33788 acc: 0.72266 | v_loss: 1.28523 v_acc: 0.73600 |  iteration: 1345 teacher: 0 stage: sketch lr: 0.000235\n",
      "batch 102 loss: 1.37586 acc: 0.71908 | v_loss: 1.21096 v_acc: 0.73796 |  iteration: 1346 teacher: 0 stage: sketch lr: 0.000235\n",
      "batch 103 loss: 1.32921 acc: 0.72363 | v_loss: 1.19212 v_acc: 0.76074 |  iteration: 1347 teacher: 0 stage: sketch lr: 0.000235\n",
      "batch 104 loss: 1.25637 acc: 0.72949 | v_loss: 1.28238 v_acc: 0.73796 |  iteration: 1348 teacher: 0 stage: sketch lr: 0.000235\n",
      "batch 105 loss: 1.24654 acc: 0.73079 | v_loss: 1.26660 v_acc: 0.75260 |  iteration: 1349 teacher: 0 stage: sketch lr: 0.000236\n",
      "batch 106 loss: 1.36155 acc: 0.71517 | v_loss: 1.23578 v_acc: 0.73633 |  iteration: 1350 teacher: 0 stage: sketch lr: 0.000236\n",
      "batch 107 loss: 1.32125 acc: 0.72721 | v_loss: 1.29036 v_acc: 0.73079 |  iteration: 1351 teacher: 1 stage: sketch lr: 0.000236\n",
      "batch 108 loss: 1.25212 acc: 0.72786 | v_loss: 1.16741 v_acc: 0.73763 |  iteration: 1352 teacher: 1 stage: sketch lr: 0.000236\n",
      "batch 109 loss: 1.24940 acc: 0.72656 | v_loss: 1.24424 v_acc: 0.74251 |  iteration: 1353 teacher: 1 stage: sketch lr: 0.000236\n",
      "batch 110 loss: 1.31392 acc: 0.72168 | v_loss: 1.36480 v_acc: 0.71777 |  iteration: 1354 teacher: 1 stage: sketch lr: 0.000237\n",
      "batch 111 loss: 1.35910 acc: 0.71908 | v_loss: 1.27433 v_acc: 0.73796 |  iteration: 1355 teacher: 0 stage: sketch lr: 0.000237\n",
      "batch 112 loss: 1.25904 acc: 0.72884 | v_loss: 1.12335 v_acc: 0.76302 |  iteration: 1356 teacher: 1 stage: sketch lr: 0.000237\n",
      "batch 113 loss: 1.32489 acc: 0.72005 | v_loss: 1.27601 v_acc: 0.72656 |  iteration: 1357 teacher: 0 stage: sketch lr: 0.000237\n",
      "batch 114 loss: 1.31440 acc: 0.72038 | v_loss: 1.30304 v_acc: 0.73665 |  iteration: 1358 teacher: 0 stage: sketch lr: 0.000237\n",
      "batch 115 loss: 1.35161 acc: 0.71745 | v_loss: 1.33478 v_acc: 0.72852 |  iteration: 1359 teacher: 1 stage: sketch lr: 0.000237\n",
      "batch 116 loss: 1.43512 acc: 0.71094 | v_loss: 1.12487 v_acc: 0.74837 |  iteration: 1360 teacher: 1 stage: sketch lr: 0.000238\n",
      "batch 117 loss: 1.27129 acc: 0.73893 | v_loss: 1.34163 v_acc: 0.72298 |  iteration: 1361 teacher: 0 stage: sketch lr: 0.000238\n",
      "batch 118 loss: 1.28503 acc: 0.72331 | v_loss: 1.24951 v_acc: 0.73633 |  iteration: 1362 teacher: 0 stage: sketch lr: 0.000238\n",
      "batch 119 loss: 1.32308 acc: 0.71940 | v_loss: 1.34723 v_acc: 0.72591 |  iteration: 1363 teacher: 0 stage: sketch lr: 0.000238\n",
      "batch 120 loss: 1.32480 acc: 0.72201 | v_loss: 1.26939 v_acc: 0.74023 |  iteration: 1364 teacher: 1 stage: sketch lr: 0.000238\n",
      "batch 121 loss: 1.20654 acc: 0.73926 | v_loss: 1.21676 v_acc: 0.74316 |  iteration: 1365 teacher: 0 stage: sketch lr: 0.000238\n",
      "batch 122 loss: 1.32551 acc: 0.72298 | v_loss: 1.20878 v_acc: 0.73568 |  iteration: 1366 teacher: 0 stage: sketch lr: 0.000239\n",
      "batch 123 loss: 1.37009 acc: 0.71810 | v_loss: 1.33943 v_acc: 0.71126 |  iteration: 1367 teacher: 0 stage: sketch lr: 0.000239\n",
      "batch 124 loss: 1.31328 acc: 0.72656 | v_loss: 1.21484 v_acc: 0.73730 |  iteration: 1368 teacher: 1 stage: sketch lr: 0.000239\n",
      "batch 125 loss: 1.31892 acc: 0.72331 | v_loss: 1.28291 v_acc: 0.71452 |  iteration: 1369 teacher: 1 stage: sketch lr: 0.000239\n",
      "batch 126 loss: 1.24670 acc: 0.73405 | v_loss: 1.25885 v_acc: 0.74056 |  iteration: 1370 teacher: 1 stage: sketch lr: 0.000239\n",
      "batch 127 loss: 1.28547 acc: 0.72689 | v_loss: 1.35408 v_acc: 0.72428 |  iteration: 1371 teacher: 1 stage: sketch lr: 0.000240\n",
      "batch 128 loss: 1.37088 acc: 0.72852 | v_loss: 1.30607 v_acc: 0.72070 |  iteration: 1372 teacher: 0 stage: sketch lr: 0.000240\n",
      "batch 129 loss: 1.27571 acc: 0.73014 | v_loss: 1.37752 v_acc: 0.72038 |  iteration: 1373 teacher: 0 stage: sketch lr: 0.000240\n",
      "batch 130 loss: 1.33582 acc: 0.72819 | v_loss: 1.26678 v_acc: 0.72103 |  iteration: 1374 teacher: 1 stage: sketch lr: 0.000240\n",
      "batch 131 loss: 1.29486 acc: 0.72917 | v_loss: 1.17694 v_acc: 0.72786 |  iteration: 1375 teacher: 0 stage: sketch lr: 0.000240\n",
      "batch 132 loss: 1.24496 acc: 0.73470 | v_loss: 1.29784 v_acc: 0.73014 |  iteration: 1376 teacher: 0 stage: sketch lr: 0.000240\n",
      "batch 133 loss: 1.23601 acc: 0.73014 | v_loss: 1.20060 v_acc: 0.75195 |  iteration: 1377 teacher: 1 stage: sketch lr: 0.000241\n",
      "batch 134 loss: 1.31826 acc: 0.72526 | v_loss: 1.36093 v_acc: 0.72135 |  iteration: 1378 teacher: 0 stage: sketch lr: 0.000241\n",
      "batch 135 loss: 1.30920 acc: 0.72624 | v_loss: 1.32347 v_acc: 0.73145 |  iteration: 1379 teacher: 0 stage: sketch lr: 0.000241\n",
      "batch 136 loss: 1.24596 acc: 0.73633 | v_loss: 1.21786 v_acc: 0.73861 |  iteration: 1380 teacher: 1 stage: sketch lr: 0.000241\n",
      "batch 137 loss: 1.24697 acc: 0.74154 | v_loss: 1.27970 v_acc: 0.73047 |  iteration: 1381 teacher: 0 stage: sketch lr: 0.000241\n",
      "batch 138 loss: 1.30949 acc: 0.72819 | v_loss: 1.26516 v_acc: 0.73275 |  iteration: 1382 teacher: 0 stage: sketch lr: 0.000241\n",
      "batch 139 loss: 1.35163 acc: 0.72396 | v_loss: 1.35511 v_acc: 0.73275 |  iteration: 1383 teacher: 0 stage: sketch lr: 0.000242\n",
      "batch 140 loss: 1.29277 acc: 0.72982 | v_loss: 1.22865 v_acc: 0.74967 |  iteration: 1384 teacher: 1 stage: sketch lr: 0.000242\n",
      "batch 141 loss: 1.31574 acc: 0.72819 | v_loss: 1.16060 v_acc: 0.74219 |  iteration: 1385 teacher: 0 stage: sketch lr: 0.000242\n",
      "batch 142 loss: 1.24582 acc: 0.72266 | v_loss: 1.13437 v_acc: 0.75423 |  iteration: 1386 teacher: 1 stage: sketch lr: 0.000242\n",
      "batch 143 loss: 1.31800 acc: 0.72526 | v_loss: 1.24082 v_acc: 0.73861 |  iteration: 1387 teacher: 0 stage: sketch lr: 0.000242\n",
      "batch 144 loss: 1.26864 acc: 0.72656 | v_loss: 1.30172 v_acc: 0.73047 |  iteration: 1388 teacher: 1 stage: sketch lr: 0.000242\n",
      "batch 145 loss: 1.31830 acc: 0.72135 | v_loss: 1.23037 v_acc: 0.73177 |  iteration: 1389 teacher: 0 stage: sketch lr: 0.000243\n",
      "batch 146 loss: 1.29070 acc: 0.73079 | v_loss: 1.21505 v_acc: 0.74154 |  iteration: 1390 teacher: 1 stage: sketch lr: 0.000243\n",
      "batch 147 loss: 1.25844 acc: 0.73210 | v_loss: 1.30015 v_acc: 0.75000 |  iteration: 1391 teacher: 0 stage: sketch lr: 0.000243\n",
      "batch 148 loss: 1.23774 acc: 0.73926 | v_loss: 1.25390 v_acc: 0.72363 |  iteration: 1392 teacher: 1 stage: sketch lr: 0.000243\n",
      "batch 149 loss: 1.34729 acc: 0.72624 | v_loss: 1.16761 v_acc: 0.74544 |  iteration: 1393 teacher: 1 stage: sketch lr: 0.000243\n",
      "batch 150 loss: 1.26564 acc: 0.72852 | v_loss: 1.16599 v_acc: 0.73633 |  iteration: 1394 teacher: 1 stage: sketch lr: 0.000244\n",
      "batch 151 loss: 1.26729 acc: 0.72298 | v_loss: 1.16701 v_acc: 0.76270 |  iteration: 1395 teacher: 1 stage: sketch lr: 0.000244\n",
      "batch 152 loss: 1.26604 acc: 0.73112 | v_loss: 1.20461 v_acc: 0.74740 |  iteration: 1396 teacher: 1 stage: sketch lr: 0.000244\n",
      "batch 153 loss: 1.32081 acc: 0.71810 | v_loss: 1.31808 v_acc: 0.72559 |  iteration: 1397 teacher: 0 stage: sketch lr: 0.000244\n",
      "batch 154 loss: 1.32980 acc: 0.72233 | v_loss: 1.31188 v_acc: 0.71582 |  iteration: 1398 teacher: 0 stage: sketch lr: 0.000244\n",
      "batch 155 loss: 1.29370 acc: 0.72884 | v_loss: 1.24511 v_acc: 0.74023 |  iteration: 1399 teacher: 1 stage: sketch lr: 0.000244\n",
      "batch 156 loss: 1.32256 acc: 0.72754 | v_loss: 1.19858 v_acc: 0.75618 |  iteration: 1400 teacher: 1 stage: sketch lr: 0.000245\n",
      "batch 157 loss: 1.27085 acc: 0.72949 | v_loss: 1.35351 v_acc: 0.72493 |  iteration: 1401 teacher: 0 stage: sketch lr: 0.000245\n",
      "batch 158 loss: 1.33335 acc: 0.72526 | v_loss: 1.37886 v_acc: 0.72038 |  iteration: 1402 teacher: 1 stage: sketch lr: 0.000245\n",
      "batch 159 loss: 1.30967 acc: 0.72461 | v_loss: 1.19938 v_acc: 0.74186 |  iteration: 1403 teacher: 1 stage: sketch lr: 0.000245\n",
      "batch 160 loss: 1.31645 acc: 0.73177 | v_loss: 1.35426 v_acc: 0.72819 |  iteration: 1404 teacher: 0 stage: sketch lr: 0.000245\n",
      "batch 161 loss: 1.21637 acc: 0.73633 | v_loss: 1.14650 v_acc: 0.74805 |  iteration: 1405 teacher: 1 stage: sketch lr: 0.000245\n",
      "batch 162 loss: 1.31105 acc: 0.72526 | v_loss: 1.28238 v_acc: 0.73665 |  iteration: 1406 teacher: 0 stage: sketch lr: 0.000246\n",
      "batch 163 loss: 1.24979 acc: 0.73828 | v_loss: 1.26128 v_acc: 0.73796 |  iteration: 1407 teacher: 1 stage: sketch lr: 0.000246\n",
      "batch 164 loss: 1.31913 acc: 0.72005 | v_loss: 1.20079 v_acc: 0.74935 |  iteration: 1408 teacher: 1 stage: sketch lr: 0.000246\n",
      "batch 165 loss: 1.28076 acc: 0.73503 | v_loss: 1.19206 v_acc: 0.74772 |  iteration: 1409 teacher: 1 stage: sketch lr: 0.000246\n",
      "batch 166 loss: 1.30176 acc: 0.72949 | v_loss: 1.22088 v_acc: 0.72949 |  iteration: 1410 teacher: 0 stage: sketch lr: 0.000246\n",
      "batch 167 loss: 1.32337 acc: 0.73372 | v_loss: 1.23093 v_acc: 0.74609 |  iteration: 1411 teacher: 0 stage: sketch lr: 0.000246\n",
      "batch 168 loss: 1.33403 acc: 0.73047 | v_loss: 1.24646 v_acc: 0.74740 |  iteration: 1412 teacher: 0 stage: sketch lr: 0.000247\n",
      "batch 169 loss: 1.28738 acc: 0.73665 | v_loss: 1.58580 v_acc: 0.69173 |  iteration: 1413 teacher: 0 stage: sketch lr: 0.000247\n",
      "batch 170 loss: 1.36198 acc: 0.72038 | v_loss: 1.20608 v_acc: 0.73210 |  iteration: 1414 teacher: 1 stage: sketch lr: 0.000247\n",
      "batch 171 loss: 1.28748 acc: 0.73210 | v_loss: 1.27352 v_acc: 0.73372 |  iteration: 1415 teacher: 0 stage: sketch lr: 0.000247\n",
      "batch 172 loss: 1.30493 acc: 0.73079 | v_loss: 1.24930 v_acc: 0.75195 |  iteration: 1416 teacher: 1 stage: sketch lr: 0.000247\n",
      "batch 173 loss: 1.26930 acc: 0.73796 | v_loss: 1.34217 v_acc: 0.72982 |  iteration: 1417 teacher: 0 stage: sketch lr: 0.000248\n",
      "batch 174 loss: 1.25652 acc: 0.73470 | v_loss: 1.16052 v_acc: 0.75553 |  iteration: 1418 teacher: 1 stage: sketch lr: 0.000248\n",
      "batch 175 loss: 1.29312 acc: 0.73047 | v_loss: 1.31093 v_acc: 0.72819 |  iteration: 1419 teacher: 1 stage: sketch lr: 0.000248\n",
      "batch 176 loss: 1.25636 acc: 0.73047 | v_loss: 1.20921 v_acc: 0.73372 |  iteration: 1420 teacher: 1 stage: sketch lr: 0.000248\n",
      "batch 177 loss: 1.29955 acc: 0.72721 | v_loss: 1.32441 v_acc: 0.72363 |  iteration: 1421 teacher: 1 stage: sketch lr: 0.000248\n",
      "batch 178 loss: 1.25316 acc: 0.72721 | v_loss: 1.32507 v_acc: 0.72852 |  iteration: 1422 teacher: 0 stage: sketch lr: 0.000248\n",
      "batch 179 loss: 1.23594 acc: 0.73861 | v_loss: 1.28979 v_acc: 0.72721 |  iteration: 1423 teacher: 1 stage: sketch lr: 0.000249\n",
      "batch 180 loss: 1.41632 acc: 0.71647 | v_loss: 1.40947 v_acc: 0.72786 |  iteration: 1424 teacher: 1 stage: sketch lr: 0.000249\n",
      "batch 181 loss: 1.25224 acc: 0.72786 | v_loss: 1.28430 v_acc: 0.73405 |  iteration: 1425 teacher: 1 stage: sketch lr: 0.000249\n",
      "batch 182 loss: 1.25234 acc: 0.73242 | v_loss: 1.26868 v_acc: 0.73177 |  iteration: 1426 teacher: 1 stage: sketch lr: 0.000249\n",
      "batch 183 loss: 1.26463 acc: 0.74251 | v_loss: 1.19674 v_acc: 0.74414 |  iteration: 1427 teacher: 0 stage: sketch lr: 0.000249\n",
      "batch 184 loss: 1.35842 acc: 0.72266 | v_loss: 1.28460 v_acc: 0.74023 |  iteration: 1428 teacher: 1 stage: sketch lr: 0.000249\n",
      "batch 185 loss: 1.26612 acc: 0.73145 | v_loss: 1.19797 v_acc: 0.74316 |  iteration: 1429 teacher: 0 stage: sketch lr: 0.000250\n",
      "batch 186 loss: 1.33183 acc: 0.71940 | v_loss: 1.20621 v_acc: 0.73991 |  iteration: 1430 teacher: 1 stage: sketch lr: 0.000250\n",
      "batch 187 loss: 1.25915 acc: 0.73177 | v_loss: 1.26621 v_acc: 0.73372 |  iteration: 1431 teacher: 0 stage: sketch lr: 0.000250\n",
      "batch 188 loss: 1.28684 acc: 0.72103 | v_loss: 1.23508 v_acc: 0.71842 |  iteration: 1432 teacher: 1 stage: sketch lr: 0.000250\n",
      "batch 189 loss: 1.27772 acc: 0.73177 | v_loss: 1.34911 v_acc: 0.71842 |  iteration: 1433 teacher: 1 stage: sketch lr: 0.000250\n",
      "batch 190 loss: 1.35497 acc: 0.71647 | v_loss: 1.30213 v_acc: 0.72363 |  iteration: 1434 teacher: 1 stage: sketch lr: 0.000251\n",
      "batch 191 loss: 1.38450 acc: 0.71029 | v_loss: 1.32850 v_acc: 0.73535 |  iteration: 1435 teacher: 0 stage: sketch lr: 0.000251\n",
      "batch 192 loss: 1.25354 acc: 0.74544 | v_loss: 1.27773 v_acc: 0.73893 |  iteration: 1436 teacher: 0 stage: sketch lr: 0.000251\n",
      "batch 193 loss: 1.33142 acc: 0.71842 | v_loss: 1.21772 v_acc: 0.73372 |  iteration: 1437 teacher: 1 stage: sketch lr: 0.000251\n",
      "batch 194 loss: 1.29765 acc: 0.72493 | v_loss: 1.17587 v_acc: 0.76107 |  iteration: 1438 teacher: 0 stage: sketch lr: 0.000251\n",
      "batch 195 loss: 1.31777 acc: 0.72591 | v_loss: 1.27298 v_acc: 0.74056 |  iteration: 1439 teacher: 1 stage: sketch lr: 0.000251\n",
      "batch 196 loss: 1.25710 acc: 0.72656 | v_loss: 1.23698 v_acc: 0.75423 |  iteration: 1440 teacher: 0 stage: sketch lr: 0.000252\n",
      "batch 197 loss: 1.26143 acc: 0.72559 | v_loss: 1.22460 v_acc: 0.73535 |  iteration: 1441 teacher: 1 stage: sketch lr: 0.000252\n",
      "batch 198 loss: 1.29405 acc: 0.71549 | v_loss: 1.28917 v_acc: 0.72396 |  iteration: 1442 teacher: 0 stage: sketch lr: 0.000252\n",
      "batch 199 loss: 1.35551 acc: 0.71908 | v_loss: 1.14192 v_acc: 0.74544 |  iteration: 1443 teacher: 1 stage: sketch lr: 0.000252\n",
      "batch 200 loss: 1.32679 acc: 0.72298 | v_loss: 1.20685 v_acc: 0.75488 |  iteration: 1444 teacher: 1 stage: sketch lr: 0.000252\n",
      "batch 201 loss: 1.33068 acc: 0.72331 | v_loss: 1.35041 v_acc: 0.71647 |  iteration: 1445 teacher: 0 stage: sketch lr: 0.000252\n",
      "batch 202 loss: 1.32539 acc: 0.73177 | v_loss: 1.25438 v_acc: 0.73991 |  iteration: 1446 teacher: 1 stage: sketch lr: 0.000253\n",
      "batch 203 loss: 1.30226 acc: 0.73210 | v_loss: 1.12268 v_acc: 0.76335 |  iteration: 1447 teacher: 1 stage: sketch lr: 0.000253\n",
      "batch 204 loss: 1.30924 acc: 0.72852 | v_loss: 1.28131 v_acc: 0.72624 |  iteration: 1448 teacher: 1 stage: sketch lr: 0.000253\n",
      "batch 205 loss: 1.19261 acc: 0.74089 | v_loss: 1.30357 v_acc: 0.73958 |  iteration: 1449 teacher: 1 stage: sketch lr: 0.000253\n",
      "batch 206 loss: 1.33817 acc: 0.71745 | v_loss: 1.35401 v_acc: 0.72982 |  iteration: 1450 teacher: 1 stage: sketch lr: 0.000253\n",
      "batch 207 loss: 1.37561 acc: 0.71842 | v_loss: 1.13241 v_acc: 0.74609 |  iteration: 1451 teacher: 1 stage: sketch lr: 0.000253\n",
      "batch 208 loss: 1.22639 acc: 0.73014 | v_loss: 1.31744 v_acc: 0.73079 |  iteration: 1452 teacher: 1 stage: sketch lr: 0.000254\n",
      "batch 209 loss: 1.35768 acc: 0.72428 | v_loss: 1.23441 v_acc: 0.73600 |  iteration: 1453 teacher: 1 stage: sketch lr: 0.000254\n",
      "batch 210 loss: 1.43519 acc: 0.70931 | v_loss: 1.34283 v_acc: 0.71647 |  iteration: 1454 teacher: 1 stage: sketch lr: 0.000254\n",
      "batch 211 loss: 1.31823 acc: 0.71712 | v_loss: 1.27764 v_acc: 0.73438 |  iteration: 1455 teacher: 0 stage: sketch lr: 0.000254\n",
      "batch 212 loss: 1.33447 acc: 0.71745 | v_loss: 1.21968 v_acc: 0.74284 |  iteration: 1456 teacher: 1 stage: sketch lr: 0.000254\n",
      "batch 213 loss: 1.26171 acc: 0.73372 | v_loss: 1.20420 v_acc: 0.74349 |  iteration: 1457 teacher: 1 stage: sketch lr: 0.000255\n",
      "batch 214 loss: 1.33630 acc: 0.72070 | v_loss: 1.24355 v_acc: 0.73014 |  iteration: 1458 teacher: 1 stage: sketch lr: 0.000255\n",
      "batch 215 loss: 1.26620 acc: 0.71745 | v_loss: 1.20478 v_acc: 0.73796 |  iteration: 1459 teacher: 1 stage: sketch lr: 0.000255\n",
      "batch 216 loss: 1.23069 acc: 0.73145 | v_loss: 1.26515 v_acc: 0.72168 |  iteration: 1460 teacher: 1 stage: sketch lr: 0.000255\n",
      "batch 217 loss: 1.32481 acc: 0.72363 | v_loss: 1.23702 v_acc: 0.74512 |  iteration: 1461 teacher: 0 stage: sketch lr: 0.000255\n",
      "batch 218 loss: 1.22629 acc: 0.73503 | v_loss: 1.34317 v_acc: 0.72038 |  iteration: 1462 teacher: 1 stage: sketch lr: 0.000255\n",
      "batch 219 loss: 1.28182 acc: 0.72917 | v_loss: 1.29844 v_acc: 0.71159 |  iteration: 1463 teacher: 0 stage: sketch lr: 0.000256\n",
      "batch 220 loss: 1.24887 acc: 0.72331 | v_loss: 1.37852 v_acc: 0.71517 |  iteration: 1464 teacher: 1 stage: sketch lr: 0.000256\n",
      "batch 221 loss: 1.28132 acc: 0.73275 | v_loss: 1.25652 v_acc: 0.72982 |  iteration: 1465 teacher: 0 stage: sketch lr: 0.000256\n",
      "batch 222 loss: 1.39249 acc: 0.72168 | v_loss: 1.16971 v_acc: 0.73861 |  iteration: 1466 teacher: 1 stage: sketch lr: 0.000256\n",
      "batch 223 loss: 1.29149 acc: 0.73014 | v_loss: 1.29099 v_acc: 0.73210 |  iteration: 1467 teacher: 0 stage: sketch lr: 0.000256\n",
      "batch 224 loss: 1.28950 acc: 0.72461 | v_loss: 1.19386 v_acc: 0.74414 |  iteration: 1468 teacher: 0 stage: sketch lr: 0.000256\n",
      "batch 225 loss: 1.23917 acc: 0.73438 | v_loss: 1.34819 v_acc: 0.72298 |  iteration: 1469 teacher: 1 stage: sketch lr: 0.000257\n",
      "batch 226 loss: 1.20619 acc: 0.73665 | v_loss: 1.30342 v_acc: 0.72721 |  iteration: 1470 teacher: 0 stage: sketch lr: 0.000257\n",
      "batch 227 loss: 1.33946 acc: 0.72526 | v_loss: 1.21625 v_acc: 0.73893 |  iteration: 1471 teacher: 1 stage: sketch lr: 0.000257\n",
      "batch 228 loss: 1.38204 acc: 0.70671 | v_loss: 1.26731 v_acc: 0.73958 |  iteration: 1472 teacher: 1 stage: sketch lr: 0.000257\n",
      "batch 229 loss: 1.19401 acc: 0.74544 | v_loss: 1.28325 v_acc: 0.72298 |  iteration: 1473 teacher: 0 stage: sketch lr: 0.000257\n",
      "batch 230 loss: 1.30001 acc: 0.72493 | v_loss: 1.34537 v_acc: 0.73503 |  iteration: 1474 teacher: 1 stage: sketch lr: 0.000257\n",
      "batch 231 loss: 1.30846 acc: 0.72266 | v_loss: 1.21712 v_acc: 0.75195 |  iteration: 1475 teacher: 1 stage: sketch lr: 0.000258\n",
      "batch 232 loss: 1.26901 acc: 0.72949 | v_loss: 1.15865 v_acc: 0.74414 |  iteration: 1476 teacher: 1 stage: sketch lr: 0.000258\n",
      "batch 233 loss: 1.30013 acc: 0.73210 | v_loss: 1.11291 v_acc: 0.75228 |  iteration: 1477 teacher: 0 stage: sketch lr: 0.000258\n",
      "batch 234 loss: 1.31340 acc: 0.72624 | v_loss: 1.23272 v_acc: 0.74577 |  iteration: 1478 teacher: 0 stage: sketch lr: 0.000258\n",
      "batch 235 loss: 1.34017 acc: 0.72103 | v_loss: 1.27617 v_acc: 0.73633 |  iteration: 1479 teacher: 0 stage: sketch lr: 0.000258\n",
      "batch 236 loss: 1.27705 acc: 0.72982 | v_loss: 1.24822 v_acc: 0.72656 |  iteration: 1480 teacher: 0 stage: sketch lr: 0.000259\n",
      "batch 237 loss: 1.32598 acc: 0.71908 | v_loss: 1.20376 v_acc: 0.75098 |  iteration: 1481 teacher: 0 stage: sketch lr: 0.000259\n",
      "batch 238 loss: 1.30181 acc: 0.73079 | v_loss: 1.30910 v_acc: 0.74219 |  iteration: 1482 teacher: 0 stage: sketch lr: 0.000259\n",
      "batch 239 loss: 1.36270 acc: 0.71289 | v_loss: 1.24246 v_acc: 0.72070 |  iteration: 1483 teacher: 0 stage: sketch lr: 0.000259\n",
      "batch 240 loss: 1.30660 acc: 0.71647 | v_loss: 1.16169 v_acc: 0.74349 |  iteration: 1484 teacher: 1 stage: sketch lr: 0.000259\n",
      "batch 241 loss: 1.31038 acc: 0.72656 | v_loss: 1.17179 v_acc: 0.74023 |  iteration: 1485 teacher: 0 stage: sketch lr: 0.000259\n",
      "batch 242 loss: 1.37555 acc: 0.71452 | v_loss: 1.17142 v_acc: 0.76432 |  iteration: 1486 teacher: 0 stage: sketch lr: 0.000260\n",
      "batch 243 loss: 1.22001 acc: 0.74414 | v_loss: 1.20225 v_acc: 0.74316 |  iteration: 1487 teacher: 1 stage: sketch lr: 0.000260\n",
      "batch 244 loss: 1.26690 acc: 0.73340 | v_loss: 1.31882 v_acc: 0.72689 |  iteration: 1488 teacher: 0 stage: sketch lr: 0.000260\n",
      "batch 245 loss: 1.29382 acc: 0.72298 | v_loss: 1.30458 v_acc: 0.71810 |  iteration: 1489 teacher: 0 stage: sketch lr: 0.000260\n",
      "batch 246 loss: 1.32712 acc: 0.72819 | v_loss: 1.23960 v_acc: 0.73796 |  iteration: 1490 teacher: 1 stage: sketch lr: 0.000260\n",
      "batch 247 loss: 1.28672 acc: 0.71973 | v_loss: 1.18791 v_acc: 0.76465 |  iteration: 1491 teacher: 0 stage: sketch lr: 0.000260\n",
      "batch 248 loss: 1.36246 acc: 0.72298 | v_loss: 1.33176 v_acc: 0.72298 |  iteration: 1492 teacher: 1 stage: sketch lr: 0.000261\n",
      "batch 249 loss: 1.25429 acc: 0.73307 | v_loss: 1.36849 v_acc: 0.71973 |  iteration: 1493 teacher: 0 stage: sketch lr: 0.000261\n",
      "batch 250 loss: 1.24604 acc: 0.73307 | v_loss: 1.19586 v_acc: 0.75033 |  iteration: 1494 teacher: 1 stage: sketch lr: 0.000261\n",
      "batch 251 loss: 1.29062 acc: 0.72689 | v_loss: 1.33336 v_acc: 0.73503 |  iteration: 1495 teacher: 0 stage: sketch lr: 0.000261\n",
      "batch 252 loss: 1.27725 acc: 0.72689 | v_loss: 1.13715 v_acc: 0.74837 |  iteration: 1496 teacher: 1 stage: sketch lr: 0.000261\n",
      "batch 253 loss: 1.31118 acc: 0.72331 | v_loss: 1.26634 v_acc: 0.73372 |  iteration: 1497 teacher: 1 stage: sketch lr: 0.000262\n",
      "batch 254 loss: 1.25999 acc: 0.72461 | v_loss: 1.25738 v_acc: 0.73568 |  iteration: 1498 teacher: 1 stage: sketch lr: 0.000262\n",
      "batch 255 loss: 1.27264 acc: 0.72428 | v_loss: 1.19460 v_acc: 0.74967 |  iteration: 1499 teacher: 0 stage: sketch lr: 0.000262\n",
      "batch 256 loss: 1.36295 acc: 0.71647 | v_loss: 1.18870 v_acc: 0.74512 |  iteration: 1500 teacher: 0 stage: sketch lr: 0.000262\n",
      "batch 257 loss: 1.36559 acc: 0.71615 | v_loss: 1.21202 v_acc: 0.73438 |  iteration: 1501 teacher: 1 stage: sketch lr: 0.000262\n",
      "batch 258 loss: 1.24715 acc: 0.74316 | v_loss: 1.23050 v_acc: 0.74674 |  iteration: 1502 teacher: 1 stage: sketch lr: 0.000262\n",
      "batch 259 loss: 1.31704 acc: 0.72884 | v_loss: 1.22839 v_acc: 0.74837 |  iteration: 1503 teacher: 0 stage: sketch lr: 0.000263\n",
      "batch 260 loss: 1.30467 acc: 0.72884 | v_loss: 1.56291 v_acc: 0.69173 |  iteration: 1504 teacher: 0 stage: sketch lr: 0.000263\n",
      "batch 261 loss: 1.15406 acc: 0.75195 | v_loss: 1.18820 v_acc: 0.73926 |  iteration: 1505 teacher: 0 stage: sketch lr: 0.000263\n",
      "batch 262 loss: 1.26749 acc: 0.73470 | v_loss: 1.26315 v_acc: 0.73861 |  iteration: 1506 teacher: 0 stage: sketch lr: 0.000263\n",
      "batch 263 loss: 1.26677 acc: 0.73372 | v_loss: 1.23514 v_acc: 0.75163 |  iteration: 1507 teacher: 1 stage: sketch lr: 0.000263\n",
      "batch 264 loss: 1.22276 acc: 0.73796 | v_loss: 1.33579 v_acc: 0.72852 |  iteration: 1508 teacher: 0 stage: sketch lr: 0.000263\n",
      "batch 265 loss: 1.37125 acc: 0.72103 | v_loss: 1.14803 v_acc: 0.75423 |  iteration: 1509 teacher: 0 stage: sketch lr: 0.000264\n",
      "batch 266 loss: 1.19055 acc: 0.74707 | v_loss: 1.30926 v_acc: 0.73014 |  iteration: 1510 teacher: 1 stage: sketch lr: 0.000264\n",
      "batch 267 loss: 1.33517 acc: 0.72331 | v_loss: 1.18419 v_acc: 0.73763 |  iteration: 1511 teacher: 0 stage: sketch lr: 0.000264\n",
      "batch 268 loss: 1.39410 acc: 0.70996 | v_loss: 1.32238 v_acc: 0.72754 |  iteration: 1512 teacher: 0 stage: sketch lr: 0.000264\n",
      "batch 269 loss: 1.25260 acc: 0.73112 | v_loss: 1.30665 v_acc: 0.72917 |  iteration: 1513 teacher: 0 stage: sketch lr: 0.000264\n",
      "batch 270 loss: 1.32654 acc: 0.72493 | v_loss: 1.27669 v_acc: 0.72656 |  iteration: 1514 teacher: 0 stage: sketch lr: 0.000264\n",
      "batch 271 loss: 1.25134 acc: 0.73893 | v_loss: 1.39491 v_acc: 0.72559 |  iteration: 1515 teacher: 0 stage: sketch lr: 0.000265\n",
      "batch 272 loss: 1.29635 acc: 0.73112 | v_loss: 1.25909 v_acc: 0.73763 |  iteration: 1516 teacher: 1 stage: sketch lr: 0.000265\n",
      "batch 273 loss: 1.26458 acc: 0.72852 | v_loss: 1.26187 v_acc: 0.73014 |  iteration: 1517 teacher: 0 stage: sketch lr: 0.000265\n",
      "batch 274 loss: 1.30683 acc: 0.73014 | v_loss: 1.18144 v_acc: 0.74219 |  iteration: 1518 teacher: 0 stage: sketch lr: 0.000265\n",
      "batch 275 loss: 1.24475 acc: 0.72819 | v_loss: 1.26669 v_acc: 0.74577 |  iteration: 1519 teacher: 1 stage: sketch lr: 0.000265\n",
      "batch 276 loss: 1.27406 acc: 0.72819 | v_loss: 1.19057 v_acc: 0.74512 |  iteration: 1520 teacher: 1 stage: sketch lr: 0.000266\n",
      "batch 277 loss: 1.18660 acc: 0.73730 | v_loss: 1.20745 v_acc: 0.74479 |  iteration: 1521 teacher: 0 stage: sketch lr: 0.000266\n",
      "batch 278 loss: 1.23148 acc: 0.72721 | v_loss: 1.26294 v_acc: 0.73698 |  iteration: 1522 teacher: 1 stage: sketch lr: 0.000266\n",
      "batch 279 loss: 1.40986 acc: 0.71680 | v_loss: 1.20355 v_acc: 0.72819 |  iteration: 1523 teacher: 1 stage: sketch lr: 0.000266\n",
      "batch 280 loss: 1.30561 acc: 0.72493 | v_loss: 1.34906 v_acc: 0.71745 |  iteration: 1524 teacher: 1 stage: sketch lr: 0.000266\n",
      "batch 281 loss: 1.26954 acc: 0.72624 | v_loss: 1.28725 v_acc: 0.71908 |  iteration: 1525 teacher: 0 stage: sketch lr: 0.000266\n",
      "batch 282 loss: 1.22890 acc: 0.72949 | v_loss: 1.33268 v_acc: 0.73242 |  iteration: 1526 teacher: 0 stage: sketch lr: 0.000267\n",
      "batch 283 loss: 1.33021 acc: 0.72493 | v_loss: 1.26263 v_acc: 0.73828 |  iteration: 1527 teacher: 1 stage: sketch lr: 0.000267\n",
      "batch 284 loss: 1.34695 acc: 0.71908 | v_loss: 1.19509 v_acc: 0.73372 |  iteration: 1528 teacher: 0 stage: sketch lr: 0.000267\n",
      "batch 285 loss: 1.29906 acc: 0.73014 | v_loss: 1.16820 v_acc: 0.76302 |  iteration: 1529 teacher: 1 stage: sketch lr: 0.000267\n",
      "batch 286 loss: 1.29928 acc: 0.73112 | v_loss: 1.26286 v_acc: 0.73926 |  iteration: 1530 teacher: 1 stage: sketch lr: 0.000267\n",
      "batch 287 loss: 1.23603 acc: 0.73177 | v_loss: 1.26183 v_acc: 0.74609 |  iteration: 1531 teacher: 0 stage: sketch lr: 0.000267\n",
      "batch 288 loss: 1.26979 acc: 0.72884 | v_loss: 1.19723 v_acc: 0.74935 |  iteration: 1532 teacher: 1 stage: sketch lr: 0.000268\n",
      "batch 289 loss: 1.29711 acc: 0.73633 | v_loss: 1.24360 v_acc: 0.74186 |  iteration: 1533 teacher: 0 stage: sketch lr: 0.000268\n",
      "batch 290 loss: 1.18976 acc: 0.74674 | v_loss: 1.11475 v_acc: 0.75000 |  iteration: 1534 teacher: 0 stage: sketch lr: 0.000268\n",
      "batch 291 loss: 1.27830 acc: 0.72819 | v_loss: 1.19030 v_acc: 0.75065 |  iteration: 1535 teacher: 0 stage: sketch lr: 0.000268\n",
      "batch 292 loss: 1.32395 acc: 0.72135 | v_loss: 1.32730 v_acc: 0.71908 |  iteration: 1536 teacher: 1 stage: sketch lr: 0.000268\n",
      "batch 293 loss: 1.29040 acc: 0.72461 | v_loss: 1.24408 v_acc: 0.74447 |  iteration: 1537 teacher: 1 stage: sketch lr: 0.000269\n",
      "batch 294 loss: 1.28421 acc: 0.73340 | v_loss: 1.09828 v_acc: 0.76888 |  iteration: 1538 teacher: 0 stage: sketch lr: 0.000269\n",
      "batch 295 loss: 1.28724 acc: 0.72852 | v_loss: 1.27009 v_acc: 0.72428 |  iteration: 1539 teacher: 1 stage: sketch lr: 0.000269\n",
      "batch 296 loss: 1.35341 acc: 0.71191 | v_loss: 1.27662 v_acc: 0.75033 |  iteration: 1540 teacher: 0 stage: sketch lr: 0.000269\n",
      "batch 297 loss: 1.23416 acc: 0.74023 | v_loss: 1.30184 v_acc: 0.73958 |  iteration: 1541 teacher: 1 stage: sketch lr: 0.000269\n",
      "batch 298 loss: 1.24116 acc: 0.74056 | v_loss: 1.09452 v_acc: 0.75163 |  iteration: 1542 teacher: 0 stage: sketch lr: 0.000269\n",
      "batch 299 loss: 1.28184 acc: 0.73079 | v_loss: 1.30444 v_acc: 0.73926 |  iteration: 1543 teacher: 0 stage: sketch lr: 0.000270\n",
      "batch 300 loss: 1.28530 acc: 0.72819 | v_loss: 1.23471 v_acc: 0.73991 |  iteration: 1544 teacher: 1 stage: sketch lr: 0.000270\n",
      "batch 301 loss: 1.25867 acc: 0.73372 | v_loss: 1.34658 v_acc: 0.72982 |  iteration: 1545 teacher: 1 stage: sketch lr: 0.000270\n",
      "batch 302 loss: 1.27155 acc: 0.72363 | v_loss: 1.23830 v_acc: 0.74349 |  iteration: 1546 teacher: 1 stage: sketch lr: 0.000270\n",
      "batch 303 loss: 1.33542 acc: 0.72005 | v_loss: 1.19379 v_acc: 0.73958 |  iteration: 1547 teacher: 0 stage: sketch lr: 0.000270\n",
      "batch 304 loss: 1.26026 acc: 0.73014 | v_loss: 1.17773 v_acc: 0.74447 |  iteration: 1548 teacher: 1 stage: sketch lr: 0.000270\n",
      "batch 305 loss: 1.33499 acc: 0.71517 | v_loss: 1.21436 v_acc: 0.73340 |  iteration: 1549 teacher: 1 stage: sketch lr: 0.000271\n",
      "batch 306 loss: 1.26500 acc: 0.73763 | v_loss: 1.20479 v_acc: 0.73893 |  iteration: 1550 teacher: 0 stage: sketch lr: 0.000271\n",
      "batch 307 loss: 1.27787 acc: 0.74056 | v_loss: 1.23934 v_acc: 0.72689 |  iteration: 1551 teacher: 1 stage: sketch lr: 0.000271\n",
      "batch 308 loss: 1.35907 acc: 0.72103 | v_loss: 1.24314 v_acc: 0.74772 |  iteration: 1552 teacher: 1 stage: sketch lr: 0.000271\n",
      "batch 309 loss: 1.33764 acc: 0.72233 | v_loss: 1.30499 v_acc: 0.72624 |  iteration: 1553 teacher: 1 stage: sketch lr: 0.000271\n",
      "batch 310 loss: 1.36211 acc: 0.73275 | v_loss: 1.25615 v_acc: 0.72884 |  iteration: 1554 teacher: 0 stage: sketch lr: 0.000271\n",
      "batch 311 loss: 1.20504 acc: 0.74609 | v_loss: 1.36948 v_acc: 0.71875 |  iteration: 1555 teacher: 0 stage: sketch lr: 0.000272\n",
      "batch 312 loss: 1.25867 acc: 0.73796 | v_loss: 1.23449 v_acc: 0.73047 |  iteration: 1556 teacher: 0 stage: sketch lr: 0.000272\n",
      "batch 313 loss: 1.28795 acc: 0.72884 | v_loss: 1.15190 v_acc: 0.73405 |  iteration: 1557 teacher: 1 stage: sketch lr: 0.000272\n",
      "batch 314 loss: 1.28334 acc: 0.73275 | v_loss: 1.29065 v_acc: 0.73470 |  iteration: 1558 teacher: 0 stage: sketch lr: 0.000272\n",
      "batch 315 loss: 1.28035 acc: 0.73079 | v_loss: 1.18204 v_acc: 0.75358 |  iteration: 1559 teacher: 0 stage: sketch lr: 0.000272\n",
      "batch 316 loss: 1.29342 acc: 0.73535 | v_loss: 1.33623 v_acc: 0.72038 |  iteration: 1560 teacher: 0 stage: sketch lr: 0.000273\n",
      "batch 317 loss: 1.36509 acc: 0.71777 | v_loss: 1.30596 v_acc: 0.72786 |  iteration: 1561 teacher: 1 stage: sketch lr: 0.000273\n",
      "batch 318 loss: 1.25251 acc: 0.73503 | v_loss: 1.21950 v_acc: 0.74577 |  iteration: 1562 teacher: 0 stage: sketch lr: 0.000273\n",
      "batch 319 loss: 1.35418 acc: 0.72852 | v_loss: 1.25094 v_acc: 0.73568 |  iteration: 1563 teacher: 0 stage: sketch lr: 0.000273\n",
      "batch 320 loss: 1.33313 acc: 0.71517 | v_loss: 1.24694 v_acc: 0.73600 |  iteration: 1564 teacher: 0 stage: sketch lr: 0.000273\n",
      "batch 321 loss: 1.29136 acc: 0.73340 | v_loss: 1.32932 v_acc: 0.73438 |  iteration: 1565 teacher: 0 stage: sketch lr: 0.000273\n",
      "batch 322 loss: 1.35417 acc: 0.72559 | v_loss: 1.20354 v_acc: 0.75033 |  iteration: 1566 teacher: 0 stage: sketch lr: 0.000274\n",
      "batch 323 loss: 1.29692 acc: 0.73014 | v_loss: 1.15179 v_acc: 0.74382 |  iteration: 1567 teacher: 0 stage: sketch lr: 0.000274\n",
      "batch 324 loss: 1.36416 acc: 0.71289 | v_loss: 1.10891 v_acc: 0.75358 |  iteration: 1568 teacher: 1 stage: sketch lr: 0.000274\n",
      "batch 325 loss: 1.31013 acc: 0.72461 | v_loss: 1.20893 v_acc: 0.74186 |  iteration: 1569 teacher: 0 stage: sketch lr: 0.000274\n",
      "batch 326 loss: 1.28448 acc: 0.71908 | v_loss: 1.27227 v_acc: 0.73307 |  iteration: 1570 teacher: 0 stage: sketch lr: 0.000274\n",
      "batch 327 loss: 1.32330 acc: 0.72591 | v_loss: 1.22026 v_acc: 0.73600 |  iteration: 1571 teacher: 1 stage: sketch lr: 0.000274\n",
      "batch 328 loss: 1.23717 acc: 0.73926 | v_loss: 1.19529 v_acc: 0.74837 |  iteration: 1572 teacher: 0 stage: sketch lr: 0.000275\n",
      "batch 329 loss: 1.26327 acc: 0.73340 | v_loss: 1.29725 v_acc: 0.74349 |  iteration: 1573 teacher: 0 stage: sketch lr: 0.000275\n",
      "batch 330 loss: 1.33603 acc: 0.72135 | v_loss: 1.24149 v_acc: 0.72591 |  iteration: 1574 teacher: 0 stage: sketch lr: 0.000275\n",
      "batch 331 loss: 1.24243 acc: 0.73145 | v_loss: 1.16111 v_acc: 0.74805 |  iteration: 1575 teacher: 0 stage: sketch lr: 0.000275\n",
      "batch 332 loss: 1.26586 acc: 0.73568 | v_loss: 1.14763 v_acc: 0.74479 |  iteration: 1576 teacher: 1 stage: sketch lr: 0.000275\n",
      "batch 333 loss: 1.24299 acc: 0.74089 | v_loss: 1.15268 v_acc: 0.76497 |  iteration: 1577 teacher: 0 stage: sketch lr: 0.000275\n",
      "batch 334 loss: 1.26375 acc: 0.73438 | v_loss: 1.18943 v_acc: 0.75684 |  iteration: 1578 teacher: 0 stage: sketch lr: 0.000276\n",
      "batch 335 loss: 1.17513 acc: 0.73926 | v_loss: 1.32061 v_acc: 0.72721 |  iteration: 1579 teacher: 1 stage: sketch lr: 0.000276\n",
      "batch 336 loss: 1.21147 acc: 0.73079 | v_loss: 1.31109 v_acc: 0.71224 |  iteration: 1580 teacher: 1 stage: sketch lr: 0.000276\n",
      "batch 337 loss: 1.21923 acc: 0.74740 | v_loss: 1.23715 v_acc: 0.74121 |  iteration: 1581 teacher: 0 stage: sketch lr: 0.000276\n",
      "batch 338 loss: 1.29487 acc: 0.72331 | v_loss: 1.18616 v_acc: 0.75814 |  iteration: 1582 teacher: 1 stage: sketch lr: 0.000276\n",
      "batch 339 loss: 1.21407 acc: 0.74186 | v_loss: 1.32090 v_acc: 0.72298 |  iteration: 1583 teacher: 1 stage: sketch lr: 0.000277\n",
      "batch 340 loss: 1.25215 acc: 0.73275 | v_loss: 1.36329 v_acc: 0.71582 |  iteration: 1584 teacher: 1 stage: sketch lr: 0.000277\n",
      "batch 341 loss: 1.23448 acc: 0.73926 | v_loss: 1.17964 v_acc: 0.74935 |  iteration: 1585 teacher: 0 stage: sketch lr: 0.000277\n",
      "batch 342 loss: 1.21660 acc: 0.74349 | v_loss: 1.32541 v_acc: 0.73438 |  iteration: 1586 teacher: 1 stage: sketch lr: 0.000277\n",
      "batch 343 loss: 1.29999 acc: 0.72559 | v_loss: 1.12190 v_acc: 0.74967 |  iteration: 1587 teacher: 1 stage: sketch lr: 0.000277\n",
      "batch 344 loss: 1.25938 acc: 0.72461 | v_loss: 1.25623 v_acc: 0.73633 |  iteration: 1588 teacher: 1 stage: sketch lr: 0.000277\n",
      "batch 345 loss: 1.28708 acc: 0.72982 | v_loss: 1.23538 v_acc: 0.74414 |  iteration: 1589 teacher: 1 stage: sketch lr: 0.000278\n",
      "batch 346 loss: 1.30831 acc: 0.74154 | v_loss: 1.20300 v_acc: 0.75423 |  iteration: 1590 teacher: 0 stage: sketch lr: 0.000278\n",
      "batch 347 loss: 1.28564 acc: 0.72884 | v_loss: 1.17700 v_acc: 0.74870 |  iteration: 1591 teacher: 1 stage: sketch lr: 0.000278\n",
      "batch 348 loss: 1.20864 acc: 0.73145 | v_loss: 1.19618 v_acc: 0.73535 |  iteration: 1592 teacher: 0 stage: sketch lr: 0.000278\n",
      "batch 349 loss: 1.23780 acc: 0.72852 | v_loss: 1.21935 v_acc: 0.74642 |  iteration: 1593 teacher: 1 stage: sketch lr: 0.000278\n",
      "batch 350 loss: 1.25307 acc: 0.73600 | v_loss: 1.20166 v_acc: 0.75618 |  iteration: 1594 teacher: 1 stage: sketch lr: 0.000278\n",
      "batch 351 loss: 1.30122 acc: 0.73145 | v_loss: 1.53648 v_acc: 0.70085 |  iteration: 1595 teacher: 1 stage: sketch lr: 0.000279\n",
      "batch 352 loss: 1.26146 acc: 0.73047 | v_loss: 1.17977 v_acc: 0.73633 |  iteration: 1596 teacher: 1 stage: sketch lr: 0.000279\n",
      "batch 353 loss: 1.28402 acc: 0.72331 | v_loss: 1.25328 v_acc: 0.73991 |  iteration: 1597 teacher: 0 stage: sketch lr: 0.000279\n",
      "batch 354 loss: 1.20942 acc: 0.74447 | v_loss: 1.23484 v_acc: 0.75033 |  iteration: 1598 teacher: 0 stage: sketch lr: 0.000279\n",
      "batch 355 loss: 1.39822 acc: 0.70964 | v_loss: 1.33239 v_acc: 0.73210 |  iteration: 1599 teacher: 0 stage: sketch lr: 0.000279\n",
      "batch 356 loss: 1.24582 acc: 0.73340 | v_loss: 1.12582 v_acc: 0.76790 |  iteration: 1600 teacher: 0 stage: sketch lr: 0.000280\n",
      "batch 357 loss: 1.23978 acc: 0.74219 | v_loss: 1.28958 v_acc: 0.73210 |  iteration: 1601 teacher: 0 stage: sketch lr: 0.000280\n",
      "batch 358 loss: 1.29687 acc: 0.73340 | v_loss: 1.18042 v_acc: 0.74349 |  iteration: 1602 teacher: 1 stage: sketch lr: 0.000280\n",
      "batch 359 loss: 1.25869 acc: 0.73275 | v_loss: 1.30280 v_acc: 0.72917 |  iteration: 1603 teacher: 0 stage: sketch lr: 0.000280\n",
      "batch 360 loss: 1.22286 acc: 0.74316 | v_loss: 1.29874 v_acc: 0.72754 |  iteration: 1604 teacher: 1 stage: sketch lr: 0.000280\n",
      "batch 361 loss: 1.19023 acc: 0.74447 | v_loss: 1.26483 v_acc: 0.72624 |  iteration: 1605 teacher: 0 stage: sketch lr: 0.000280\n",
      "batch 362 loss: 1.33784 acc: 0.71842 | v_loss: 1.38533 v_acc: 0.71875 |  iteration: 1606 teacher: 0 stage: sketch lr: 0.000281\n",
      "batch 363 loss: 1.23403 acc: 0.73828 | v_loss: 1.25676 v_acc: 0.73763 |  iteration: 1607 teacher: 0 stage: sketch lr: 0.000281\n",
      "batch 364 loss: 1.27564 acc: 0.74056 | v_loss: 1.25905 v_acc: 0.72624 |  iteration: 1608 teacher: 1 stage: sketch lr: 0.000281\n",
      "batch 365 loss: 1.27015 acc: 0.73372 | v_loss: 1.18417 v_acc: 0.74642 |  iteration: 1609 teacher: 0 stage: sketch lr: 0.000281\n",
      "batch 366 loss: 1.19268 acc: 0.74870 | v_loss: 1.26791 v_acc: 0.74056 |  iteration: 1610 teacher: 0 stage: sketch lr: 0.000281\n",
      "batch 367 loss: 1.29688 acc: 0.72917 | v_loss: 1.19864 v_acc: 0.74479 |  iteration: 1611 teacher: 0 stage: sketch lr: 0.000281\n",
      "batch 368 loss: 1.30250 acc: 0.72331 | v_loss: 1.19081 v_acc: 0.74544 |  iteration: 1612 teacher: 1 stage: sketch lr: 0.000282\n",
      "batch 369 loss: 1.27717 acc: 0.73503 | v_loss: 1.24470 v_acc: 0.74251 |  iteration: 1613 teacher: 1 stage: sketch lr: 0.000282\n",
      "batch 370 loss: 1.25013 acc: 0.73926 | v_loss: 1.21261 v_acc: 0.72493 |  iteration: 1614 teacher: 1 stage: sketch lr: 0.000282\n",
      "batch 371 loss: 1.29920 acc: 0.73568 | v_loss: 1.32067 v_acc: 0.72331 |  iteration: 1615 teacher: 1 stage: sketch lr: 0.000282\n",
      "batch 372 loss: 1.24655 acc: 0.73503 | v_loss: 1.28515 v_acc: 0.72591 |  iteration: 1616 teacher: 0 stage: sketch lr: 0.000282\n",
      "batch 373 loss: 1.28102 acc: 0.73535 | v_loss: 1.31200 v_acc: 0.74121 |  iteration: 1617 teacher: 1 stage: sketch lr: 0.000282\n",
      "batch 374 loss: 1.29888 acc: 0.73275 | v_loss: 1.25133 v_acc: 0.73991 |  iteration: 1618 teacher: 0 stage: sketch lr: 0.000283\n",
      "batch 375 loss: 1.29990 acc: 0.73665 | v_loss: 1.18823 v_acc: 0.73503 |  iteration: 1619 teacher: 1 stage: sketch lr: 0.000283\n",
      "batch 376 loss: 1.32917 acc: 0.71908 | v_loss: 1.16519 v_acc: 0.76009 |  iteration: 1620 teacher: 0 stage: sketch lr: 0.000283\n",
      "batch 377 loss: 1.31482 acc: 0.72233 | v_loss: 1.24917 v_acc: 0.73665 |  iteration: 1621 teacher: 0 stage: sketch lr: 0.000283\n",
      "batch 378 loss: 1.23233 acc: 0.73210 | v_loss: 1.23238 v_acc: 0.75326 |  iteration: 1622 teacher: 1 stage: sketch lr: 0.000283\n",
      "batch 379 loss: 1.31363 acc: 0.72396 | v_loss: 1.18753 v_acc: 0.74284 |  iteration: 1623 teacher: 1 stage: sketch lr: 0.000284\n",
      "batch 380 loss: 1.29272 acc: 0.73730 | v_loss: 1.25041 v_acc: 0.73893 |  iteration: 1624 teacher: 0 stage: sketch lr: 0.000284\n",
      "batch 381 loss: 1.24936 acc: 0.73503 | v_loss: 1.12490 v_acc: 0.75130 |  iteration: 1625 teacher: 1 stage: sketch lr: 0.000284\n",
      "batch 382 loss: 1.23560 acc: 0.73958 | v_loss: 1.19337 v_acc: 0.75228 |  iteration: 1626 teacher: 0 stage: sketch lr: 0.000284\n",
      "batch 383 loss: 1.23986 acc: 0.73796 | v_loss: 1.32569 v_acc: 0.72038 |  iteration: 1627 teacher: 0 stage: sketch lr: 0.000284\n",
      "batch 384 loss: 1.26971 acc: 0.72721 | v_loss: 1.23804 v_acc: 0.74642 |  iteration: 1628 teacher: 1 stage: sketch lr: 0.000284\n",
      "batch 385 loss: 1.20152 acc: 0.73405 | v_loss: 1.09075 v_acc: 0.76855 |  iteration: 1629 teacher: 0 stage: sketch lr: 0.000285\n",
      "batch 386 loss: 1.14628 acc: 0.75130 | v_loss: 1.27214 v_acc: 0.72689 |  iteration: 1630 teacher: 1 stage: sketch lr: 0.000285\n",
      "batch 387 loss: 1.24885 acc: 0.73438 | v_loss: 1.25568 v_acc: 0.75293 |  iteration: 1631 teacher: 0 stage: sketch lr: 0.000285\n",
      "batch 388 loss: 1.27292 acc: 0.73079 | v_loss: 1.29805 v_acc: 0.74674 |  iteration: 1632 teacher: 0 stage: sketch lr: 0.000285\n",
      "batch 389 loss: 1.21587 acc: 0.73861 | v_loss: 1.10523 v_acc: 0.75618 |  iteration: 1633 teacher: 1 stage: sketch lr: 0.000285\n",
      "batch 390 loss: 1.22925 acc: 0.73893 | v_loss: 1.30525 v_acc: 0.73503 |  iteration: 1634 teacher: 0 stage: sketch lr: 0.000285\n",
      "batch 391 loss: 1.27292 acc: 0.73600 | v_loss: 1.22778 v_acc: 0.74154 |  iteration: 1635 teacher: 1 stage: sketch lr: 0.000286\n",
      "batch 392 loss: 1.25382 acc: 0.72689 | v_loss: 1.33345 v_acc: 0.72363 |  iteration: 1636 teacher: 1 stage: sketch lr: 0.000286\n",
      "batch 393 loss: 1.23224 acc: 0.73828 | v_loss: 1.23698 v_acc: 0.74056 |  iteration: 1637 teacher: 1 stage: sketch lr: 0.000286\n",
      "batch 394 loss: 1.25281 acc: 0.73535 | v_loss: 1.16616 v_acc: 0.74805 |  iteration: 1638 teacher: 1 stage: sketch lr: 0.000286\n",
      "batch 395 loss: 1.32524 acc: 0.71582 | v_loss: 1.17090 v_acc: 0.74121 |  iteration: 1639 teacher: 1 stage: sketch lr: 0.000286\n",
      "batch 396 loss: 1.27703 acc: 0.72559 | v_loss: 1.24078 v_acc: 0.72949 |  iteration: 1640 teacher: 1 stage: sketch lr: 0.000286\n",
      "batch 397 loss: 1.29556 acc: 0.73470 | v_loss: 1.18893 v_acc: 0.74186 |  iteration: 1641 teacher: 1 stage: sketch lr: 0.000287\n",
      "batch 398 loss: 1.24979 acc: 0.72689 | v_loss: 1.22096 v_acc: 0.72852 |  iteration: 1642 teacher: 1 stage: sketch lr: 0.000287\n",
      "batch 399 loss: 1.20996 acc: 0.72884 | v_loss: 1.23526 v_acc: 0.74414 |  iteration: 1643 teacher: 1 stage: sketch lr: 0.000287\n",
      "batch 400 loss: 1.32901 acc: 0.72331 | v_loss: 1.29297 v_acc: 0.73047 |  iteration: 1644 teacher: 1 stage: sketch lr: 0.000287\n",
      "batch 401 loss: 1.24670 acc: 0.74056 | v_loss: 1.24937 v_acc: 0.73210 |  iteration: 1645 teacher: 1 stage: sketch lr: 0.000287\n",
      "batch 402 loss: 1.23404 acc: 0.74284 | v_loss: 1.32859 v_acc: 0.72754 |  iteration: 1646 teacher: 1 stage: sketch lr: 0.000288\n",
      "batch 403 loss: 1.23919 acc: 0.73698 | v_loss: 1.22539 v_acc: 0.73242 |  iteration: 1647 teacher: 1 stage: sketch lr: 0.000288\n",
      "batch 404 loss: 1.18592 acc: 0.74219 | v_loss: 1.13775 v_acc: 0.74121 |  iteration: 1648 teacher: 0 stage: sketch lr: 0.000288\n",
      "batch 405 loss: 1.16863 acc: 0.74316 | v_loss: 1.27219 v_acc: 0.73600 |  iteration: 1649 teacher: 0 stage: sketch lr: 0.000288\n",
      "batch 406 loss: 1.18517 acc: 0.75130 | v_loss: 1.15931 v_acc: 0.75846 |  iteration: 1650 teacher: 0 stage: sketch lr: 0.000288\n",
      "batch 407 loss: 1.33334 acc: 0.72656 | v_loss: 1.32096 v_acc: 0.72721 |  iteration: 1651 teacher: 1 stage: sketch lr: 0.000288\n",
      "batch 408 loss: 1.26305 acc: 0.72493 | v_loss: 1.28781 v_acc: 0.73177 |  iteration: 1652 teacher: 0 stage: sketch lr: 0.000289\n",
      "batch 409 loss: 1.23143 acc: 0.73828 | v_loss: 1.20539 v_acc: 0.74935 |  iteration: 1653 teacher: 1 stage: sketch lr: 0.000289\n",
      "batch 410 loss: 1.26918 acc: 0.73893 | v_loss: 1.24491 v_acc: 0.73047 |  iteration: 1654 teacher: 1 stage: sketch lr: 0.000289\n",
      "batch 411 loss: 1.34077 acc: 0.72428 | v_loss: 1.23982 v_acc: 0.73405 |  iteration: 1655 teacher: 0 stage: sketch lr: 0.000289\n",
      "batch 412 loss: 1.24630 acc: 0.73763 | v_loss: 1.30929 v_acc: 0.73991 |  iteration: 1656 teacher: 0 stage: sketch lr: 0.000289\n",
      "batch 413 loss: 1.28318 acc: 0.72852 | v_loss: 1.19557 v_acc: 0.75260 |  iteration: 1657 teacher: 0 stage: sketch lr: 0.000289\n",
      "batch 414 loss: 1.27841 acc: 0.74056 | v_loss: 1.13639 v_acc: 0.74674 |  iteration: 1658 teacher: 0 stage: sketch lr: 0.000290\n",
      "batch 415 loss: 1.37119 acc: 0.71419 | v_loss: 1.08505 v_acc: 0.76074 |  iteration: 1659 teacher: 0 stage: sketch lr: 0.000290\n",
      "batch 416 loss: 1.31393 acc: 0.73503 | v_loss: 1.18899 v_acc: 0.74512 |  iteration: 1660 teacher: 1 stage: sketch lr: 0.000290\n",
      "batch 417 loss: 1.28036 acc: 0.73535 | v_loss: 1.27025 v_acc: 0.73503 |  iteration: 1661 teacher: 0 stage: sketch lr: 0.000290\n",
      "batch 418 loss: 1.28144 acc: 0.72819 | v_loss: 1.22469 v_acc: 0.72949 |  iteration: 1662 teacher: 1 stage: sketch lr: 0.000290\n",
      "batch 419 loss: 1.18857 acc: 0.74023 | v_loss: 1.20153 v_acc: 0.74642 |  iteration: 1663 teacher: 1 stage: sketch lr: 0.000291\n",
      "batch 420 loss: 1.25344 acc: 0.73340 | v_loss: 1.29758 v_acc: 0.74479 |  iteration: 1664 teacher: 0 stage: sketch lr: 0.000291\n",
      "batch 421 loss: 1.20716 acc: 0.72884 | v_loss: 1.23533 v_acc: 0.72819 |  iteration: 1665 teacher: 1 stage: sketch lr: 0.000291\n",
      "batch 422 loss: 1.28488 acc: 0.72135 | v_loss: 1.15678 v_acc: 0.74479 |  iteration: 1666 teacher: 1 stage: sketch lr: 0.000291\n",
      "batch 423 loss: 1.30754 acc: 0.72819 | v_loss: 1.14590 v_acc: 0.74479 |  iteration: 1667 teacher: 1 stage: sketch lr: 0.000291\n",
      "batch 424 loss: 1.31254 acc: 0.73242 | v_loss: 1.15860 v_acc: 0.76270 |  iteration: 1668 teacher: 0 stage: sketch lr: 0.000291\n",
      "batch 425 loss: 1.21708 acc: 0.73991 | v_loss: 1.17986 v_acc: 0.75000 |  iteration: 1669 teacher: 0 stage: sketch lr: 0.000292\n",
      "batch 426 loss: 1.18514 acc: 0.74023 | v_loss: 1.30554 v_acc: 0.72819 |  iteration: 1670 teacher: 1 stage: sketch lr: 0.000292\n",
      "batch 427 loss: 1.19016 acc: 0.74902 | v_loss: 1.30851 v_acc: 0.71289 |  iteration: 1671 teacher: 1 stage: sketch lr: 0.000292\n",
      "batch 428 loss: 1.25925 acc: 0.73991 | v_loss: 1.22973 v_acc: 0.73014 |  iteration: 1672 teacher: 1 stage: sketch lr: 0.000292\n",
      "batch 429 loss: 1.32904 acc: 0.72559 | v_loss: 1.16915 v_acc: 0.75846 |  iteration: 1673 teacher: 0 stage: sketch lr: 0.000292\n",
      "batch 430 loss: 1.25478 acc: 0.72786 | v_loss: 1.30700 v_acc: 0.72461 |  iteration: 1674 teacher: 1 stage: sketch lr: 0.000292\n",
      "batch 431 loss: 1.16116 acc: 0.74089 | v_loss: 1.35644 v_acc: 0.71940 |  iteration: 1675 teacher: 1 stage: sketch lr: 0.000293\n",
      "batch 432 loss: 1.28503 acc: 0.72493 | v_loss: 1.17811 v_acc: 0.74544 |  iteration: 1676 teacher: 1 stage: sketch lr: 0.000293\n",
      "batch 433 loss: 1.35791 acc: 0.72624 | v_loss: 1.31529 v_acc: 0.73177 |  iteration: 1677 teacher: 0 stage: sketch lr: 0.000293\n",
      "batch 434 loss: 1.26447 acc: 0.73568 | v_loss: 1.13204 v_acc: 0.74121 |  iteration: 1678 teacher: 0 stage: sketch lr: 0.000293\n",
      "batch 435 loss: 1.26810 acc: 0.72917 | v_loss: 1.24356 v_acc: 0.74154 |  iteration: 1679 teacher: 0 stage: sketch lr: 0.000293\n",
      "batch 436 loss: 1.26874 acc: 0.73438 | v_loss: 1.22966 v_acc: 0.74284 |  iteration: 1680 teacher: 0 stage: sketch lr: 0.000293\n",
      "batch 437 loss: 1.25883 acc: 0.73698 | v_loss: 1.18632 v_acc: 0.74805 |  iteration: 1681 teacher: 1 stage: sketch lr: 0.000294\n",
      "batch 438 loss: 1.31026 acc: 0.72461 | v_loss: 1.16768 v_acc: 0.75065 |  iteration: 1682 teacher: 0 stage: sketch lr: 0.000294\n",
      "batch 439 loss: 1.21692 acc: 0.74544 | v_loss: 1.20927 v_acc: 0.72624 |  iteration: 1683 teacher: 1 stage: sketch lr: 0.000294\n",
      "batch 440 loss: 1.23247 acc: 0.73568 | v_loss: 1.22136 v_acc: 0.74837 |  iteration: 1684 teacher: 1 stage: sketch lr: 0.000294\n",
      "batch 441 loss: 1.24425 acc: 0.73568 | v_loss: 1.20868 v_acc: 0.75098 |  iteration: 1685 teacher: 1 stage: sketch lr: 0.000294\n",
      "batch 442 loss: 1.19810 acc: 0.74902 | v_loss: 1.53597 v_acc: 0.69922 |  iteration: 1686 teacher: 0 stage: sketch lr: 0.000295\n",
      "batch 443 loss: 1.32391 acc: 0.72721 | v_loss: 1.18968 v_acc: 0.73828 |  iteration: 1687 teacher: 1 stage: sketch lr: 0.000295\n",
      "batch 444 loss: 1.31341 acc: 0.71908 | v_loss: 1.25935 v_acc: 0.73438 |  iteration: 1688 teacher: 0 stage: sketch lr: 0.000295\n",
      "batch 445 loss: 1.32746 acc: 0.71354 | v_loss: 1.23119 v_acc: 0.75326 |  iteration: 1689 teacher: 0 stage: sketch lr: 0.000295\n",
      "batch 446 loss: 1.17974 acc: 0.75065 | v_loss: 1.33056 v_acc: 0.73079 |  iteration: 1690 teacher: 0 stage: sketch lr: 0.000295\n",
      "batch 447 loss: 1.22946 acc: 0.74805 | v_loss: 1.11902 v_acc: 0.76921 |  iteration: 1691 teacher: 0 stage: sketch lr: 0.000295\n",
      "batch 448 loss: 1.24024 acc: 0.73958 | v_loss: 1.29398 v_acc: 0.73470 |  iteration: 1692 teacher: 0 stage: sketch lr: 0.000296\n",
      "batch 449 loss: 1.32692 acc: 0.72135 | v_loss: 1.18871 v_acc: 0.73633 |  iteration: 1693 teacher: 0 stage: sketch lr: 0.000296\n",
      "batch 450 loss: 1.27550 acc: 0.73763 | v_loss: 1.32193 v_acc: 0.72266 |  iteration: 1694 teacher: 0 stage: sketch lr: 0.000296\n",
      "batch 451 loss: 1.32159 acc: 0.71940 | v_loss: 1.30248 v_acc: 0.72884 |  iteration: 1695 teacher: 0 stage: sketch lr: 0.000296\n",
      "batch 452 loss: 1.23372 acc: 0.72884 | v_loss: 1.27887 v_acc: 0.72526 |  iteration: 1696 teacher: 1 stage: sketch lr: 0.000296\n",
      "batch 453 loss: 1.25786 acc: 0.73861 | v_loss: 1.38081 v_acc: 0.71810 |  iteration: 1697 teacher: 0 stage: sketch lr: 0.000296\n",
      "batch 454 loss: 1.27582 acc: 0.73796 | v_loss: 1.26239 v_acc: 0.73242 |  iteration: 1698 teacher: 1 stage: sketch lr: 0.000297\n",
      "batch 455 loss: 1.25492 acc: 0.73047 | v_loss: 1.24784 v_acc: 0.73210 |  iteration: 1699 teacher: 0 stage: sketch lr: 0.000297\n",
      "batch 456 loss: 1.27172 acc: 0.73372 | v_loss: 1.17413 v_acc: 0.74447 |  iteration: 1700 teacher: 1 stage: sketch lr: 0.000297\n",
      "batch 457 loss: 1.20250 acc: 0.74284 | v_loss: 1.27009 v_acc: 0.74414 |  iteration: 1701 teacher: 0 stage: sketch lr: 0.000297\n",
      "batch 458 loss: 1.22373 acc: 0.73535 | v_loss: 1.20072 v_acc: 0.74186 |  iteration: 1702 teacher: 1 stage: sketch lr: 0.000297\n",
      "batch 459 loss: 1.26877 acc: 0.73079 | v_loss: 1.19999 v_acc: 0.74674 |  iteration: 1703 teacher: 0 stage: sketch lr: 0.000298\n",
      "batch 460 loss: 1.32262 acc: 0.72884 | v_loss: 1.24791 v_acc: 0.74121 |  iteration: 1704 teacher: 0 stage: sketch lr: 0.000298\n",
      "batch 461 loss: 1.30679 acc: 0.71745 | v_loss: 1.20215 v_acc: 0.72982 |  iteration: 1705 teacher: 0 stage: sketch lr: 0.000298\n",
      "batch 462 loss: 1.25697 acc: 0.73079 | v_loss: 1.34389 v_acc: 0.71452 |  iteration: 1706 teacher: 1 stage: sketch lr: 0.000298\n",
      "batch 463 loss: 1.31005 acc: 0.73600 | v_loss: 1.27137 v_acc: 0.73275 |  iteration: 1707 teacher: 0 stage: sketch lr: 0.000298\n",
      "batch 464 loss: 1.27491 acc: 0.72624 | v_loss: 1.29733 v_acc: 0.73503 |  iteration: 1708 teacher: 1 stage: sketch lr: 0.000298\n",
      "batch 465 loss: 1.23485 acc: 0.73503 | v_loss: 1.25445 v_acc: 0.74219 |  iteration: 1709 teacher: 1 stage: sketch lr: 0.000299\n",
      "batch 466 loss: 1.27468 acc: 0.73177 | v_loss: 1.19073 v_acc: 0.73633 |  iteration: 1710 teacher: 1 stage: sketch lr: 0.000299\n",
      "batch 467 loss: 1.19718 acc: 0.74056 | v_loss: 1.14573 v_acc: 0.76400 |  iteration: 1711 teacher: 0 stage: sketch lr: 0.000299\n",
      "batch 468 loss: 1.25175 acc: 0.72689 | v_loss: 1.24551 v_acc: 0.74186 |  iteration: 1712 teacher: 1 stage: sketch lr: 0.000299\n",
      "batch 469 loss: 1.26002 acc: 0.73275 | v_loss: 1.23527 v_acc: 0.75423 |  iteration: 1713 teacher: 1 stage: sketch lr: 0.000299\n",
      "batch 470 loss: 1.30568 acc: 0.73405 | v_loss: 1.18453 v_acc: 0.75065 |  iteration: 1714 teacher: 1 stage: sketch lr: 0.000299\n",
      "batch 471 loss: 1.27578 acc: 0.73340 | v_loss: 1.25062 v_acc: 0.74089 |  iteration: 1715 teacher: 1 stage: sketch lr: 0.000300\n",
      "batch 472 loss: 1.20423 acc: 0.74251 | v_loss: 1.11219 v_acc: 0.74609 |  iteration: 1716 teacher: 0 stage: sketch lr: 0.000300\n",
      "batch 473 loss: 1.24425 acc: 0.74186 | v_loss: 1.18452 v_acc: 0.75618 |  iteration: 1717 teacher: 1 stage: sketch lr: 0.000300\n",
      "batch 474 loss: 1.23061 acc: 0.73796 | v_loss: 1.32323 v_acc: 0.71810 |  iteration: 1718 teacher: 1 stage: sketch lr: 0.000300\n",
      "batch 475 loss: 1.15993 acc: 0.75456 | v_loss: 1.21575 v_acc: 0.74707 |  iteration: 1719 teacher: 0 stage: sketch lr: 0.000300\n",
      "batch 476 loss: 1.26042 acc: 0.73470 | v_loss: 1.08072 v_acc: 0.77148 |  iteration: 1720 teacher: 1 stage: sketch lr: 0.000300\n",
      "batch 477 loss: 1.26674 acc: 0.73242 | v_loss: 1.26034 v_acc: 0.73372 |  iteration: 1721 teacher: 0 stage: sketch lr: 0.000301\n",
      "batch 478 loss: 1.21467 acc: 0.73470 | v_loss: 1.25695 v_acc: 0.75098 |  iteration: 1722 teacher: 1 stage: sketch lr: 0.000301\n",
      "batch 479 loss: 1.26386 acc: 0.73503 | v_loss: 1.30813 v_acc: 0.73763 |  iteration: 1723 teacher: 0 stage: sketch lr: 0.000301\n",
      "batch 480 loss: 1.25847 acc: 0.72754 | v_loss: 1.09925 v_acc: 0.75228 |  iteration: 1724 teacher: 0 stage: sketch lr: 0.000301\n",
      "batch 481 loss: 1.21899 acc: 0.73307 | v_loss: 1.30087 v_acc: 0.73600 |  iteration: 1725 teacher: 1 stage: sketch lr: 0.000301\n",
      "batch 482 loss: 1.25043 acc: 0.72493 | v_loss: 1.22799 v_acc: 0.73665 |  iteration: 1726 teacher: 1 stage: sketch lr: 0.000302\n",
      "batch 483 loss: 1.22011 acc: 0.72949 | v_loss: 1.32533 v_acc: 0.72819 |  iteration: 1727 teacher: 0 stage: sketch lr: 0.000302\n",
      "batch 484 loss: 1.33512 acc: 0.72819 | v_loss: 1.23340 v_acc: 0.73958 |  iteration: 1728 teacher: 0 stage: sketch lr: 0.000302\n",
      "batch 485 loss: 1.25337 acc: 0.73828 | v_loss: 1.16239 v_acc: 0.74870 |  iteration: 1729 teacher: 0 stage: sketch lr: 0.000302\n",
      "batch 486 loss: 1.15426 acc: 0.74674 | v_loss: 1.16298 v_acc: 0.75163 |  iteration: 1730 teacher: 1 stage: sketch lr: 0.000302\n",
      "batch 487 loss: 1.32618 acc: 0.71452 | v_loss: 1.22736 v_acc: 0.72819 |  iteration: 1731 teacher: 0 stage: sketch lr: 0.000302\n",
      "batch 488 loss: 1.32232 acc: 0.72266 | v_loss: 1.17872 v_acc: 0.73926 |  iteration: 1732 teacher: 0 stage: sketch lr: 0.000303\n",
      "batch 489 loss: 1.27473 acc: 0.73405 | v_loss: 1.23159 v_acc: 0.72754 |  iteration: 1733 teacher: 0 stage: sketch lr: 0.000303\n",
      "batch 490 loss: 1.25970 acc: 0.72917 | v_loss: 1.22816 v_acc: 0.74967 |  iteration: 1734 teacher: 0 stage: sketch lr: 0.000303\n",
      "batch 491 loss: 1.32054 acc: 0.72721 | v_loss: 1.29104 v_acc: 0.73340 |  iteration: 1735 teacher: 1 stage: sketch lr: 0.000303\n",
      "batch 492 loss: 1.31347 acc: 0.72526 | v_loss: 1.24446 v_acc: 0.72493 |  iteration: 1736 teacher: 1 stage: sketch lr: 0.000303\n",
      "batch 493 loss: 1.20438 acc: 0.73893 | v_loss: 1.33667 v_acc: 0.72428 |  iteration: 1737 teacher: 0 stage: sketch lr: 0.000303\n",
      "batch 494 loss: 1.29950 acc: 0.73112 | v_loss: 1.22919 v_acc: 0.72786 |  iteration: 1738 teacher: 1 stage: sketch lr: 0.000304\n",
      "batch 495 loss: 1.19215 acc: 0.73828 | v_loss: 1.13818 v_acc: 0.73926 |  iteration: 1739 teacher: 0 stage: sketch lr: 0.000304\n",
      "batch 496 loss: 1.28332 acc: 0.73340 | v_loss: 1.26946 v_acc: 0.73275 |  iteration: 1740 teacher: 1 stage: sketch lr: 0.000304\n",
      "batch 497 loss: 1.22792 acc: 0.74219 | v_loss: 1.15849 v_acc: 0.75553 |  iteration: 1741 teacher: 0 stage: sketch lr: 0.000304\n",
      "batch 498 loss: 1.24532 acc: 0.73275 | v_loss: 1.31493 v_acc: 0.72461 |  iteration: 1742 teacher: 1 stage: sketch lr: 0.000304\n",
      "batch 499 loss: 1.26281 acc: 0.73665 | v_loss: 1.27915 v_acc: 0.72721 |  iteration: 1743 teacher: 1 stage: sketch lr: 0.000304\n",
      "batch 500 loss: 1.25274 acc: 0.73112 | v_loss: 1.20937 v_acc: 0.74772 |  iteration: 1744 teacher: 1 stage: sketch lr: 0.000305\n",
      "batch 501 loss: 1.24943 acc: 0.72656 | v_loss: 1.23772 v_acc: 0.73828 |  iteration: 1745 teacher: 1 stage: sketch lr: 0.000305\n",
      "batch 502 loss: 1.22499 acc: 0.73828 | v_loss: 1.24115 v_acc: 0.73014 |  iteration: 1746 teacher: 1 stage: sketch lr: 0.000305\n",
      "batch 503 loss: 1.16704 acc: 0.74707 | v_loss: 1.31598 v_acc: 0.73861 |  iteration: 1747 teacher: 1 stage: sketch lr: 0.000305\n",
      "batch 504 loss: 1.30619 acc: 0.72949 | v_loss: 1.17662 v_acc: 0.75879 |  iteration: 1748 teacher: 0 stage: sketch lr: 0.000305\n",
      "batch 505 loss: 1.19907 acc: 0.74349 | v_loss: 1.13660 v_acc: 0.74479 |  iteration: 1749 teacher: 1 stage: sketch lr: 0.000306\n",
      "batch 506 loss: 1.22793 acc: 0.72884 | v_loss: 1.09394 v_acc: 0.75521 |  iteration: 1750 teacher: 1 stage: sketch lr: 0.000306\n",
      "batch 507 loss: 1.20403 acc: 0.73730 | v_loss: 1.18479 v_acc: 0.74544 |  iteration: 1751 teacher: 1 stage: sketch lr: 0.000306\n",
      "batch 508 loss: 1.30132 acc: 0.73079 | v_loss: 1.26439 v_acc: 0.73861 |  iteration: 1752 teacher: 1 stage: sketch lr: 0.000306\n",
      "batch 509 loss: 1.27843 acc: 0.72917 | v_loss: 1.21630 v_acc: 0.72819 |  iteration: 1753 teacher: 1 stage: sketch lr: 0.000306\n",
      "batch 510 loss: 1.30459 acc: 0.72754 | v_loss: 1.19082 v_acc: 0.74544 |  iteration: 1754 teacher: 0 stage: sketch lr: 0.000306\n",
      "batch 511 loss: 1.20161 acc: 0.74609 | v_loss: 1.28111 v_acc: 0.74805 |  iteration: 1755 teacher: 0 stage: sketch lr: 0.000307\n",
      "batch 512 loss: 1.25206 acc: 0.73828 | v_loss: 1.21349 v_acc: 0.72819 |  iteration: 1756 teacher: 1 stage: sketch lr: 0.000307\n",
      "batch 513 loss: 1.29949 acc: 0.72298 | v_loss: 1.16592 v_acc: 0.74186 |  iteration: 1757 teacher: 1 stage: sketch lr: 0.000307\n",
      "batch 514 loss: 1.29098 acc: 0.72396 | v_loss: 1.13302 v_acc: 0.74414 |  iteration: 1758 teacher: 1 stage: sketch lr: 0.000307\n",
      "batch 515 loss: 1.27139 acc: 0.72689 | v_loss: 1.14675 v_acc: 0.75293 |  iteration: 1759 teacher: 0 stage: sketch lr: 0.000307\n",
      "batch 516 loss: 1.23239 acc: 0.72852 | v_loss: 1.17025 v_acc: 0.75098 |  iteration: 1760 teacher: 0 stage: sketch lr: 0.000307\n",
      "batch 517 loss: 1.32397 acc: 0.72982 | v_loss: 1.30246 v_acc: 0.73112 |  iteration: 1761 teacher: 0 stage: sketch lr: 0.000308\n",
      "batch 518 loss: 1.26636 acc: 0.72884 | v_loss: 1.29185 v_acc: 0.72005 |  iteration: 1762 teacher: 1 stage: sketch lr: 0.000308\n",
      "batch 519 loss: 1.29950 acc: 0.72493 | v_loss: 1.22033 v_acc: 0.74251 |  iteration: 1763 teacher: 1 stage: sketch lr: 0.000308\n",
      "batch 520 loss: 1.25991 acc: 0.74023 | v_loss: 1.16883 v_acc: 0.76693 |  iteration: 1764 teacher: 1 stage: sketch lr: 0.000308\n",
      "batch 521 loss: 1.26931 acc: 0.73698 | v_loss: 1.27721 v_acc: 0.72526 |  iteration: 1765 teacher: 0 stage: sketch lr: 0.000308\n",
      "batch 522 loss: 1.33484 acc: 0.72135 | v_loss: 1.35290 v_acc: 0.71908 |  iteration: 1766 teacher: 0 stage: sketch lr: 0.000309\n",
      "batch 523 loss: 1.35263 acc: 0.71810 | v_loss: 1.18512 v_acc: 0.74349 |  iteration: 1767 teacher: 1 stage: sketch lr: 0.000309\n",
      "batch 524 loss: 1.25733 acc: 0.72754 | v_loss: 1.29697 v_acc: 0.73405 |  iteration: 1768 teacher: 1 stage: sketch lr: 0.000309\n",
      "batch 525 loss: 1.28183 acc: 0.73079 | v_loss: 1.11211 v_acc: 0.75618 |  iteration: 1769 teacher: 1 stage: sketch lr: 0.000309\n",
      "batch 526 loss: 1.25964 acc: 0.73372 | v_loss: 1.24150 v_acc: 0.73275 |  iteration: 1770 teacher: 0 stage: sketch lr: 0.000309\n",
      "batch 527 loss: 1.20226 acc: 0.74447 | v_loss: 1.21501 v_acc: 0.74870 |  iteration: 1771 teacher: 1 stage: sketch lr: 0.000309\n",
      "batch 528 loss: 1.10840 acc: 0.74772 | v_loss: 1.18001 v_acc: 0.75163 |  iteration: 1772 teacher: 0 stage: sketch lr: 0.000310\n",
      "batch 529 loss: 1.32452 acc: 0.73470 | v_loss: 1.17238 v_acc: 0.74967 |  iteration: 1773 teacher: 1 stage: sketch lr: 0.000310\n",
      "batch 530 loss: 1.25017 acc: 0.74447 | v_loss: 1.18915 v_acc: 0.73828 |  iteration: 1774 teacher: 1 stage: sketch lr: 0.000310\n",
      "batch 531 loss: 1.27056 acc: 0.73014 | v_loss: 1.21461 v_acc: 0.75521 |  iteration: 1775 teacher: 0 stage: sketch lr: 0.000310\n",
      "batch 532 loss: 1.20469 acc: 0.74316 | v_loss: 1.21684 v_acc: 0.74544 |  iteration: 1776 teacher: 1 stage: sketch lr: 0.000310\n",
      "batch 533 loss: 1.22081 acc: 0.73503 | v_loss: 1.52692 v_acc: 0.69466 |  iteration: 1777 teacher: 1 stage: sketch lr: 0.000310\n",
      "batch 534 loss: 1.30214 acc: 0.72396 | v_loss: 1.16449 v_acc: 0.74544 |  iteration: 1778 teacher: 0 stage: sketch lr: 0.000311\n",
      "batch 535 loss: 1.23526 acc: 0.73600 | v_loss: 1.24985 v_acc: 0.74316 |  iteration: 1779 teacher: 1 stage: sketch lr: 0.000311\n",
      "batch 536 loss: 1.33763 acc: 0.72949 | v_loss: 1.22259 v_acc: 0.75098 |  iteration: 1780 teacher: 1 stage: sketch lr: 0.000311\n",
      "batch 537 loss: 1.23460 acc: 0.73828 | v_loss: 1.32146 v_acc: 0.73633 |  iteration: 1781 teacher: 0 stage: sketch lr: 0.000311\n",
      "batch 538 loss: 1.20889 acc: 0.74121 | v_loss: 1.11957 v_acc: 0.76400 |  iteration: 1782 teacher: 1 stage: sketch lr: 0.000311\n",
      "batch 539 loss: 1.20208 acc: 0.73665 | v_loss: 1.29908 v_acc: 0.73730 |  iteration: 1783 teacher: 0 stage: sketch lr: 0.000311\n",
      "batch 540 loss: 1.31771 acc: 0.73405 | v_loss: 1.17437 v_acc: 0.74089 |  iteration: 1784 teacher: 0 stage: sketch lr: 0.000312\n",
      "batch 541 loss: 1.23676 acc: 0.73047 | v_loss: 1.30437 v_acc: 0.73047 |  iteration: 1785 teacher: 1 stage: sketch lr: 0.000312\n",
      "batch 542 loss: 1.35336 acc: 0.73014 | v_loss: 1.28224 v_acc: 0.73079 |  iteration: 1786 teacher: 0 stage: sketch lr: 0.000312\n",
      "batch 543 loss: 1.28007 acc: 0.72493 | v_loss: 1.24506 v_acc: 0.73275 |  iteration: 1787 teacher: 0 stage: sketch lr: 0.000312\n",
      "batch 544 loss: 1.26914 acc: 0.72721 | v_loss: 1.37871 v_acc: 0.72135 |  iteration: 1788 teacher: 0 stage: sketch lr: 0.000312\n",
      "batch 545 loss: 1.32187 acc: 0.71875 | v_loss: 1.24153 v_acc: 0.73535 |  iteration: 1789 teacher: 0 stage: sketch lr: 0.000313\n",
      "batch 546 loss: 1.37283 acc: 0.72266 | v_loss: 1.24484 v_acc: 0.72852 |  iteration: 1790 teacher: 1 stage: sketch lr: 0.000313\n",
      "batch 547 loss: 1.19688 acc: 0.73242 | v_loss: 1.14727 v_acc: 0.75586 |  iteration: 1791 teacher: 0 stage: sketch lr: 0.000313\n",
      "batch 548 loss: 1.30741 acc: 0.72266 | v_loss: 1.24719 v_acc: 0.74479 |  iteration: 1792 teacher: 0 stage: sketch lr: 0.000313\n",
      "batch 549 loss: 1.30967 acc: 0.72754 | v_loss: 1.18487 v_acc: 0.74382 |  iteration: 1793 teacher: 0 stage: sketch lr: 0.000313\n",
      "batch 550 loss: 1.25627 acc: 0.73372 | v_loss: 1.16938 v_acc: 0.75814 |  iteration: 1794 teacher: 1 stage: sketch lr: 0.000313\n",
      "batch 551 loss: 1.22148 acc: 0.73633 | v_loss: 1.24009 v_acc: 0.74186 |  iteration: 1795 teacher: 0 stage: sketch lr: 0.000314\n",
      "batch 552 loss: 1.21652 acc: 0.73730 | v_loss: 1.20742 v_acc: 0.73633 |  iteration: 1796 teacher: 1 stage: sketch lr: 0.000314\n",
      "batch 553 loss: 1.27404 acc: 0.72624 | v_loss: 1.32614 v_acc: 0.72135 |  iteration: 1797 teacher: 1 stage: sketch lr: 0.000314\n",
      "batch 554 loss: 1.28728 acc: 0.72754 | v_loss: 1.28521 v_acc: 0.72428 |  iteration: 1798 teacher: 0 stage: sketch lr: 0.000314\n",
      "batch 555 loss: 1.27998 acc: 0.72721 | v_loss: 1.29211 v_acc: 0.73633 |  iteration: 1799 teacher: 1 stage: sketch lr: 0.000314\n",
      "batch 556 loss: 1.28004 acc: 0.73145 | v_loss: 1.24498 v_acc: 0.74544 |  iteration: 1800 teacher: 0 stage: sketch lr: 0.000314\n",
      "batch 557 loss: 1.33856 acc: 0.72168 | v_loss: 1.17355 v_acc: 0.73405 |  iteration: 1801 teacher: 1 stage: sketch lr: 0.000315\n",
      "batch 558 loss: 1.25021 acc: 0.73145 | v_loss: 1.14280 v_acc: 0.77116 |  iteration: 1802 teacher: 0 stage: sketch lr: 0.000315\n",
      "batch 559 loss: 1.28723 acc: 0.73079 | v_loss: 1.24349 v_acc: 0.74544 |  iteration: 1803 teacher: 1 stage: sketch lr: 0.000315\n",
      "batch 560 loss: 1.28782 acc: 0.73958 | v_loss: 1.23632 v_acc: 0.76432 |  iteration: 1804 teacher: 1 stage: sketch lr: 0.000315\n",
      "batch 561 loss: 1.26893 acc: 0.72852 | v_loss: 1.18786 v_acc: 0.74414 |  iteration: 1805 teacher: 1 stage: sketch lr: 0.000315\n",
      "batch 562 loss: 1.35080 acc: 0.72070 | v_loss: 1.24298 v_acc: 0.74089 |  iteration: 1806 teacher: 1 stage: sketch lr: 0.000315\n",
      "batch 563 loss: 1.23126 acc: 0.73568 | v_loss: 1.09268 v_acc: 0.75618 |  iteration: 1807 teacher: 0 stage: sketch lr: 0.000316\n",
      "batch 564 loss: 1.21031 acc: 0.74349 | v_loss: 1.17723 v_acc: 0.75618 |  iteration: 1808 teacher: 1 stage: sketch lr: 0.000316\n",
      "batch 565 loss: 1.23092 acc: 0.73861 | v_loss: 1.29948 v_acc: 0.71940 |  iteration: 1809 teacher: 0 stage: sketch lr: 0.000316\n",
      "batch 566 loss: 1.31647 acc: 0.73145 | v_loss: 1.23391 v_acc: 0.74772 |  iteration: 1810 teacher: 1 stage: sketch lr: 0.000316\n",
      "batch 567 loss: 1.29839 acc: 0.71680 | v_loss: 1.09843 v_acc: 0.77051 |  iteration: 1811 teacher: 0 stage: sketch lr: 0.000316\n",
      "batch 568 loss: 1.24079 acc: 0.73275 | v_loss: 1.27520 v_acc: 0.72559 |  iteration: 1812 teacher: 0 stage: sketch lr: 0.000317\n",
      "batch 569 loss: 1.29470 acc: 0.72949 | v_loss: 1.24801 v_acc: 0.74382 |  iteration: 1813 teacher: 1 stage: sketch lr: 0.000317\n",
      "batch 570 loss: 1.27775 acc: 0.72428 | v_loss: 1.29704 v_acc: 0.73730 |  iteration: 1814 teacher: 1 stage: sketch lr: 0.000317\n",
      "batch 571 loss: 1.34537 acc: 0.71973 | v_loss: 1.09086 v_acc: 0.75098 |  iteration: 1815 teacher: 1 stage: sketch lr: 0.000317\n",
      "batch 572 loss: 1.24064 acc: 0.74512 | v_loss: 1.30949 v_acc: 0.73568 |  iteration: 1816 teacher: 1 stage: sketch lr: 0.000317\n",
      "batch 573 loss: 1.31314 acc: 0.72461 | v_loss: 1.22042 v_acc: 0.73958 |  iteration: 1817 teacher: 1 stage: sketch lr: 0.000317\n",
      "batch 574 loss: 1.23252 acc: 0.72852 | v_loss: 1.32414 v_acc: 0.73047 |  iteration: 1818 teacher: 1 stage: sketch lr: 0.000318\n",
      "batch 575 loss: 1.19635 acc: 0.73730 | v_loss: 1.22666 v_acc: 0.74154 |  iteration: 1819 teacher: 1 stage: sketch lr: 0.000318\n",
      "batch 576 loss: 1.19470 acc: 0.74154 | v_loss: 1.16146 v_acc: 0.75195 |  iteration: 1820 teacher: 1 stage: sketch lr: 0.000318\n",
      "batch 577 loss: 1.25736 acc: 0.73014 | v_loss: 1.16046 v_acc: 0.74935 |  iteration: 1821 teacher: 0 stage: sketch lr: 0.000318\n",
      "batch 578 loss: 1.29523 acc: 0.72461 | v_loss: 1.23474 v_acc: 0.72396 |  iteration: 1822 teacher: 1 stage: sketch lr: 0.000318\n",
      "batch 579 loss: 1.27022 acc: 0.72493 | v_loss: 1.18152 v_acc: 0.73893 |  iteration: 1823 teacher: 0 stage: sketch lr: 0.000318\n",
      "batch 580 loss: 1.20670 acc: 0.73665 | v_loss: 1.21272 v_acc: 0.72884 |  iteration: 1824 teacher: 1 stage: sketch lr: 0.000319\n",
      "batch 581 loss: 1.25746 acc: 0.73275 | v_loss: 1.21917 v_acc: 0.75098 |  iteration: 1825 teacher: 0 stage: sketch lr: 0.000319\n",
      "batch 582 loss: 1.29218 acc: 0.72591 | v_loss: 1.27637 v_acc: 0.73177 |  iteration: 1826 teacher: 0 stage: sketch lr: 0.000319\n",
      "batch 583 loss: 1.24050 acc: 0.73568 | v_loss: 1.24306 v_acc: 0.72917 |  iteration: 1827 teacher: 0 stage: sketch lr: 0.000319\n",
      "batch 584 loss: 1.21578 acc: 0.74479 | v_loss: 1.33925 v_acc: 0.72331 |  iteration: 1828 teacher: 0 stage: sketch lr: 0.000319\n",
      "batch 585 loss: 1.34971 acc: 0.71191 | v_loss: 1.23170 v_acc: 0.73145 |  iteration: 1829 teacher: 0 stage: sketch lr: 0.000320\n",
      "batch 586 loss: 1.21207 acc: 0.74219 | v_loss: 1.13633 v_acc: 0.74609 |  iteration: 1830 teacher: 0 stage: sketch lr: 0.000320\n",
      "batch 587 loss: 1.24689 acc: 0.73763 | v_loss: 1.25915 v_acc: 0.73861 |  iteration: 1831 teacher: 1 stage: sketch lr: 0.000320\n",
      "batch 588 loss: 1.17259 acc: 0.75163 | v_loss: 1.14881 v_acc: 0.75781 |  iteration: 1832 teacher: 0 stage: sketch lr: 0.000320\n",
      "batch 589 loss: 1.26424 acc: 0.73307 | v_loss: 1.30865 v_acc: 0.72591 |  iteration: 1833 teacher: 0 stage: sketch lr: 0.000320\n",
      "batch 590 loss: 1.28538 acc: 0.72656 | v_loss: 1.27912 v_acc: 0.72689 |  iteration: 1834 teacher: 1 stage: sketch lr: 0.000320\n",
      "batch 591 loss: 1.22121 acc: 0.73926 | v_loss: 1.21054 v_acc: 0.74577 |  iteration: 1835 teacher: 1 stage: sketch lr: 0.000321\n",
      "batch 592 loss: 1.15137 acc: 0.75391 | v_loss: 1.23517 v_acc: 0.73893 |  iteration: 1836 teacher: 0 stage: sketch lr: 0.000321\n",
      "batch 593 loss: 1.22459 acc: 0.73861 | v_loss: 1.23284 v_acc: 0.72949 |  iteration: 1837 teacher: 1 stage: sketch lr: 0.000321\n",
      "batch 594 loss: 1.20742 acc: 0.74870 | v_loss: 1.28898 v_acc: 0.73926 |  iteration: 1838 teacher: 1 stage: sketch lr: 0.000321\n",
      "batch 595 loss: 1.17420 acc: 0.74967 | v_loss: 1.18071 v_acc: 0.74870 |  iteration: 1839 teacher: 0 stage: sketch lr: 0.000321\n",
      "batch 596 loss: 1.35070 acc: 0.71777 | v_loss: 1.12690 v_acc: 0.75130 |  iteration: 1840 teacher: 0 stage: sketch lr: 0.000321\n",
      "batch 597 loss: 1.19913 acc: 0.74219 | v_loss: 1.09535 v_acc: 0.76074 |  iteration: 1841 teacher: 0 stage: sketch lr: 0.000322\n",
      "batch 598 loss: 1.25526 acc: 0.72624 | v_loss: 1.18331 v_acc: 0.74186 |  iteration: 1842 teacher: 0 stage: sketch lr: 0.000322\n",
      "batch 599 loss: 1.21165 acc: 0.73275 | v_loss: 1.25159 v_acc: 0.73828 |  iteration: 1843 teacher: 0 stage: sketch lr: 0.000322\n",
      "batch 600 loss: 1.22078 acc: 0.74414 | v_loss: 1.21052 v_acc: 0.72852 |  iteration: 1844 teacher: 0 stage: sketch lr: 0.000322\n",
      "batch 601 loss: 1.26512 acc: 0.73210 | v_loss: 1.17904 v_acc: 0.75228 |  iteration: 1845 teacher: 0 stage: sketch lr: 0.000322\n",
      "batch 602 loss: 1.23730 acc: 0.72656 | v_loss: 1.27806 v_acc: 0.74772 |  iteration: 1846 teacher: 0 stage: sketch lr: 0.000322\n",
      "batch 603 loss: 1.32963 acc: 0.72819 | v_loss: 1.20735 v_acc: 0.72721 |  iteration: 1847 teacher: 1 stage: sketch lr: 0.000323\n",
      "batch 604 loss: 1.24316 acc: 0.73372 | v_loss: 1.16004 v_acc: 0.74316 |  iteration: 1848 teacher: 1 stage: sketch lr: 0.000323\n",
      "batch 605 loss: 1.27657 acc: 0.72493 | v_loss: 1.14978 v_acc: 0.74154 |  iteration: 1849 teacher: 0 stage: sketch lr: 0.000323\n",
      "batch 606 loss: 1.26911 acc: 0.73210 | v_loss: 1.14854 v_acc: 0.75944 |  iteration: 1850 teacher: 0 stage: sketch lr: 0.000323\n",
      "batch 607 loss: 1.29118 acc: 0.72884 | v_loss: 1.16450 v_acc: 0.75423 |  iteration: 1851 teacher: 0 stage: sketch lr: 0.000323\n",
      "batch 608 loss: 1.31158 acc: 0.71647 | v_loss: 1.29117 v_acc: 0.73405 |  iteration: 1852 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 609 loss: 1.33565 acc: 0.72103 | v_loss: 1.28839 v_acc: 0.72135 |  iteration: 1853 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 610 loss: 1.21800 acc: 0.73893 | v_loss: 1.19880 v_acc: 0.74316 |  iteration: 1854 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 611 loss: 1.23647 acc: 0.73600 | v_loss: 1.15770 v_acc: 0.76009 |  iteration: 1855 teacher: 1 stage: sketch lr: 0.000324\n",
      "batch 612 loss: 1.32265 acc: 0.73763 | v_loss: 1.28264 v_acc: 0.72917 |  iteration: 1856 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 613 loss: 1.16079 acc: 0.74674 | v_loss: 1.34926 v_acc: 0.72135 |  iteration: 1857 teacher: 0 stage: sketch lr: 0.000324\n",
      "batch 614 loss: 1.26746 acc: 0.73079 | v_loss: 1.17340 v_acc: 0.75000 |  iteration: 1858 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 615 loss: 1.21423 acc: 0.73763 | v_loss: 1.29977 v_acc: 0.73275 |  iteration: 1859 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 616 loss: 1.25505 acc: 0.73340 | v_loss: 1.11461 v_acc: 0.75163 |  iteration: 1860 teacher: 1 stage: sketch lr: 0.000325\n",
      "batch 617 loss: 1.22820 acc: 0.73503 | v_loss: 1.23033 v_acc: 0.73991 |  iteration: 1861 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 618 loss: 1.24508 acc: 0.73372 | v_loss: 1.23108 v_acc: 0.74349 |  iteration: 1862 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 619 loss: 1.27923 acc: 0.73145 | v_loss: 1.17790 v_acc: 0.75228 |  iteration: 1863 teacher: 0 stage: sketch lr: 0.000325\n",
      "batch 620 loss: 1.13863 acc: 0.75195 | v_loss: 1.17300 v_acc: 0.74805 |  iteration: 1864 teacher: 1 stage: sketch lr: 0.000326\n",
      "batch 621 loss: 1.29257 acc: 0.73275 | v_loss: 1.19361 v_acc: 0.73210 |  iteration: 1865 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 622 loss: 1.24405 acc: 0.72461 | v_loss: 1.20757 v_acc: 0.75488 |  iteration: 1866 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 623 loss: 1.18701 acc: 0.74642 | v_loss: 1.20246 v_acc: 0.75293 |  iteration: 1867 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 624 loss: 1.27472 acc: 0.72852 | v_loss: 1.52060 v_acc: 0.69922 |  iteration: 1868 teacher: 0 stage: sketch lr: 0.000326\n",
      "batch 625 loss: 1.22156 acc: 0.73242 | v_loss: 1.17641 v_acc: 0.73665 |  iteration: 1869 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 626 loss: 1.29959 acc: 0.73079 | v_loss: 1.24467 v_acc: 0.74349 |  iteration: 1870 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 627 loss: 1.22212 acc: 0.73275 | v_loss: 1.22741 v_acc: 0.74935 |  iteration: 1871 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 628 loss: 1.25675 acc: 0.73079 | v_loss: 1.32172 v_acc: 0.72949 |  iteration: 1872 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 629 loss: 1.26165 acc: 0.73600 | v_loss: 1.11868 v_acc: 0.76172 |  iteration: 1873 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 630 loss: 1.27986 acc: 0.73926 | v_loss: 1.28099 v_acc: 0.73698 |  iteration: 1874 teacher: 1 stage: sketch lr: 0.000327\n",
      "batch 631 loss: 1.31584 acc: 0.72135 | v_loss: 1.17780 v_acc: 0.73828 |  iteration: 1875 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 632 loss: 1.23367 acc: 0.72917 | v_loss: 1.30335 v_acc: 0.72559 |  iteration: 1876 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 633 loss: 1.21852 acc: 0.73861 | v_loss: 1.27451 v_acc: 0.73535 |  iteration: 1877 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 634 loss: 1.16161 acc: 0.74284 | v_loss: 1.26200 v_acc: 0.72721 |  iteration: 1878 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 635 loss: 1.28128 acc: 0.71908 | v_loss: 1.35717 v_acc: 0.72624 |  iteration: 1879 teacher: 1 stage: sketch lr: 0.000328\n",
      "batch 636 loss: 1.24278 acc: 0.73112 | v_loss: 1.23911 v_acc: 0.73730 |  iteration: 1880 teacher: 0 stage: sketch lr: 0.000328\n",
      "batch 637 loss: 1.14963 acc: 0.74479 | v_loss: 1.22060 v_acc: 0.73438 |  iteration: 1881 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 638 loss: 1.22908 acc: 0.73730 | v_loss: 1.15236 v_acc: 0.74642 |  iteration: 1882 teacher: 0 stage: sketch lr: 0.000329\n",
      "batch 639 loss: 1.22510 acc: 0.73861 | v_loss: 1.24958 v_acc: 0.74609 |  iteration: 1883 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 640 loss: 1.25936 acc: 0.73242 | v_loss: 1.17755 v_acc: 0.74772 |  iteration: 1884 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 641 loss: 1.28243 acc: 0.72884 | v_loss: 1.16259 v_acc: 0.74902 |  iteration: 1885 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 642 loss: 1.27340 acc: 0.73438 | v_loss: 1.23424 v_acc: 0.74186 |  iteration: 1886 teacher: 1 stage: sketch lr: 0.000329\n",
      "batch 643 loss: 1.34442 acc: 0.72493 | v_loss: 1.19915 v_acc: 0.73307 |  iteration: 1887 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 644 loss: 1.25071 acc: 0.73470 | v_loss: 1.29347 v_acc: 0.72591 |  iteration: 1888 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 645 loss: 1.26589 acc: 0.73958 | v_loss: 1.25586 v_acc: 0.72949 |  iteration: 1889 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 646 loss: 1.31858 acc: 0.73242 | v_loss: 1.28398 v_acc: 0.73991 |  iteration: 1890 teacher: 0 stage: sketch lr: 0.000330\n",
      "batch 647 loss: 1.29329 acc: 0.73112 | v_loss: 1.24301 v_acc: 0.74447 |  iteration: 1891 teacher: 1 stage: sketch lr: 0.000330\n",
      "batch 648 loss: 1.33075 acc: 0.72624 | v_loss: 1.18012 v_acc: 0.74023 |  iteration: 1892 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 649 loss: 1.16650 acc: 0.74609 | v_loss: 1.13130 v_acc: 0.76367 |  iteration: 1893 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 650 loss: 1.26973 acc: 0.73079 | v_loss: 1.23437 v_acc: 0.74186 |  iteration: 1894 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 651 loss: 1.25023 acc: 0.74251 | v_loss: 1.24383 v_acc: 0.75260 |  iteration: 1895 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 652 loss: 1.24624 acc: 0.73242 | v_loss: 1.18269 v_acc: 0.75488 |  iteration: 1896 teacher: 0 stage: sketch lr: 0.000331\n",
      "batch 653 loss: 1.28677 acc: 0.72819 | v_loss: 1.21413 v_acc: 0.74674 |  iteration: 1897 teacher: 1 stage: sketch lr: 0.000331\n",
      "batch 654 loss: 1.27977 acc: 0.72917 | v_loss: 1.10601 v_acc: 0.74577 |  iteration: 1898 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 655 loss: 1.20510 acc: 0.73307 | v_loss: 1.17179 v_acc: 0.74870 |  iteration: 1899 teacher: 0 stage: sketch lr: 0.000332\n",
      "batch 656 loss: 1.18081 acc: 0.74219 | v_loss: 1.30822 v_acc: 0.71810 |  iteration: 1900 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 657 loss: 1.24047 acc: 0.73210 | v_loss: 1.22284 v_acc: 0.75000 |  iteration: 1901 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 658 loss: 1.29088 acc: 0.73014 | v_loss: 1.09363 v_acc: 0.76855 |  iteration: 1902 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 659 loss: 1.23034 acc: 0.74414 | v_loss: 1.26440 v_acc: 0.73405 |  iteration: 1903 teacher: 1 stage: sketch lr: 0.000332\n",
      "batch 660 loss: 1.21076 acc: 0.73763 | v_loss: 1.24307 v_acc: 0.75521 |  iteration: 1904 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 661 loss: 1.28575 acc: 0.73275 | v_loss: 1.28173 v_acc: 0.73796 |  iteration: 1905 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 662 loss: 1.26058 acc: 0.73405 | v_loss: 1.08794 v_acc: 0.75000 |  iteration: 1906 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 663 loss: 1.30004 acc: 0.73372 | v_loss: 1.32324 v_acc: 0.73893 |  iteration: 1907 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 664 loss: 1.26925 acc: 0.73405 | v_loss: 1.21988 v_acc: 0.74349 |  iteration: 1908 teacher: 1 stage: sketch lr: 0.000333\n",
      "batch 665 loss: 1.21813 acc: 0.74447 | v_loss: 1.32374 v_acc: 0.72493 |  iteration: 1909 teacher: 0 stage: sketch lr: 0.000333\n",
      "batch 666 loss: 1.26737 acc: 0.73177 | v_loss: 1.21834 v_acc: 0.74284 |  iteration: 1910 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 667 loss: 1.18962 acc: 0.74414 | v_loss: 1.15351 v_acc: 0.75749 |  iteration: 1911 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 668 loss: 1.20366 acc: 0.74121 | v_loss: 1.20104 v_acc: 0.73926 |  iteration: 1912 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 669 loss: 1.26309 acc: 0.73503 | v_loss: 1.22983 v_acc: 0.72559 |  iteration: 1913 teacher: 0 stage: sketch lr: 0.000334\n",
      "batch 670 loss: 1.28872 acc: 0.72721 | v_loss: 1.18221 v_acc: 0.74414 |  iteration: 1914 teacher: 1 stage: sketch lr: 0.000334\n",
      "batch 671 loss: 1.25035 acc: 0.72852 | v_loss: 1.21591 v_acc: 0.73665 |  iteration: 1915 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 672 loss: 1.22956 acc: 0.73470 | v_loss: 1.22722 v_acc: 0.75065 |  iteration: 1916 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 673 loss: 1.23027 acc: 0.73926 | v_loss: 1.28629 v_acc: 0.72689 |  iteration: 1917 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 674 loss: 1.27746 acc: 0.73958 | v_loss: 1.23076 v_acc: 0.73112 |  iteration: 1918 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 675 loss: 1.23127 acc: 0.73796 | v_loss: 1.31375 v_acc: 0.72363 |  iteration: 1919 teacher: 1 stage: sketch lr: 0.000335\n",
      "batch 676 loss: 1.26975 acc: 0.72526 | v_loss: 1.21917 v_acc: 0.73145 |  iteration: 1920 teacher: 0 stage: sketch lr: 0.000335\n",
      "batch 677 loss: 1.21147 acc: 0.73242 | v_loss: 1.13114 v_acc: 0.74349 |  iteration: 1921 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 678 loss: 1.23264 acc: 0.73600 | v_loss: 1.27411 v_acc: 0.73991 |  iteration: 1922 teacher: 1 stage: sketch lr: 0.000336\n",
      "batch 679 loss: 1.28680 acc: 0.72884 | v_loss: 1.15029 v_acc: 0.75163 |  iteration: 1923 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 680 loss: 1.30362 acc: 0.72168 | v_loss: 1.30285 v_acc: 0.72982 |  iteration: 1924 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 681 loss: 1.26210 acc: 0.72884 | v_loss: 1.28575 v_acc: 0.72038 |  iteration: 1925 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 682 loss: 1.27175 acc: 0.73698 | v_loss: 1.20793 v_acc: 0.74674 |  iteration: 1926 teacher: 0 stage: sketch lr: 0.000336\n",
      "batch 683 loss: 1.19976 acc: 0.73958 | v_loss: 1.23431 v_acc: 0.73991 |  iteration: 1927 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 684 loss: 1.20996 acc: 0.73470 | v_loss: 1.22259 v_acc: 0.73600 |  iteration: 1928 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 685 loss: 1.24363 acc: 0.73828 | v_loss: 1.29833 v_acc: 0.74219 |  iteration: 1929 teacher: 1 stage: sketch lr: 0.000337\n",
      "batch 686 loss: 1.29156 acc: 0.73535 | v_loss: 1.16689 v_acc: 0.75618 |  iteration: 1930 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 687 loss: 1.23737 acc: 0.73242 | v_loss: 1.12907 v_acc: 0.75098 |  iteration: 1931 teacher: 0 stage: sketch lr: 0.000337\n",
      "batch 688 loss: 1.17512 acc: 0.74902 | v_loss: 1.07478 v_acc: 0.76009 |  iteration: 1932 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 689 loss: 1.28306 acc: 0.72852 | v_loss: 1.16998 v_acc: 0.75130 |  iteration: 1933 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 690 loss: 1.22960 acc: 0.73405 | v_loss: 1.26261 v_acc: 0.73014 |  iteration: 1934 teacher: 0 stage: sketch lr: 0.000338\n",
      "batch 691 loss: 1.23601 acc: 0.73763 | v_loss: 1.20966 v_acc: 0.72559 |  iteration: 1935 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 692 loss: 1.18639 acc: 0.73568 | v_loss: 1.19230 v_acc: 0.74870 |  iteration: 1936 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 693 loss: 1.20037 acc: 0.75260 | v_loss: 1.26636 v_acc: 0.75228 |  iteration: 1937 teacher: 1 stage: sketch lr: 0.000338\n",
      "batch 694 loss: 1.27127 acc: 0.73372 | v_loss: 1.22965 v_acc: 0.72526 |  iteration: 1938 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 695 loss: 1.28334 acc: 0.72461 | v_loss: 1.15817 v_acc: 0.74284 |  iteration: 1939 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 696 loss: 1.29449 acc: 0.73014 | v_loss: 1.12866 v_acc: 0.75098 |  iteration: 1940 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 697 loss: 1.26088 acc: 0.73307 | v_loss: 1.13859 v_acc: 0.76986 |  iteration: 1941 teacher: 1 stage: sketch lr: 0.000339\n",
      "batch 698 loss: 1.36716 acc: 0.71940 | v_loss: 1.16861 v_acc: 0.75163 |  iteration: 1942 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 699 loss: 1.23703 acc: 0.72070 | v_loss: 1.30492 v_acc: 0.73047 |  iteration: 1943 teacher: 0 stage: sketch lr: 0.000339\n",
      "batch 700 loss: 1.21738 acc: 0.74740 | v_loss: 1.29054 v_acc: 0.72331 |  iteration: 1944 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 701 loss: 1.27618 acc: 0.73600 | v_loss: 1.19572 v_acc: 0.74023 |  iteration: 1945 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 702 loss: 1.22125 acc: 0.74674 | v_loss: 1.15850 v_acc: 0.75846 |  iteration: 1946 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 703 loss: 1.26550 acc: 0.73763 | v_loss: 1.28675 v_acc: 0.72982 |  iteration: 1947 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 704 loss: 1.28322 acc: 0.72168 | v_loss: 1.35432 v_acc: 0.72721 |  iteration: 1948 teacher: 0 stage: sketch lr: 0.000340\n",
      "batch 705 loss: 1.31439 acc: 0.72819 | v_loss: 1.16678 v_acc: 0.75098 |  iteration: 1949 teacher: 1 stage: sketch lr: 0.000340\n",
      "batch 706 loss: 1.25627 acc: 0.73340 | v_loss: 1.27805 v_acc: 0.73535 |  iteration: 1950 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 707 loss: 1.33500 acc: 0.73210 | v_loss: 1.10073 v_acc: 0.75358 |  iteration: 1951 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 708 loss: 1.25748 acc: 0.73177 | v_loss: 1.23499 v_acc: 0.73991 |  iteration: 1952 teacher: 1 stage: sketch lr: 0.000341\n",
      "batch 709 loss: 1.16065 acc: 0.74447 | v_loss: 1.22577 v_acc: 0.74089 |  iteration: 1953 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 710 loss: 1.29761 acc: 0.72949 | v_loss: 1.16113 v_acc: 0.75586 |  iteration: 1954 teacher: 0 stage: sketch lr: 0.000341\n",
      "batch 711 loss: 1.35778 acc: 0.72331 | v_loss: 1.15305 v_acc: 0.75391 |  iteration: 1955 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 712 loss: 1.13373 acc: 0.75228 | v_loss: 1.18101 v_acc: 0.73665 |  iteration: 1956 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 713 loss: 1.16689 acc: 0.74479 | v_loss: 1.22451 v_acc: 0.75000 |  iteration: 1957 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 714 loss: 1.29954 acc: 0.72656 | v_loss: 1.20211 v_acc: 0.75195 |  iteration: 1958 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 715 loss: 1.29087 acc: 0.73665 | v_loss: 1.53032 v_acc: 0.70085 |  iteration: 1959 teacher: 0 stage: sketch lr: 0.000342\n",
      "batch 716 loss: 1.16692 acc: 0.74447 | v_loss: 1.15875 v_acc: 0.74154 |  iteration: 1960 teacher: 1 stage: sketch lr: 0.000342\n",
      "batch 717 loss: 1.20406 acc: 0.74479 | v_loss: 1.23936 v_acc: 0.74447 |  iteration: 1961 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 718 loss: 1.24353 acc: 0.74023 | v_loss: 1.22204 v_acc: 0.75391 |  iteration: 1962 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 719 loss: 1.23045 acc: 0.73503 | v_loss: 1.32291 v_acc: 0.73112 |  iteration: 1963 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 720 loss: 1.22854 acc: 0.73698 | v_loss: 1.10865 v_acc: 0.76432 |  iteration: 1964 teacher: 1 stage: sketch lr: 0.000343\n",
      "batch 721 loss: 1.22775 acc: 0.73275 | v_loss: 1.28447 v_acc: 0.73079 |  iteration: 1965 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 722 loss: 1.16621 acc: 0.75098 | v_loss: 1.17342 v_acc: 0.73861 |  iteration: 1966 teacher: 0 stage: sketch lr: 0.000343\n",
      "batch 723 loss: 1.26148 acc: 0.73112 | v_loss: 1.31806 v_acc: 0.72852 |  iteration: 1967 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 724 loss: 1.20868 acc: 0.74609 | v_loss: 1.25284 v_acc: 0.73861 |  iteration: 1968 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 725 loss: 1.21792 acc: 0.73535 | v_loss: 1.24277 v_acc: 0.73503 |  iteration: 1969 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 726 loss: 1.26912 acc: 0.74414 | v_loss: 1.36740 v_acc: 0.73145 |  iteration: 1970 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 727 loss: 1.18123 acc: 0.73861 | v_loss: 1.22584 v_acc: 0.74186 |  iteration: 1971 teacher: 1 stage: sketch lr: 0.000344\n",
      "batch 728 loss: 1.20675 acc: 0.74447 | v_loss: 1.22258 v_acc: 0.74512 |  iteration: 1972 teacher: 0 stage: sketch lr: 0.000344\n",
      "batch 729 loss: 1.21812 acc: 0.73958 | v_loss: 1.15578 v_acc: 0.74902 |  iteration: 1973 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 730 loss: 1.35013 acc: 0.72526 | v_loss: 1.24732 v_acc: 0.74447 |  iteration: 1974 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 731 loss: 1.27055 acc: 0.73210 | v_loss: 1.17211 v_acc: 0.74772 |  iteration: 1975 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 732 loss: 1.23393 acc: 0.73307 | v_loss: 1.16111 v_acc: 0.75195 |  iteration: 1976 teacher: 1 stage: sketch lr: 0.000345\n",
      "batch 733 loss: 1.20578 acc: 0.73893 | v_loss: 1.22732 v_acc: 0.74447 |  iteration: 1977 teacher: 0 stage: sketch lr: 0.000345\n",
      "batch 734 loss: 1.26495 acc: 0.73828 | v_loss: 1.20152 v_acc: 0.72917 |  iteration: 1978 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 735 loss: 1.27478 acc: 0.73698 | v_loss: 1.35239 v_acc: 0.71647 |  iteration: 1979 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 736 loss: 1.19718 acc: 0.74707 | v_loss: 1.27140 v_acc: 0.72852 |  iteration: 1980 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 737 loss: 1.21367 acc: 0.74935 | v_loss: 1.27178 v_acc: 0.73926 |  iteration: 1981 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 738 loss: 1.19943 acc: 0.74251 | v_loss: 1.26530 v_acc: 0.73796 |  iteration: 1982 teacher: 0 stage: sketch lr: 0.000346\n",
      "batch 739 loss: 1.16739 acc: 0.74967 | v_loss: 1.19148 v_acc: 0.73470 |  iteration: 1983 teacher: 1 stage: sketch lr: 0.000346\n",
      "batch 740 loss: 1.17106 acc: 0.73763 | v_loss: 1.14578 v_acc: 0.76725 |  iteration: 1984 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 741 loss: 1.24950 acc: 0.73958 | v_loss: 1.22834 v_acc: 0.74219 |  iteration: 1985 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 742 loss: 1.14777 acc: 0.74707 | v_loss: 1.25277 v_acc: 0.74251 |  iteration: 1986 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 743 loss: 1.18517 acc: 0.74121 | v_loss: 1.17965 v_acc: 0.74512 |  iteration: 1987 teacher: 0 stage: sketch lr: 0.000347\n",
      "batch 744 loss: 1.25220 acc: 0.73014 | v_loss: 1.23854 v_acc: 0.73600 |  iteration: 1988 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 745 loss: 1.22942 acc: 0.73633 | v_loss: 1.07602 v_acc: 0.75618 |  iteration: 1989 teacher: 1 stage: sketch lr: 0.000347\n",
      "batch 746 loss: 1.30313 acc: 0.73307 | v_loss: 1.16516 v_acc: 0.75684 |  iteration: 1990 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 747 loss: 1.19362 acc: 0.75033 | v_loss: 1.27424 v_acc: 0.73079 |  iteration: 1991 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 748 loss: 1.26840 acc: 0.73340 | v_loss: 1.21300 v_acc: 0.75130 |  iteration: 1992 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 749 loss: 1.20809 acc: 0.73893 | v_loss: 1.08881 v_acc: 0.77246 |  iteration: 1993 teacher: 1 stage: sketch lr: 0.000348\n",
      "batch 750 loss: 1.27904 acc: 0.72786 | v_loss: 1.25931 v_acc: 0.73177 |  iteration: 1994 teacher: 0 stage: sketch lr: 0.000348\n",
      "batch 751 loss: 1.19152 acc: 0.73926 | v_loss: 1.24356 v_acc: 0.75000 |  iteration: 1995 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 752 loss: 1.26682 acc: 0.73438 | v_loss: 1.30773 v_acc: 0.74121 |  iteration: 1996 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 753 loss: 1.22118 acc: 0.73307 | v_loss: 1.08605 v_acc: 0.74870 |  iteration: 1997 teacher: 0 stage: sketch lr: 0.000349\n",
      "batch 754 loss: 1.40549 acc: 0.71517 | v_loss: 1.32453 v_acc: 0.73568 |  iteration: 1998 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 755 loss: 1.22971 acc: 0.74154 | v_loss: 1.21798 v_acc: 0.73991 |  iteration: 1999 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 756 loss: 1.26848 acc: 0.73275 | v_loss: 1.33493 v_acc: 0.72786 |  iteration: 2000 teacher: 1 stage: sketch lr: 0.000349\n",
      "batch 757 loss: 1.20269 acc: 0.73665 | v_loss: 1.21535 v_acc: 0.74544 |  iteration: 2001 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 758 loss: 1.16118 acc: 0.74609 | v_loss: 1.16003 v_acc: 0.75130 |  iteration: 2002 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 759 loss: 1.24252 acc: 0.73763 | v_loss: 1.15213 v_acc: 0.74837 |  iteration: 2003 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 760 loss: 1.22390 acc: 0.74121 | v_loss: 1.19333 v_acc: 0.73014 |  iteration: 2004 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 761 loss: 1.16714 acc: 0.74349 | v_loss: 1.17169 v_acc: 0.74609 |  iteration: 2005 teacher: 1 stage: sketch lr: 0.000350\n",
      "batch 762 loss: 1.15293 acc: 0.75000 | v_loss: 1.21309 v_acc: 0.73405 |  iteration: 2006 teacher: 0 stage: sketch lr: 0.000350\n",
      "batch 763 loss: 1.25768 acc: 0.72949 | v_loss: 1.22321 v_acc: 0.75098 |  iteration: 2007 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 764 loss: 1.28796 acc: 0.72624 | v_loss: 1.27066 v_acc: 0.73698 |  iteration: 2008 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 765 loss: 1.26388 acc: 0.73535 | v_loss: 1.22572 v_acc: 0.73275 |  iteration: 2009 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 766 loss: 1.25720 acc: 0.73796 | v_loss: 1.32682 v_acc: 0.72298 |  iteration: 2010 teacher: 0 stage: sketch lr: 0.000351\n",
      "batch 767 loss: 1.24680 acc: 0.74089 | v_loss: 1.20955 v_acc: 0.73210 |  iteration: 2011 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 768 loss: 1.26713 acc: 0.73177 | v_loss: 1.13558 v_acc: 0.74349 |  iteration: 2012 teacher: 1 stage: sketch lr: 0.000351\n",
      "batch 769 loss: 1.29052 acc: 0.72754 | v_loss: 1.25494 v_acc: 0.74056 |  iteration: 2013 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 770 loss: 1.26336 acc: 0.73438 | v_loss: 1.14021 v_acc: 0.75716 |  iteration: 2014 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 771 loss: 1.27751 acc: 0.73340 | v_loss: 1.29801 v_acc: 0.73210 |  iteration: 2015 teacher: 0 stage: sketch lr: 0.000352\n",
      "batch 772 loss: 1.25545 acc: 0.73568 | v_loss: 1.26340 v_acc: 0.73210 |  iteration: 2016 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 773 loss: 1.25428 acc: 0.73503 | v_loss: 1.17909 v_acc: 0.75586 |  iteration: 2017 teacher: 1 stage: sketch lr: 0.000352\n",
      "batch 774 loss: 1.26683 acc: 0.72656 | v_loss: 1.21950 v_acc: 0.74219 |  iteration: 2018 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 775 loss: 1.24833 acc: 0.72917 | v_loss: 1.23320 v_acc: 0.73210 |  iteration: 2019 teacher: 0 stage: sketch lr: 0.000353\n",
      "batch 776 loss: 1.16791 acc: 0.74609 | v_loss: 1.29410 v_acc: 0.73600 |  iteration: 2020 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 777 loss: 1.25689 acc: 0.73600 | v_loss: 1.16372 v_acc: 0.75977 |  iteration: 2021 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 778 loss: 1.17994 acc: 0.74056 | v_loss: 1.12255 v_acc: 0.75195 |  iteration: 2022 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 779 loss: 1.19560 acc: 0.74186 | v_loss: 1.07823 v_acc: 0.75911 |  iteration: 2023 teacher: 1 stage: sketch lr: 0.000353\n",
      "batch 780 loss: 1.23784 acc: 0.73730 | v_loss: 1.16308 v_acc: 0.75098 |  iteration: 2024 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 781 loss: 1.23056 acc: 0.73828 | v_loss: 1.26076 v_acc: 0.73372 |  iteration: 2025 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 782 loss: 1.13277 acc: 0.74805 | v_loss: 1.19559 v_acc: 0.72982 |  iteration: 2026 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 783 loss: 1.22066 acc: 0.73470 | v_loss: 1.18951 v_acc: 0.74772 |  iteration: 2027 teacher: 0 stage: sketch lr: 0.000354\n",
      "batch 784 loss: 1.28870 acc: 0.72331 | v_loss: 1.26846 v_acc: 0.74740 |  iteration: 2028 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 785 loss: 1.30867 acc: 0.72656 | v_loss: 1.20505 v_acc: 0.73470 |  iteration: 2029 teacher: 1 stage: sketch lr: 0.000354\n",
      "batch 786 loss: 1.28103 acc: 0.73145 | v_loss: 1.15180 v_acc: 0.74772 |  iteration: 2030 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 787 loss: 1.26377 acc: 0.73177 | v_loss: 1.11973 v_acc: 0.75228 |  iteration: 2031 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 788 loss: 1.28647 acc: 0.72754 | v_loss: 1.13607 v_acc: 0.76823 |  iteration: 2032 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 789 loss: 1.19252 acc: 0.74186 | v_loss: 1.16484 v_acc: 0.75391 |  iteration: 2033 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 790 loss: 1.22834 acc: 0.73372 | v_loss: 1.29123 v_acc: 0.73372 |  iteration: 2034 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 791 loss: 1.27548 acc: 0.73210 | v_loss: 1.28917 v_acc: 0.72656 |  iteration: 2035 teacher: 0 stage: sketch lr: 0.000355\n",
      "batch 792 loss: 1.27786 acc: 0.73079 | v_loss: 1.18342 v_acc: 0.74870 |  iteration: 2036 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 793 loss: 1.40249 acc: 0.71419 | v_loss: 1.14742 v_acc: 0.76335 |  iteration: 2037 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 794 loss: 1.26365 acc: 0.73633 | v_loss: 1.28894 v_acc: 0.72428 |  iteration: 2038 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 795 loss: 1.28698 acc: 0.72949 | v_loss: 1.35809 v_acc: 0.71647 |  iteration: 2039 teacher: 1 stage: sketch lr: 0.000356\n",
      "batch 796 loss: 1.24069 acc: 0.73275 | v_loss: 1.15992 v_acc: 0.75293 |  iteration: 2040 teacher: 0 stage: sketch lr: 0.000356\n",
      "batch 797 loss: 1.33961 acc: 0.72559 | v_loss: 1.27084 v_acc: 0.73665 |  iteration: 2041 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 798 loss: 1.29638 acc: 0.73210 | v_loss: 1.10744 v_acc: 0.75195 |  iteration: 2042 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 799 loss: 1.30848 acc: 0.71842 | v_loss: 1.25195 v_acc: 0.74056 |  iteration: 2043 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 800 loss: 1.19639 acc: 0.74870 | v_loss: 1.22656 v_acc: 0.75033 |  iteration: 2044 teacher: 0 stage: sketch lr: 0.000357\n",
      "batch 801 loss: 1.10354 acc: 0.75911 | v_loss: 1.16662 v_acc: 0.75326 |  iteration: 2045 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 802 loss: 1.17918 acc: 0.73438 | v_loss: 1.14740 v_acc: 0.75228 |  iteration: 2046 teacher: 1 stage: sketch lr: 0.000357\n",
      "batch 803 loss: 1.18778 acc: 0.73926 | v_loss: 1.17015 v_acc: 0.73926 |  iteration: 2047 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 804 loss: 1.21875 acc: 0.73275 | v_loss: 1.20409 v_acc: 0.75586 |  iteration: 2048 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 805 loss: 1.28225 acc: 0.73047 | v_loss: 1.19086 v_acc: 0.75586 |  iteration: 2049 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 806 loss: 1.25303 acc: 0.73763 | v_loss: 1.54014 v_acc: 0.69661 |  iteration: 2050 teacher: 0 stage: sketch lr: 0.000358\n",
      "batch 807 loss: 1.19902 acc: 0.73535 | v_loss: 1.15740 v_acc: 0.74121 |  iteration: 2051 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 808 loss: 1.25382 acc: 0.73307 | v_loss: 1.22596 v_acc: 0.74902 |  iteration: 2052 teacher: 1 stage: sketch lr: 0.000358\n",
      "batch 809 loss: 1.26205 acc: 0.73633 | v_loss: 1.20490 v_acc: 0.75684 |  iteration: 2053 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 810 loss: 1.27999 acc: 0.73112 | v_loss: 1.32502 v_acc: 0.73014 |  iteration: 2054 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 811 loss: 1.28900 acc: 0.72461 | v_loss: 1.11197 v_acc: 0.76302 |  iteration: 2055 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 812 loss: 1.21994 acc: 0.73698 | v_loss: 1.28299 v_acc: 0.73568 |  iteration: 2056 teacher: 0 stage: sketch lr: 0.000359\n",
      "batch 813 loss: 1.24261 acc: 0.73275 | v_loss: 1.16367 v_acc: 0.73535 |  iteration: 2057 teacher: 1 stage: sketch lr: 0.000359\n",
      "batch 814 loss: 1.25203 acc: 0.74186 | v_loss: 1.29420 v_acc: 0.72656 |  iteration: 2058 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 815 loss: 1.23868 acc: 0.73503 | v_loss: 1.25525 v_acc: 0.73698 |  iteration: 2059 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 816 loss: 1.26987 acc: 0.73470 | v_loss: 1.25779 v_acc: 0.72526 |  iteration: 2060 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 817 loss: 1.23654 acc: 0.72852 | v_loss: 1.35909 v_acc: 0.72461 |  iteration: 2061 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 818 loss: 1.34008 acc: 0.71680 | v_loss: 1.23660 v_acc: 0.73796 |  iteration: 2062 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 819 loss: 1.25479 acc: 0.74642 | v_loss: 1.21681 v_acc: 0.73503 |  iteration: 2063 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 820 loss: 1.21002 acc: 0.74154 | v_loss: 1.15046 v_acc: 0.74902 |  iteration: 2064 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 821 loss: 1.27871 acc: 0.73991 | v_loss: 1.26207 v_acc: 0.74447 |  iteration: 2065 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 822 loss: 1.29762 acc: 0.73600 | v_loss: 1.18771 v_acc: 0.74479 |  iteration: 2066 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 823 loss: 1.19880 acc: 0.74740 | v_loss: 1.19040 v_acc: 0.74544 |  iteration: 2067 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 824 loss: 1.21486 acc: 0.73828 | v_loss: 1.23328 v_acc: 0.74447 |  iteration: 2068 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 825 loss: 1.23795 acc: 0.73275 | v_loss: 1.19206 v_acc: 0.72689 |  iteration: 2069 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 826 loss: 1.21671 acc: 0.74837 | v_loss: 1.29217 v_acc: 0.72721 |  iteration: 2070 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 827 loss: 1.20286 acc: 0.73503 | v_loss: 1.25834 v_acc: 0.73307 |  iteration: 2071 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 828 loss: 1.18460 acc: 0.73991 | v_loss: 1.28135 v_acc: 0.73568 |  iteration: 2072 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 829 loss: 1.26670 acc: 0.73405 | v_loss: 1.24021 v_acc: 0.74056 |  iteration: 2073 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 830 loss: 1.23506 acc: 0.73372 | v_loss: 1.16918 v_acc: 0.74121 |  iteration: 2074 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 831 loss: 1.20654 acc: 0.74186 | v_loss: 1.13426 v_acc: 0.76660 |  iteration: 2075 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 832 loss: 1.15713 acc: 0.74772 | v_loss: 1.23087 v_acc: 0.73926 |  iteration: 2076 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 833 loss: 1.21436 acc: 0.74056 | v_loss: 1.21949 v_acc: 0.75488 |  iteration: 2077 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 834 loss: 1.27708 acc: 0.73633 | v_loss: 1.15921 v_acc: 0.75000 |  iteration: 2078 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 835 loss: 1.31384 acc: 0.72852 | v_loss: 1.23345 v_acc: 0.74186 |  iteration: 2079 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 836 loss: 1.15481 acc: 0.75586 | v_loss: 1.08922 v_acc: 0.75358 |  iteration: 2080 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 837 loss: 1.23064 acc: 0.73861 | v_loss: 1.16217 v_acc: 0.76204 |  iteration: 2081 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 838 loss: 1.24510 acc: 0.73600 | v_loss: 1.29446 v_acc: 0.72754 |  iteration: 2082 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 839 loss: 1.28916 acc: 0.72689 | v_loss: 1.20584 v_acc: 0.75000 |  iteration: 2083 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 840 loss: 1.20369 acc: 0.74382 | v_loss: 1.07490 v_acc: 0.77246 |  iteration: 2084 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 841 loss: 1.17560 acc: 0.75293 | v_loss: 1.24475 v_acc: 0.73828 |  iteration: 2085 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 842 loss: 1.26148 acc: 0.72884 | v_loss: 1.24225 v_acc: 0.75228 |  iteration: 2086 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 843 loss: 1.25943 acc: 0.73730 | v_loss: 1.27501 v_acc: 0.74382 |  iteration: 2087 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 844 loss: 1.17604 acc: 0.75391 | v_loss: 1.09113 v_acc: 0.76074 |  iteration: 2088 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 845 loss: 1.25231 acc: 0.73861 | v_loss: 1.29161 v_acc: 0.73730 |  iteration: 2089 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 846 loss: 1.21719 acc: 0.74609 | v_loss: 1.20802 v_acc: 0.74447 |  iteration: 2090 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 847 loss: 1.17396 acc: 0.74577 | v_loss: 1.33101 v_acc: 0.72982 |  iteration: 2091 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 848 loss: 1.07677 acc: 0.74577 | v_loss: 1.22232 v_acc: 0.74935 |  iteration: 2092 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 849 loss: 1.25497 acc: 0.74284 | v_loss: 1.15097 v_acc: 0.75260 |  iteration: 2093 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 850 loss: 1.18302 acc: 0.73828 | v_loss: 1.16733 v_acc: 0.73991 |  iteration: 2094 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 851 loss: 1.29803 acc: 0.73242 | v_loss: 1.20961 v_acc: 0.73112 |  iteration: 2095 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 852 loss: 1.23415 acc: 0.73796 | v_loss: 1.18298 v_acc: 0.74154 |  iteration: 2096 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 853 loss: 1.29930 acc: 0.73372 | v_loss: 1.22117 v_acc: 0.73145 |  iteration: 2097 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 854 loss: 1.25309 acc: 0.73145 | v_loss: 1.19004 v_acc: 0.75260 |  iteration: 2098 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 855 loss: 1.19185 acc: 0.73275 | v_loss: 1.26569 v_acc: 0.73340 |  iteration: 2099 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 856 loss: 1.27371 acc: 0.72917 | v_loss: 1.23632 v_acc: 0.73340 |  iteration: 2100 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 857 loss: 1.25648 acc: 0.73470 | v_loss: 1.33171 v_acc: 0.72461 |  iteration: 2101 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 858 loss: 1.27554 acc: 0.73568 | v_loss: 1.21086 v_acc: 0.73535 |  iteration: 2102 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 859 loss: 1.27435 acc: 0.72721 | v_loss: 1.11683 v_acc: 0.74577 |  iteration: 2103 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 860 loss: 1.19239 acc: 0.74284 | v_loss: 1.23668 v_acc: 0.74154 |  iteration: 2104 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 861 loss: 1.19647 acc: 0.74154 | v_loss: 1.13314 v_acc: 0.75488 |  iteration: 2105 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 862 loss: 1.17063 acc: 0.74674 | v_loss: 1.32398 v_acc: 0.72786 |  iteration: 2106 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 863 loss: 1.23687 acc: 0.72689 | v_loss: 1.25825 v_acc: 0.72982 |  iteration: 2107 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 864 loss: 1.22325 acc: 0.73079 | v_loss: 1.18771 v_acc: 0.75228 |  iteration: 2108 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 865 loss: 1.24888 acc: 0.73405 | v_loss: 1.20004 v_acc: 0.74609 |  iteration: 2109 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 866 loss: 1.16854 acc: 0.74512 | v_loss: 1.21092 v_acc: 0.73698 |  iteration: 2110 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 867 loss: 1.25037 acc: 0.72624 | v_loss: 1.28724 v_acc: 0.73893 |  iteration: 2111 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 868 loss: 1.28044 acc: 0.73893 | v_loss: 1.17563 v_acc: 0.75293 |  iteration: 2112 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 869 loss: 1.18535 acc: 0.74251 | v_loss: 1.11475 v_acc: 0.74414 |  iteration: 2113 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 870 loss: 1.24313 acc: 0.74023 | v_loss: 1.06793 v_acc: 0.76725 |  iteration: 2114 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 871 loss: 1.20260 acc: 0.74186 | v_loss: 1.15813 v_acc: 0.75065 |  iteration: 2115 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 872 loss: 1.23517 acc: 0.73828 | v_loss: 1.24115 v_acc: 0.74512 |  iteration: 2116 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 873 loss: 1.24415 acc: 0.73698 | v_loss: 1.17978 v_acc: 0.73470 |  iteration: 2117 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 874 loss: 1.25534 acc: 0.72624 | v_loss: 1.17009 v_acc: 0.75944 |  iteration: 2118 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 875 loss: 1.17696 acc: 0.74902 | v_loss: 1.24623 v_acc: 0.75228 |  iteration: 2119 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 876 loss: 1.22710 acc: 0.74479 | v_loss: 1.19998 v_acc: 0.73405 |  iteration: 2120 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 877 loss: 1.22304 acc: 0.73926 | v_loss: 1.13300 v_acc: 0.74544 |  iteration: 2121 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 878 loss: 1.27240 acc: 0.73600 | v_loss: 1.10956 v_acc: 0.75228 |  iteration: 2122 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 879 loss: 1.30248 acc: 0.71908 | v_loss: 1.12356 v_acc: 0.76465 |  iteration: 2123 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 880 loss: 1.16500 acc: 0.74382 | v_loss: 1.16888 v_acc: 0.75130 |  iteration: 2124 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 881 loss: 1.25374 acc: 0.73730 | v_loss: 1.29505 v_acc: 0.72982 |  iteration: 2125 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 882 loss: 1.28026 acc: 0.73210 | v_loss: 1.29820 v_acc: 0.72331 |  iteration: 2126 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 883 loss: 1.19191 acc: 0.74740 | v_loss: 1.18894 v_acc: 0.75065 |  iteration: 2127 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 884 loss: 1.25396 acc: 0.73698 | v_loss: 1.14883 v_acc: 0.76465 |  iteration: 2128 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 885 loss: 1.24674 acc: 0.74219 | v_loss: 1.26518 v_acc: 0.73275 |  iteration: 2129 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 886 loss: 1.25452 acc: 0.73372 | v_loss: 1.34523 v_acc: 0.72363 |  iteration: 2130 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 887 loss: 1.30373 acc: 0.72949 | v_loss: 1.16506 v_acc: 0.74447 |  iteration: 2131 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 888 loss: 1.27716 acc: 0.73145 | v_loss: 1.28319 v_acc: 0.73470 |  iteration: 2132 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 889 loss: 1.27921 acc: 0.72852 | v_loss: 1.10303 v_acc: 0.75521 |  iteration: 2133 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 890 loss: 1.15642 acc: 0.74642 | v_loss: 1.23038 v_acc: 0.73893 |  iteration: 2134 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 891 loss: 1.22845 acc: 0.74447 | v_loss: 1.20793 v_acc: 0.74609 |  iteration: 2135 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 892 loss: 1.23698 acc: 0.73340 | v_loss: 1.17266 v_acc: 0.74902 |  iteration: 2136 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 893 loss: 1.16865 acc: 0.75846 | v_loss: 1.14317 v_acc: 0.75228 |  iteration: 2137 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 894 loss: 1.28695 acc: 0.73047 | v_loss: 1.17151 v_acc: 0.74154 |  iteration: 2138 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 895 loss: 1.25196 acc: 0.73763 | v_loss: 1.20406 v_acc: 0.75260 |  iteration: 2139 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 896 loss: 1.20643 acc: 0.73600 | v_loss: 1.19667 v_acc: 0.75228 |  iteration: 2140 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 897 loss: 1.22559 acc: 0.74023 | v_loss: 1.52358 v_acc: 0.70540 |  iteration: 2141 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 898 loss: 1.21292 acc: 0.74284 | v_loss: 1.18195 v_acc: 0.74772 |  iteration: 2142 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 899 loss: 1.29785 acc: 0.73438 | v_loss: 1.25513 v_acc: 0.74284 |  iteration: 2143 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 900 loss: 1.17658 acc: 0.75293 | v_loss: 1.21325 v_acc: 0.75749 |  iteration: 2144 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 901 loss: 1.24933 acc: 0.73112 | v_loss: 1.31166 v_acc: 0.73470 |  iteration: 2145 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 902 loss: 1.23342 acc: 0.73828 | v_loss: 1.10038 v_acc: 0.76660 |  iteration: 2146 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 903 loss: 1.25930 acc: 0.73861 | v_loss: 1.27859 v_acc: 0.73763 |  iteration: 2147 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 904 loss: 1.20347 acc: 0.75163 | v_loss: 1.17664 v_acc: 0.73828 |  iteration: 2148 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 905 loss: 1.18377 acc: 0.75195 | v_loss: 1.30262 v_acc: 0.73242 |  iteration: 2149 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 906 loss: 1.20320 acc: 0.74349 | v_loss: 1.28805 v_acc: 0.73242 |  iteration: 2150 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 907 loss: 1.34259 acc: 0.72038 | v_loss: 1.25205 v_acc: 0.72884 |  iteration: 2151 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 908 loss: 1.19570 acc: 0.74935 | v_loss: 1.35130 v_acc: 0.73210 |  iteration: 2152 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 909 loss: 1.17406 acc: 0.74642 | v_loss: 1.22574 v_acc: 0.74479 |  iteration: 2153 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 910 loss: 1.20670 acc: 0.74186 | v_loss: 1.20924 v_acc: 0.73633 |  iteration: 2154 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 911 loss: 1.32569 acc: 0.72461 | v_loss: 1.15365 v_acc: 0.75033 |  iteration: 2155 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 912 loss: 1.22858 acc: 0.73014 | v_loss: 1.26622 v_acc: 0.74023 |  iteration: 2156 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 913 loss: 1.25901 acc: 0.73210 | v_loss: 1.17966 v_acc: 0.74772 |  iteration: 2157 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 914 loss: 1.17026 acc: 0.73828 | v_loss: 1.16567 v_acc: 0.75000 |  iteration: 2158 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 915 loss: 1.15985 acc: 0.74056 | v_loss: 1.22948 v_acc: 0.74512 |  iteration: 2159 teacher: 0 stage: sketch lr: 0.000377\n",
      "batch 916 loss: 1.26844 acc: 0.73698 | v_loss: 1.19994 v_acc: 0.73079 |  iteration: 2160 teacher: 1 stage: sketch lr: 0.000377\n",
      "batch 917 loss: 1.33042 acc: 0.71777 | v_loss: 1.29171 v_acc: 0.72526 |  iteration: 2161 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 918 loss: 1.22132 acc: 0.74251 | v_loss: 1.26579 v_acc: 0.73372 |  iteration: 2162 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 919 loss: 1.27470 acc: 0.73991 | v_loss: 1.28771 v_acc: 0.73861 |  iteration: 2163 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 920 loss: 1.13123 acc: 0.75879 | v_loss: 1.24305 v_acc: 0.74772 |  iteration: 2164 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 921 loss: 1.28396 acc: 0.73438 | v_loss: 1.16498 v_acc: 0.75260 |  iteration: 2165 teacher: 1 stage: sketch lr: 0.000378\n",
      "batch 922 loss: 1.25105 acc: 0.73438 | v_loss: 1.13307 v_acc: 0.76465 |  iteration: 2166 teacher: 0 stage: sketch lr: 0.000378\n",
      "batch 923 loss: 1.25631 acc: 0.74544 | v_loss: 1.22486 v_acc: 0.74382 |  iteration: 2167 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 924 loss: 1.25492 acc: 0.73535 | v_loss: 1.21562 v_acc: 0.76302 |  iteration: 2168 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 925 loss: 1.24589 acc: 0.72461 | v_loss: 1.15353 v_acc: 0.75716 |  iteration: 2169 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 926 loss: 1.21382 acc: 0.73926 | v_loss: 1.22656 v_acc: 0.73730 |  iteration: 2170 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 927 loss: 1.26204 acc: 0.73600 | v_loss: 1.08174 v_acc: 0.75553 |  iteration: 2171 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 928 loss: 1.23902 acc: 0.73861 | v_loss: 1.16255 v_acc: 0.75944 |  iteration: 2172 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 929 loss: 1.25733 acc: 0.74186 | v_loss: 1.28220 v_acc: 0.72331 |  iteration: 2173 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 930 loss: 1.30590 acc: 0.73568 | v_loss: 1.20309 v_acc: 0.74935 |  iteration: 2174 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 931 loss: 1.20550 acc: 0.74089 | v_loss: 1.07798 v_acc: 0.77376 |  iteration: 2175 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 932 loss: 1.30382 acc: 0.73600 | v_loss: 1.26083 v_acc: 0.74382 |  iteration: 2176 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 933 loss: 1.27820 acc: 0.72689 | v_loss: 1.24696 v_acc: 0.74642 |  iteration: 2177 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 934 loss: 1.41241 acc: 0.71680 | v_loss: 1.27256 v_acc: 0.75163 |  iteration: 2178 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 935 loss: 1.21571 acc: 0.74121 | v_loss: 1.10273 v_acc: 0.75358 |  iteration: 2179 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 936 loss: 1.29041 acc: 0.73568 | v_loss: 1.29693 v_acc: 0.73568 |  iteration: 2180 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 937 loss: 1.27653 acc: 0.73405 | v_loss: 1.21892 v_acc: 0.73926 |  iteration: 2181 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 938 loss: 1.26224 acc: 0.74056 | v_loss: 1.32028 v_acc: 0.72884 |  iteration: 2182 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 939 loss: 1.36082 acc: 0.72396 | v_loss: 1.22123 v_acc: 0.74479 |  iteration: 2183 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 940 loss: 1.21951 acc: 0.73828 | v_loss: 1.16625 v_acc: 0.75586 |  iteration: 2184 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 941 loss: 1.19406 acc: 0.73633 | v_loss: 1.13844 v_acc: 0.74805 |  iteration: 2185 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 942 loss: 1.29845 acc: 0.73079 | v_loss: 1.23364 v_acc: 0.71582 |  iteration: 2186 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 943 loss: 1.22090 acc: 0.74707 | v_loss: 1.17469 v_acc: 0.74382 |  iteration: 2187 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 944 loss: 1.21015 acc: 0.73861 | v_loss: 1.22739 v_acc: 0.72786 |  iteration: 2188 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 945 loss: 1.14239 acc: 0.74577 | v_loss: 1.20059 v_acc: 0.75228 |  iteration: 2189 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 946 loss: 1.31180 acc: 0.71745 | v_loss: 1.27416 v_acc: 0.72786 |  iteration: 2190 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 947 loss: 1.27952 acc: 0.72852 | v_loss: 1.24186 v_acc: 0.73828 |  iteration: 2191 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 948 loss: 1.16214 acc: 0.74544 | v_loss: 1.35065 v_acc: 0.72461 |  iteration: 2192 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 949 loss: 1.19406 acc: 0.74674 | v_loss: 1.22140 v_acc: 0.72721 |  iteration: 2193 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 950 loss: 1.23824 acc: 0.73665 | v_loss: 1.14204 v_acc: 0.74056 |  iteration: 2194 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 951 loss: 1.25183 acc: 0.73665 | v_loss: 1.26552 v_acc: 0.73926 |  iteration: 2195 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 952 loss: 1.22457 acc: 0.73633 | v_loss: 1.13878 v_acc: 0.75553 |  iteration: 2196 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 953 loss: 1.27770 acc: 0.73047 | v_loss: 1.31395 v_acc: 0.72852 |  iteration: 2197 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 954 loss: 1.24968 acc: 0.74089 | v_loss: 1.26530 v_acc: 0.73698 |  iteration: 2198 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 955 loss: 1.18625 acc: 0.75065 | v_loss: 1.18748 v_acc: 0.74902 |  iteration: 2199 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 956 loss: 1.28587 acc: 0.71680 | v_loss: 1.22665 v_acc: 0.74382 |  iteration: 2200 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 957 loss: 1.20987 acc: 0.72819 | v_loss: 1.22355 v_acc: 0.74121 |  iteration: 2201 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 958 loss: 1.28614 acc: 0.72917 | v_loss: 1.29711 v_acc: 0.74121 |  iteration: 2202 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 959 loss: 1.28354 acc: 0.72396 | v_loss: 1.15481 v_acc: 0.76204 |  iteration: 2203 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 960 loss: 1.20674 acc: 0.74349 | v_loss: 1.10303 v_acc: 0.75618 |  iteration: 2204 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 961 loss: 1.16954 acc: 0.75098 | v_loss: 1.08877 v_acc: 0.76042 |  iteration: 2205 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 962 loss: 1.22994 acc: 0.73828 | v_loss: 1.17329 v_acc: 0.74740 |  iteration: 2206 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 963 loss: 1.22123 acc: 0.74154 | v_loss: 1.24967 v_acc: 0.73665 |  iteration: 2207 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 964 loss: 1.32892 acc: 0.72656 | v_loss: 1.20766 v_acc: 0.73242 |  iteration: 2208 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 965 loss: 1.16135 acc: 0.74674 | v_loss: 1.18752 v_acc: 0.74837 |  iteration: 2209 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 966 loss: 1.21940 acc: 0.73991 | v_loss: 1.28014 v_acc: 0.74642 |  iteration: 2210 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 967 loss: 1.29426 acc: 0.73340 | v_loss: 1.20255 v_acc: 0.72917 |  iteration: 2211 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 968 loss: 1.26090 acc: 0.74121 | v_loss: 1.12699 v_acc: 0.75391 |  iteration: 2212 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 969 loss: 1.32604 acc: 0.73079 | v_loss: 1.12886 v_acc: 0.75130 |  iteration: 2213 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 970 loss: 1.20544 acc: 0.74382 | v_loss: 1.14277 v_acc: 0.76237 |  iteration: 2214 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 971 loss: 1.26428 acc: 0.73047 | v_loss: 1.17163 v_acc: 0.74935 |  iteration: 2215 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 972 loss: 1.22025 acc: 0.73438 | v_loss: 1.30760 v_acc: 0.73210 |  iteration: 2216 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 973 loss: 1.23739 acc: 0.74056 | v_loss: 1.30312 v_acc: 0.72201 |  iteration: 2217 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 974 loss: 1.30132 acc: 0.73307 | v_loss: 1.19672 v_acc: 0.74544 |  iteration: 2218 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 975 loss: 1.27930 acc: 0.73405 | v_loss: 1.13118 v_acc: 0.76953 |  iteration: 2219 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 976 loss: 1.25098 acc: 0.73405 | v_loss: 1.26960 v_acc: 0.72884 |  iteration: 2220 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 977 loss: 1.23084 acc: 0.73503 | v_loss: 1.34512 v_acc: 0.72005 |  iteration: 2221 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 978 loss: 1.21692 acc: 0.74577 | v_loss: 1.17712 v_acc: 0.75456 |  iteration: 2222 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 979 loss: 1.26258 acc: 0.73438 | v_loss: 1.29502 v_acc: 0.73210 |  iteration: 2223 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 980 loss: 1.12846 acc: 0.75163 | v_loss: 1.10188 v_acc: 0.75977 |  iteration: 2224 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 981 loss: 1.28505 acc: 0.73633 | v_loss: 1.22187 v_acc: 0.74772 |  iteration: 2225 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 982 loss: 1.16464 acc: 0.74674 | v_loss: 1.22187 v_acc: 0.74577 |  iteration: 2226 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 983 loss: 1.26238 acc: 0.73763 | v_loss: 1.16600 v_acc: 0.75521 |  iteration: 2227 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 984 loss: 1.29045 acc: 0.73177 | v_loss: 1.14579 v_acc: 0.74935 |  iteration: 2228 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 985 loss: 1.28812 acc: 0.73275 | v_loss: 1.16697 v_acc: 0.74089 |  iteration: 2229 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 986 loss: 1.17008 acc: 0.75228 | v_loss: 1.20750 v_acc: 0.75423 |  iteration: 2230 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 987 loss: 1.21494 acc: 0.74121 | v_loss: 1.21147 v_acc: 0.75456 |  iteration: 2231 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 988 loss: 1.29234 acc: 0.73470 | v_loss: 1.50541 v_acc: 0.70345 |  iteration: 2232 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 989 loss: 1.20831 acc: 0.74577 | v_loss: 1.14884 v_acc: 0.74642 |  iteration: 2233 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 990 loss: 1.25190 acc: 0.73014 | v_loss: 1.22654 v_acc: 0.74805 |  iteration: 2234 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 991 loss: 1.29244 acc: 0.72949 | v_loss: 1.21989 v_acc: 0.75228 |  iteration: 2235 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 992 loss: 1.14425 acc: 0.74512 | v_loss: 1.31678 v_acc: 0.73438 |  iteration: 2236 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 993 loss: 1.24804 acc: 0.73828 | v_loss: 1.09360 v_acc: 0.76986 |  iteration: 2237 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 994 loss: 1.22966 acc: 0.73405 | v_loss: 1.28588 v_acc: 0.73210 |  iteration: 2238 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 995 loss: 1.11312 acc: 0.75326 | v_loss: 1.16036 v_acc: 0.73926 |  iteration: 2239 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 996 loss: 1.21872 acc: 0.73730 | v_loss: 1.30330 v_acc: 0.72428 |  iteration: 2240 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 997 loss: 1.18053 acc: 0.74447 | v_loss: 1.25067 v_acc: 0.73796 |  iteration: 2241 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 998 loss: 1.20546 acc: 0.73503 | v_loss: 1.22987 v_acc: 0.73242 |  iteration: 2242 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 999 loss: 1.25464 acc: 0.72917 | v_loss: 1.33140 v_acc: 0.73763 |  iteration: 2243 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 1000 loss: 1.22091 acc: 0.73926 | v_loss: 1.22140 v_acc: 0.74382 |  iteration: 2244 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 1001 loss: 1.27333 acc: 0.73405 | v_loss: 1.21250 v_acc: 0.73079 |  iteration: 2245 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 1002 loss: 1.20756 acc: 0.74512 | v_loss: 1.14420 v_acc: 0.74837 |  iteration: 2246 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 1003 loss: 1.29205 acc: 0.73796 | v_loss: 1.23038 v_acc: 0.74740 |  iteration: 2247 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 1004 loss: 1.16344 acc: 0.74870 | v_loss: 1.15927 v_acc: 0.75488 |  iteration: 2248 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 1005 loss: 1.21037 acc: 0.73926 | v_loss: 1.14670 v_acc: 0.75130 |  iteration: 2249 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 1006 loss: 1.26623 acc: 0.73014 | v_loss: 1.22516 v_acc: 0.74414 |  iteration: 2250 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 1007 loss: 1.24069 acc: 0.73633 | v_loss: 1.17877 v_acc: 0.73958 |  iteration: 2251 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 1008 loss: 1.33647 acc: 0.73405 | v_loss: 1.29023 v_acc: 0.72461 |  iteration: 2252 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 1009 loss: 1.24077 acc: 0.73535 | v_loss: 1.25049 v_acc: 0.72949 |  iteration: 2253 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 1010 loss: 1.22255 acc: 0.74382 | v_loss: 1.25885 v_acc: 0.74479 |  iteration: 2254 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 1011 loss: 1.27026 acc: 0.73047 | v_loss: 1.23594 v_acc: 0.74447 |  iteration: 2255 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 1012 loss: 1.18818 acc: 0.74284 | v_loss: 1.16642 v_acc: 0.74186 |  iteration: 2256 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 1013 loss: 1.20690 acc: 0.73861 | v_loss: 1.12145 v_acc: 0.76986 |  iteration: 2257 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 1014 loss: 1.34320 acc: 0.72201 | v_loss: 1.21993 v_acc: 0.74349 |  iteration: 2258 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 1015 loss: 1.21853 acc: 0.74740 | v_loss: 1.21343 v_acc: 0.76270 |  iteration: 2259 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 1016 loss: 1.16890 acc: 0.74772 | v_loss: 1.15334 v_acc: 0.75521 |  iteration: 2260 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 1017 loss: 1.17156 acc: 0.74805 | v_loss: 1.22829 v_acc: 0.74447 |  iteration: 2261 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 1018 loss: 1.22789 acc: 0.74089 | v_loss: 1.07088 v_acc: 0.75651 |  iteration: 2262 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 1019 loss: 1.18308 acc: 0.74577 | v_loss: 1.14593 v_acc: 0.76009 |  iteration: 2263 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 1020 loss: 1.26282 acc: 0.72363 | v_loss: 1.27029 v_acc: 0.72461 |  iteration: 2264 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 1021 loss: 1.19946 acc: 0.73730 | v_loss: 1.20350 v_acc: 0.74967 |  iteration: 2265 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 1022 loss: 1.25399 acc: 0.74447 | v_loss: 1.06367 v_acc: 0.77865 |  iteration: 2266 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 1023 loss: 1.20347 acc: 0.74251 | v_loss: 1.24426 v_acc: 0.73307 |  iteration: 2267 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 1024 loss: 1.19048 acc: 0.73893 | v_loss: 1.21978 v_acc: 0.75456 |  iteration: 2268 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 1025 loss: 1.20435 acc: 0.74284 | v_loss: 1.29767 v_acc: 0.73861 |  iteration: 2269 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 1026 loss: 1.34300 acc: 0.72917 | v_loss: 1.07849 v_acc: 0.74870 |  iteration: 2270 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1027 loss: 1.32879 acc: 0.72624 | v_loss: 1.26613 v_acc: 0.74023 |  iteration: 2271 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1028 loss: 1.17699 acc: 0.74805 | v_loss: 1.18595 v_acc: 0.75423 |  iteration: 2272 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1029 loss: 1.24185 acc: 0.74251 | v_loss: 1.31019 v_acc: 0.72949 |  iteration: 2273 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1030 loss: 1.29345 acc: 0.73275 | v_loss: 1.21204 v_acc: 0.74447 |  iteration: 2274 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1031 loss: 1.27254 acc: 0.73210 | v_loss: 1.13001 v_acc: 0.75814 |  iteration: 2275 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1032 loss: 1.22864 acc: 0.74674 | v_loss: 1.13313 v_acc: 0.75195 |  iteration: 2276 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1033 loss: 1.09811 acc: 0.76042 | v_loss: 1.20896 v_acc: 0.73177 |  iteration: 2277 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1034 loss: 1.21573 acc: 0.73796 | v_loss: 1.16289 v_acc: 0.74609 |  iteration: 2278 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1035 loss: 1.34279 acc: 0.72786 | v_loss: 1.21147 v_acc: 0.72949 |  iteration: 2279 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1036 loss: 1.21076 acc: 0.74349 | v_loss: 1.20156 v_acc: 0.75195 |  iteration: 2280 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1037 loss: 1.30306 acc: 0.73340 | v_loss: 1.27160 v_acc: 0.72493 |  iteration: 2281 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1038 loss: 1.29334 acc: 0.72982 | v_loss: 1.23674 v_acc: 0.72852 |  iteration: 2282 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1039 loss: 1.25576 acc: 0.73242 | v_loss: 1.32211 v_acc: 0.72428 |  iteration: 2283 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1040 loss: 1.25125 acc: 0.73991 | v_loss: 1.21295 v_acc: 0.72949 |  iteration: 2284 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1041 loss: 1.17586 acc: 0.75033 | v_loss: 1.11550 v_acc: 0.74837 |  iteration: 2285 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1042 loss: 1.15596 acc: 0.74870 | v_loss: 1.22873 v_acc: 0.74447 |  iteration: 2286 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1043 loss: 1.18426 acc: 0.75000 | v_loss: 1.12869 v_acc: 0.75846 |  iteration: 2287 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1044 loss: 1.26535 acc: 0.72656 | v_loss: 1.28919 v_acc: 0.72982 |  iteration: 2288 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1045 loss: 1.15740 acc: 0.75618 | v_loss: 1.25724 v_acc: 0.73047 |  iteration: 2289 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1046 loss: 1.26007 acc: 0.73340 | v_loss: 1.18161 v_acc: 0.75130 |  iteration: 2290 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1047 loss: 1.25917 acc: 0.73991 | v_loss: 1.23288 v_acc: 0.74414 |  iteration: 2291 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1048 loss: 1.20757 acc: 0.74349 | v_loss: 1.21546 v_acc: 0.73665 |  iteration: 2292 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1049 loss: 1.36207 acc: 0.71745 | v_loss: 1.28470 v_acc: 0.74089 |  iteration: 2293 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 1050 loss: 1.23591 acc: 0.74870 | v_loss: 1.16677 v_acc: 0.75391 |  iteration: 2294 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 1051 loss: 1.37608 acc: 0.71549 | v_loss: 1.11918 v_acc: 0.75228 |  iteration: 2295 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 1052 loss: 1.22916 acc: 0.73568 | v_loss: 1.06830 v_acc: 0.76237 |  iteration: 2296 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 1053 loss: 1.23327 acc: 0.73112 | v_loss: 1.16430 v_acc: 0.74805 |  iteration: 2297 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 1054 loss: 1.26325 acc: 0.73600 | v_loss: 1.24286 v_acc: 0.74382 |  iteration: 2298 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 1055 loss: 1.24438 acc: 0.73600 | v_loss: 1.17909 v_acc: 0.74056 |  iteration: 2299 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 1056 loss: 1.20983 acc: 0.73372 | v_loss: 1.17532 v_acc: 0.75358 |  iteration: 2300 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 1057 loss: 1.12659 acc: 0.75651 | v_loss: 1.26248 v_acc: 0.75130 |  iteration: 2301 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 1058 loss: 1.23218 acc: 0.73861 | v_loss: 1.18934 v_acc: 0.73730 |  iteration: 2302 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 1059 loss: 1.24295 acc: 0.72786 | v_loss: 1.12192 v_acc: 0.75521 |  iteration: 2303 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 1060 loss: 1.27185 acc: 0.73177 | v_loss: 1.10543 v_acc: 0.75781 |  iteration: 2304 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 1061 loss: 1.21924 acc: 0.74382 | v_loss: 1.10987 v_acc: 0.76465 |  iteration: 2305 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 1062 loss: 1.21441 acc: 0.73242 | v_loss: 1.15759 v_acc: 0.75553 |  iteration: 2306 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 1063 loss: 1.26493 acc: 0.73730 | v_loss: 1.28446 v_acc: 0.73438 |  iteration: 2307 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 1064 loss: 1.24543 acc: 0.73828 | v_loss: 1.27367 v_acc: 0.72656 |  iteration: 2308 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 1065 loss: 1.21673 acc: 0.74121 | v_loss: 1.17608 v_acc: 0.74805 |  iteration: 2309 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 1066 loss: 1.26765 acc: 0.73633 | v_loss: 1.13994 v_acc: 0.76628 |  iteration: 2310 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 1067 loss: 1.29821 acc: 0.73438 | v_loss: 1.25963 v_acc: 0.73079 |  iteration: 2311 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 1068 loss: 1.23705 acc: 0.73796 | v_loss: 1.32611 v_acc: 0.72461 |  iteration: 2312 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 1069 loss: 1.29895 acc: 0.73210 | v_loss: 1.14091 v_acc: 0.75130 |  iteration: 2313 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 1070 loss: 1.20700 acc: 0.73991 | v_loss: 1.26812 v_acc: 0.74219 |  iteration: 2314 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 1071 loss: 1.13505 acc: 0.75000 | v_loss: 1.09509 v_acc: 0.75716 |  iteration: 2315 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 1072 loss: 1.15510 acc: 0.74544 | v_loss: 1.21360 v_acc: 0.74544 |  iteration: 2316 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 1073 loss: 1.23936 acc: 0.73112 | v_loss: 1.20661 v_acc: 0.75521 |  iteration: 2317 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 1074 loss: 1.21716 acc: 0.73958 | v_loss: 1.15434 v_acc: 0.75684 |  iteration: 2318 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 1075 loss: 1.17463 acc: 0.73730 | v_loss: 1.13274 v_acc: 0.75684 |  iteration: 2319 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 1076 loss: 1.16422 acc: 0.74837 | v_loss: 1.15785 v_acc: 0.74251 |  iteration: 2320 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 1077 loss: 1.17418 acc: 0.74219 | v_loss: 1.19505 v_acc: 0.75488 |  iteration: 2321 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 1078 loss: 1.28850 acc: 0.72949 | v_loss: 1.19146 v_acc: 0.75456 |  iteration: 2322 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 1079 loss: 1.29366 acc: 0.72852 | v_loss: 1.51753 v_acc: 0.70117 |  iteration: 2323 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 1080 loss: 1.22089 acc: 0.73698 | v_loss: 1.15050 v_acc: 0.74577 |  iteration: 2324 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 1081 loss: 1.25138 acc: 0.72949 | v_loss: 1.22194 v_acc: 0.74674 |  iteration: 2325 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 1082 loss: 1.29477 acc: 0.73828 | v_loss: 1.20843 v_acc: 0.76074 |  iteration: 2326 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 1083 loss: 1.14504 acc: 0.75033 | v_loss: 1.30445 v_acc: 0.73861 |  iteration: 2327 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 1084 loss: 1.26816 acc: 0.72559 | v_loss: 1.08141 v_acc: 0.77279 |  iteration: 2328 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 1085 loss: 1.22874 acc: 0.73926 | v_loss: 1.26707 v_acc: 0.73535 |  iteration: 2329 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 1086 loss: 1.22253 acc: 0.74805 | v_loss: 1.15008 v_acc: 0.74674 |  iteration: 2330 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 1087 loss: 1.16364 acc: 0.75163 | v_loss: 1.28289 v_acc: 0.73014 |  iteration: 2331 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 1088 loss: 1.19442 acc: 0.75033 | v_loss: 1.25328 v_acc: 0.74056 |  iteration: 2332 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 1089 loss: 1.24016 acc: 0.74447 | v_loss: 1.23902 v_acc: 0.73275 |  iteration: 2333 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 1090 loss: 1.25704 acc: 0.73796 | v_loss: 1.34757 v_acc: 0.72591 |  iteration: 2334 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 1091 loss: 1.29134 acc: 0.72656 | v_loss: 1.21371 v_acc: 0.73861 |  iteration: 2335 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 1092 loss: 1.24147 acc: 0.73470 | v_loss: 1.20518 v_acc: 0.73861 |  iteration: 2336 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 1093 loss: 1.23971 acc: 0.72754 | v_loss: 1.14008 v_acc: 0.75586 |  iteration: 2337 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 1094 loss: 1.25364 acc: 0.73665 | v_loss: 1.23432 v_acc: 0.74707 |  iteration: 2338 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 1095 loss: 1.21548 acc: 0.74023 | v_loss: 1.16268 v_acc: 0.74544 |  iteration: 2339 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 1096 loss: 1.19475 acc: 0.74740 | v_loss: 1.15056 v_acc: 0.75651 |  iteration: 2340 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 1097 loss: 1.22070 acc: 0.74089 | v_loss: 1.22017 v_acc: 0.74870 |  iteration: 2341 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 1098 loss: 1.19023 acc: 0.74544 | v_loss: 1.18360 v_acc: 0.73893 |  iteration: 2342 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 1099 loss: 1.22663 acc: 0.74316 | v_loss: 1.30639 v_acc: 0.72852 |  iteration: 2343 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 1100 loss: 1.21432 acc: 0.73503 | v_loss: 1.25925 v_acc: 0.73145 |  iteration: 2344 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 1101 loss: 1.24480 acc: 0.74284 | v_loss: 1.25388 v_acc: 0.74251 |  iteration: 2345 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 1102 loss: 1.20963 acc: 0.73926 | v_loss: 1.25057 v_acc: 0.74219 |  iteration: 2346 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 1103 loss: 1.17158 acc: 0.74805 | v_loss: 1.16222 v_acc: 0.74154 |  iteration: 2347 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 1104 loss: 1.20860 acc: 0.73991 | v_loss: 1.11593 v_acc: 0.77279 |  iteration: 2348 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 1105 loss: 1.23455 acc: 0.74056 | v_loss: 1.22709 v_acc: 0.74447 |  iteration: 2349 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 1106 loss: 1.29214 acc: 0.73112 | v_loss: 1.20276 v_acc: 0.76530 |  iteration: 2350 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 1107 loss: 1.23151 acc: 0.73796 | v_loss: 1.16719 v_acc: 0.74805 |  iteration: 2351 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 1108 loss: 1.15260 acc: 0.74316 | v_loss: 1.22754 v_acc: 0.74349 |  iteration: 2352 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 1109 loss: 1.20678 acc: 0.74479 | v_loss: 1.07915 v_acc: 0.75456 |  iteration: 2353 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 1110 loss: 1.20724 acc: 0.74121 | v_loss: 1.16648 v_acc: 0.76107 |  iteration: 2354 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 1111 loss: 1.23340 acc: 0.74186 | v_loss: 1.26198 v_acc: 0.73405 |  iteration: 2355 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 1112 loss: 1.19460 acc: 0.74805 | v_loss: 1.18984 v_acc: 0.75553 |  iteration: 2356 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 1113 loss: 1.18639 acc: 0.74870 | v_loss: 1.07488 v_acc: 0.77799 |  iteration: 2357 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 1114 loss: 1.26536 acc: 0.73242 | v_loss: 1.25581 v_acc: 0.73665 |  iteration: 2358 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 1115 loss: 1.18549 acc: 0.74186 | v_loss: 1.23368 v_acc: 0.75098 |  iteration: 2359 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 1116 loss: 1.26989 acc: 0.73991 | v_loss: 1.29184 v_acc: 0.74056 |  iteration: 2360 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 1117 loss: 1.28307 acc: 0.72819 | v_loss: 1.07706 v_acc: 0.76042 |  iteration: 2361 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 1118 loss: 1.22524 acc: 0.73730 | v_loss: 1.28229 v_acc: 0.73730 |  iteration: 2362 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 1119 loss: 1.26999 acc: 0.72917 | v_loss: 1.20146 v_acc: 0.75358 |  iteration: 2363 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 1120 loss: 1.17463 acc: 0.75846 | v_loss: 1.29373 v_acc: 0.73405 |  iteration: 2364 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 1121 loss: 1.23888 acc: 0.73242 | v_loss: 1.20333 v_acc: 0.75098 |  iteration: 2365 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 1122 loss: 1.21800 acc: 0.74674 | v_loss: 1.12877 v_acc: 0.75977 |  iteration: 2366 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 1123 loss: 1.14581 acc: 0.76107 | v_loss: 1.15814 v_acc: 0.74805 |  iteration: 2367 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 1124 loss: 1.20165 acc: 0.74674 | v_loss: 1.19330 v_acc: 0.72103 |  iteration: 2368 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 1125 loss: 1.24588 acc: 0.73698 | v_loss: 1.16328 v_acc: 0.74284 |  iteration: 2369 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 1126 loss: 1.27149 acc: 0.73177 | v_loss: 1.19513 v_acc: 0.74284 |  iteration: 2370 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 1127 loss: 1.26950 acc: 0.73470 | v_loss: 1.19716 v_acc: 0.75618 |  iteration: 2371 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 1128 loss: 1.12018 acc: 0.76042 | v_loss: 1.24713 v_acc: 0.73958 |  iteration: 2372 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 1129 loss: 1.24588 acc: 0.74089 | v_loss: 1.21852 v_acc: 0.73047 |  iteration: 2373 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 1130 loss: 1.28660 acc: 0.73405 | v_loss: 1.31429 v_acc: 0.73079 |  iteration: 2374 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 1131 loss: 1.28313 acc: 0.72852 | v_loss: 1.21437 v_acc: 0.73047 |  iteration: 2375 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 1132 loss: 1.23922 acc: 0.73730 | v_loss: 1.11834 v_acc: 0.74577 |  iteration: 2376 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 1133 loss: 1.16579 acc: 0.74902 | v_loss: 1.26186 v_acc: 0.73861 |  iteration: 2377 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 1134 loss: 1.23306 acc: 0.74382 | v_loss: 1.12886 v_acc: 0.76335 |  iteration: 2378 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 1135 loss: 1.22685 acc: 0.73861 | v_loss: 1.30729 v_acc: 0.73047 |  iteration: 2379 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 1136 loss: 1.14575 acc: 0.75033 | v_loss: 1.24150 v_acc: 0.73796 |  iteration: 2380 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 1137 loss: 1.15277 acc: 0.75488 | v_loss: 1.17578 v_acc: 0.75586 |  iteration: 2381 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 1138 loss: 1.20667 acc: 0.74772 | v_loss: 1.22033 v_acc: 0.74186 |  iteration: 2382 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 1139 loss: 1.23619 acc: 0.74544 | v_loss: 1.21932 v_acc: 0.74089 |  iteration: 2383 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 1140 loss: 1.33225 acc: 0.72070 | v_loss: 1.29245 v_acc: 0.74219 |  iteration: 2384 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 1141 loss: 1.25362 acc: 0.73861 | v_loss: 1.15692 v_acc: 0.75716 |  iteration: 2385 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 1142 loss: 1.23731 acc: 0.74284 | v_loss: 1.12315 v_acc: 0.75000 |  iteration: 2386 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 1143 loss: 1.23402 acc: 0.73828 | v_loss: 1.07064 v_acc: 0.76660 |  iteration: 2387 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 1144 loss: 1.17806 acc: 0.75260 | v_loss: 1.15476 v_acc: 0.75228 |  iteration: 2388 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 1145 loss: 1.16734 acc: 0.75000 | v_loss: 1.24037 v_acc: 0.73568 |  iteration: 2389 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 1146 loss: 1.17519 acc: 0.74447 | v_loss: 1.20182 v_acc: 0.72884 |  iteration: 2390 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1147 loss: 1.20459 acc: 0.74023 | v_loss: 1.18209 v_acc: 0.75293 |  iteration: 2391 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1148 loss: 1.29361 acc: 0.73372 | v_loss: 1.27171 v_acc: 0.74740 |  iteration: 2392 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1149 loss: 1.19311 acc: 0.74805 | v_loss: 1.19323 v_acc: 0.73438 |  iteration: 2393 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1150 loss: 1.26334 acc: 0.73535 | v_loss: 1.12437 v_acc: 0.75098 |  iteration: 2394 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1151 loss: 1.18326 acc: 0.75195 | v_loss: 1.10901 v_acc: 0.75098 |  iteration: 2395 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1152 loss: 1.22125 acc: 0.73307 | v_loss: 1.12405 v_acc: 0.76790 |  iteration: 2396 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1153 loss: 1.21169 acc: 0.75000 | v_loss: 1.16355 v_acc: 0.75033 |  iteration: 2397 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1154 loss: 1.24286 acc: 0.73730 | v_loss: 1.29507 v_acc: 0.73438 |  iteration: 2398 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1155 loss: 1.19320 acc: 0.75163 | v_loss: 1.27019 v_acc: 0.72624 |  iteration: 2399 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1156 loss: 1.25682 acc: 0.73177 | v_loss: 1.17851 v_acc: 0.74414 |  iteration: 2400 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1157 loss: 1.23965 acc: 0.73470 | v_loss: 1.13617 v_acc: 0.76270 |  iteration: 2401 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1158 loss: 1.23713 acc: 0.73633 | v_loss: 1.25006 v_acc: 0.73503 |  iteration: 2402 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1159 loss: 1.18475 acc: 0.74642 | v_loss: 1.33643 v_acc: 0.72005 |  iteration: 2403 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1160 loss: 1.14782 acc: 0.74772 | v_loss: 1.15176 v_acc: 0.75033 |  iteration: 2404 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1161 loss: 1.18653 acc: 0.73405 | v_loss: 1.25983 v_acc: 0.74023 |  iteration: 2405 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1162 loss: 1.12114 acc: 0.76107 | v_loss: 1.09208 v_acc: 0.75260 |  iteration: 2406 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1163 loss: 1.21500 acc: 0.74056 | v_loss: 1.21311 v_acc: 0.74642 |  iteration: 2407 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1164 loss: 1.14680 acc: 0.76139 | v_loss: 1.20655 v_acc: 0.75195 |  iteration: 2408 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1165 loss: 1.12200 acc: 0.76107 | v_loss: 1.16647 v_acc: 0.75423 |  iteration: 2409 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1166 loss: 1.19912 acc: 0.74902 | v_loss: 1.12822 v_acc: 0.75586 |  iteration: 2410 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1167 loss: 1.20824 acc: 0.74772 | v_loss: 1.17241 v_acc: 0.74349 |  iteration: 2411 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1168 loss: 1.25248 acc: 0.73405 | v_loss: 1.19715 v_acc: 0.75911 |  iteration: 2412 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1169 loss: 1.22074 acc: 0.73926 | v_loss: 1.18807 v_acc: 0.75456 |  iteration: 2413 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1170 loss: 1.28185 acc: 0.72819 | v_loss: 1.51988 v_acc: 0.69694 |  iteration: 2414 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1171 loss: 1.18885 acc: 0.74382 | v_loss: 1.14512 v_acc: 0.74837 |  iteration: 2415 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1172 loss: 1.17584 acc: 0.74674 | v_loss: 1.21144 v_acc: 0.75358 |  iteration: 2416 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1173 loss: 1.16484 acc: 0.74870 | v_loss: 1.19215 v_acc: 0.75911 |  iteration: 2417 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1174 loss: 1.43044 acc: 0.71289 | v_loss: 1.30374 v_acc: 0.73698 |  iteration: 2418 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1175 loss: 1.34685 acc: 0.72168 | v_loss: 1.12412 v_acc: 0.76562 |  iteration: 2419 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 1176 loss: 1.26675 acc: 0.73372 | v_loss: 1.31849 v_acc: 0.74023 |  iteration: 2420 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 1177 loss: 1.16899 acc: 0.75488 | v_loss: 1.18062 v_acc: 0.73893 |  iteration: 2421 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 1178 loss: 1.25545 acc: 0.73145 | v_loss: 1.32685 v_acc: 0.72493 |  iteration: 2422 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 1179 loss: 1.23588 acc: 0.73893 | v_loss: 1.26364 v_acc: 0.73405 |  iteration: 2423 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 1180 loss: 1.25589 acc: 0.73405 | v_loss: 1.24892 v_acc: 0.72689 |  iteration: 2424 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 1181 loss: 1.23877 acc: 0.74349 | v_loss: 1.34694 v_acc: 0.73861 |  iteration: 2425 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 1182 loss: 1.25646 acc: 0.73340 | v_loss: 1.23738 v_acc: 0.73535 |  iteration: 2426 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 1183 loss: 1.26384 acc: 0.73372 | v_loss: 1.21293 v_acc: 0.73600 |  iteration: 2427 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 1184 loss: 1.17767 acc: 0.74805 | v_loss: 1.15837 v_acc: 0.74935 |  iteration: 2428 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 1185 loss: 1.22041 acc: 0.73568 | v_loss: 1.24325 v_acc: 0.74349 |  iteration: 2429 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 1186 loss: 1.28541 acc: 0.72852 | v_loss: 1.19673 v_acc: 0.74251 |  iteration: 2430 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 1187 loss: 1.23836 acc: 0.73958 | v_loss: 1.17868 v_acc: 0.75065 |  iteration: 2431 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 1188 loss: 1.21387 acc: 0.73047 | v_loss: 1.23199 v_acc: 0.74251 |  iteration: 2432 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 1189 loss: 1.30618 acc: 0.72038 | v_loss: 1.18458 v_acc: 0.73112 |  iteration: 2433 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 1190 loss: 1.27890 acc: 0.73893 | v_loss: 1.29400 v_acc: 0.72493 |  iteration: 2434 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 1191 loss: 1.26739 acc: 0.73079 | v_loss: 1.27033 v_acc: 0.73047 |  iteration: 2435 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 1192 loss: 1.22423 acc: 0.74186 | v_loss: 1.27138 v_acc: 0.74154 |  iteration: 2436 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 1193 loss: 1.21072 acc: 0.74512 | v_loss: 1.25072 v_acc: 0.74056 |  iteration: 2437 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 1194 loss: 1.25510 acc: 0.72689 | v_loss: 1.16590 v_acc: 0.74740 |  iteration: 2438 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 1195 loss: 1.24899 acc: 0.74316 | v_loss: 1.11570 v_acc: 0.76465 |  iteration: 2439 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 1196 loss: 1.29798 acc: 0.73470 | v_loss: 1.22581 v_acc: 0.74219 |  iteration: 2440 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 1197 loss: 1.16849 acc: 0.74707 | v_loss: 1.22367 v_acc: 0.75618 |  iteration: 2441 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 1198 loss: 1.23888 acc: 0.73763 | v_loss: 1.16390 v_acc: 0.75423 |  iteration: 2442 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 1199 loss: 1.21566 acc: 0.73242 | v_loss: 1.22700 v_acc: 0.74870 |  iteration: 2443 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 1200 loss: 1.21539 acc: 0.73405 | v_loss: 1.09959 v_acc: 0.74316 |  iteration: 2444 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 1201 loss: 1.26615 acc: 0.73372 | v_loss: 1.16143 v_acc: 0.75781 |  iteration: 2445 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 1202 loss: 1.19317 acc: 0.74186 | v_loss: 1.27220 v_acc: 0.73047 |  iteration: 2446 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 1203 loss: 1.17849 acc: 0.74870 | v_loss: 1.20059 v_acc: 0.75163 |  iteration: 2447 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 1204 loss: 1.29248 acc: 0.72754 | v_loss: 1.06028 v_acc: 0.77572 |  iteration: 2448 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 1205 loss: 1.26203 acc: 0.74382 | v_loss: 1.25613 v_acc: 0.73210 |  iteration: 2449 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 1206 loss: 1.20396 acc: 0.74023 | v_loss: 1.23854 v_acc: 0.75228 |  iteration: 2450 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 1207 loss: 1.19375 acc: 0.73730 | v_loss: 1.26917 v_acc: 0.75293 |  iteration: 2451 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 1208 loss: 1.20598 acc: 0.74577 | v_loss: 1.08035 v_acc: 0.75326 |  iteration: 2452 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 1209 loss: 1.22696 acc: 0.73926 | v_loss: 1.27900 v_acc: 0.74089 |  iteration: 2453 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 1210 loss: 1.20980 acc: 0.74512 | v_loss: 1.18240 v_acc: 0.75260 |  iteration: 2454 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 1211 loss: 1.24567 acc: 0.73340 | v_loss: 1.30373 v_acc: 0.72656 |  iteration: 2455 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 1212 loss: 1.19230 acc: 0.73665 | v_loss: 1.20715 v_acc: 0.74512 |  iteration: 2456 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 1213 loss: 1.21631 acc: 0.74414 | v_loss: 1.12927 v_acc: 0.75846 |  iteration: 2457 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 1214 loss: 1.26706 acc: 0.73340 | v_loss: 1.13985 v_acc: 0.75684 |  iteration: 2458 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 1215 loss: 1.25017 acc: 0.72917 | v_loss: 1.21791 v_acc: 0.72786 |  iteration: 2459 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 1216 loss: 1.27250 acc: 0.73568 | v_loss: 1.16518 v_acc: 0.74512 |  iteration: 2460 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 1217 loss: 1.15357 acc: 0.74349 | v_loss: 1.20945 v_acc: 0.73665 |  iteration: 2461 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 1218 loss: 1.23640 acc: 0.73470 | v_loss: 1.22095 v_acc: 0.74544 |  iteration: 2462 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 1219 loss: 1.16677 acc: 0.74935 | v_loss: 1.26280 v_acc: 0.72949 |  iteration: 2463 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 1220 loss: 1.24439 acc: 0.73926 | v_loss: 1.24106 v_acc: 0.72559 |  iteration: 2464 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 1221 loss: 1.21437 acc: 0.73568 | v_loss: 1.33505 v_acc: 0.72363 |  iteration: 2465 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 1222 loss: 1.26418 acc: 0.73242 | v_loss: 1.23186 v_acc: 0.72461 |  iteration: 2466 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 1223 loss: 1.28241 acc: 0.73372 | v_loss: 1.09796 v_acc: 0.75553 |  iteration: 2467 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 1224 loss: 1.20865 acc: 0.73405 | v_loss: 1.23897 v_acc: 0.73828 |  iteration: 2468 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 1225 loss: 1.24195 acc: 0.74284 | v_loss: 1.12420 v_acc: 0.75781 |  iteration: 2469 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 1226 loss: 1.22727 acc: 0.74056 | v_loss: 1.29109 v_acc: 0.73730 |  iteration: 2470 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 1227 loss: 1.31470 acc: 0.73145 | v_loss: 1.23624 v_acc: 0.73633 |  iteration: 2471 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 1228 loss: 1.21171 acc: 0.73893 | v_loss: 1.20389 v_acc: 0.74674 |  iteration: 2472 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 1229 loss: 1.25117 acc: 0.73861 | v_loss: 1.19977 v_acc: 0.74479 |  iteration: 2473 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 1230 loss: 1.22331 acc: 0.74284 | v_loss: 1.20711 v_acc: 0.74154 |  iteration: 2474 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 1231 loss: 1.21055 acc: 0.75000 | v_loss: 1.27054 v_acc: 0.74544 |  iteration: 2475 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 1232 loss: 1.16435 acc: 0.74837 | v_loss: 1.14763 v_acc: 0.76139 |  iteration: 2476 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 1233 loss: 1.15330 acc: 0.74512 | v_loss: 1.09256 v_acc: 0.75488 |  iteration: 2477 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 1234 loss: 1.25429 acc: 0.74186 | v_loss: 1.05819 v_acc: 0.76400 |  iteration: 2478 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 1235 loss: 1.15873 acc: 0.74544 | v_loss: 1.15867 v_acc: 0.75163 |  iteration: 2479 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 1236 loss: 1.23566 acc: 0.74219 | v_loss: 1.22903 v_acc: 0.74219 |  iteration: 2480 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 1237 loss: 1.16407 acc: 0.74772 | v_loss: 1.20642 v_acc: 0.72852 |  iteration: 2481 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 1238 loss: 1.34232 acc: 0.73145 | v_loss: 1.16787 v_acc: 0.75521 |  iteration: 2482 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 1239 loss: 1.14104 acc: 0.74609 | v_loss: 1.23485 v_acc: 0.75130 |  iteration: 2483 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 1240 loss: 1.29010 acc: 0.73047 | v_loss: 1.18842 v_acc: 0.73600 |  iteration: 2484 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 1241 loss: 1.21571 acc: 0.74642 | v_loss: 1.11885 v_acc: 0.75260 |  iteration: 2485 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 1242 loss: 1.28836 acc: 0.73796 | v_loss: 1.11530 v_acc: 0.75391 |  iteration: 2486 teacher: 1 stage: sketch lr: 0.000434\n",
      "epoch 1 loss: 1.25965 acc: 0.73367 | v_loss: 1.22982 v_acc: 0.74049 \n",
      "epoch: 2\n",
      "__________________________________________\n",
      "batch 0 loss: 1.25913 acc: 0.73210 | v_loss: 1.20757 v_acc: 0.73958 |  iteration: 2487 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 1 loss: 1.28410 acc: 0.72754 | v_loss: 1.13647 v_acc: 0.76042 |  iteration: 2488 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 2 loss: 1.27806 acc: 0.72493 | v_loss: 1.23981 v_acc: 0.74479 |  iteration: 2489 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 3 loss: 1.14608 acc: 0.75358 | v_loss: 1.17148 v_acc: 0.75000 |  iteration: 2490 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 4 loss: 1.21250 acc: 0.73242 | v_loss: 1.14974 v_acc: 0.75684 |  iteration: 2491 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 5 loss: 1.21911 acc: 0.74805 | v_loss: 1.22533 v_acc: 0.74512 |  iteration: 2492 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 6 loss: 1.18057 acc: 0.74056 | v_loss: 1.18052 v_acc: 0.74219 |  iteration: 2493 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 7 loss: 1.23970 acc: 0.74642 | v_loss: 1.28679 v_acc: 0.73177 |  iteration: 2494 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 8 loss: 1.14111 acc: 0.75163 | v_loss: 1.25838 v_acc: 0.73177 |  iteration: 2495 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 9 loss: 1.22153 acc: 0.74186 | v_loss: 1.27933 v_acc: 0.73893 |  iteration: 2496 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 10 loss: 1.28729 acc: 0.73763 | v_loss: 1.23222 v_acc: 0.74154 |  iteration: 2497 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 11 loss: 1.19778 acc: 0.74544 | v_loss: 1.17037 v_acc: 0.74479 |  iteration: 2498 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 12 loss: 1.24112 acc: 0.74251 | v_loss: 1.11403 v_acc: 0.76953 |  iteration: 2499 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 13 loss: 1.16820 acc: 0.74837 | v_loss: 1.20838 v_acc: 0.74642 |  iteration: 2500 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 14 loss: 1.21520 acc: 0.74219 | v_loss: 1.23368 v_acc: 0.75684 |  iteration: 2501 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 15 loss: 1.18608 acc: 0.74674 | v_loss: 1.14166 v_acc: 0.75684 |  iteration: 2502 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 16 loss: 1.09416 acc: 0.76302 | v_loss: 1.21865 v_acc: 0.74674 |  iteration: 2503 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 17 loss: 1.30869 acc: 0.72982 | v_loss: 1.08965 v_acc: 0.75293 |  iteration: 2504 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 18 loss: 1.21518 acc: 0.73861 | v_loss: 1.17242 v_acc: 0.76139 |  iteration: 2505 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 19 loss: 1.14785 acc: 0.75326 | v_loss: 1.30048 v_acc: 0.73112 |  iteration: 2506 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 20 loss: 1.20492 acc: 0.73991 | v_loss: 1.19125 v_acc: 0.75846 |  iteration: 2507 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 21 loss: 1.16056 acc: 0.75000 | v_loss: 1.06577 v_acc: 0.78092 |  iteration: 2508 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 22 loss: 1.17260 acc: 0.74674 | v_loss: 1.25599 v_acc: 0.74284 |  iteration: 2509 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 23 loss: 1.24775 acc: 0.74186 | v_loss: 1.22928 v_acc: 0.75130 |  iteration: 2510 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 24 loss: 1.21667 acc: 0.74251 | v_loss: 1.26976 v_acc: 0.74805 |  iteration: 2511 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 25 loss: 1.21099 acc: 0.73763 | v_loss: 1.05993 v_acc: 0.76432 |  iteration: 2512 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 26 loss: 1.19681 acc: 0.74121 | v_loss: 1.27626 v_acc: 0.74251 |  iteration: 2513 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 27 loss: 1.28606 acc: 0.72754 | v_loss: 1.18128 v_acc: 0.74479 |  iteration: 2514 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 28 loss: 1.21681 acc: 0.74023 | v_loss: 1.30086 v_acc: 0.73242 |  iteration: 2515 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 29 loss: 1.20969 acc: 0.74121 | v_loss: 1.20755 v_acc: 0.74902 |  iteration: 2516 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 30 loss: 1.21495 acc: 0.74284 | v_loss: 1.13708 v_acc: 0.75423 |  iteration: 2517 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 31 loss: 1.15984 acc: 0.74772 | v_loss: 1.14197 v_acc: 0.74870 |  iteration: 2518 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 32 loss: 1.20391 acc: 0.75130 | v_loss: 1.17091 v_acc: 0.73014 |  iteration: 2519 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 33 loss: 1.17458 acc: 0.74902 | v_loss: 1.15612 v_acc: 0.74251 |  iteration: 2520 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 34 loss: 1.15632 acc: 0.74870 | v_loss: 1.21187 v_acc: 0.73340 |  iteration: 2521 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 35 loss: 1.26984 acc: 0.73177 | v_loss: 1.21193 v_acc: 0.75228 |  iteration: 2522 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 36 loss: 1.26395 acc: 0.73796 | v_loss: 1.24315 v_acc: 0.73503 |  iteration: 2523 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 37 loss: 1.21956 acc: 0.74447 | v_loss: 1.21559 v_acc: 0.73600 |  iteration: 2524 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 38 loss: 1.23280 acc: 0.74251 | v_loss: 1.30428 v_acc: 0.72656 |  iteration: 2525 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 39 loss: 1.34471 acc: 0.72135 | v_loss: 1.21843 v_acc: 0.72884 |  iteration: 2526 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 40 loss: 1.19527 acc: 0.74316 | v_loss: 1.10242 v_acc: 0.74870 |  iteration: 2527 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 41 loss: 1.22732 acc: 0.74512 | v_loss: 1.22176 v_acc: 0.74056 |  iteration: 2528 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 42 loss: 1.19315 acc: 0.74512 | v_loss: 1.11788 v_acc: 0.75749 |  iteration: 2529 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 43 loss: 1.25783 acc: 0.73307 | v_loss: 1.28163 v_acc: 0.73763 |  iteration: 2530 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 44 loss: 1.24313 acc: 0.74219 | v_loss: 1.25647 v_acc: 0.74056 |  iteration: 2531 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 45 loss: 1.28639 acc: 0.72949 | v_loss: 1.18515 v_acc: 0.75814 |  iteration: 2532 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 46 loss: 1.24761 acc: 0.73535 | v_loss: 1.20375 v_acc: 0.74577 |  iteration: 2533 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 47 loss: 1.21423 acc: 0.73796 | v_loss: 1.21571 v_acc: 0.73861 |  iteration: 2534 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 48 loss: 1.17954 acc: 0.74609 | v_loss: 1.27353 v_acc: 0.74740 |  iteration: 2535 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 49 loss: 1.21879 acc: 0.73926 | v_loss: 1.16252 v_acc: 0.75228 |  iteration: 2536 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 50 loss: 1.28741 acc: 0.72884 | v_loss: 1.12121 v_acc: 0.75163 |  iteration: 2537 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 51 loss: 1.23470 acc: 0.73503 | v_loss: 1.05998 v_acc: 0.76628 |  iteration: 2538 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 52 loss: 1.18553 acc: 0.74219 | v_loss: 1.15267 v_acc: 0.75130 |  iteration: 2539 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 53 loss: 1.18623 acc: 0.73405 | v_loss: 1.22407 v_acc: 0.74284 |  iteration: 2540 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 54 loss: 1.12703 acc: 0.75488 | v_loss: 1.19093 v_acc: 0.73340 |  iteration: 2541 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 55 loss: 1.20601 acc: 0.74512 | v_loss: 1.16809 v_acc: 0.76172 |  iteration: 2542 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 56 loss: 1.20750 acc: 0.73958 | v_loss: 1.26866 v_acc: 0.75651 |  iteration: 2543 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 57 loss: 1.18802 acc: 0.74740 | v_loss: 1.19689 v_acc: 0.72493 |  iteration: 2544 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 58 loss: 1.21551 acc: 0.74219 | v_loss: 1.13487 v_acc: 0.74772 |  iteration: 2545 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 59 loss: 1.14941 acc: 0.75098 | v_loss: 1.10761 v_acc: 0.75423 |  iteration: 2546 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 60 loss: 1.18651 acc: 0.74902 | v_loss: 1.11026 v_acc: 0.77214 |  iteration: 2547 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 61 loss: 1.16782 acc: 0.74316 | v_loss: 1.15169 v_acc: 0.75879 |  iteration: 2548 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 62 loss: 1.19200 acc: 0.74544 | v_loss: 1.28838 v_acc: 0.73600 |  iteration: 2549 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 63 loss: 1.25121 acc: 0.74089 | v_loss: 1.27761 v_acc: 0.72754 |  iteration: 2550 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 64 loss: 1.25462 acc: 0.73568 | v_loss: 1.19118 v_acc: 0.74349 |  iteration: 2551 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 65 loss: 1.17015 acc: 0.74577 | v_loss: 1.13736 v_acc: 0.77181 |  iteration: 2552 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 66 loss: 1.15301 acc: 0.74121 | v_loss: 1.25737 v_acc: 0.73275 |  iteration: 2553 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 67 loss: 1.21722 acc: 0.73991 | v_loss: 1.33058 v_acc: 0.72493 |  iteration: 2554 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 68 loss: 1.22912 acc: 0.74154 | v_loss: 1.15197 v_acc: 0.75260 |  iteration: 2555 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 69 loss: 1.27438 acc: 0.73828 | v_loss: 1.25621 v_acc: 0.74121 |  iteration: 2556 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 70 loss: 1.19747 acc: 0.75065 | v_loss: 1.08699 v_acc: 0.75814 |  iteration: 2557 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 71 loss: 1.26735 acc: 0.73047 | v_loss: 1.22387 v_acc: 0.74186 |  iteration: 2558 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 72 loss: 1.28455 acc: 0.74382 | v_loss: 1.21520 v_acc: 0.74349 |  iteration: 2559 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 73 loss: 1.20579 acc: 0.74414 | v_loss: 1.16543 v_acc: 0.75553 |  iteration: 2560 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 74 loss: 1.20714 acc: 0.74382 | v_loss: 1.12800 v_acc: 0.75977 |  iteration: 2561 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 75 loss: 1.21160 acc: 0.74805 | v_loss: 1.16649 v_acc: 0.73796 |  iteration: 2562 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 76 loss: 1.23672 acc: 0.74023 | v_loss: 1.20290 v_acc: 0.75260 |  iteration: 2563 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 77 loss: 1.15385 acc: 0.75684 | v_loss: 1.17374 v_acc: 0.75651 |  iteration: 2564 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 78 loss: 1.19692 acc: 0.74447 | v_loss: 1.48888 v_acc: 0.70931 |  iteration: 2565 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 79 loss: 1.25099 acc: 0.73535 | v_loss: 1.15706 v_acc: 0.74349 |  iteration: 2566 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 80 loss: 1.16708 acc: 0.75228 | v_loss: 1.22299 v_acc: 0.74967 |  iteration: 2567 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 81 loss: 1.28573 acc: 0.73535 | v_loss: 1.20507 v_acc: 0.75553 |  iteration: 2568 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 82 loss: 1.19763 acc: 0.74642 | v_loss: 1.30883 v_acc: 0.73503 |  iteration: 2569 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 83 loss: 1.21571 acc: 0.74349 | v_loss: 1.10365 v_acc: 0.76823 |  iteration: 2570 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 84 loss: 1.26875 acc: 0.73828 | v_loss: 1.27116 v_acc: 0.74121 |  iteration: 2571 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 85 loss: 1.25452 acc: 0.74023 | v_loss: 1.14935 v_acc: 0.74609 |  iteration: 2572 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 86 loss: 1.27306 acc: 0.74056 | v_loss: 1.28794 v_acc: 0.72949 |  iteration: 2573 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 87 loss: 1.25547 acc: 0.72852 | v_loss: 1.24464 v_acc: 0.74154 |  iteration: 2574 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 88 loss: 1.24093 acc: 0.73242 | v_loss: 1.23874 v_acc: 0.73177 |  iteration: 2575 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 89 loss: 1.27124 acc: 0.73991 | v_loss: 1.34121 v_acc: 0.73014 |  iteration: 2576 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 90 loss: 1.26461 acc: 0.73047 | v_loss: 1.21604 v_acc: 0.73828 |  iteration: 2577 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 91 loss: 1.22159 acc: 0.73307 | v_loss: 1.19461 v_acc: 0.73991 |  iteration: 2578 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 92 loss: 1.24276 acc: 0.73633 | v_loss: 1.13577 v_acc: 0.76009 |  iteration: 2579 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 93 loss: 1.21618 acc: 0.73665 | v_loss: 1.22694 v_acc: 0.74740 |  iteration: 2580 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 94 loss: 1.11388 acc: 0.75586 | v_loss: 1.16355 v_acc: 0.75130 |  iteration: 2581 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 95 loss: 1.25956 acc: 0.73014 | v_loss: 1.14059 v_acc: 0.75944 |  iteration: 2582 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 96 loss: 1.28583 acc: 0.73600 | v_loss: 1.22826 v_acc: 0.74447 |  iteration: 2583 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 97 loss: 1.25960 acc: 0.72754 | v_loss: 1.17092 v_acc: 0.74349 |  iteration: 2584 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 98 loss: 1.25666 acc: 0.73861 | v_loss: 1.24532 v_acc: 0.73372 |  iteration: 2585 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 99 loss: 1.24169 acc: 0.74447 | v_loss: 1.25503 v_acc: 0.73665 |  iteration: 2586 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 100 loss: 1.26683 acc: 0.72819 | v_loss: 1.25961 v_acc: 0.74414 |  iteration: 2587 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 101 loss: 1.17100 acc: 0.75391 | v_loss: 1.23781 v_acc: 0.74512 |  iteration: 2588 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 102 loss: 1.17709 acc: 0.74837 | v_loss: 1.17292 v_acc: 0.74512 |  iteration: 2589 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 103 loss: 1.21279 acc: 0.73861 | v_loss: 1.13538 v_acc: 0.76628 |  iteration: 2590 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 104 loss: 1.26460 acc: 0.73665 | v_loss: 1.21001 v_acc: 0.74837 |  iteration: 2591 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 105 loss: 1.23580 acc: 0.74642 | v_loss: 1.20468 v_acc: 0.76204 |  iteration: 2592 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 106 loss: 1.23477 acc: 0.73958 | v_loss: 1.14991 v_acc: 0.75130 |  iteration: 2593 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 107 loss: 1.28363 acc: 0.72852 | v_loss: 1.22576 v_acc: 0.74479 |  iteration: 2594 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 108 loss: 1.18986 acc: 0.75065 | v_loss: 1.07498 v_acc: 0.75358 |  iteration: 2595 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 109 loss: 1.21225 acc: 0.73633 | v_loss: 1.14327 v_acc: 0.76139 |  iteration: 2596 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 110 loss: 1.22057 acc: 0.74382 | v_loss: 1.26864 v_acc: 0.73633 |  iteration: 2597 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 111 loss: 1.13267 acc: 0.75260 | v_loss: 1.22270 v_acc: 0.74544 |  iteration: 2598 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 112 loss: 1.30061 acc: 0.73307 | v_loss: 1.05717 v_acc: 0.78125 |  iteration: 2599 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 113 loss: 1.15961 acc: 0.75130 | v_loss: 1.23874 v_acc: 0.73307 |  iteration: 2600 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 114 loss: 1.20865 acc: 0.74154 | v_loss: 1.23384 v_acc: 0.75033 |  iteration: 2601 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 115 loss: 1.29506 acc: 0.73438 | v_loss: 1.29347 v_acc: 0.74349 |  iteration: 2602 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 116 loss: 1.22447 acc: 0.74056 | v_loss: 1.08241 v_acc: 0.75098 |  iteration: 2603 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 117 loss: 1.25890 acc: 0.73568 | v_loss: 1.28741 v_acc: 0.73991 |  iteration: 2604 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 118 loss: 1.17151 acc: 0.74609 | v_loss: 1.19542 v_acc: 0.74870 |  iteration: 2605 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 119 loss: 1.27920 acc: 0.73177 | v_loss: 1.31396 v_acc: 0.72884 |  iteration: 2606 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 120 loss: 1.22157 acc: 0.73796 | v_loss: 1.21828 v_acc: 0.74479 |  iteration: 2607 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 121 loss: 1.31328 acc: 0.74089 | v_loss: 1.13477 v_acc: 0.76302 |  iteration: 2608 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 122 loss: 1.15378 acc: 0.75098 | v_loss: 1.14829 v_acc: 0.75488 |  iteration: 2609 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 123 loss: 1.31518 acc: 0.72949 | v_loss: 1.21357 v_acc: 0.72201 |  iteration: 2610 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 124 loss: 1.21977 acc: 0.73861 | v_loss: 1.17511 v_acc: 0.74707 |  iteration: 2611 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 125 loss: 1.19697 acc: 0.74512 | v_loss: 1.21144 v_acc: 0.73307 |  iteration: 2612 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 126 loss: 1.24340 acc: 0.73405 | v_loss: 1.21382 v_acc: 0.75293 |  iteration: 2613 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 127 loss: 1.30787 acc: 0.73893 | v_loss: 1.26258 v_acc: 0.73014 |  iteration: 2614 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 128 loss: 1.22008 acc: 0.73600 | v_loss: 1.23132 v_acc: 0.72917 |  iteration: 2615 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 129 loss: 1.19619 acc: 0.73730 | v_loss: 1.33202 v_acc: 0.71940 |  iteration: 2616 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 130 loss: 1.28476 acc: 0.73307 | v_loss: 1.20978 v_acc: 0.73828 |  iteration: 2617 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 131 loss: 1.25499 acc: 0.73112 | v_loss: 1.10845 v_acc: 0.75130 |  iteration: 2618 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 132 loss: 1.33114 acc: 0.73438 | v_loss: 1.25002 v_acc: 0.73665 |  iteration: 2619 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 133 loss: 1.23239 acc: 0.73665 | v_loss: 1.13099 v_acc: 0.75488 |  iteration: 2620 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 134 loss: 1.20891 acc: 0.74284 | v_loss: 1.30104 v_acc: 0.72819 |  iteration: 2621 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 135 loss: 1.20559 acc: 0.74837 | v_loss: 1.24830 v_acc: 0.73503 |  iteration: 2622 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 136 loss: 1.20013 acc: 0.73796 | v_loss: 1.22153 v_acc: 0.74707 |  iteration: 2623 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 137 loss: 1.15037 acc: 0.75977 | v_loss: 1.20216 v_acc: 0.74414 |  iteration: 2624 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 138 loss: 1.35379 acc: 0.72559 | v_loss: 1.21053 v_acc: 0.74414 |  iteration: 2625 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 139 loss: 1.27513 acc: 0.73242 | v_loss: 1.26808 v_acc: 0.74577 |  iteration: 2626 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 140 loss: 1.26205 acc: 0.73796 | v_loss: 1.15353 v_acc: 0.75944 |  iteration: 2627 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 141 loss: 1.26844 acc: 0.72949 | v_loss: 1.10500 v_acc: 0.75749 |  iteration: 2628 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 142 loss: 1.21696 acc: 0.74056 | v_loss: 1.05842 v_acc: 0.77148 |  iteration: 2629 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 143 loss: 1.10816 acc: 0.75456 | v_loss: 1.15428 v_acc: 0.75391 |  iteration: 2630 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 144 loss: 1.18937 acc: 0.74382 | v_loss: 1.22631 v_acc: 0.74479 |  iteration: 2631 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 145 loss: 1.31954 acc: 0.72819 | v_loss: 1.20374 v_acc: 0.73535 |  iteration: 2632 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 146 loss: 1.25337 acc: 0.74089 | v_loss: 1.16781 v_acc: 0.75781 |  iteration: 2633 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 147 loss: 1.18056 acc: 0.75130 | v_loss: 1.25061 v_acc: 0.75130 |  iteration: 2634 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 148 loss: 1.21248 acc: 0.73600 | v_loss: 1.19841 v_acc: 0.73926 |  iteration: 2635 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 149 loss: 1.18701 acc: 0.75195 | v_loss: 1.12945 v_acc: 0.74967 |  iteration: 2636 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 150 loss: 1.25726 acc: 0.73796 | v_loss: 1.11214 v_acc: 0.75684 |  iteration: 2637 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 151 loss: 1.19284 acc: 0.74902 | v_loss: 1.12691 v_acc: 0.76595 |  iteration: 2638 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 152 loss: 1.26850 acc: 0.73568 | v_loss: 1.16643 v_acc: 0.74740 |  iteration: 2639 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 153 loss: 1.21225 acc: 0.73861 | v_loss: 1.29494 v_acc: 0.73210 |  iteration: 2640 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 154 loss: 1.24840 acc: 0.73014 | v_loss: 1.27736 v_acc: 0.72656 |  iteration: 2641 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 155 loss: 1.24475 acc: 0.73535 | v_loss: 1.18268 v_acc: 0.74967 |  iteration: 2642 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 156 loss: 1.26910 acc: 0.72819 | v_loss: 1.14608 v_acc: 0.76790 |  iteration: 2643 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 157 loss: 1.23999 acc: 0.74544 | v_loss: 1.25989 v_acc: 0.72852 |  iteration: 2644 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 158 loss: 1.22354 acc: 0.73145 | v_loss: 1.33932 v_acc: 0.72103 |  iteration: 2645 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 159 loss: 1.32096 acc: 0.73014 | v_loss: 1.14317 v_acc: 0.75684 |  iteration: 2646 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 160 loss: 1.18030 acc: 0.74642 | v_loss: 1.26601 v_acc: 0.73470 |  iteration: 2647 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 161 loss: 1.27891 acc: 0.73503 | v_loss: 1.08356 v_acc: 0.75977 |  iteration: 2648 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 162 loss: 1.22125 acc: 0.74186 | v_loss: 1.22820 v_acc: 0.73763 |  iteration: 2649 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 163 loss: 1.23119 acc: 0.74121 | v_loss: 1.21961 v_acc: 0.74642 |  iteration: 2650 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 164 loss: 1.26852 acc: 0.74642 | v_loss: 1.18071 v_acc: 0.75065 |  iteration: 2651 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 165 loss: 1.20236 acc: 0.75326 | v_loss: 1.14629 v_acc: 0.75781 |  iteration: 2652 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 166 loss: 1.31145 acc: 0.72949 | v_loss: 1.17959 v_acc: 0.74284 |  iteration: 2653 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 167 loss: 1.25842 acc: 0.73828 | v_loss: 1.19784 v_acc: 0.75586 |  iteration: 2654 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 168 loss: 1.15200 acc: 0.75358 | v_loss: 1.18321 v_acc: 0.75293 |  iteration: 2655 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 169 loss: 1.23751 acc: 0.74121 | v_loss: 1.50888 v_acc: 0.70605 |  iteration: 2656 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 170 loss: 1.25471 acc: 0.73926 | v_loss: 1.13739 v_acc: 0.75293 |  iteration: 2657 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 171 loss: 1.23636 acc: 0.73730 | v_loss: 1.23218 v_acc: 0.74577 |  iteration: 2658 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 172 loss: 1.28050 acc: 0.72819 | v_loss: 1.21435 v_acc: 0.75228 |  iteration: 2659 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 173 loss: 1.35639 acc: 0.72624 | v_loss: 1.31172 v_acc: 0.73991 |  iteration: 2660 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 174 loss: 1.22748 acc: 0.74447 | v_loss: 1.11123 v_acc: 0.76465 |  iteration: 2661 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 175 loss: 1.24896 acc: 0.73503 | v_loss: 1.27839 v_acc: 0.74056 |  iteration: 2662 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 176 loss: 1.29075 acc: 0.73633 | v_loss: 1.17303 v_acc: 0.74382 |  iteration: 2663 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 177 loss: 1.25476 acc: 0.74382 | v_loss: 1.28339 v_acc: 0.73112 |  iteration: 2664 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 178 loss: 1.20562 acc: 0.74186 | v_loss: 1.24971 v_acc: 0.73991 |  iteration: 2665 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 179 loss: 1.25409 acc: 0.73600 | v_loss: 1.22823 v_acc: 0.73405 |  iteration: 2666 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 180 loss: 1.26504 acc: 0.73307 | v_loss: 1.33763 v_acc: 0.72754 |  iteration: 2667 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 181 loss: 1.27359 acc: 0.72852 | v_loss: 1.21808 v_acc: 0.74023 |  iteration: 2668 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 182 loss: 1.25520 acc: 0.72396 | v_loss: 1.21369 v_acc: 0.74447 |  iteration: 2669 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 183 loss: 1.22059 acc: 0.74154 | v_loss: 1.13325 v_acc: 0.75911 |  iteration: 2670 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 184 loss: 1.17011 acc: 0.74967 | v_loss: 1.23264 v_acc: 0.74902 |  iteration: 2671 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 185 loss: 1.22021 acc: 0.75130 | v_loss: 1.15782 v_acc: 0.75065 |  iteration: 2672 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 186 loss: 1.18173 acc: 0.75000 | v_loss: 1.14676 v_acc: 0.75846 |  iteration: 2673 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 187 loss: 1.20367 acc: 0.74382 | v_loss: 1.22149 v_acc: 0.75000 |  iteration: 2674 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 188 loss: 1.25667 acc: 0.73503 | v_loss: 1.17970 v_acc: 0.73405 |  iteration: 2675 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 189 loss: 1.14578 acc: 0.74837 | v_loss: 1.27675 v_acc: 0.72689 |  iteration: 2676 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 190 loss: 1.20793 acc: 0.73600 | v_loss: 1.24458 v_acc: 0.73568 |  iteration: 2677 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 191 loss: 1.26142 acc: 0.73438 | v_loss: 1.25480 v_acc: 0.74414 |  iteration: 2678 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 192 loss: 1.22550 acc: 0.73405 | v_loss: 1.24227 v_acc: 0.74219 |  iteration: 2679 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 193 loss: 1.28728 acc: 0.73991 | v_loss: 1.16638 v_acc: 0.74544 |  iteration: 2680 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 194 loss: 1.25227 acc: 0.73372 | v_loss: 1.12743 v_acc: 0.76855 |  iteration: 2681 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 195 loss: 1.20730 acc: 0.74479 | v_loss: 1.21087 v_acc: 0.74512 |  iteration: 2682 teacher: 1 stage: sketch lr: 0.000469\n",
      "batch 196 loss: 1.20607 acc: 0.74251 | v_loss: 1.21843 v_acc: 0.75911 |  iteration: 2683 teacher: 1 stage: sketch lr: 0.000469\n",
      "batch 197 loss: 1.21987 acc: 0.74219 | v_loss: 1.14531 v_acc: 0.75065 |  iteration: 2684 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 198 loss: 1.26650 acc: 0.73893 | v_loss: 1.21827 v_acc: 0.74316 |  iteration: 2685 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 199 loss: 1.25303 acc: 0.73014 | v_loss: 1.06934 v_acc: 0.75716 |  iteration: 2686 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 200 loss: 1.20162 acc: 0.74414 | v_loss: 1.14766 v_acc: 0.76139 |  iteration: 2687 teacher: 1 stage: sketch lr: 0.000469\n",
      "batch 201 loss: 1.11177 acc: 0.75000 | v_loss: 1.25916 v_acc: 0.73828 |  iteration: 2688 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 202 loss: 1.22828 acc: 0.73991 | v_loss: 1.19339 v_acc: 0.75456 |  iteration: 2689 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 203 loss: 1.42229 acc: 0.72819 | v_loss: 1.06147 v_acc: 0.77930 |  iteration: 2690 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 204 loss: 1.18278 acc: 0.75260 | v_loss: 1.24358 v_acc: 0.74154 |  iteration: 2691 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 205 loss: 1.21741 acc: 0.73796 | v_loss: 1.24797 v_acc: 0.74707 |  iteration: 2692 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 206 loss: 1.11952 acc: 0.75456 | v_loss: 1.27133 v_acc: 0.74935 |  iteration: 2693 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 207 loss: 1.22625 acc: 0.73730 | v_loss: 1.06941 v_acc: 0.76107 |  iteration: 2694 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 208 loss: 1.17357 acc: 0.75195 | v_loss: 1.27299 v_acc: 0.74219 |  iteration: 2695 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 209 loss: 1.19059 acc: 0.75521 | v_loss: 1.18827 v_acc: 0.74674 |  iteration: 2696 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 210 loss: 1.20829 acc: 0.73893 | v_loss: 1.30964 v_acc: 0.73503 |  iteration: 2697 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 211 loss: 1.13542 acc: 0.74967 | v_loss: 1.20020 v_acc: 0.74382 |  iteration: 2698 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 212 loss: 1.20903 acc: 0.73600 | v_loss: 1.13408 v_acc: 0.75814 |  iteration: 2699 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 213 loss: 1.21466 acc: 0.74284 | v_loss: 1.13836 v_acc: 0.75000 |  iteration: 2700 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 214 loss: 1.32296 acc: 0.73177 | v_loss: 1.20967 v_acc: 0.72884 |  iteration: 2701 teacher: 1 stage: sketch lr: 0.000472\n",
      "batch 215 loss: 1.17461 acc: 0.75228 | v_loss: 1.15765 v_acc: 0.74414 |  iteration: 2702 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 216 loss: 1.18058 acc: 0.74967 | v_loss: 1.19285 v_acc: 0.73991 |  iteration: 2703 teacher: 1 stage: sketch lr: 0.000472\n",
      "batch 217 loss: 1.29646 acc: 0.72331 | v_loss: 1.19839 v_acc: 0.75391 |  iteration: 2704 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 218 loss: 1.29585 acc: 0.73242 | v_loss: 1.24112 v_acc: 0.73665 |  iteration: 2705 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 219 loss: 1.24275 acc: 0.74154 | v_loss: 1.21042 v_acc: 0.72461 |  iteration: 2706 teacher: 1 stage: sketch lr: 0.000473\n",
      "batch 220 loss: 1.22605 acc: 0.73991 | v_loss: 1.30577 v_acc: 0.73242 |  iteration: 2707 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 221 loss: 1.17363 acc: 0.75521 | v_loss: 1.20439 v_acc: 0.73079 |  iteration: 2708 teacher: 1 stage: sketch lr: 0.000473\n",
      "batch 222 loss: 1.34254 acc: 0.72428 | v_loss: 1.11047 v_acc: 0.75195 |  iteration: 2709 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 223 loss: 1.28091 acc: 0.72754 | v_loss: 1.22345 v_acc: 0.74349 |  iteration: 2710 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 224 loss: 1.20410 acc: 0.75195 | v_loss: 1.11913 v_acc: 0.75944 |  iteration: 2711 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 225 loss: 1.21908 acc: 0.74544 | v_loss: 1.29142 v_acc: 0.73079 |  iteration: 2712 teacher: 0 stage: sketch lr: 0.000474\n",
      "batch 226 loss: 1.19102 acc: 0.74772 | v_loss: 1.23879 v_acc: 0.74023 |  iteration: 2713 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 227 loss: 1.20770 acc: 0.73796 | v_loss: 1.19646 v_acc: 0.74935 |  iteration: 2714 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 228 loss: 1.28898 acc: 0.72266 | v_loss: 1.20627 v_acc: 0.74447 |  iteration: 2715 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 229 loss: 1.16698 acc: 0.74154 | v_loss: 1.20842 v_acc: 0.73600 |  iteration: 2716 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 230 loss: 1.20033 acc: 0.74251 | v_loss: 1.27931 v_acc: 0.73958 |  iteration: 2717 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 231 loss: 1.22653 acc: 0.73665 | v_loss: 1.15435 v_acc: 0.76107 |  iteration: 2718 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 232 loss: 1.10322 acc: 0.76042 | v_loss: 1.10090 v_acc: 0.76042 |  iteration: 2719 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 233 loss: 1.13809 acc: 0.75391 | v_loss: 1.05613 v_acc: 0.76660 |  iteration: 2720 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 234 loss: 1.30104 acc: 0.73210 | v_loss: 1.14987 v_acc: 0.75781 |  iteration: 2721 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 235 loss: 1.25200 acc: 0.74121 | v_loss: 1.21660 v_acc: 0.73926 |  iteration: 2722 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 236 loss: 1.11234 acc: 0.76367 | v_loss: 1.18919 v_acc: 0.73177 |  iteration: 2723 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 237 loss: 1.18995 acc: 0.75000 | v_loss: 1.16146 v_acc: 0.76432 |  iteration: 2724 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 238 loss: 1.20801 acc: 0.74674 | v_loss: 1.26659 v_acc: 0.75358 |  iteration: 2725 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 239 loss: 1.18410 acc: 0.74382 | v_loss: 1.18172 v_acc: 0.73861 |  iteration: 2726 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 240 loss: 1.19811 acc: 0.74642 | v_loss: 1.11143 v_acc: 0.75814 |  iteration: 2727 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 241 loss: 1.24811 acc: 0.74349 | v_loss: 1.08504 v_acc: 0.76009 |  iteration: 2728 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 242 loss: 1.22255 acc: 0.74219 | v_loss: 1.10972 v_acc: 0.76921 |  iteration: 2729 teacher: 1 stage: sketch lr: 0.000477\n",
      "batch 243 loss: 1.16172 acc: 0.74772 | v_loss: 1.15004 v_acc: 0.75423 |  iteration: 2730 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 244 loss: 1.22262 acc: 0.74414 | v_loss: 1.27852 v_acc: 0.73438 |  iteration: 2731 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 245 loss: 1.20653 acc: 0.74479 | v_loss: 1.27652 v_acc: 0.73145 |  iteration: 2732 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 246 loss: 1.24690 acc: 0.73079 | v_loss: 1.16200 v_acc: 0.75618 |  iteration: 2733 teacher: 1 stage: sketch lr: 0.000477\n",
      "batch 247 loss: 1.17779 acc: 0.73665 | v_loss: 1.13105 v_acc: 0.76758 |  iteration: 2734 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 248 loss: 1.12003 acc: 0.76530 | v_loss: 1.25308 v_acc: 0.73958 |  iteration: 2735 teacher: 1 stage: sketch lr: 0.000478\n",
      "batch 249 loss: 1.20270 acc: 0.74870 | v_loss: 1.33815 v_acc: 0.72103 |  iteration: 2736 teacher: 1 stage: sketch lr: 0.000478\n",
      "batch 250 loss: 1.27411 acc: 0.73275 | v_loss: 1.15578 v_acc: 0.74805 |  iteration: 2737 teacher: 1 stage: sketch lr: 0.000478\n",
      "batch 251 loss: 1.16790 acc: 0.74740 | v_loss: 1.28460 v_acc: 0.74023 |  iteration: 2738 teacher: 1 stage: sketch lr: 0.000478\n",
      "batch 252 loss: 1.18829 acc: 0.74414 | v_loss: 1.09318 v_acc: 0.75846 |  iteration: 2739 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 253 loss: 1.23087 acc: 0.73600 | v_loss: 1.20339 v_acc: 0.74772 |  iteration: 2740 teacher: 1 stage: sketch lr: 0.000479\n",
      "batch 254 loss: 1.25347 acc: 0.73503 | v_loss: 1.17761 v_acc: 0.75879 |  iteration: 2741 teacher: 1 stage: sketch lr: 0.000479\n",
      "batch 255 loss: 1.18402 acc: 0.74479 | v_loss: 1.15023 v_acc: 0.75977 |  iteration: 2742 teacher: 1 stage: sketch lr: 0.000479\n",
      "batch 256 loss: 1.20079 acc: 0.73861 | v_loss: 1.12116 v_acc: 0.75521 |  iteration: 2743 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 257 loss: 1.25511 acc: 0.74349 | v_loss: 1.15323 v_acc: 0.74674 |  iteration: 2744 teacher: 1 stage: sketch lr: 0.000479\n",
      "batch 258 loss: 1.13645 acc: 0.75130 | v_loss: 1.17962 v_acc: 0.75586 |  iteration: 2745 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 259 loss: 1.29908 acc: 0.72786 | v_loss: 1.17207 v_acc: 0.75846 |  iteration: 2746 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 260 loss: 1.12873 acc: 0.75749 | v_loss: 1.48672 v_acc: 0.70312 |  iteration: 2747 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 261 loss: 1.15768 acc: 0.74382 | v_loss: 1.14342 v_acc: 0.75098 |  iteration: 2748 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 262 loss: 1.11390 acc: 0.76107 | v_loss: 1.22711 v_acc: 0.74837 |  iteration: 2749 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 263 loss: 1.17143 acc: 0.74837 | v_loss: 1.18743 v_acc: 0.76465 |  iteration: 2750 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 264 loss: 1.13137 acc: 0.75977 | v_loss: 1.28864 v_acc: 0.74967 |  iteration: 2751 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 265 loss: 1.11441 acc: 0.75553 | v_loss: 1.09351 v_acc: 0.76921 |  iteration: 2752 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 266 loss: 1.27872 acc: 0.74251 | v_loss: 1.29227 v_acc: 0.73503 |  iteration: 2753 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 267 loss: 1.19042 acc: 0.74512 | v_loss: 1.14581 v_acc: 0.74902 |  iteration: 2754 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 268 loss: 1.19426 acc: 0.74837 | v_loss: 1.27403 v_acc: 0.73079 |  iteration: 2755 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 269 loss: 1.24821 acc: 0.73796 | v_loss: 1.22837 v_acc: 0.73991 |  iteration: 2756 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 270 loss: 1.21667 acc: 0.73730 | v_loss: 1.22723 v_acc: 0.73503 |  iteration: 2757 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 271 loss: 1.24359 acc: 0.74089 | v_loss: 1.32465 v_acc: 0.73438 |  iteration: 2758 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 272 loss: 1.19901 acc: 0.74577 | v_loss: 1.19793 v_acc: 0.74447 |  iteration: 2759 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 273 loss: 1.13983 acc: 0.75065 | v_loss: 1.19680 v_acc: 0.73893 |  iteration: 2760 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 274 loss: 1.20870 acc: 0.74707 | v_loss: 1.12926 v_acc: 0.75944 |  iteration: 2761 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 275 loss: 1.24019 acc: 0.74414 | v_loss: 1.22090 v_acc: 0.75163 |  iteration: 2762 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 276 loss: 1.19758 acc: 0.75553 | v_loss: 1.14932 v_acc: 0.75228 |  iteration: 2763 teacher: 0 stage: sketch lr: 0.000483\n",
      "batch 277 loss: 1.28219 acc: 0.73210 | v_loss: 1.13389 v_acc: 0.76400 |  iteration: 2764 teacher: 0 stage: sketch lr: 0.000483\n",
      "batch 278 loss: 1.16572 acc: 0.74577 | v_loss: 1.21862 v_acc: 0.74870 |  iteration: 2765 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 279 loss: 1.25277 acc: 0.74089 | v_loss: 1.17769 v_acc: 0.74316 |  iteration: 2766 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 280 loss: 1.16699 acc: 0.74674 | v_loss: 1.27908 v_acc: 0.72982 |  iteration: 2767 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 281 loss: 1.20265 acc: 0.75065 | v_loss: 1.24594 v_acc: 0.73372 |  iteration: 2768 teacher: 0 stage: sketch lr: 0.000484\n",
      "batch 282 loss: 1.21083 acc: 0.74609 | v_loss: 1.23693 v_acc: 0.74740 |  iteration: 2769 teacher: 0 stage: sketch lr: 0.000484\n",
      "batch 283 loss: 1.14986 acc: 0.74609 | v_loss: 1.21442 v_acc: 0.74447 |  iteration: 2770 teacher: 0 stage: sketch lr: 0.000484\n",
      "batch 284 loss: 1.27807 acc: 0.73275 | v_loss: 1.14604 v_acc: 0.74772 |  iteration: 2771 teacher: 0 stage: sketch lr: 0.000484\n",
      "batch 285 loss: 1.24632 acc: 0.74186 | v_loss: 1.11613 v_acc: 0.77474 |  iteration: 2772 teacher: 0 stage: sketch lr: 0.000484\n",
      "batch 286 loss: 1.12349 acc: 0.76204 | v_loss: 1.20839 v_acc: 0.74642 |  iteration: 2773 teacher: 1 stage: sketch lr: 0.000484\n",
      "batch 287 loss: 1.18917 acc: 0.74479 | v_loss: 1.20818 v_acc: 0.76725 |  iteration: 2774 teacher: 0 stage: sketch lr: 0.000485\n",
      "batch 288 loss: 1.20623 acc: 0.74772 | v_loss: 1.13030 v_acc: 0.75553 |  iteration: 2775 teacher: 0 stage: sketch lr: 0.000485\n",
      "batch 289 loss: 1.20631 acc: 0.74154 | v_loss: 1.20506 v_acc: 0.74284 |  iteration: 2776 teacher: 1 stage: sketch lr: 0.000485\n",
      "batch 290 loss: 1.23320 acc: 0.73698 | v_loss: 1.06517 v_acc: 0.75228 |  iteration: 2777 teacher: 0 stage: sketch lr: 0.000485\n",
      "batch 291 loss: 1.25040 acc: 0.73307 | v_loss: 1.12884 v_acc: 0.76823 |  iteration: 2778 teacher: 0 stage: sketch lr: 0.000485\n",
      "batch 292 loss: 1.20328 acc: 0.75195 | v_loss: 1.24876 v_acc: 0.73665 |  iteration: 2779 teacher: 1 stage: sketch lr: 0.000485\n",
      "batch 293 loss: 1.23888 acc: 0.73861 | v_loss: 1.18361 v_acc: 0.75781 |  iteration: 2780 teacher: 1 stage: sketch lr: 0.000486\n",
      "batch 294 loss: 1.20975 acc: 0.74805 | v_loss: 1.06301 v_acc: 0.77897 |  iteration: 2781 teacher: 1 stage: sketch lr: 0.000486\n",
      "batch 295 loss: 1.13498 acc: 0.75488 | v_loss: 1.22862 v_acc: 0.74609 |  iteration: 2782 teacher: 0 stage: sketch lr: 0.000486\n",
      "batch 296 loss: 1.23720 acc: 0.73698 | v_loss: 1.22607 v_acc: 0.75651 |  iteration: 2783 teacher: 0 stage: sketch lr: 0.000486\n",
      "batch 297 loss: 1.14100 acc: 0.75749 | v_loss: 1.26990 v_acc: 0.74023 |  iteration: 2784 teacher: 1 stage: sketch lr: 0.000486\n",
      "batch 298 loss: 1.22818 acc: 0.73730 | v_loss: 1.05429 v_acc: 0.75911 |  iteration: 2785 teacher: 1 stage: sketch lr: 0.000487\n",
      "batch 299 loss: 1.16456 acc: 0.75358 | v_loss: 1.27682 v_acc: 0.73926 |  iteration: 2786 teacher: 1 stage: sketch lr: 0.000487\n",
      "batch 300 loss: 1.21630 acc: 0.74414 | v_loss: 1.17293 v_acc: 0.75456 |  iteration: 2787 teacher: 0 stage: sketch lr: 0.000487\n",
      "batch 301 loss: 1.26161 acc: 0.73047 | v_loss: 1.29381 v_acc: 0.73600 |  iteration: 2788 teacher: 0 stage: sketch lr: 0.000487\n",
      "batch 302 loss: 1.28680 acc: 0.74740 | v_loss: 1.19168 v_acc: 0.74740 |  iteration: 2789 teacher: 1 stage: sketch lr: 0.000487\n",
      "batch 303 loss: 1.23621 acc: 0.74056 | v_loss: 1.13015 v_acc: 0.75911 |  iteration: 2790 teacher: 0 stage: sketch lr: 0.000487\n",
      "batch 304 loss: 1.24383 acc: 0.73828 | v_loss: 1.14308 v_acc: 0.75195 |  iteration: 2791 teacher: 0 stage: sketch lr: 0.000488\n",
      "batch 305 loss: 1.17568 acc: 0.75228 | v_loss: 1.17422 v_acc: 0.73405 |  iteration: 2792 teacher: 0 stage: sketch lr: 0.000488\n",
      "batch 306 loss: 1.17517 acc: 0.75684 | v_loss: 1.15217 v_acc: 0.74740 |  iteration: 2793 teacher: 1 stage: sketch lr: 0.000488\n",
      "batch 307 loss: 1.14722 acc: 0.74837 | v_loss: 1.18446 v_acc: 0.74056 |  iteration: 2794 teacher: 1 stage: sketch lr: 0.000488\n",
      "batch 308 loss: 1.21251 acc: 0.74284 | v_loss: 1.18674 v_acc: 0.75358 |  iteration: 2795 teacher: 0 stage: sketch lr: 0.000488\n",
      "batch 309 loss: 1.24975 acc: 0.73861 | v_loss: 1.23194 v_acc: 0.73958 |  iteration: 2796 teacher: 0 stage: sketch lr: 0.000488\n",
      "batch 310 loss: 1.18607 acc: 0.74967 | v_loss: 1.21478 v_acc: 0.73177 |  iteration: 2797 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 311 loss: 1.19712 acc: 0.74642 | v_loss: 1.30928 v_acc: 0.73210 |  iteration: 2798 teacher: 0 stage: sketch lr: 0.000489\n",
      "batch 312 loss: 1.15580 acc: 0.74479 | v_loss: 1.18896 v_acc: 0.72917 |  iteration: 2799 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 313 loss: 1.25001 acc: 0.74023 | v_loss: 1.09248 v_acc: 0.75195 |  iteration: 2800 teacher: 0 stage: sketch lr: 0.000489\n",
      "batch 314 loss: 1.24693 acc: 0.73568 | v_loss: 1.22734 v_acc: 0.74837 |  iteration: 2801 teacher: 0 stage: sketch lr: 0.000489\n",
      "batch 315 loss: 1.23074 acc: 0.74284 | v_loss: 1.12219 v_acc: 0.76465 |  iteration: 2802 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 316 loss: 1.28279 acc: 0.73600 | v_loss: 1.28398 v_acc: 0.72982 |  iteration: 2803 teacher: 0 stage: sketch lr: 0.000490\n",
      "batch 317 loss: 1.23020 acc: 0.74284 | v_loss: 1.25121 v_acc: 0.73893 |  iteration: 2804 teacher: 1 stage: sketch lr: 0.000490\n",
      "batch 318 loss: 1.06120 acc: 0.77799 | v_loss: 1.17371 v_acc: 0.75911 |  iteration: 2805 teacher: 1 stage: sketch lr: 0.000490\n",
      "batch 319 loss: 1.22682 acc: 0.73568 | v_loss: 1.17802 v_acc: 0.75195 |  iteration: 2806 teacher: 0 stage: sketch lr: 0.000490\n",
      "batch 320 loss: 1.21768 acc: 0.74154 | v_loss: 1.20588 v_acc: 0.74023 |  iteration: 2807 teacher: 1 stage: sketch lr: 0.000490\n",
      "batch 321 loss: 1.14208 acc: 0.74902 | v_loss: 1.26922 v_acc: 0.74414 |  iteration: 2808 teacher: 1 stage: sketch lr: 0.000491\n",
      "batch 322 loss: 1.17666 acc: 0.75033 | v_loss: 1.15126 v_acc: 0.76204 |  iteration: 2809 teacher: 1 stage: sketch lr: 0.000491\n",
      "batch 323 loss: 1.19960 acc: 0.74935 | v_loss: 1.09802 v_acc: 0.76270 |  iteration: 2810 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 324 loss: 1.21800 acc: 0.74772 | v_loss: 1.05302 v_acc: 0.77083 |  iteration: 2811 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 325 loss: 1.26537 acc: 0.74284 | v_loss: 1.15857 v_acc: 0.75749 |  iteration: 2812 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 326 loss: 1.18179 acc: 0.74967 | v_loss: 1.21844 v_acc: 0.74284 |  iteration: 2813 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 327 loss: 1.30178 acc: 0.73568 | v_loss: 1.18571 v_acc: 0.73568 |  iteration: 2814 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 328 loss: 1.27937 acc: 0.72689 | v_loss: 1.15395 v_acc: 0.76107 |  iteration: 2815 teacher: 1 stage: sketch lr: 0.000492\n",
      "batch 329 loss: 1.08666 acc: 0.76237 | v_loss: 1.24999 v_acc: 0.75423 |  iteration: 2816 teacher: 1 stage: sketch lr: 0.000492\n",
      "batch 330 loss: 1.26850 acc: 0.74284 | v_loss: 1.18005 v_acc: 0.73405 |  iteration: 2817 teacher: 1 stage: sketch lr: 0.000492\n",
      "batch 331 loss: 1.18850 acc: 0.74512 | v_loss: 1.10866 v_acc: 0.76074 |  iteration: 2818 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 332 loss: 1.25814 acc: 0.73926 | v_loss: 1.09026 v_acc: 0.75749 |  iteration: 2819 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 333 loss: 1.13858 acc: 0.75944 | v_loss: 1.11314 v_acc: 0.77116 |  iteration: 2820 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 334 loss: 1.25985 acc: 0.74284 | v_loss: 1.14070 v_acc: 0.75358 |  iteration: 2821 teacher: 0 stage: sketch lr: 0.000493\n",
      "batch 335 loss: 1.28354 acc: 0.72656 | v_loss: 1.26565 v_acc: 0.73503 |  iteration: 2822 teacher: 0 stage: sketch lr: 0.000493\n",
      "batch 336 loss: 1.16782 acc: 0.74674 | v_loss: 1.27698 v_acc: 0.72884 |  iteration: 2823 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 337 loss: 1.12667 acc: 0.75846 | v_loss: 1.16015 v_acc: 0.75000 |  iteration: 2824 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 338 loss: 1.20722 acc: 0.74447 | v_loss: 1.13051 v_acc: 0.77181 |  iteration: 2825 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 339 loss: 1.26143 acc: 0.74479 | v_loss: 1.24944 v_acc: 0.73535 |  iteration: 2826 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 340 loss: 1.21362 acc: 0.73958 | v_loss: 1.33884 v_acc: 0.72559 |  iteration: 2827 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 341 loss: 1.15362 acc: 0.75814 | v_loss: 1.14339 v_acc: 0.75618 |  iteration: 2828 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 342 loss: 1.21003 acc: 0.74219 | v_loss: 1.24205 v_acc: 0.74284 |  iteration: 2829 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 343 loss: 1.22604 acc: 0.73893 | v_loss: 1.06087 v_acc: 0.76302 |  iteration: 2830 teacher: 1 stage: sketch lr: 0.000494\n",
      "batch 344 loss: 1.20702 acc: 0.75033 | v_loss: 1.19520 v_acc: 0.75781 |  iteration: 2831 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 345 loss: 1.15520 acc: 0.75977 | v_loss: 1.17523 v_acc: 0.75326 |  iteration: 2832 teacher: 1 stage: sketch lr: 0.000495\n",
      "batch 346 loss: 1.27288 acc: 0.73405 | v_loss: 1.14088 v_acc: 0.75879 |  iteration: 2833 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 347 loss: 1.19440 acc: 0.73861 | v_loss: 1.12681 v_acc: 0.75911 |  iteration: 2834 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 348 loss: 1.25314 acc: 0.73861 | v_loss: 1.15248 v_acc: 0.74642 |  iteration: 2835 teacher: 1 stage: sketch lr: 0.000495\n",
      "batch 349 loss: 1.12700 acc: 0.75944 | v_loss: 1.18560 v_acc: 0.76139 |  iteration: 2836 teacher: 1 stage: sketch lr: 0.000495\n",
      "batch 350 loss: 1.15344 acc: 0.74837 | v_loss: 1.16896 v_acc: 0.75521 |  iteration: 2837 teacher: 0 stage: sketch lr: 0.000496\n",
      "batch 351 loss: 1.20520 acc: 0.74447 | v_loss: 1.48429 v_acc: 0.70378 |  iteration: 2838 teacher: 0 stage: sketch lr: 0.000496\n",
      "batch 352 loss: 1.17692 acc: 0.74902 | v_loss: 1.14092 v_acc: 0.75293 |  iteration: 2839 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 353 loss: 1.25696 acc: 0.73438 | v_loss: 1.21279 v_acc: 0.74902 |  iteration: 2840 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 354 loss: 1.27168 acc: 0.72461 | v_loss: 1.21123 v_acc: 0.75553 |  iteration: 2841 teacher: 0 stage: sketch lr: 0.000496\n",
      "batch 355 loss: 1.13241 acc: 0.75586 | v_loss: 1.29420 v_acc: 0.73796 |  iteration: 2842 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 356 loss: 1.31254 acc: 0.72624 | v_loss: 1.07257 v_acc: 0.77409 |  iteration: 2843 teacher: 1 stage: sketch lr: 0.000497\n",
      "batch 357 loss: 1.16952 acc: 0.74121 | v_loss: 1.27541 v_acc: 0.73763 |  iteration: 2844 teacher: 1 stage: sketch lr: 0.000497\n",
      "batch 358 loss: 1.21908 acc: 0.73438 | v_loss: 1.13607 v_acc: 0.75065 |  iteration: 2845 teacher: 1 stage: sketch lr: 0.000497\n",
      "batch 359 loss: 1.24325 acc: 0.73079 | v_loss: 1.27607 v_acc: 0.73405 |  iteration: 2846 teacher: 1 stage: sketch lr: 0.000497\n",
      "batch 360 loss: 1.27947 acc: 0.74121 | v_loss: 1.23772 v_acc: 0.73763 |  iteration: 2847 teacher: 1 stage: sketch lr: 0.000497\n",
      "batch 361 loss: 1.22661 acc: 0.74056 | v_loss: 1.22131 v_acc: 0.74056 |  iteration: 2848 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 362 loss: 1.15039 acc: 0.74219 | v_loss: 1.32811 v_acc: 0.73145 |  iteration: 2849 teacher: 0 stage: sketch lr: 0.000498\n",
      "batch 363 loss: 1.18695 acc: 0.75065 | v_loss: 1.19695 v_acc: 0.74837 |  iteration: 2850 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 364 loss: 1.21662 acc: 0.75033 | v_loss: 1.19579 v_acc: 0.74870 |  iteration: 2851 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 365 loss: 1.25502 acc: 0.73242 | v_loss: 1.12773 v_acc: 0.76042 |  iteration: 2852 teacher: 0 stage: sketch lr: 0.000498\n",
      "batch 366 loss: 1.12514 acc: 0.76139 | v_loss: 1.23313 v_acc: 0.74251 |  iteration: 2853 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 367 loss: 1.26188 acc: 0.72917 | v_loss: 1.14397 v_acc: 0.75456 |  iteration: 2854 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 368 loss: 1.27567 acc: 0.73893 | v_loss: 1.13456 v_acc: 0.75814 |  iteration: 2855 teacher: 0 stage: sketch lr: 0.000499\n",
      "batch 369 loss: 1.24299 acc: 0.73730 | v_loss: 1.21042 v_acc: 0.75130 |  iteration: 2856 teacher: 0 stage: sketch lr: 0.000499\n",
      "batch 370 loss: 1.25438 acc: 0.74219 | v_loss: 1.15690 v_acc: 0.74414 |  iteration: 2857 teacher: 0 stage: sketch lr: 0.000499\n",
      "batch 371 loss: 1.23923 acc: 0.73893 | v_loss: 1.26349 v_acc: 0.72591 |  iteration: 2858 teacher: 0 stage: sketch lr: 0.000499\n",
      "batch 372 loss: 1.10236 acc: 0.75358 | v_loss: 1.25776 v_acc: 0.73210 |  iteration: 2859 teacher: 0 stage: sketch lr: 0.000499\n",
      "batch 373 loss: 1.17877 acc: 0.74707 | v_loss: 1.23912 v_acc: 0.74902 |  iteration: 2860 teacher: 0 stage: sketch lr: 0.000500\n",
      "batch 374 loss: 1.16329 acc: 0.76074 | v_loss: 1.21722 v_acc: 0.74837 |  iteration: 2861 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 375 loss: 1.26416 acc: 0.73893 | v_loss: 1.15057 v_acc: 0.75293 |  iteration: 2862 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 376 loss: 1.18228 acc: 0.75033 | v_loss: 1.10625 v_acc: 0.77018 |  iteration: 2863 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 377 loss: 1.21020 acc: 0.74707 | v_loss: 1.20473 v_acc: 0.74740 |  iteration: 2864 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 378 loss: 1.18760 acc: 0.74642 | v_loss: 1.22407 v_acc: 0.75521 |  iteration: 2865 teacher: 0 stage: sketch lr: 0.000500\n",
      "batch 379 loss: 1.18777 acc: 0.74544 | v_loss: 1.15005 v_acc: 0.75423 |  iteration: 2866 teacher: 0 stage: sketch lr: 0.000501\n",
      "batch 380 loss: 1.19798 acc: 0.74251 | v_loss: 1.23574 v_acc: 0.74023 |  iteration: 2867 teacher: 0 stage: sketch lr: 0.000501\n",
      "batch 381 loss: 1.19129 acc: 0.74316 | v_loss: 1.07069 v_acc: 0.76107 |  iteration: 2868 teacher: 0 stage: sketch lr: 0.000501\n",
      "batch 382 loss: 1.26010 acc: 0.74089 | v_loss: 1.14416 v_acc: 0.76400 |  iteration: 2869 teacher: 0 stage: sketch lr: 0.000501\n",
      "batch 383 loss: 1.25801 acc: 0.73926 | v_loss: 1.24563 v_acc: 0.74479 |  iteration: 2870 teacher: 1 stage: sketch lr: 0.000501\n",
      "batch 384 loss: 1.14909 acc: 0.75098 | v_loss: 1.18569 v_acc: 0.75977 |  iteration: 2871 teacher: 1 stage: sketch lr: 0.000502\n",
      "batch 385 loss: 1.23801 acc: 0.74284 | v_loss: 1.06515 v_acc: 0.78190 |  iteration: 2872 teacher: 1 stage: sketch lr: 0.000502\n",
      "batch 386 loss: 1.19361 acc: 0.74284 | v_loss: 1.22788 v_acc: 0.74349 |  iteration: 2873 teacher: 0 stage: sketch lr: 0.000502\n",
      "batch 387 loss: 1.30328 acc: 0.72917 | v_loss: 1.21530 v_acc: 0.75423 |  iteration: 2874 teacher: 0 stage: sketch lr: 0.000502\n",
      "batch 388 loss: 1.25932 acc: 0.74577 | v_loss: 1.27028 v_acc: 0.74772 |  iteration: 2875 teacher: 0 stage: sketch lr: 0.000502\n",
      "batch 389 loss: 1.23568 acc: 0.74577 | v_loss: 1.07629 v_acc: 0.75781 |  iteration: 2876 teacher: 1 stage: sketch lr: 0.000502\n",
      "batch 390 loss: 1.19570 acc: 0.74902 | v_loss: 1.28877 v_acc: 0.74056 |  iteration: 2877 teacher: 1 stage: sketch lr: 0.000503\n",
      "batch 391 loss: 1.23137 acc: 0.74609 | v_loss: 1.18083 v_acc: 0.75553 |  iteration: 2878 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 392 loss: 1.23264 acc: 0.74251 | v_loss: 1.29745 v_acc: 0.73438 |  iteration: 2879 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 393 loss: 1.16734 acc: 0.74642 | v_loss: 1.18828 v_acc: 0.75228 |  iteration: 2880 teacher: 1 stage: sketch lr: 0.000503\n",
      "batch 394 loss: 1.17508 acc: 0.74512 | v_loss: 1.13029 v_acc: 0.75781 |  iteration: 2881 teacher: 1 stage: sketch lr: 0.000503\n",
      "batch 395 loss: 1.15275 acc: 0.74544 | v_loss: 1.12425 v_acc: 0.75618 |  iteration: 2882 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 396 loss: 1.20873 acc: 0.75130 | v_loss: 1.16844 v_acc: 0.73568 |  iteration: 2883 teacher: 1 stage: sketch lr: 0.000504\n",
      "batch 397 loss: 1.30839 acc: 0.73730 | v_loss: 1.15131 v_acc: 0.75000 |  iteration: 2884 teacher: 0 stage: sketch lr: 0.000504\n",
      "batch 398 loss: 1.12948 acc: 0.76335 | v_loss: 1.18596 v_acc: 0.74544 |  iteration: 2885 teacher: 1 stage: sketch lr: 0.000504\n",
      "batch 399 loss: 1.21892 acc: 0.74349 | v_loss: 1.17789 v_acc: 0.75684 |  iteration: 2886 teacher: 1 stage: sketch lr: 0.000504\n",
      "batch 400 loss: 1.32026 acc: 0.72038 | v_loss: 1.23533 v_acc: 0.73796 |  iteration: 2887 teacher: 0 stage: sketch lr: 0.000504\n",
      "batch 401 loss: 1.22204 acc: 0.74251 | v_loss: 1.19118 v_acc: 0.74219 |  iteration: 2888 teacher: 0 stage: sketch lr: 0.000505\n",
      "batch 402 loss: 1.28573 acc: 0.73730 | v_loss: 1.29685 v_acc: 0.72754 |  iteration: 2889 teacher: 0 stage: sketch lr: 0.000505\n",
      "batch 403 loss: 1.15257 acc: 0.74935 | v_loss: 1.20090 v_acc: 0.74023 |  iteration: 2890 teacher: 1 stage: sketch lr: 0.000505\n",
      "batch 404 loss: 1.24143 acc: 0.74121 | v_loss: 1.08948 v_acc: 0.75749 |  iteration: 2891 teacher: 1 stage: sketch lr: 0.000505\n",
      "batch 405 loss: 1.26537 acc: 0.73796 | v_loss: 1.22013 v_acc: 0.74023 |  iteration: 2892 teacher: 1 stage: sketch lr: 0.000505\n",
      "batch 406 loss: 1.08148 acc: 0.75488 | v_loss: 1.11507 v_acc: 0.76139 |  iteration: 2893 teacher: 0 stage: sketch lr: 0.000505\n",
      "batch 407 loss: 1.24026 acc: 0.73763 | v_loss: 1.28586 v_acc: 0.72754 |  iteration: 2894 teacher: 1 stage: sketch lr: 0.000506\n",
      "batch 408 loss: 1.17454 acc: 0.73730 | v_loss: 1.25101 v_acc: 0.74154 |  iteration: 2895 teacher: 1 stage: sketch lr: 0.000506\n",
      "batch 409 loss: 1.22168 acc: 0.74186 | v_loss: 1.18467 v_acc: 0.74935 |  iteration: 2896 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 410 loss: 1.14472 acc: 0.75814 | v_loss: 1.18379 v_acc: 0.75033 |  iteration: 2897 teacher: 1 stage: sketch lr: 0.000506\n",
      "batch 411 loss: 1.26564 acc: 0.74414 | v_loss: 1.20988 v_acc: 0.74251 |  iteration: 2898 teacher: 1 stage: sketch lr: 0.000506\n",
      "batch 412 loss: 1.22465 acc: 0.74544 | v_loss: 1.28415 v_acc: 0.74414 |  iteration: 2899 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 413 loss: 1.21593 acc: 0.74219 | v_loss: 1.14657 v_acc: 0.76204 |  iteration: 2900 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 414 loss: 1.15978 acc: 0.75781 | v_loss: 1.09362 v_acc: 0.76367 |  iteration: 2901 teacher: 1 stage: sketch lr: 0.000507\n",
      "batch 415 loss: 1.25845 acc: 0.74577 | v_loss: 1.04949 v_acc: 0.76660 |  iteration: 2902 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 416 loss: 1.21722 acc: 0.74284 | v_loss: 1.14592 v_acc: 0.75651 |  iteration: 2903 teacher: 1 stage: sketch lr: 0.000507\n",
      "batch 417 loss: 1.29097 acc: 0.73958 | v_loss: 1.21749 v_acc: 0.74219 |  iteration: 2904 teacher: 1 stage: sketch lr: 0.000507\n",
      "batch 418 loss: 1.11076 acc: 0.76335 | v_loss: 1.18768 v_acc: 0.73763 |  iteration: 2905 teacher: 1 stage: sketch lr: 0.000507\n",
      "batch 419 loss: 1.18673 acc: 0.74154 | v_loss: 1.13800 v_acc: 0.76758 |  iteration: 2906 teacher: 0 stage: sketch lr: 0.000508\n",
      "batch 420 loss: 1.18845 acc: 0.74447 | v_loss: 1.22198 v_acc: 0.75749 |  iteration: 2907 teacher: 0 stage: sketch lr: 0.000508\n",
      "batch 421 loss: 1.20695 acc: 0.74577 | v_loss: 1.19639 v_acc: 0.72852 |  iteration: 2908 teacher: 1 stage: sketch lr: 0.000508\n",
      "batch 422 loss: 1.22185 acc: 0.74089 | v_loss: 1.12148 v_acc: 0.75228 |  iteration: 2909 teacher: 1 stage: sketch lr: 0.000508\n",
      "batch 423 loss: 1.14667 acc: 0.75521 | v_loss: 1.09393 v_acc: 0.76009 |  iteration: 2910 teacher: 1 stage: sketch lr: 0.000508\n",
      "batch 424 loss: 1.17322 acc: 0.74837 | v_loss: 1.09708 v_acc: 0.77344 |  iteration: 2911 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 425 loss: 1.14715 acc: 0.75618 | v_loss: 1.13431 v_acc: 0.75684 |  iteration: 2912 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 426 loss: 1.26490 acc: 0.73438 | v_loss: 1.26780 v_acc: 0.73535 |  iteration: 2913 teacher: 0 stage: sketch lr: 0.000509\n",
      "batch 427 loss: 1.27598 acc: 0.73535 | v_loss: 1.27652 v_acc: 0.73014 |  iteration: 2914 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 428 loss: 1.23107 acc: 0.74056 | v_loss: 1.16273 v_acc: 0.75000 |  iteration: 2915 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 429 loss: 1.17914 acc: 0.75423 | v_loss: 1.12282 v_acc: 0.77148 |  iteration: 2916 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 430 loss: 1.24526 acc: 0.74642 | v_loss: 1.23338 v_acc: 0.73600 |  iteration: 2917 teacher: 1 stage: sketch lr: 0.000510\n",
      "batch 431 loss: 1.18247 acc: 0.74186 | v_loss: 1.31893 v_acc: 0.72493 |  iteration: 2918 teacher: 0 stage: sketch lr: 0.000510\n",
      "batch 432 loss: 1.17566 acc: 0.74447 | v_loss: 1.13362 v_acc: 0.75586 |  iteration: 2919 teacher: 1 stage: sketch lr: 0.000510\n",
      "batch 433 loss: 1.29007 acc: 0.72819 | v_loss: 1.26019 v_acc: 0.74447 |  iteration: 2920 teacher: 0 stage: sketch lr: 0.000510\n",
      "batch 434 loss: 1.14440 acc: 0.74805 | v_loss: 1.06556 v_acc: 0.76530 |  iteration: 2921 teacher: 1 stage: sketch lr: 0.000510\n",
      "batch 435 loss: 1.05863 acc: 0.77767 | v_loss: 1.19302 v_acc: 0.75000 |  iteration: 2922 teacher: 1 stage: sketch lr: 0.000510\n",
      "batch 436 loss: 1.19842 acc: 0.74870 | v_loss: 1.16942 v_acc: 0.76497 |  iteration: 2923 teacher: 0 stage: sketch lr: 0.000511\n",
      "batch 437 loss: 1.17989 acc: 0.74837 | v_loss: 1.14339 v_acc: 0.76139 |  iteration: 2924 teacher: 0 stage: sketch lr: 0.000511\n",
      "batch 438 loss: 1.26785 acc: 0.73242 | v_loss: 1.12562 v_acc: 0.75846 |  iteration: 2925 teacher: 1 stage: sketch lr: 0.000511\n",
      "batch 439 loss: 1.15443 acc: 0.74382 | v_loss: 1.15233 v_acc: 0.74577 |  iteration: 2926 teacher: 0 stage: sketch lr: 0.000511\n",
      "batch 440 loss: 1.23854 acc: 0.74512 | v_loss: 1.17999 v_acc: 0.75618 |  iteration: 2927 teacher: 1 stage: sketch lr: 0.000511\n",
      "batch 441 loss: 1.17453 acc: 0.74382 | v_loss: 1.17305 v_acc: 0.75586 |  iteration: 2928 teacher: 1 stage: sketch lr: 0.000512\n",
      "batch 442 loss: 1.26190 acc: 0.74251 | v_loss: 1.49336 v_acc: 0.70312 |  iteration: 2929 teacher: 0 stage: sketch lr: 0.000512\n",
      "batch 443 loss: 1.13175 acc: 0.76497 | v_loss: 1.12432 v_acc: 0.75033 |  iteration: 2930 teacher: 1 stage: sketch lr: 0.000512\n",
      "batch 444 loss: 1.28702 acc: 0.73405 | v_loss: 1.21108 v_acc: 0.75326 |  iteration: 2931 teacher: 0 stage: sketch lr: 0.000512\n",
      "batch 445 loss: 1.23037 acc: 0.74577 | v_loss: 1.19391 v_acc: 0.75553 |  iteration: 2932 teacher: 1 stage: sketch lr: 0.000512\n",
      "batch 446 loss: 1.25248 acc: 0.74544 | v_loss: 1.28480 v_acc: 0.73470 |  iteration: 2933 teacher: 0 stage: sketch lr: 0.000512\n",
      "batch 447 loss: 1.17361 acc: 0.74805 | v_loss: 1.06493 v_acc: 0.78092 |  iteration: 2934 teacher: 1 stage: sketch lr: 0.000513\n",
      "batch 448 loss: 1.20035 acc: 0.74870 | v_loss: 1.26119 v_acc: 0.74382 |  iteration: 2935 teacher: 1 stage: sketch lr: 0.000513\n",
      "batch 449 loss: 1.21978 acc: 0.73730 | v_loss: 1.14140 v_acc: 0.75358 |  iteration: 2936 teacher: 0 stage: sketch lr: 0.000513\n",
      "batch 450 loss: 1.15293 acc: 0.76172 | v_loss: 1.28685 v_acc: 0.73275 |  iteration: 2937 teacher: 1 stage: sketch lr: 0.000513\n",
      "batch 451 loss: 1.21791 acc: 0.75260 | v_loss: 1.20611 v_acc: 0.74967 |  iteration: 2938 teacher: 1 stage: sketch lr: 0.000513\n",
      "batch 452 loss: 1.16707 acc: 0.75065 | v_loss: 1.22233 v_acc: 0.73535 |  iteration: 2939 teacher: 0 stage: sketch lr: 0.000513\n",
      "batch 453 loss: 1.22069 acc: 0.75195 | v_loss: 1.30620 v_acc: 0.73210 |  iteration: 2940 teacher: 0 stage: sketch lr: 0.000514\n",
      "batch 454 loss: 1.12441 acc: 0.74707 | v_loss: 1.19026 v_acc: 0.74577 |  iteration: 2941 teacher: 0 stage: sketch lr: 0.000514\n",
      "batch 455 loss: 1.24471 acc: 0.73893 | v_loss: 1.16405 v_acc: 0.74805 |  iteration: 2942 teacher: 1 stage: sketch lr: 0.000514\n",
      "batch 456 loss: 1.21897 acc: 0.75260 | v_loss: 1.12131 v_acc: 0.76302 |  iteration: 2943 teacher: 1 stage: sketch lr: 0.000514\n",
      "batch 457 loss: 1.19479 acc: 0.74837 | v_loss: 1.21374 v_acc: 0.75553 |  iteration: 2944 teacher: 1 stage: sketch lr: 0.000514\n",
      "batch 458 loss: 1.10278 acc: 0.76172 | v_loss: 1.13855 v_acc: 0.76107 |  iteration: 2945 teacher: 1 stage: sketch lr: 0.000514\n",
      "batch 459 loss: 1.25402 acc: 0.73177 | v_loss: 1.13884 v_acc: 0.75618 |  iteration: 2946 teacher: 1 stage: sketch lr: 0.000515\n",
      "batch 460 loss: 1.22511 acc: 0.73568 | v_loss: 1.19999 v_acc: 0.75749 |  iteration: 2947 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 461 loss: 1.27788 acc: 0.73340 | v_loss: 1.16917 v_acc: 0.73633 |  iteration: 2948 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 462 loss: 1.23071 acc: 0.74935 | v_loss: 1.27477 v_acc: 0.73307 |  iteration: 2949 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 463 loss: 1.17371 acc: 0.75260 | v_loss: 1.25159 v_acc: 0.74121 |  iteration: 2950 teacher: 1 stage: sketch lr: 0.000515\n",
      "batch 464 loss: 1.25442 acc: 0.73828 | v_loss: 1.21894 v_acc: 0.75293 |  iteration: 2951 teacher: 0 stage: sketch lr: 0.000516\n",
      "batch 465 loss: 1.10187 acc: 0.75944 | v_loss: 1.20099 v_acc: 0.75228 |  iteration: 2952 teacher: 1 stage: sketch lr: 0.000516\n",
      "batch 466 loss: 1.23839 acc: 0.74902 | v_loss: 1.14601 v_acc: 0.74967 |  iteration: 2953 teacher: 1 stage: sketch lr: 0.000516\n",
      "batch 467 loss: 1.23666 acc: 0.74902 | v_loss: 1.11100 v_acc: 0.77116 |  iteration: 2954 teacher: 1 stage: sketch lr: 0.000516\n",
      "batch 468 loss: 1.18837 acc: 0.74544 | v_loss: 1.20581 v_acc: 0.75260 |  iteration: 2955 teacher: 1 stage: sketch lr: 0.000516\n",
      "batch 469 loss: 1.23411 acc: 0.73535 | v_loss: 1.23947 v_acc: 0.77181 |  iteration: 2956 teacher: 0 stage: sketch lr: 0.000516\n",
      "batch 470 loss: 1.23923 acc: 0.74154 | v_loss: 1.14059 v_acc: 0.75618 |  iteration: 2957 teacher: 1 stage: sketch lr: 0.000517\n",
      "batch 471 loss: 1.17810 acc: 0.75293 | v_loss: 1.21977 v_acc: 0.74544 |  iteration: 2958 teacher: 1 stage: sketch lr: 0.000517\n",
      "batch 472 loss: 1.24558 acc: 0.73828 | v_loss: 1.09724 v_acc: 0.74805 |  iteration: 2959 teacher: 1 stage: sketch lr: 0.000517\n",
      "batch 473 loss: 1.15505 acc: 0.74414 | v_loss: 1.18598 v_acc: 0.75260 |  iteration: 2960 teacher: 1 stage: sketch lr: 0.000517\n",
      "batch 474 loss: 1.29879 acc: 0.72526 | v_loss: 1.27468 v_acc: 0.72721 |  iteration: 2961 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 475 loss: 1.31049 acc: 0.72884 | v_loss: 1.22972 v_acc: 0.74609 |  iteration: 2962 teacher: 1 stage: sketch lr: 0.000517\n",
      "batch 476 loss: 1.15890 acc: 0.75423 | v_loss: 1.06246 v_acc: 0.77539 |  iteration: 2963 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 477 loss: 1.08987 acc: 0.76204 | v_loss: 1.24330 v_acc: 0.73307 |  iteration: 2964 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 478 loss: 1.19310 acc: 0.75716 | v_loss: 1.22303 v_acc: 0.75814 |  iteration: 2965 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 479 loss: 1.23734 acc: 0.74284 | v_loss: 1.28503 v_acc: 0.74219 |  iteration: 2966 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 480 loss: 1.13490 acc: 0.75326 | v_loss: 1.06004 v_acc: 0.76204 |  iteration: 2967 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 481 loss: 1.18464 acc: 0.74382 | v_loss: 1.28786 v_acc: 0.73079 |  iteration: 2968 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 482 loss: 1.27289 acc: 0.73079 | v_loss: 1.18355 v_acc: 0.74902 |  iteration: 2969 teacher: 0 stage: sketch lr: 0.000519\n",
      "batch 483 loss: 1.27286 acc: 0.73535 | v_loss: 1.30591 v_acc: 0.72852 |  iteration: 2970 teacher: 1 stage: sketch lr: 0.000519\n",
      "batch 484 loss: 1.24989 acc: 0.73828 | v_loss: 1.18970 v_acc: 0.74967 |  iteration: 2971 teacher: 1 stage: sketch lr: 0.000519\n",
      "batch 485 loss: 1.21275 acc: 0.73340 | v_loss: 1.13268 v_acc: 0.75879 |  iteration: 2972 teacher: 0 stage: sketch lr: 0.000519\n",
      "batch 486 loss: 1.18287 acc: 0.74642 | v_loss: 1.12334 v_acc: 0.75358 |  iteration: 2973 teacher: 0 stage: sketch lr: 0.000519\n",
      "batch 487 loss: 1.15977 acc: 0.74414 | v_loss: 1.18884 v_acc: 0.72884 |  iteration: 2974 teacher: 1 stage: sketch lr: 0.000520\n",
      "batch 488 loss: 1.20333 acc: 0.74609 | v_loss: 1.15104 v_acc: 0.75065 |  iteration: 2975 teacher: 1 stage: sketch lr: 0.000520\n",
      "batch 489 loss: 1.24107 acc: 0.73796 | v_loss: 1.17565 v_acc: 0.74219 |  iteration: 2976 teacher: 0 stage: sketch lr: 0.000520\n",
      "batch 490 loss: 1.22396 acc: 0.74284 | v_loss: 1.17838 v_acc: 0.75911 |  iteration: 2977 teacher: 0 stage: sketch lr: 0.000520\n",
      "batch 491 loss: 1.17140 acc: 0.74837 | v_loss: 1.23004 v_acc: 0.74023 |  iteration: 2978 teacher: 0 stage: sketch lr: 0.000520\n",
      "batch 492 loss: 1.18724 acc: 0.74642 | v_loss: 1.19666 v_acc: 0.74284 |  iteration: 2979 teacher: 0 stage: sketch lr: 0.000520\n",
      "batch 493 loss: 1.17258 acc: 0.75098 | v_loss: 1.30013 v_acc: 0.73210 |  iteration: 2980 teacher: 1 stage: sketch lr: 0.000521\n",
      "batch 494 loss: 1.10993 acc: 0.76204 | v_loss: 1.19315 v_acc: 0.73340 |  iteration: 2981 teacher: 1 stage: sketch lr: 0.000521\n",
      "batch 495 loss: 1.18928 acc: 0.74837 | v_loss: 1.10543 v_acc: 0.75130 |  iteration: 2982 teacher: 0 stage: sketch lr: 0.000521\n",
      "batch 496 loss: 1.20011 acc: 0.74382 | v_loss: 1.22724 v_acc: 0.74772 |  iteration: 2983 teacher: 0 stage: sketch lr: 0.000521\n",
      "batch 497 loss: 1.17574 acc: 0.75846 | v_loss: 1.11884 v_acc: 0.75944 |  iteration: 2984 teacher: 1 stage: sketch lr: 0.000521\n",
      "batch 498 loss: 1.22496 acc: 0.74967 | v_loss: 1.29596 v_acc: 0.72884 |  iteration: 2985 teacher: 1 stage: sketch lr: 0.000521\n",
      "batch 499 loss: 1.22922 acc: 0.74121 | v_loss: 1.24046 v_acc: 0.74349 |  iteration: 2986 teacher: 1 stage: sketch lr: 0.000522\n",
      "batch 500 loss: 1.23581 acc: 0.74447 | v_loss: 1.18201 v_acc: 0.75911 |  iteration: 2987 teacher: 0 stage: sketch lr: 0.000522\n",
      "batch 501 loss: 1.19609 acc: 0.74251 | v_loss: 1.17533 v_acc: 0.74707 |  iteration: 2988 teacher: 0 stage: sketch lr: 0.000522\n",
      "batch 502 loss: 1.17268 acc: 0.75000 | v_loss: 1.22197 v_acc: 0.73730 |  iteration: 2989 teacher: 1 stage: sketch lr: 0.000522\n",
      "batch 503 loss: 1.27538 acc: 0.74284 | v_loss: 1.26896 v_acc: 0.75065 |  iteration: 2990 teacher: 0 stage: sketch lr: 0.000522\n",
      "batch 504 loss: 1.10831 acc: 0.76042 | v_loss: 1.14760 v_acc: 0.75521 |  iteration: 2991 teacher: 0 stage: sketch lr: 0.000523\n",
      "batch 505 loss: 1.24955 acc: 0.73763 | v_loss: 1.08711 v_acc: 0.76042 |  iteration: 2992 teacher: 0 stage: sketch lr: 0.000523\n",
      "batch 506 loss: 1.19448 acc: 0.74023 | v_loss: 1.04327 v_acc: 0.77507 |  iteration: 2993 teacher: 1 stage: sketch lr: 0.000523\n",
      "batch 507 loss: 1.17117 acc: 0.75879 | v_loss: 1.13532 v_acc: 0.75391 |  iteration: 2994 teacher: 0 stage: sketch lr: 0.000523\n",
      "batch 508 loss: 1.17568 acc: 0.74154 | v_loss: 1.22898 v_acc: 0.73926 |  iteration: 2995 teacher: 0 stage: sketch lr: 0.000523\n",
      "batch 509 loss: 1.24125 acc: 0.74544 | v_loss: 1.18071 v_acc: 0.73568 |  iteration: 2996 teacher: 1 stage: sketch lr: 0.000523\n",
      "batch 510 loss: 1.23579 acc: 0.73796 | v_loss: 1.16035 v_acc: 0.76139 |  iteration: 2997 teacher: 1 stage: sketch lr: 0.000524\n",
      "batch 511 loss: 1.26233 acc: 0.73698 | v_loss: 1.22258 v_acc: 0.75684 |  iteration: 2998 teacher: 0 stage: sketch lr: 0.000524\n",
      "batch 512 loss: 1.19549 acc: 0.75130 | v_loss: 1.20247 v_acc: 0.73047 |  iteration: 2999 teacher: 0 stage: sketch lr: 0.000524\n",
      "batch 513 loss: 1.11594 acc: 0.75391 | v_loss: 1.11649 v_acc: 0.75684 |  iteration: 3000 teacher: 0 stage: sketch lr: 0.000524\n",
      "batch 514 loss: 1.23779 acc: 0.74870 | v_loss: 1.09083 v_acc: 0.75846 |  iteration: 3001 teacher: 1 stage: sketch lr: 0.000524\n",
      "batch 515 loss: 1.18355 acc: 0.74902 | v_loss: 1.10024 v_acc: 0.76888 |  iteration: 3002 teacher: 0 stage: sketch lr: 0.000524\n",
      "batch 516 loss: 1.16834 acc: 0.74186 | v_loss: 1.14438 v_acc: 0.75586 |  iteration: 3003 teacher: 0 stage: sketch lr: 0.000525\n",
      "batch 517 loss: 1.23424 acc: 0.73926 | v_loss: 1.26772 v_acc: 0.73665 |  iteration: 3004 teacher: 0 stage: sketch lr: 0.000525\n",
      "batch 518 loss: 1.29700 acc: 0.74089 | v_loss: 1.26451 v_acc: 0.73470 |  iteration: 3005 teacher: 1 stage: sketch lr: 0.000525\n",
      "batch 519 loss: 1.28452 acc: 0.72754 | v_loss: 1.16244 v_acc: 0.75130 |  iteration: 3006 teacher: 0 stage: sketch lr: 0.000525\n",
      "batch 520 loss: 1.17805 acc: 0.75521 | v_loss: 1.12656 v_acc: 0.77474 |  iteration: 3007 teacher: 1 stage: sketch lr: 0.000525\n",
      "batch 521 loss: 1.13352 acc: 0.75684 | v_loss: 1.23328 v_acc: 0.73145 |  iteration: 3008 teacher: 0 stage: sketch lr: 0.000525\n",
      "batch 522 loss: 1.19868 acc: 0.75000 | v_loss: 1.31688 v_acc: 0.72852 |  iteration: 3009 teacher: 1 stage: sketch lr: 0.000526\n",
      "batch 523 loss: 1.23492 acc: 0.73665 | v_loss: 1.14870 v_acc: 0.75521 |  iteration: 3010 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 524 loss: 1.23504 acc: 0.73568 | v_loss: 1.25075 v_acc: 0.74902 |  iteration: 3011 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 525 loss: 1.17184 acc: 0.74674 | v_loss: 1.06642 v_acc: 0.76172 |  iteration: 3012 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 526 loss: 1.14349 acc: 0.74935 | v_loss: 1.18003 v_acc: 0.75553 |  iteration: 3013 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 527 loss: 1.19295 acc: 0.74837 | v_loss: 1.15740 v_acc: 0.76139 |  iteration: 3014 teacher: 1 stage: sketch lr: 0.000527\n",
      "batch 528 loss: 1.18002 acc: 0.75326 | v_loss: 1.14071 v_acc: 0.76465 |  iteration: 3015 teacher: 1 stage: sketch lr: 0.000527\n",
      "batch 529 loss: 1.22649 acc: 0.74479 | v_loss: 1.12081 v_acc: 0.76400 |  iteration: 3016 teacher: 1 stage: sketch lr: 0.000527\n",
      "batch 530 loss: 1.18725 acc: 0.75228 | v_loss: 1.16485 v_acc: 0.73503 |  iteration: 3017 teacher: 1 stage: sketch lr: 0.000527\n",
      "batch 531 loss: 1.23472 acc: 0.73470 | v_loss: 1.15958 v_acc: 0.76367 |  iteration: 3018 teacher: 0 stage: sketch lr: 0.000527\n",
      "batch 532 loss: 1.23458 acc: 0.74186 | v_loss: 1.17620 v_acc: 0.75781 |  iteration: 3019 teacher: 0 stage: sketch lr: 0.000527\n",
      "batch 533 loss: 1.25331 acc: 0.74284 | v_loss: 1.45582 v_acc: 0.71159 |  iteration: 3020 teacher: 1 stage: sketch lr: 0.000528\n",
      "batch 534 loss: 1.22497 acc: 0.73828 | v_loss: 1.13303 v_acc: 0.74544 |  iteration: 3021 teacher: 0 stage: sketch lr: 0.000528\n",
      "batch 535 loss: 1.24387 acc: 0.74089 | v_loss: 1.19571 v_acc: 0.75553 |  iteration: 3022 teacher: 0 stage: sketch lr: 0.000528\n",
      "batch 536 loss: 1.22238 acc: 0.74935 | v_loss: 1.18771 v_acc: 0.76595 |  iteration: 3023 teacher: 1 stage: sketch lr: 0.000528\n",
      "batch 537 loss: 1.21206 acc: 0.74479 | v_loss: 1.28117 v_acc: 0.73991 |  iteration: 3024 teacher: 1 stage: sketch lr: 0.000528\n",
      "batch 538 loss: 1.21293 acc: 0.75260 | v_loss: 1.06770 v_acc: 0.78158 |  iteration: 3025 teacher: 0 stage: sketch lr: 0.000528\n",
      "batch 539 loss: 1.15499 acc: 0.74642 | v_loss: 1.25062 v_acc: 0.74447 |  iteration: 3026 teacher: 1 stage: sketch lr: 0.000529\n",
      "batch 540 loss: 1.20106 acc: 0.73568 | v_loss: 1.12996 v_acc: 0.75488 |  iteration: 3027 teacher: 0 stage: sketch lr: 0.000529\n",
      "batch 541 loss: 1.21258 acc: 0.73796 | v_loss: 1.27305 v_acc: 0.74023 |  iteration: 3028 teacher: 1 stage: sketch lr: 0.000529\n",
      "batch 542 loss: 1.27233 acc: 0.74154 | v_loss: 1.20827 v_acc: 0.75000 |  iteration: 3029 teacher: 1 stage: sketch lr: 0.000529\n",
      "batch 543 loss: 1.12439 acc: 0.76107 | v_loss: 1.21839 v_acc: 0.73568 |  iteration: 3030 teacher: 1 stage: sketch lr: 0.000529\n",
      "batch 544 loss: 1.17969 acc: 0.75228 | v_loss: 1.29709 v_acc: 0.74186 |  iteration: 3031 teacher: 1 stage: sketch lr: 0.000529\n",
      "batch 545 loss: 1.21294 acc: 0.74251 | v_loss: 1.18327 v_acc: 0.75293 |  iteration: 3032 teacher: 0 stage: sketch lr: 0.000530\n",
      "batch 546 loss: 1.16164 acc: 0.75391 | v_loss: 1.17412 v_acc: 0.75033 |  iteration: 3033 teacher: 1 stage: sketch lr: 0.000530\n",
      "batch 547 loss: 1.08085 acc: 0.76172 | v_loss: 1.12866 v_acc: 0.76693 |  iteration: 3034 teacher: 1 stage: sketch lr: 0.000530\n",
      "batch 548 loss: 1.18748 acc: 0.74414 | v_loss: 1.21842 v_acc: 0.75033 |  iteration: 3035 teacher: 0 stage: sketch lr: 0.000530\n",
      "batch 549 loss: 1.11056 acc: 0.75260 | v_loss: 1.12849 v_acc: 0.75846 |  iteration: 3036 teacher: 1 stage: sketch lr: 0.000530\n",
      "batch 550 loss: 1.25531 acc: 0.74154 | v_loss: 1.14769 v_acc: 0.76270 |  iteration: 3037 teacher: 0 stage: sketch lr: 0.000531\n",
      "batch 551 loss: 1.22658 acc: 0.74935 | v_loss: 1.20713 v_acc: 0.74902 |  iteration: 3038 teacher: 1 stage: sketch lr: 0.000531\n",
      "batch 552 loss: 1.20491 acc: 0.74967 | v_loss: 1.17844 v_acc: 0.74414 |  iteration: 3039 teacher: 1 stage: sketch lr: 0.000531\n",
      "batch 553 loss: 1.24955 acc: 0.73079 | v_loss: 1.22944 v_acc: 0.74121 |  iteration: 3040 teacher: 0 stage: sketch lr: 0.000531\n",
      "batch 554 loss: 1.20770 acc: 0.74609 | v_loss: 1.23236 v_acc: 0.74349 |  iteration: 3041 teacher: 1 stage: sketch lr: 0.000531\n",
      "batch 555 loss: 1.28565 acc: 0.72786 | v_loss: 1.23490 v_acc: 0.74707 |  iteration: 3042 teacher: 0 stage: sketch lr: 0.000531\n",
      "batch 556 loss: 1.16964 acc: 0.74772 | v_loss: 1.20300 v_acc: 0.75065 |  iteration: 3043 teacher: 0 stage: sketch lr: 0.000532\n",
      "batch 557 loss: 1.20266 acc: 0.74935 | v_loss: 1.13688 v_acc: 0.75521 |  iteration: 3044 teacher: 1 stage: sketch lr: 0.000532\n",
      "batch 558 loss: 1.14128 acc: 0.76009 | v_loss: 1.10000 v_acc: 0.77474 |  iteration: 3045 teacher: 1 stage: sketch lr: 0.000532\n",
      "batch 559 loss: 1.25540 acc: 0.74023 | v_loss: 1.18965 v_acc: 0.74967 |  iteration: 3046 teacher: 0 stage: sketch lr: 0.000532\n",
      "batch 560 loss: 1.22409 acc: 0.74186 | v_loss: 1.22487 v_acc: 0.76497 |  iteration: 3047 teacher: 0 stage: sketch lr: 0.000532\n",
      "batch 561 loss: 1.18751 acc: 0.74707 | v_loss: 1.11895 v_acc: 0.76009 |  iteration: 3048 teacher: 0 stage: sketch lr: 0.000532\n",
      "batch 562 loss: 1.26248 acc: 0.74479 | v_loss: 1.20215 v_acc: 0.75000 |  iteration: 3049 teacher: 0 stage: sketch lr: 0.000533\n",
      "batch 563 loss: 1.09931 acc: 0.75977 | v_loss: 1.05356 v_acc: 0.76074 |  iteration: 3050 teacher: 1 stage: sketch lr: 0.000533\n",
      "batch 564 loss: 1.22075 acc: 0.74577 | v_loss: 1.12142 v_acc: 0.77051 |  iteration: 3051 teacher: 0 stage: sketch lr: 0.000533\n",
      "batch 565 loss: 1.16578 acc: 0.75749 | v_loss: 1.24248 v_acc: 0.75000 |  iteration: 3052 teacher: 1 stage: sketch lr: 0.000533\n",
      "batch 566 loss: 1.16779 acc: 0.74837 | v_loss: 1.17250 v_acc: 0.76367 |  iteration: 3053 teacher: 1 stage: sketch lr: 0.000533\n",
      "batch 567 loss: 1.08406 acc: 0.76953 | v_loss: 1.05120 v_acc: 0.77897 |  iteration: 3054 teacher: 1 stage: sketch lr: 0.000534\n",
      "batch 568 loss: 1.21638 acc: 0.75456 | v_loss: 1.23603 v_acc: 0.74154 |  iteration: 3055 teacher: 1 stage: sketch lr: 0.000534\n",
      "batch 569 loss: 1.20430 acc: 0.74642 | v_loss: 1.20121 v_acc: 0.76172 |  iteration: 3056 teacher: 0 stage: sketch lr: 0.000534\n",
      "batch 570 loss: 1.21013 acc: 0.74577 | v_loss: 1.28280 v_acc: 0.74349 |  iteration: 3057 teacher: 1 stage: sketch lr: 0.000534\n",
      "batch 571 loss: 1.21446 acc: 0.74935 | v_loss: 1.04674 v_acc: 0.76204 |  iteration: 3058 teacher: 1 stage: sketch lr: 0.000534\n",
      "batch 572 loss: 1.26360 acc: 0.74349 | v_loss: 1.25855 v_acc: 0.74056 |  iteration: 3059 teacher: 0 stage: sketch lr: 0.000534\n",
      "batch 573 loss: 1.16917 acc: 0.74935 | v_loss: 1.16500 v_acc: 0.75977 |  iteration: 3060 teacher: 1 stage: sketch lr: 0.000535\n",
      "batch 574 loss: 1.13372 acc: 0.74382 | v_loss: 1.28338 v_acc: 0.73275 |  iteration: 3061 teacher: 0 stage: sketch lr: 0.000535\n",
      "batch 575 loss: 1.26365 acc: 0.73828 | v_loss: 1.17395 v_acc: 0.74902 |  iteration: 3062 teacher: 0 stage: sketch lr: 0.000535\n",
      "batch 576 loss: 1.17710 acc: 0.74479 | v_loss: 1.11712 v_acc: 0.76432 |  iteration: 3063 teacher: 0 stage: sketch lr: 0.000535\n",
      "batch 577 loss: 1.21928 acc: 0.74674 | v_loss: 1.10983 v_acc: 0.76042 |  iteration: 3064 teacher: 0 stage: sketch lr: 0.000535\n",
      "batch 578 loss: 1.20039 acc: 0.75456 | v_loss: 1.17996 v_acc: 0.74512 |  iteration: 3065 teacher: 1 stage: sketch lr: 0.000535\n",
      "batch 579 loss: 1.12048 acc: 0.75814 | v_loss: 1.14089 v_acc: 0.75391 |  iteration: 3066 teacher: 0 stage: sketch lr: 0.000536\n",
      "batch 580 loss: 1.16969 acc: 0.75260 | v_loss: 1.17217 v_acc: 0.74609 |  iteration: 3067 teacher: 1 stage: sketch lr: 0.000536\n",
      "batch 581 loss: 1.27129 acc: 0.73763 | v_loss: 1.17784 v_acc: 0.75423 |  iteration: 3068 teacher: 0 stage: sketch lr: 0.000536\n",
      "batch 582 loss: 1.26396 acc: 0.73926 | v_loss: 1.22229 v_acc: 0.74251 |  iteration: 3069 teacher: 0 stage: sketch lr: 0.000536\n",
      "batch 583 loss: 1.17281 acc: 0.74447 | v_loss: 1.18472 v_acc: 0.74219 |  iteration: 3070 teacher: 0 stage: sketch lr: 0.000536\n",
      "batch 584 loss: 1.10525 acc: 0.76335 | v_loss: 1.28661 v_acc: 0.73665 |  iteration: 3071 teacher: 1 stage: sketch lr: 0.000536\n",
      "batch 585 loss: 1.27319 acc: 0.72754 | v_loss: 1.18522 v_acc: 0.74154 |  iteration: 3072 teacher: 0 stage: sketch lr: 0.000537\n",
      "batch 586 loss: 1.17644 acc: 0.75879 | v_loss: 1.07276 v_acc: 0.75618 |  iteration: 3073 teacher: 1 stage: sketch lr: 0.000537\n",
      "batch 587 loss: 1.19424 acc: 0.75651 | v_loss: 1.20962 v_acc: 0.74967 |  iteration: 3074 teacher: 0 stage: sketch lr: 0.000537\n",
      "batch 588 loss: 1.24633 acc: 0.74089 | v_loss: 1.10621 v_acc: 0.76302 |  iteration: 3075 teacher: 0 stage: sketch lr: 0.000537\n",
      "batch 589 loss: 1.18276 acc: 0.75098 | v_loss: 1.27749 v_acc: 0.73307 |  iteration: 3076 teacher: 1 stage: sketch lr: 0.000537\n",
      "batch 590 loss: 1.24962 acc: 0.74902 | v_loss: 1.21634 v_acc: 0.74382 |  iteration: 3077 teacher: 0 stage: sketch lr: 0.000538\n",
      "batch 591 loss: 1.22004 acc: 0.74642 | v_loss: 1.17569 v_acc: 0.75423 |  iteration: 3078 teacher: 0 stage: sketch lr: 0.000538\n",
      "batch 592 loss: 1.28364 acc: 0.73633 | v_loss: 1.21834 v_acc: 0.74186 |  iteration: 3079 teacher: 0 stage: sketch lr: 0.000538\n",
      "batch 593 loss: 1.17442 acc: 0.75065 | v_loss: 1.19618 v_acc: 0.74870 |  iteration: 3080 teacher: 0 stage: sketch lr: 0.000538\n",
      "batch 594 loss: 1.16557 acc: 0.75098 | v_loss: 1.24473 v_acc: 0.75228 |  iteration: 3081 teacher: 0 stage: sketch lr: 0.000538\n",
      "batch 595 loss: 1.23641 acc: 0.73568 | v_loss: 1.13561 v_acc: 0.76595 |  iteration: 3082 teacher: 1 stage: sketch lr: 0.000538\n",
      "batch 596 loss: 1.26072 acc: 0.73405 | v_loss: 1.08949 v_acc: 0.76823 |  iteration: 3083 teacher: 0 stage: sketch lr: 0.000539\n",
      "batch 597 loss: 1.22103 acc: 0.74056 | v_loss: 1.03499 v_acc: 0.77507 |  iteration: 3084 teacher: 1 stage: sketch lr: 0.000539\n",
      "batch 598 loss: 1.30286 acc: 0.73503 | v_loss: 1.13944 v_acc: 0.75749 |  iteration: 3085 teacher: 1 stage: sketch lr: 0.000539\n",
      "batch 599 loss: 1.15885 acc: 0.74316 | v_loss: 1.20745 v_acc: 0.75065 |  iteration: 3086 teacher: 1 stage: sketch lr: 0.000539\n",
      "batch 600 loss: 1.19342 acc: 0.74674 | v_loss: 1.15900 v_acc: 0.74870 |  iteration: 3087 teacher: 0 stage: sketch lr: 0.000539\n",
      "batch 601 loss: 1.10416 acc: 0.76953 | v_loss: 1.14427 v_acc: 0.76823 |  iteration: 3088 teacher: 1 stage: sketch lr: 0.000539\n",
      "batch 602 loss: 1.18236 acc: 0.74609 | v_loss: 1.22590 v_acc: 0.76204 |  iteration: 3089 teacher: 0 stage: sketch lr: 0.000540\n",
      "batch 603 loss: 1.27434 acc: 0.73405 | v_loss: 1.17893 v_acc: 0.73568 |  iteration: 3090 teacher: 1 stage: sketch lr: 0.000540\n",
      "batch 604 loss: 1.19274 acc: 0.74805 | v_loss: 1.10515 v_acc: 0.76042 |  iteration: 3091 teacher: 1 stage: sketch lr: 0.000540\n",
      "batch 605 loss: 1.15499 acc: 0.75749 | v_loss: 1.07497 v_acc: 0.76595 |  iteration: 3092 teacher: 1 stage: sketch lr: 0.000540\n",
      "batch 606 loss: 1.17302 acc: 0.74870 | v_loss: 1.08625 v_acc: 0.77832 |  iteration: 3093 teacher: 0 stage: sketch lr: 0.000540\n",
      "batch 607 loss: 1.13301 acc: 0.75977 | v_loss: 1.14340 v_acc: 0.75684 |  iteration: 3094 teacher: 1 stage: sketch lr: 0.000540\n",
      "batch 608 loss: 1.19735 acc: 0.75684 | v_loss: 1.25284 v_acc: 0.74056 |  iteration: 3095 teacher: 1 stage: sketch lr: 0.000541\n",
      "batch 609 loss: 1.15799 acc: 0.75228 | v_loss: 1.25742 v_acc: 0.73405 |  iteration: 3096 teacher: 0 stage: sketch lr: 0.000541\n",
      "batch 610 loss: 1.21061 acc: 0.74902 | v_loss: 1.15050 v_acc: 0.75488 |  iteration: 3097 teacher: 1 stage: sketch lr: 0.000541\n",
      "batch 611 loss: 1.19225 acc: 0.75293 | v_loss: 1.11825 v_acc: 0.77051 |  iteration: 3098 teacher: 1 stage: sketch lr: 0.000541\n",
      "batch 612 loss: 1.17836 acc: 0.75228 | v_loss: 1.21602 v_acc: 0.74805 |  iteration: 3099 teacher: 1 stage: sketch lr: 0.000541\n",
      "batch 613 loss: 1.18242 acc: 0.74740 | v_loss: 1.29254 v_acc: 0.73340 |  iteration: 3100 teacher: 1 stage: sketch lr: 0.000542\n",
      "batch 614 loss: 1.25185 acc: 0.73893 | v_loss: 1.10720 v_acc: 0.76400 |  iteration: 3101 teacher: 1 stage: sketch lr: 0.000542\n",
      "batch 615 loss: 1.21683 acc: 0.74674 | v_loss: 1.22793 v_acc: 0.74674 |  iteration: 3102 teacher: 1 stage: sketch lr: 0.000542\n",
      "batch 616 loss: 1.21559 acc: 0.75228 | v_loss: 1.04783 v_acc: 0.77539 |  iteration: 3103 teacher: 0 stage: sketch lr: 0.000542\n",
      "batch 617 loss: 1.12284 acc: 0.75326 | v_loss: 1.16501 v_acc: 0.76237 |  iteration: 3104 teacher: 1 stage: sketch lr: 0.000542\n",
      "batch 618 loss: 1.22278 acc: 0.74023 | v_loss: 1.15505 v_acc: 0.75944 |  iteration: 3105 teacher: 0 stage: sketch lr: 0.000542\n",
      "batch 619 loss: 1.24076 acc: 0.75098 | v_loss: 1.13171 v_acc: 0.76172 |  iteration: 3106 teacher: 0 stage: sketch lr: 0.000543\n",
      "batch 620 loss: 1.24660 acc: 0.75000 | v_loss: 1.11365 v_acc: 0.76270 |  iteration: 3107 teacher: 0 stage: sketch lr: 0.000543\n",
      "batch 621 loss: 1.20523 acc: 0.75456 | v_loss: 1.13651 v_acc: 0.75391 |  iteration: 3108 teacher: 1 stage: sketch lr: 0.000543\n",
      "batch 622 loss: 1.17638 acc: 0.75130 | v_loss: 1.13838 v_acc: 0.76400 |  iteration: 3109 teacher: 0 stage: sketch lr: 0.000543\n",
      "batch 623 loss: 1.18392 acc: 0.74674 | v_loss: 1.15502 v_acc: 0.76107 |  iteration: 3110 teacher: 0 stage: sketch lr: 0.000543\n",
      "batch 624 loss: 1.26196 acc: 0.74414 | v_loss: 1.42377 v_acc: 0.71615 |  iteration: 3111 teacher: 0 stage: sketch lr: 0.000543\n",
      "batch 625 loss: 1.08718 acc: 0.77474 | v_loss: 1.11698 v_acc: 0.75098 |  iteration: 3112 teacher: 1 stage: sketch lr: 0.000544\n",
      "batch 626 loss: 1.23897 acc: 0.74512 | v_loss: 1.20838 v_acc: 0.75814 |  iteration: 3113 teacher: 1 stage: sketch lr: 0.000544\n",
      "batch 627 loss: 1.23015 acc: 0.74512 | v_loss: 1.19026 v_acc: 0.76335 |  iteration: 3114 teacher: 0 stage: sketch lr: 0.000544\n",
      "batch 628 loss: 1.21795 acc: 0.74089 | v_loss: 1.27450 v_acc: 0.74316 |  iteration: 3115 teacher: 0 stage: sketch lr: 0.000544\n",
      "batch 629 loss: 1.13827 acc: 0.76107 | v_loss: 1.07714 v_acc: 0.77409 |  iteration: 3116 teacher: 0 stage: sketch lr: 0.000544\n",
      "batch 630 loss: 1.14221 acc: 0.76107 | v_loss: 1.24147 v_acc: 0.74674 |  iteration: 3117 teacher: 1 stage: sketch lr: 0.000545\n",
      "batch 631 loss: 1.13058 acc: 0.75488 | v_loss: 1.12468 v_acc: 0.75391 |  iteration: 3118 teacher: 1 stage: sketch lr: 0.000545\n",
      "batch 632 loss: 1.13719 acc: 0.75716 | v_loss: 1.27352 v_acc: 0.73438 |  iteration: 3119 teacher: 0 stage: sketch lr: 0.000545\n",
      "batch 633 loss: 1.18651 acc: 0.74056 | v_loss: 1.19204 v_acc: 0.75065 |  iteration: 3120 teacher: 1 stage: sketch lr: 0.000545\n",
      "batch 634 loss: 1.19693 acc: 0.75553 | v_loss: 1.18384 v_acc: 0.74382 |  iteration: 3121 teacher: 1 stage: sketch lr: 0.000545\n",
      "batch 635 loss: 1.25473 acc: 0.73926 | v_loss: 1.29111 v_acc: 0.74154 |  iteration: 3122 teacher: 1 stage: sketch lr: 0.000545\n",
      "batch 636 loss: 1.17384 acc: 0.74740 | v_loss: 1.16464 v_acc: 0.74870 |  iteration: 3123 teacher: 0 stage: sketch lr: 0.000546\n",
      "batch 637 loss: 1.11543 acc: 0.75358 | v_loss: 1.14507 v_acc: 0.74902 |  iteration: 3124 teacher: 0 stage: sketch lr: 0.000546\n",
      "batch 638 loss: 1.25124 acc: 0.74902 | v_loss: 1.10485 v_acc: 0.77539 |  iteration: 3125 teacher: 0 stage: sketch lr: 0.000546\n",
      "batch 639 loss: 1.13258 acc: 0.76009 | v_loss: 1.20744 v_acc: 0.75521 |  iteration: 3126 teacher: 0 stage: sketch lr: 0.000546\n",
      "batch 640 loss: 1.20721 acc: 0.74870 | v_loss: 1.10730 v_acc: 0.76595 |  iteration: 3127 teacher: 0 stage: sketch lr: 0.000546\n",
      "batch 641 loss: 1.16624 acc: 0.74935 | v_loss: 1.12989 v_acc: 0.76432 |  iteration: 3128 teacher: 1 stage: sketch lr: 0.000546\n",
      "batch 642 loss: 1.11398 acc: 0.75879 | v_loss: 1.17798 v_acc: 0.75781 |  iteration: 3129 teacher: 0 stage: sketch lr: 0.000547\n",
      "batch 643 loss: 1.30971 acc: 0.73438 | v_loss: 1.17436 v_acc: 0.74414 |  iteration: 3130 teacher: 1 stage: sketch lr: 0.000547\n",
      "batch 644 loss: 1.14792 acc: 0.75814 | v_loss: 1.26735 v_acc: 0.73470 |  iteration: 3131 teacher: 1 stage: sketch lr: 0.000547\n",
      "batch 645 loss: 1.30339 acc: 0.73372 | v_loss: 1.21766 v_acc: 0.74382 |  iteration: 3132 teacher: 1 stage: sketch lr: 0.000547\n",
      "batch 646 loss: 1.14063 acc: 0.75716 | v_loss: 1.22883 v_acc: 0.75163 |  iteration: 3133 teacher: 0 stage: sketch lr: 0.000547\n",
      "batch 647 loss: 1.21710 acc: 0.74837 | v_loss: 1.19493 v_acc: 0.75195 |  iteration: 3134 teacher: 0 stage: sketch lr: 0.000547\n",
      "batch 648 loss: 1.23877 acc: 0.73372 | v_loss: 1.15951 v_acc: 0.74674 |  iteration: 3135 teacher: 0 stage: sketch lr: 0.000548\n",
      "batch 649 loss: 1.16452 acc: 0.74740 | v_loss: 1.10308 v_acc: 0.77572 |  iteration: 3136 teacher: 1 stage: sketch lr: 0.000548\n",
      "batch 650 loss: 1.13306 acc: 0.75488 | v_loss: 1.19144 v_acc: 0.75000 |  iteration: 3137 teacher: 1 stage: sketch lr: 0.000548\n",
      "batch 651 loss: 1.09699 acc: 0.76725 | v_loss: 1.20579 v_acc: 0.76432 |  iteration: 3138 teacher: 1 stage: sketch lr: 0.000548\n",
      "batch 652 loss: 1.16765 acc: 0.74512 | v_loss: 1.11240 v_acc: 0.76562 |  iteration: 3139 teacher: 0 stage: sketch lr: 0.000548\n",
      "batch 653 loss: 1.15485 acc: 0.75651 | v_loss: 1.20014 v_acc: 0.75260 |  iteration: 3140 teacher: 1 stage: sketch lr: 0.000549\n",
      "batch 654 loss: 1.13509 acc: 0.76270 | v_loss: 1.04750 v_acc: 0.75716 |  iteration: 3141 teacher: 1 stage: sketch lr: 0.000549\n",
      "batch 655 loss: 1.16186 acc: 0.75977 | v_loss: 1.12275 v_acc: 0.76855 |  iteration: 3142 teacher: 1 stage: sketch lr: 0.000549\n",
      "batch 656 loss: 1.22331 acc: 0.74902 | v_loss: 1.20081 v_acc: 0.74772 |  iteration: 3143 teacher: 0 stage: sketch lr: 0.000549\n",
      "batch 657 loss: 1.11404 acc: 0.75195 | v_loss: 1.17509 v_acc: 0.75521 |  iteration: 3144 teacher: 1 stage: sketch lr: 0.000549\n",
      "batch 658 loss: 1.20303 acc: 0.74479 | v_loss: 1.03853 v_acc: 0.78125 |  iteration: 3145 teacher: 0 stage: sketch lr: 0.000549\n",
      "batch 659 loss: 1.11323 acc: 0.76009 | v_loss: 1.22468 v_acc: 0.74154 |  iteration: 3146 teacher: 1 stage: sketch lr: 0.000550\n",
      "batch 660 loss: 1.10006 acc: 0.76530 | v_loss: 1.19682 v_acc: 0.75911 |  iteration: 3147 teacher: 1 stage: sketch lr: 0.000550\n",
      "batch 661 loss: 1.11851 acc: 0.76400 | v_loss: 1.25825 v_acc: 0.75456 |  iteration: 3148 teacher: 1 stage: sketch lr: 0.000550\n",
      "batch 662 loss: 1.18001 acc: 0.75391 | v_loss: 1.04983 v_acc: 0.75879 |  iteration: 3149 teacher: 1 stage: sketch lr: 0.000550\n",
      "batch 663 loss: 1.19563 acc: 0.74609 | v_loss: 1.25987 v_acc: 0.73958 |  iteration: 3150 teacher: 0 stage: sketch lr: 0.000550\n",
      "batch 664 loss: 1.18698 acc: 0.75391 | v_loss: 1.16846 v_acc: 0.75716 |  iteration: 3151 teacher: 0 stage: sketch lr: 0.000550\n",
      "batch 665 loss: 1.16354 acc: 0.75684 | v_loss: 1.28529 v_acc: 0.73991 |  iteration: 3152 teacher: 1 stage: sketch lr: 0.000551\n",
      "batch 666 loss: 1.12524 acc: 0.76042 | v_loss: 1.15438 v_acc: 0.75521 |  iteration: 3153 teacher: 1 stage: sketch lr: 0.000551\n",
      "batch 667 loss: 1.17990 acc: 0.75293 | v_loss: 1.11938 v_acc: 0.76367 |  iteration: 3154 teacher: 1 stage: sketch lr: 0.000551\n",
      "batch 668 loss: 1.13225 acc: 0.75749 | v_loss: 1.10219 v_acc: 0.76530 |  iteration: 3155 teacher: 1 stage: sketch lr: 0.000551\n",
      "batch 669 loss: 1.20704 acc: 0.74967 | v_loss: 1.19095 v_acc: 0.73210 |  iteration: 3156 teacher: 0 stage: sketch lr: 0.000551\n",
      "batch 670 loss: 1.19109 acc: 0.75000 | v_loss: 1.11623 v_acc: 0.74967 |  iteration: 3157 teacher: 0 stage: sketch lr: 0.000552\n",
      "batch 671 loss: 1.19291 acc: 0.75033 | v_loss: 1.17390 v_acc: 0.75195 |  iteration: 3158 teacher: 0 stage: sketch lr: 0.000552\n",
      "batch 672 loss: 1.19854 acc: 0.75033 | v_loss: 1.18044 v_acc: 0.75749 |  iteration: 3159 teacher: 1 stage: sketch lr: 0.000552\n",
      "batch 673 loss: 1.25913 acc: 0.73763 | v_loss: 1.21159 v_acc: 0.74186 |  iteration: 3160 teacher: 0 stage: sketch lr: 0.000552\n",
      "batch 674 loss: 1.24863 acc: 0.73210 | v_loss: 1.18103 v_acc: 0.74479 |  iteration: 3161 teacher: 0 stage: sketch lr: 0.000552\n",
      "batch 675 loss: 1.08155 acc: 0.76107 | v_loss: 1.27657 v_acc: 0.73763 |  iteration: 3162 teacher: 1 stage: sketch lr: 0.000552\n",
      "batch 676 loss: 1.15737 acc: 0.75195 | v_loss: 1.18072 v_acc: 0.74121 |  iteration: 3163 teacher: 0 stage: sketch lr: 0.000553\n",
      "batch 677 loss: 1.13108 acc: 0.75651 | v_loss: 1.08471 v_acc: 0.75977 |  iteration: 3164 teacher: 1 stage: sketch lr: 0.000553\n",
      "batch 678 loss: 1.23859 acc: 0.73503 | v_loss: 1.21321 v_acc: 0.74740 |  iteration: 3165 teacher: 0 stage: sketch lr: 0.000553\n",
      "batch 679 loss: 1.18333 acc: 0.74935 | v_loss: 1.10475 v_acc: 0.76432 |  iteration: 3166 teacher: 0 stage: sketch lr: 0.000553\n",
      "batch 680 loss: 1.06136 acc: 0.77539 | v_loss: 1.25594 v_acc: 0.73633 |  iteration: 3167 teacher: 1 stage: sketch lr: 0.000553\n",
      "batch 681 loss: 1.25984 acc: 0.73535 | v_loss: 1.21094 v_acc: 0.75000 |  iteration: 3168 teacher: 1 stage: sketch lr: 0.000553\n",
      "batch 682 loss: 1.17173 acc: 0.74674 | v_loss: 1.18411 v_acc: 0.75911 |  iteration: 3169 teacher: 0 stage: sketch lr: 0.000554\n",
      "batch 683 loss: 1.17001 acc: 0.75553 | v_loss: 1.16455 v_acc: 0.76042 |  iteration: 3170 teacher: 1 stage: sketch lr: 0.000554\n",
      "batch 684 loss: 1.13717 acc: 0.75618 | v_loss: 1.20356 v_acc: 0.74056 |  iteration: 3171 teacher: 1 stage: sketch lr: 0.000554\n",
      "batch 685 loss: 1.27311 acc: 0.73568 | v_loss: 1.25631 v_acc: 0.75065 |  iteration: 3172 teacher: 0 stage: sketch lr: 0.000554\n",
      "batch 686 loss: 1.11886 acc: 0.75651 | v_loss: 1.13374 v_acc: 0.76562 |  iteration: 3173 teacher: 1 stage: sketch lr: 0.000554\n",
      "batch 687 loss: 1.23924 acc: 0.73730 | v_loss: 1.08565 v_acc: 0.77116 |  iteration: 3174 teacher: 1 stage: sketch lr: 0.000554\n",
      "batch 688 loss: 1.18808 acc: 0.74544 | v_loss: 1.03620 v_acc: 0.77474 |  iteration: 3175 teacher: 0 stage: sketch lr: 0.000555\n",
      "batch 689 loss: 1.18957 acc: 0.73796 | v_loss: 1.12864 v_acc: 0.75781 |  iteration: 3176 teacher: 0 stage: sketch lr: 0.000555\n",
      "batch 690 loss: 1.13828 acc: 0.76595 | v_loss: 1.20955 v_acc: 0.75781 |  iteration: 3177 teacher: 1 stage: sketch lr: 0.000555\n",
      "batch 691 loss: 1.20643 acc: 0.75163 | v_loss: 1.18327 v_acc: 0.74609 |  iteration: 3178 teacher: 1 stage: sketch lr: 0.000555\n",
      "batch 692 loss: 1.18573 acc: 0.75326 | v_loss: 1.13844 v_acc: 0.76855 |  iteration: 3179 teacher: 0 stage: sketch lr: 0.000555\n",
      "batch 693 loss: 1.22006 acc: 0.74284 | v_loss: 1.21079 v_acc: 0.75944 |  iteration: 3180 teacher: 0 stage: sketch lr: 0.000556\n",
      "batch 694 loss: 1.15806 acc: 0.75000 | v_loss: 1.15995 v_acc: 0.74284 |  iteration: 3181 teacher: 0 stage: sketch lr: 0.000556\n",
      "batch 695 loss: 1.27330 acc: 0.73112 | v_loss: 1.09884 v_acc: 0.75586 |  iteration: 3182 teacher: 1 stage: sketch lr: 0.000556\n",
      "batch 696 loss: 1.12843 acc: 0.76204 | v_loss: 1.07137 v_acc: 0.76758 |  iteration: 3183 teacher: 0 stage: sketch lr: 0.000556\n",
      "batch 697 loss: 1.05705 acc: 0.75944 | v_loss: 1.09391 v_acc: 0.77539 |  iteration: 3184 teacher: 1 stage: sketch lr: 0.000556\n",
      "batch 698 loss: 1.13793 acc: 0.75423 | v_loss: 1.13707 v_acc: 0.75716 |  iteration: 3185 teacher: 1 stage: sketch lr: 0.000556\n",
      "batch 699 loss: 1.27467 acc: 0.74805 | v_loss: 1.26983 v_acc: 0.73926 |  iteration: 3186 teacher: 0 stage: sketch lr: 0.000557\n",
      "batch 700 loss: 1.19679 acc: 0.73568 | v_loss: 1.27670 v_acc: 0.73079 |  iteration: 3187 teacher: 0 stage: sketch lr: 0.000557\n",
      "batch 701 loss: 1.14021 acc: 0.75000 | v_loss: 1.16864 v_acc: 0.75911 |  iteration: 3188 teacher: 1 stage: sketch lr: 0.000557\n",
      "batch 702 loss: 1.24574 acc: 0.74154 | v_loss: 1.13193 v_acc: 0.77279 |  iteration: 3189 teacher: 0 stage: sketch lr: 0.000557\n",
      "batch 703 loss: 1.17459 acc: 0.75195 | v_loss: 1.23657 v_acc: 0.73893 |  iteration: 3190 teacher: 0 stage: sketch lr: 0.000557\n",
      "batch 704 loss: 1.19032 acc: 0.74382 | v_loss: 1.30386 v_acc: 0.72786 |  iteration: 3191 teacher: 0 stage: sketch lr: 0.000557\n",
      "batch 705 loss: 1.11353 acc: 0.75944 | v_loss: 1.10858 v_acc: 0.76302 |  iteration: 3192 teacher: 1 stage: sketch lr: 0.000558\n",
      "batch 706 loss: 1.23759 acc: 0.73568 | v_loss: 1.23024 v_acc: 0.74382 |  iteration: 3193 teacher: 0 stage: sketch lr: 0.000558\n",
      "batch 707 loss: 1.26277 acc: 0.74186 | v_loss: 1.07333 v_acc: 0.76725 |  iteration: 3194 teacher: 0 stage: sketch lr: 0.000558\n",
      "batch 708 loss: 1.22976 acc: 0.74089 | v_loss: 1.18614 v_acc: 0.75195 |  iteration: 3195 teacher: 0 stage: sketch lr: 0.000558\n",
      "batch 709 loss: 1.23729 acc: 0.74512 | v_loss: 1.16879 v_acc: 0.76237 |  iteration: 3196 teacher: 1 stage: sketch lr: 0.000558\n",
      "batch 710 loss: 1.24579 acc: 0.73958 | v_loss: 1.13687 v_acc: 0.75716 |  iteration: 3197 teacher: 0 stage: sketch lr: 0.000558\n",
      "batch 711 loss: 1.18035 acc: 0.75521 | v_loss: 1.11063 v_acc: 0.76074 |  iteration: 3198 teacher: 1 stage: sketch lr: 0.000559\n",
      "batch 712 loss: 1.16152 acc: 0.75358 | v_loss: 1.14620 v_acc: 0.74316 |  iteration: 3199 teacher: 0 stage: sketch lr: 0.000559\n",
      "batch 713 loss: 1.32530 acc: 0.73698 | v_loss: 1.13620 v_acc: 0.76758 |  iteration: 3200 teacher: 0 stage: sketch lr: 0.000559\n",
      "batch 714 loss: 1.16162 acc: 0.75488 | v_loss: 1.15894 v_acc: 0.76660 |  iteration: 3201 teacher: 1 stage: sketch lr: 0.000559\n",
      "batch 715 loss: 1.28488 acc: 0.73600 | v_loss: 1.39123 v_acc: 0.71745 |  iteration: 3202 teacher: 0 stage: sketch lr: 0.000559\n",
      "batch 716 loss: 1.16902 acc: 0.75033 | v_loss: 1.10973 v_acc: 0.75586 |  iteration: 3203 teacher: 1 stage: sketch lr: 0.000560\n",
      "batch 717 loss: 1.19045 acc: 0.74967 | v_loss: 1.20345 v_acc: 0.75977 |  iteration: 3204 teacher: 0 stage: sketch lr: 0.000560\n",
      "batch 718 loss: 1.30153 acc: 0.73112 | v_loss: 1.17271 v_acc: 0.76725 |  iteration: 3205 teacher: 0 stage: sketch lr: 0.000560\n",
      "batch 719 loss: 1.17932 acc: 0.75944 | v_loss: 1.26700 v_acc: 0.74414 |  iteration: 3206 teacher: 0 stage: sketch lr: 0.000560\n",
      "batch 720 loss: 1.25223 acc: 0.73503 | v_loss: 1.07199 v_acc: 0.77637 |  iteration: 3207 teacher: 1 stage: sketch lr: 0.000560\n",
      "batch 721 loss: 1.10323 acc: 0.76432 | v_loss: 1.23827 v_acc: 0.74382 |  iteration: 3208 teacher: 0 stage: sketch lr: 0.000560\n",
      "batch 722 loss: 1.22147 acc: 0.73470 | v_loss: 1.10778 v_acc: 0.75911 |  iteration: 3209 teacher: 0 stage: sketch lr: 0.000561\n",
      "batch 723 loss: 1.19582 acc: 0.75033 | v_loss: 1.27770 v_acc: 0.73926 |  iteration: 3210 teacher: 1 stage: sketch lr: 0.000561\n",
      "batch 724 loss: 1.19460 acc: 0.74967 | v_loss: 1.19485 v_acc: 0.74870 |  iteration: 3211 teacher: 0 stage: sketch lr: 0.000561\n",
      "batch 725 loss: 1.24787 acc: 0.75195 | v_loss: 1.19631 v_acc: 0.74544 |  iteration: 3212 teacher: 1 stage: sketch lr: 0.000561\n",
      "batch 726 loss: 1.19981 acc: 0.74967 | v_loss: 1.27788 v_acc: 0.73796 |  iteration: 3213 teacher: 0 stage: sketch lr: 0.000561\n",
      "batch 727 loss: 1.16208 acc: 0.75000 | v_loss: 1.16654 v_acc: 0.75684 |  iteration: 3214 teacher: 1 stage: sketch lr: 0.000561\n",
      "batch 728 loss: 1.19825 acc: 0.74935 | v_loss: 1.13396 v_acc: 0.76237 |  iteration: 3215 teacher: 0 stage: sketch lr: 0.000562\n",
      "batch 729 loss: 1.10069 acc: 0.76595 | v_loss: 1.09855 v_acc: 0.76953 |  iteration: 3216 teacher: 1 stage: sketch lr: 0.000562\n",
      "batch 730 loss: 1.20441 acc: 0.75293 | v_loss: 1.19205 v_acc: 0.75814 |  iteration: 3217 teacher: 0 stage: sketch lr: 0.000562\n",
      "batch 731 loss: 1.31110 acc: 0.73210 | v_loss: 1.11874 v_acc: 0.76595 |  iteration: 3218 teacher: 0 stage: sketch lr: 0.000562\n",
      "batch 732 loss: 1.17886 acc: 0.75488 | v_loss: 1.12429 v_acc: 0.76074 |  iteration: 3219 teacher: 1 stage: sketch lr: 0.000562\n",
      "batch 733 loss: 1.18440 acc: 0.74414 | v_loss: 1.18493 v_acc: 0.75228 |  iteration: 3220 teacher: 0 stage: sketch lr: 0.000563\n",
      "batch 734 loss: 1.08753 acc: 0.76465 | v_loss: 1.15295 v_acc: 0.74740 |  iteration: 3221 teacher: 0 stage: sketch lr: 0.000563\n",
      "batch 735 loss: 1.18121 acc: 0.75130 | v_loss: 1.23259 v_acc: 0.73926 |  iteration: 3222 teacher: 1 stage: sketch lr: 0.000563\n",
      "batch 736 loss: 1.16193 acc: 0.75098 | v_loss: 1.22157 v_acc: 0.74642 |  iteration: 3223 teacher: 1 stage: sketch lr: 0.000563\n",
      "batch 737 loss: 1.18857 acc: 0.75065 | v_loss: 1.24482 v_acc: 0.75456 |  iteration: 3224 teacher: 0 stage: sketch lr: 0.000563\n",
      "batch 738 loss: 1.30952 acc: 0.72949 | v_loss: 1.20228 v_acc: 0.75130 |  iteration: 3225 teacher: 0 stage: sketch lr: 0.000563\n",
      "batch 739 loss: 1.28118 acc: 0.73828 | v_loss: 1.15274 v_acc: 0.75098 |  iteration: 3226 teacher: 0 stage: sketch lr: 0.000564\n",
      "batch 740 loss: 1.34003 acc: 0.73210 | v_loss: 1.10441 v_acc: 0.77376 |  iteration: 3227 teacher: 0 stage: sketch lr: 0.000564\n",
      "batch 741 loss: 1.18695 acc: 0.75358 | v_loss: 1.17680 v_acc: 0.74902 |  iteration: 3228 teacher: 0 stage: sketch lr: 0.000564\n",
      "batch 742 loss: 1.14523 acc: 0.75228 | v_loss: 1.17226 v_acc: 0.76725 |  iteration: 3229 teacher: 1 stage: sketch lr: 0.000564\n",
      "batch 743 loss: 1.10506 acc: 0.76270 | v_loss: 1.09742 v_acc: 0.76497 |  iteration: 3230 teacher: 1 stage: sketch lr: 0.000564\n",
      "batch 744 loss: 1.11600 acc: 0.75098 | v_loss: 1.19010 v_acc: 0.75749 |  iteration: 3231 teacher: 1 stage: sketch lr: 0.000564\n",
      "batch 745 loss: 1.20941 acc: 0.75195 | v_loss: 1.05858 v_acc: 0.75293 |  iteration: 3232 teacher: 0 stage: sketch lr: 0.000565\n",
      "batch 746 loss: 1.15139 acc: 0.75423 | v_loss: 1.12022 v_acc: 0.77018 |  iteration: 3233 teacher: 0 stage: sketch lr: 0.000565\n",
      "batch 747 loss: 1.15795 acc: 0.75065 | v_loss: 1.20885 v_acc: 0.74642 |  iteration: 3234 teacher: 1 stage: sketch lr: 0.000565\n",
      "batch 748 loss: 1.18661 acc: 0.74870 | v_loss: 1.16437 v_acc: 0.75326 |  iteration: 3235 teacher: 0 stage: sketch lr: 0.000565\n",
      "batch 749 loss: 1.26129 acc: 0.74447 | v_loss: 1.03498 v_acc: 0.78418 |  iteration: 3236 teacher: 0 stage: sketch lr: 0.000565\n",
      "batch 750 loss: 1.18926 acc: 0.75553 | v_loss: 1.21269 v_acc: 0.74544 |  iteration: 3237 teacher: 1 stage: sketch lr: 0.000565\n",
      "batch 751 loss: 1.22500 acc: 0.74284 | v_loss: 1.20158 v_acc: 0.75456 |  iteration: 3238 teacher: 0 stage: sketch lr: 0.000566\n",
      "batch 752 loss: 1.18371 acc: 0.74349 | v_loss: 1.26449 v_acc: 0.74837 |  iteration: 3239 teacher: 0 stage: sketch lr: 0.000566\n",
      "batch 753 loss: 1.18964 acc: 0.74219 | v_loss: 1.02465 v_acc: 0.76237 |  iteration: 3240 teacher: 1 stage: sketch lr: 0.000566\n",
      "batch 754 loss: 1.16160 acc: 0.74609 | v_loss: 1.25502 v_acc: 0.73991 |  iteration: 3241 teacher: 0 stage: sketch lr: 0.000566\n",
      "batch 755 loss: 1.24375 acc: 0.73763 | v_loss: 1.13686 v_acc: 0.76270 |  iteration: 3242 teacher: 0 stage: sketch lr: 0.000566\n",
      "batch 756 loss: 1.21314 acc: 0.73633 | v_loss: 1.28112 v_acc: 0.73828 |  iteration: 3243 teacher: 0 stage: sketch lr: 0.000567\n",
      "batch 757 loss: 1.10677 acc: 0.76335 | v_loss: 1.15179 v_acc: 0.75749 |  iteration: 3244 teacher: 1 stage: sketch lr: 0.000567\n",
      "batch 758 loss: 1.20136 acc: 0.74837 | v_loss: 1.11418 v_acc: 0.76400 |  iteration: 3245 teacher: 1 stage: sketch lr: 0.000567\n",
      "batch 759 loss: 1.13752 acc: 0.75098 | v_loss: 1.10939 v_acc: 0.75488 |  iteration: 3246 teacher: 0 stage: sketch lr: 0.000567\n",
      "batch 760 loss: 1.28125 acc: 0.73112 | v_loss: 1.12970 v_acc: 0.73665 |  iteration: 3247 teacher: 1 stage: sketch lr: 0.000567\n",
      "batch 761 loss: 1.13637 acc: 0.75456 | v_loss: 1.12248 v_acc: 0.75130 |  iteration: 3248 teacher: 0 stage: sketch lr: 0.000567\n",
      "batch 762 loss: 1.17575 acc: 0.74967 | v_loss: 1.16524 v_acc: 0.75000 |  iteration: 3249 teacher: 1 stage: sketch lr: 0.000568\n",
      "batch 763 loss: 1.17095 acc: 0.73926 | v_loss: 1.17498 v_acc: 0.75684 |  iteration: 3250 teacher: 0 stage: sketch lr: 0.000568\n",
      "batch 764 loss: 1.22056 acc: 0.74382 | v_loss: 1.19972 v_acc: 0.74284 |  iteration: 3251 teacher: 0 stage: sketch lr: 0.000568\n",
      "batch 765 loss: 1.27303 acc: 0.74056 | v_loss: 1.17973 v_acc: 0.74219 |  iteration: 3252 teacher: 0 stage: sketch lr: 0.000568\n",
      "batch 766 loss: 1.17821 acc: 0.74544 | v_loss: 1.26409 v_acc: 0.74186 |  iteration: 3253 teacher: 0 stage: sketch lr: 0.000568\n",
      "batch 767 loss: 1.11915 acc: 0.76497 | v_loss: 1.18074 v_acc: 0.73828 |  iteration: 3254 teacher: 1 stage: sketch lr: 0.000568\n",
      "batch 768 loss: 1.16465 acc: 0.75423 | v_loss: 1.06072 v_acc: 0.76628 |  iteration: 3255 teacher: 0 stage: sketch lr: 0.000569\n",
      "batch 769 loss: 1.16997 acc: 0.75163 | v_loss: 1.21270 v_acc: 0.74674 |  iteration: 3256 teacher: 0 stage: sketch lr: 0.000569\n",
      "batch 770 loss: 1.27966 acc: 0.73698 | v_loss: 1.09285 v_acc: 0.76725 |  iteration: 3257 teacher: 0 stage: sketch lr: 0.000569\n",
      "batch 771 loss: 1.12727 acc: 0.76432 | v_loss: 1.24954 v_acc: 0.74512 |  iteration: 3258 teacher: 0 stage: sketch lr: 0.000569\n",
      "batch 772 loss: 1.26240 acc: 0.73958 | v_loss: 1.19287 v_acc: 0.75391 |  iteration: 3259 teacher: 0 stage: sketch lr: 0.000569\n",
      "batch 773 loss: 1.27760 acc: 0.74284 | v_loss: 1.15600 v_acc: 0.76009 |  iteration: 3260 teacher: 0 stage: sketch lr: 0.000569\n",
      "batch 774 loss: 1.17383 acc: 0.74902 | v_loss: 1.18507 v_acc: 0.74967 |  iteration: 3261 teacher: 0 stage: sketch lr: 0.000570\n",
      "batch 775 loss: 1.02191 acc: 0.77767 | v_loss: 1.19991 v_acc: 0.74609 |  iteration: 3262 teacher: 1 stage: sketch lr: 0.000570\n",
      "batch 776 loss: 1.09935 acc: 0.76367 | v_loss: 1.24884 v_acc: 0.75293 |  iteration: 3263 teacher: 1 stage: sketch lr: 0.000570\n",
      "batch 777 loss: 1.20898 acc: 0.74447 | v_loss: 1.13166 v_acc: 0.76823 |  iteration: 3264 teacher: 1 stage: sketch lr: 0.000570\n",
      "batch 778 loss: 1.15969 acc: 0.75228 | v_loss: 1.09058 v_acc: 0.76888 |  iteration: 3265 teacher: 0 stage: sketch lr: 0.000570\n",
      "batch 779 loss: 1.12841 acc: 0.76270 | v_loss: 1.03425 v_acc: 0.77669 |  iteration: 3266 teacher: 1 stage: sketch lr: 0.000571\n",
      "batch 780 loss: 1.15895 acc: 0.76074 | v_loss: 1.11786 v_acc: 0.75781 |  iteration: 3267 teacher: 1 stage: sketch lr: 0.000571\n",
      "batch 781 loss: 1.25727 acc: 0.73665 | v_loss: 1.19383 v_acc: 0.75000 |  iteration: 3268 teacher: 0 stage: sketch lr: 0.000571\n",
      "batch 782 loss: 1.10428 acc: 0.76302 | v_loss: 1.15568 v_acc: 0.75098 |  iteration: 3269 teacher: 1 stage: sketch lr: 0.000571\n",
      "batch 783 loss: 1.09356 acc: 0.76693 | v_loss: 1.10198 v_acc: 0.77930 |  iteration: 3270 teacher: 1 stage: sketch lr: 0.000571\n",
      "batch 784 loss: 1.15219 acc: 0.74642 | v_loss: 1.19261 v_acc: 0.75716 |  iteration: 3271 teacher: 1 stage: sketch lr: 0.000571\n",
      "batch 785 loss: 1.15584 acc: 0.76725 | v_loss: 1.15802 v_acc: 0.74902 |  iteration: 3272 teacher: 1 stage: sketch lr: 0.000572\n",
      "batch 786 loss: 1.11638 acc: 0.76465 | v_loss: 1.11795 v_acc: 0.75684 |  iteration: 3273 teacher: 1 stage: sketch lr: 0.000572\n",
      "batch 787 loss: 1.18841 acc: 0.74870 | v_loss: 1.06260 v_acc: 0.76562 |  iteration: 3274 teacher: 1 stage: sketch lr: 0.000572\n",
      "batch 788 loss: 1.11084 acc: 0.76009 | v_loss: 1.07954 v_acc: 0.77897 |  iteration: 3275 teacher: 1 stage: sketch lr: 0.000572\n",
      "batch 789 loss: 1.22136 acc: 0.73796 | v_loss: 1.13173 v_acc: 0.76530 |  iteration: 3276 teacher: 0 stage: sketch lr: 0.000572\n",
      "batch 790 loss: 1.16088 acc: 0.74447 | v_loss: 1.22706 v_acc: 0.75358 |  iteration: 3277 teacher: 1 stage: sketch lr: 0.000572\n",
      "batch 791 loss: 1.20268 acc: 0.74219 | v_loss: 1.28400 v_acc: 0.73079 |  iteration: 3278 teacher: 1 stage: sketch lr: 0.000573\n",
      "batch 792 loss: 1.06958 acc: 0.75618 | v_loss: 1.13150 v_acc: 0.75944 |  iteration: 3279 teacher: 0 stage: sketch lr: 0.000573\n",
      "batch 793 loss: 1.18482 acc: 0.74935 | v_loss: 1.11728 v_acc: 0.77767 |  iteration: 3280 teacher: 0 stage: sketch lr: 0.000573\n",
      "batch 794 loss: 1.30240 acc: 0.73861 | v_loss: 1.21214 v_acc: 0.74089 |  iteration: 3281 teacher: 0 stage: sketch lr: 0.000573\n",
      "batch 795 loss: 1.10407 acc: 0.76302 | v_loss: 1.29838 v_acc: 0.73535 |  iteration: 3282 teacher: 0 stage: sketch lr: 0.000573\n",
      "batch 796 loss: 1.21506 acc: 0.74154 | v_loss: 1.06566 v_acc: 0.76465 |  iteration: 3283 teacher: 0 stage: sketch lr: 0.000574\n",
      "batch 797 loss: 1.14723 acc: 0.75814 | v_loss: 1.20972 v_acc: 0.75293 |  iteration: 3284 teacher: 1 stage: sketch lr: 0.000574\n",
      "batch 798 loss: 1.28212 acc: 0.73047 | v_loss: 1.04183 v_acc: 0.77018 |  iteration: 3285 teacher: 0 stage: sketch lr: 0.000574\n",
      "batch 799 loss: 1.13391 acc: 0.74902 | v_loss: 1.16482 v_acc: 0.75488 |  iteration: 3286 teacher: 1 stage: sketch lr: 0.000574\n",
      "batch 800 loss: 1.20483 acc: 0.75163 | v_loss: 1.13034 v_acc: 0.76530 |  iteration: 3287 teacher: 0 stage: sketch lr: 0.000574\n",
      "batch 801 loss: 1.34095 acc: 0.72754 | v_loss: 1.11780 v_acc: 0.76953 |  iteration: 3288 teacher: 0 stage: sketch lr: 0.000574\n",
      "batch 802 loss: 1.22170 acc: 0.75293 | v_loss: 1.10946 v_acc: 0.76204 |  iteration: 3289 teacher: 0 stage: sketch lr: 0.000575\n",
      "batch 803 loss: 1.15678 acc: 0.74772 | v_loss: 1.14180 v_acc: 0.74740 |  iteration: 3290 teacher: 0 stage: sketch lr: 0.000575\n",
      "batch 804 loss: 1.10625 acc: 0.75879 | v_loss: 1.08653 v_acc: 0.77214 |  iteration: 3291 teacher: 1 stage: sketch lr: 0.000575\n",
      "batch 805 loss: 1.17171 acc: 0.75195 | v_loss: 1.14953 v_acc: 0.76725 |  iteration: 3292 teacher: 1 stage: sketch lr: 0.000575\n",
      "batch 806 loss: 1.13242 acc: 0.75684 | v_loss: 1.30920 v_acc: 0.71712 |  iteration: 3293 teacher: 1 stage: sketch lr: 0.000575\n",
      "batch 807 loss: 1.15598 acc: 0.75423 | v_loss: 1.09824 v_acc: 0.75716 |  iteration: 3294 teacher: 1 stage: sketch lr: 0.000575\n",
      "batch 808 loss: 1.14378 acc: 0.75781 | v_loss: 1.16987 v_acc: 0.75846 |  iteration: 3295 teacher: 1 stage: sketch lr: 0.000576\n",
      "batch 809 loss: 1.14631 acc: 0.74707 | v_loss: 1.17002 v_acc: 0.76465 |  iteration: 3296 teacher: 0 stage: sketch lr: 0.000576\n",
      "batch 810 loss: 1.21496 acc: 0.74674 | v_loss: 1.27131 v_acc: 0.74251 |  iteration: 3297 teacher: 0 stage: sketch lr: 0.000576\n",
      "batch 811 loss: 1.16691 acc: 0.74577 | v_loss: 1.04332 v_acc: 0.77474 |  iteration: 3298 teacher: 1 stage: sketch lr: 0.000576\n",
      "batch 812 loss: 1.21235 acc: 0.75033 | v_loss: 1.22669 v_acc: 0.74870 |  iteration: 3299 teacher: 0 stage: sketch lr: 0.000576\n",
      "batch 813 loss: 1.17165 acc: 0.74805 | v_loss: 1.11634 v_acc: 0.76530 |  iteration: 3300 teacher: 0 stage: sketch lr: 0.000576\n",
      "batch 814 loss: 1.11559 acc: 0.75879 | v_loss: 1.27163 v_acc: 0.72852 |  iteration: 3301 teacher: 1 stage: sketch lr: 0.000577\n",
      "batch 815 loss: 1.20166 acc: 0.74674 | v_loss: 1.16171 v_acc: 0.75163 |  iteration: 3302 teacher: 1 stage: sketch lr: 0.000577\n",
      "batch 816 loss: 1.18990 acc: 0.74414 | v_loss: 1.18897 v_acc: 0.74707 |  iteration: 3303 teacher: 1 stage: sketch lr: 0.000577\n",
      "batch 817 loss: 1.10398 acc: 0.76107 | v_loss: 1.27229 v_acc: 0.74089 |  iteration: 3304 teacher: 1 stage: sketch lr: 0.000577\n",
      "batch 818 loss: 1.17019 acc: 0.74805 | v_loss: 1.12495 v_acc: 0.75586 |  iteration: 3305 teacher: 1 stage: sketch lr: 0.000577\n",
      "batch 819 loss: 1.07213 acc: 0.76823 | v_loss: 1.13041 v_acc: 0.75586 |  iteration: 3306 teacher: 0 stage: sketch lr: 0.000578\n",
      "batch 820 loss: 1.24508 acc: 0.73926 | v_loss: 1.08932 v_acc: 0.76953 |  iteration: 3307 teacher: 0 stage: sketch lr: 0.000578\n",
      "batch 821 loss: 1.17040 acc: 0.75456 | v_loss: 1.16859 v_acc: 0.75944 |  iteration: 3308 teacher: 1 stage: sketch lr: 0.000578\n",
      "batch 822 loss: 1.11886 acc: 0.75944 | v_loss: 1.07476 v_acc: 0.77148 |  iteration: 3309 teacher: 1 stage: sketch lr: 0.000578\n",
      "batch 823 loss: 1.12268 acc: 0.75879 | v_loss: 1.13383 v_acc: 0.76204 |  iteration: 3310 teacher: 1 stage: sketch lr: 0.000578\n",
      "batch 824 loss: 1.12094 acc: 0.76465 | v_loss: 1.13501 v_acc: 0.76660 |  iteration: 3311 teacher: 1 stage: sketch lr: 0.000578\n",
      "batch 825 loss: 1.19661 acc: 0.75684 | v_loss: 1.15556 v_acc: 0.74870 |  iteration: 3312 teacher: 0 stage: sketch lr: 0.000579\n",
      "batch 826 loss: 1.17851 acc: 0.74740 | v_loss: 1.23579 v_acc: 0.73763 |  iteration: 3313 teacher: 1 stage: sketch lr: 0.000579\n",
      "batch 827 loss: 1.12724 acc: 0.76660 | v_loss: 1.16949 v_acc: 0.75065 |  iteration: 3314 teacher: 0 stage: sketch lr: 0.000579\n",
      "batch 828 loss: 1.08752 acc: 0.75130 | v_loss: 1.21503 v_acc: 0.75488 |  iteration: 3315 teacher: 1 stage: sketch lr: 0.000579\n",
      "batch 829 loss: 1.25404 acc: 0.73242 | v_loss: 1.14317 v_acc: 0.75716 |  iteration: 3316 teacher: 0 stage: sketch lr: 0.000579\n",
      "batch 830 loss: 1.10582 acc: 0.76465 | v_loss: 1.13000 v_acc: 0.75618 |  iteration: 3317 teacher: 0 stage: sketch lr: 0.000579\n",
      "batch 831 loss: 1.18333 acc: 0.75260 | v_loss: 1.06688 v_acc: 0.77865 |  iteration: 3318 teacher: 0 stage: sketch lr: 0.000580\n",
      "batch 832 loss: 1.08377 acc: 0.76953 | v_loss: 1.12809 v_acc: 0.76270 |  iteration: 3319 teacher: 1 stage: sketch lr: 0.000580\n",
      "batch 833 loss: 1.21305 acc: 0.74837 | v_loss: 1.21011 v_acc: 0.76530 |  iteration: 3320 teacher: 1 stage: sketch lr: 0.000580\n",
      "batch 834 loss: 1.08270 acc: 0.76432 | v_loss: 1.09904 v_acc: 0.76628 |  iteration: 3321 teacher: 0 stage: sketch lr: 0.000580\n",
      "batch 835 loss: 1.18756 acc: 0.74316 | v_loss: 1.18679 v_acc: 0.75586 |  iteration: 3322 teacher: 0 stage: sketch lr: 0.000580\n",
      "batch 836 loss: 1.17031 acc: 0.74577 | v_loss: 1.04081 v_acc: 0.76562 |  iteration: 3323 teacher: 1 stage: sketch lr: 0.000581\n",
      "batch 837 loss: 1.22578 acc: 0.74707 | v_loss: 1.10721 v_acc: 0.76725 |  iteration: 3324 teacher: 0 stage: sketch lr: 0.000581\n",
      "batch 838 loss: 1.16077 acc: 0.75130 | v_loss: 1.16687 v_acc: 0.75488 |  iteration: 3325 teacher: 0 stage: sketch lr: 0.000581\n",
      "batch 839 loss: 1.14038 acc: 0.75846 | v_loss: 1.12735 v_acc: 0.75684 |  iteration: 3326 teacher: 1 stage: sketch lr: 0.000581\n",
      "batch 840 loss: 1.16302 acc: 0.74870 | v_loss: 1.04245 v_acc: 0.78190 |  iteration: 3327 teacher: 0 stage: sketch lr: 0.000581\n",
      "batch 841 loss: 1.18018 acc: 0.75391 | v_loss: 1.18703 v_acc: 0.74447 |  iteration: 3328 teacher: 1 stage: sketch lr: 0.000581\n",
      "batch 842 loss: 1.17483 acc: 0.74967 | v_loss: 1.18376 v_acc: 0.76270 |  iteration: 3329 teacher: 1 stage: sketch lr: 0.000582\n",
      "batch 843 loss: 1.06831 acc: 0.77214 | v_loss: 1.25169 v_acc: 0.75423 |  iteration: 3330 teacher: 1 stage: sketch lr: 0.000582\n",
      "batch 844 loss: 1.12975 acc: 0.75618 | v_loss: 1.02955 v_acc: 0.76367 |  iteration: 3331 teacher: 0 stage: sketch lr: 0.000582\n",
      "batch 845 loss: 1.17451 acc: 0.74740 | v_loss: 1.22755 v_acc: 0.75000 |  iteration: 3332 teacher: 0 stage: sketch lr: 0.000582\n",
      "batch 846 loss: 1.14313 acc: 0.75488 | v_loss: 1.10453 v_acc: 0.75846 |  iteration: 3333 teacher: 1 stage: sketch lr: 0.000582\n",
      "batch 847 loss: 1.20939 acc: 0.74577 | v_loss: 1.25816 v_acc: 0.73893 |  iteration: 3334 teacher: 1 stage: sketch lr: 0.000582\n",
      "batch 848 loss: 1.21477 acc: 0.74479 | v_loss: 1.13183 v_acc: 0.76204 |  iteration: 3335 teacher: 0 stage: sketch lr: 0.000583\n",
      "batch 849 loss: 1.14715 acc: 0.76302 | v_loss: 1.09837 v_acc: 0.77214 |  iteration: 3336 teacher: 0 stage: sketch lr: 0.000583\n",
      "batch 850 loss: 1.10471 acc: 0.76400 | v_loss: 1.09396 v_acc: 0.76823 |  iteration: 3337 teacher: 1 stage: sketch lr: 0.000583\n",
      "batch 851 loss: 1.11602 acc: 0.76237 | v_loss: 1.13376 v_acc: 0.74577 |  iteration: 3338 teacher: 1 stage: sketch lr: 0.000583\n",
      "batch 852 loss: 1.18532 acc: 0.74479 | v_loss: 1.07988 v_acc: 0.75749 |  iteration: 3339 teacher: 0 stage: sketch lr: 0.000583\n",
      "batch 853 loss: 1.11230 acc: 0.75814 | v_loss: 1.17352 v_acc: 0.74870 |  iteration: 3340 teacher: 0 stage: sketch lr: 0.000583\n",
      "batch 854 loss: 1.18825 acc: 0.75000 | v_loss: 1.17531 v_acc: 0.75651 |  iteration: 3341 teacher: 0 stage: sketch lr: 0.000584\n",
      "batch 855 loss: 1.17182 acc: 0.75618 | v_loss: 1.19588 v_acc: 0.74089 |  iteration: 3342 teacher: 0 stage: sketch lr: 0.000584\n",
      "batch 856 loss: 1.19685 acc: 0.74414 | v_loss: 1.16164 v_acc: 0.74870 |  iteration: 3343 teacher: 0 stage: sketch lr: 0.000584\n",
      "batch 857 loss: 1.09581 acc: 0.76758 | v_loss: 1.25754 v_acc: 0.74219 |  iteration: 3344 teacher: 1 stage: sketch lr: 0.000584\n",
      "batch 858 loss: 1.18174 acc: 0.74251 | v_loss: 1.16077 v_acc: 0.74349 |  iteration: 3345 teacher: 0 stage: sketch lr: 0.000584\n",
      "batch 859 loss: 1.12942 acc: 0.76790 | v_loss: 1.05535 v_acc: 0.76530 |  iteration: 3346 teacher: 1 stage: sketch lr: 0.000585\n",
      "batch 860 loss: 1.24507 acc: 0.74056 | v_loss: 1.20609 v_acc: 0.75130 |  iteration: 3347 teacher: 0 stage: sketch lr: 0.000585\n",
      "batch 861 loss: 1.08880 acc: 0.76270 | v_loss: 1.09412 v_acc: 0.76530 |  iteration: 3348 teacher: 0 stage: sketch lr: 0.000585\n",
      "batch 862 loss: 1.17178 acc: 0.75195 | v_loss: 1.23882 v_acc: 0.73730 |  iteration: 3349 teacher: 0 stage: sketch lr: 0.000585\n",
      "batch 863 loss: 1.18456 acc: 0.75391 | v_loss: 1.15179 v_acc: 0.75684 |  iteration: 3350 teacher: 0 stage: sketch lr: 0.000585\n",
      "batch 864 loss: 1.21140 acc: 0.74772 | v_loss: 1.12310 v_acc: 0.75521 |  iteration: 3351 teacher: 0 stage: sketch lr: 0.000585\n",
      "batch 865 loss: 1.15291 acc: 0.75260 | v_loss: 1.16649 v_acc: 0.75618 |  iteration: 3352 teacher: 0 stage: sketch lr: 0.000586\n",
      "batch 866 loss: 1.10992 acc: 0.76432 | v_loss: 1.18395 v_acc: 0.74479 |  iteration: 3353 teacher: 1 stage: sketch lr: 0.000586\n",
      "batch 867 loss: 1.13699 acc: 0.75911 | v_loss: 1.25043 v_acc: 0.75195 |  iteration: 3354 teacher: 1 stage: sketch lr: 0.000586\n",
      "batch 868 loss: 1.11718 acc: 0.76790 | v_loss: 1.12398 v_acc: 0.76400 |  iteration: 3355 teacher: 1 stage: sketch lr: 0.000586\n",
      "batch 869 loss: 1.22595 acc: 0.74935 | v_loss: 1.03512 v_acc: 0.77669 |  iteration: 3356 teacher: 0 stage: sketch lr: 0.000586\n",
      "batch 870 loss: 1.17968 acc: 0.75521 | v_loss: 1.02944 v_acc: 0.77441 |  iteration: 3357 teacher: 1 stage: sketch lr: 0.000586\n",
      "batch 871 loss: 1.04485 acc: 0.77311 | v_loss: 1.11296 v_acc: 0.75586 |  iteration: 3358 teacher: 1 stage: sketch lr: 0.000587\n",
      "batch 872 loss: 1.09885 acc: 0.76074 | v_loss: 1.19200 v_acc: 0.75326 |  iteration: 3359 teacher: 0 stage: sketch lr: 0.000587\n",
      "batch 873 loss: 1.24656 acc: 0.73307 | v_loss: 1.13284 v_acc: 0.74674 |  iteration: 3360 teacher: 0 stage: sketch lr: 0.000587\n",
      "batch 874 loss: 1.14452 acc: 0.75618 | v_loss: 1.07612 v_acc: 0.77995 |  iteration: 3361 teacher: 1 stage: sketch lr: 0.000587\n",
      "batch 875 loss: 1.09383 acc: 0.75814 | v_loss: 1.18218 v_acc: 0.75521 |  iteration: 3362 teacher: 1 stage: sketch lr: 0.000587\n",
      "batch 876 loss: 1.10025 acc: 0.75586 | v_loss: 1.15706 v_acc: 0.73763 |  iteration: 3363 teacher: 0 stage: sketch lr: 0.000587\n",
      "batch 877 loss: 1.08124 acc: 0.75651 | v_loss: 1.10200 v_acc: 0.75456 |  iteration: 3364 teacher: 1 stage: sketch lr: 0.000588\n",
      "batch 878 loss: 1.12947 acc: 0.76172 | v_loss: 1.03054 v_acc: 0.77181 |  iteration: 3365 teacher: 1 stage: sketch lr: 0.000588\n",
      "batch 879 loss: 1.13496 acc: 0.75879 | v_loss: 1.02970 v_acc: 0.76953 |  iteration: 3366 teacher: 1 stage: sketch lr: 0.000588\n",
      "batch 880 loss: 1.12013 acc: 0.76074 | v_loss: 1.08070 v_acc: 0.76562 |  iteration: 3367 teacher: 0 stage: sketch lr: 0.000588\n",
      "batch 881 loss: 1.13448 acc: 0.75846 | v_loss: 1.13152 v_acc: 0.75000 |  iteration: 3368 teacher: 0 stage: sketch lr: 0.000588\n",
      "batch 882 loss: 1.12042 acc: 0.75228 | v_loss: 1.23021 v_acc: 0.73535 |  iteration: 3369 teacher: 0 stage: sketch lr: 0.000589\n",
      "batch 883 loss: 1.23895 acc: 0.74349 | v_loss: 1.10665 v_acc: 0.76107 |  iteration: 3370 teacher: 0 stage: sketch lr: 0.000589\n",
      "batch 884 loss: 1.20818 acc: 0.73438 | v_loss: 1.11181 v_acc: 0.77376 |  iteration: 3371 teacher: 0 stage: sketch lr: 0.000589\n",
      "batch 885 loss: 1.00223 acc: 0.77865 | v_loss: 1.21893 v_acc: 0.74154 |  iteration: 3372 teacher: 1 stage: sketch lr: 0.000589\n",
      "batch 886 loss: 1.19692 acc: 0.73177 | v_loss: 1.27572 v_acc: 0.72786 |  iteration: 3373 teacher: 0 stage: sketch lr: 0.000589\n",
      "batch 887 loss: 1.25488 acc: 0.73014 | v_loss: 1.05720 v_acc: 0.76270 |  iteration: 3374 teacher: 0 stage: sketch lr: 0.000589\n",
      "batch 888 loss: 1.09776 acc: 0.75391 | v_loss: 1.20814 v_acc: 0.74577 |  iteration: 3375 teacher: 1 stage: sketch lr: 0.000590\n",
      "batch 889 loss: 1.15365 acc: 0.75163 | v_loss: 1.02543 v_acc: 0.76758 |  iteration: 3376 teacher: 1 stage: sketch lr: 0.000590\n",
      "batch 890 loss: 1.09153 acc: 0.75716 | v_loss: 1.13688 v_acc: 0.75618 |  iteration: 3377 teacher: 1 stage: sketch lr: 0.000590\n",
      "batch 891 loss: 1.09381 acc: 0.75358 | v_loss: 1.09434 v_acc: 0.76367 |  iteration: 3378 teacher: 0 stage: sketch lr: 0.000590\n",
      "batch 892 loss: 1.13119 acc: 0.74967 | v_loss: 1.08202 v_acc: 0.75879 |  iteration: 3379 teacher: 1 stage: sketch lr: 0.000590\n",
      "batch 893 loss: 1.09886 acc: 0.75293 | v_loss: 1.08071 v_acc: 0.76042 |  iteration: 3380 teacher: 0 stage: sketch lr: 0.000590\n",
      "batch 894 loss: 1.09747 acc: 0.75000 | v_loss: 1.13113 v_acc: 0.74870 |  iteration: 3381 teacher: 1 stage: sketch lr: 0.000591\n",
      "batch 895 loss: 1.16111 acc: 0.74967 | v_loss: 1.04467 v_acc: 0.77018 |  iteration: 3382 teacher: 0 stage: sketch lr: 0.000591\n",
      "batch 896 loss: 1.14900 acc: 0.74382 | v_loss: 1.12072 v_acc: 0.76335 |  iteration: 3383 teacher: 0 stage: sketch lr: 0.000591\n",
      "batch 897 loss: 1.13976 acc: 0.75814 | v_loss: 1.22608 v_acc: 0.72135 |  iteration: 3384 teacher: 0 stage: sketch lr: 0.000591\n",
      "batch 898 loss: 1.13631 acc: 0.75130 | v_loss: 1.10533 v_acc: 0.75488 |  iteration: 3385 teacher: 1 stage: sketch lr: 0.000591\n",
      "batch 899 loss: 1.15145 acc: 0.74316 | v_loss: 1.05007 v_acc: 0.76074 |  iteration: 3386 teacher: 0 stage: sketch lr: 0.000592\n",
      "batch 900 loss: 1.17071 acc: 0.74577 | v_loss: 0.97550 v_acc: 0.76790 |  iteration: 3387 teacher: 1 stage: sketch lr: 0.000592\n",
      "batch 901 loss: 1.11879 acc: 0.75195 | v_loss: 1.13517 v_acc: 0.74089 |  iteration: 3388 teacher: 0 stage: sketch lr: 0.000592\n",
      "batch 902 loss: 1.12032 acc: 0.74089 | v_loss: 0.98135 v_acc: 0.77799 |  iteration: 3389 teacher: 1 stage: sketch lr: 0.000592\n",
      "batch 903 loss: 1.08720 acc: 0.75911 | v_loss: 1.14316 v_acc: 0.74707 |  iteration: 3390 teacher: 1 stage: sketch lr: 0.000592\n",
      "batch 904 loss: 1.12796 acc: 0.74837 | v_loss: 1.08989 v_acc: 0.76107 |  iteration: 3391 teacher: 0 stage: sketch lr: 0.000592\n",
      "batch 905 loss: 1.22248 acc: 0.73600 | v_loss: 1.23981 v_acc: 0.72786 |  iteration: 3392 teacher: 0 stage: sketch lr: 0.000593\n",
      "batch 906 loss: 1.10454 acc: 0.75618 | v_loss: 1.11856 v_acc: 0.74935 |  iteration: 3393 teacher: 1 stage: sketch lr: 0.000593\n",
      "batch 907 loss: 1.06892 acc: 0.74349 | v_loss: 1.12247 v_acc: 0.74609 |  iteration: 3394 teacher: 1 stage: sketch lr: 0.000593\n",
      "batch 908 loss: 1.21838 acc: 0.73307 | v_loss: 1.20625 v_acc: 0.74284 |  iteration: 3395 teacher: 1 stage: sketch lr: 0.000593\n",
      "batch 909 loss: 1.13148 acc: 0.74935 | v_loss: 1.05823 v_acc: 0.74349 |  iteration: 3396 teacher: 0 stage: sketch lr: 0.000593\n",
      "batch 910 loss: 1.12984 acc: 0.75130 | v_loss: 1.12139 v_acc: 0.74707 |  iteration: 3397 teacher: 1 stage: sketch lr: 0.000593\n",
      "batch 911 loss: 1.19203 acc: 0.73861 | v_loss: 1.03677 v_acc: 0.76693 |  iteration: 3398 teacher: 1 stage: sketch lr: 0.000594\n",
      "batch 912 loss: 1.17822 acc: 0.72917 | v_loss: 1.06147 v_acc: 0.74902 |  iteration: 3399 teacher: 0 stage: sketch lr: 0.000594\n",
      "batch 913 loss: 1.00081 acc: 0.75716 | v_loss: 1.05738 v_acc: 0.74707 |  iteration: 3400 teacher: 1 stage: sketch lr: 0.000594\n",
      "batch 914 loss: 1.22271 acc: 0.73372 | v_loss: 1.07609 v_acc: 0.76270 |  iteration: 3401 teacher: 0 stage: sketch lr: 0.000594\n",
      "batch 915 loss: 1.04049 acc: 0.76172 | v_loss: 0.93995 v_acc: 0.76237 |  iteration: 3402 teacher: 1 stage: sketch lr: 0.000594\n",
      "batch 916 loss: 1.05881 acc: 0.75553 | v_loss: 1.09098 v_acc: 0.74740 |  iteration: 3403 teacher: 1 stage: sketch lr: 0.000594\n",
      "batch 917 loss: 1.10974 acc: 0.74219 | v_loss: 1.20298 v_acc: 0.72852 |  iteration: 3404 teacher: 0 stage: sketch lr: 0.000595\n",
      "batch 918 loss: 1.11582 acc: 0.74609 | v_loss: 1.06094 v_acc: 0.74316 |  iteration: 3405 teacher: 0 stage: sketch lr: 0.000595\n",
      "batch 919 loss: 1.02476 acc: 0.76172 | v_loss: 1.20180 v_acc: 0.74121 |  iteration: 3406 teacher: 1 stage: sketch lr: 0.000595\n",
      "batch 920 loss: 1.13342 acc: 0.73958 | v_loss: 0.96449 v_acc: 0.74414 |  iteration: 3407 teacher: 0 stage: sketch lr: 0.000595\n",
      "batch 921 loss: 1.16239 acc: 0.72135 | v_loss: 1.06047 v_acc: 0.75195 |  iteration: 3408 teacher: 0 stage: sketch lr: 0.000595\n",
      "batch 922 loss: 1.04912 acc: 0.74805 | v_loss: 1.00345 v_acc: 0.77669 |  iteration: 3409 teacher: 0 stage: sketch lr: 0.000596\n",
      "batch 923 loss: 1.12663 acc: 0.73991 | v_loss: 0.97769 v_acc: 0.75814 |  iteration: 3410 teacher: 0 stage: sketch lr: 0.000596\n",
      "batch 924 loss: 1.06407 acc: 0.75977 | v_loss: 1.21642 v_acc: 0.76009 |  iteration: 3411 teacher: 1 stage: sketch lr: 0.000596\n",
      "batch 925 loss: 1.04983 acc: 0.75391 | v_loss: 1.04213 v_acc: 0.75814 |  iteration: 3412 teacher: 1 stage: sketch lr: 0.000596\n",
      "batch 926 loss: 1.18182 acc: 0.72428 | v_loss: 1.12934 v_acc: 0.74023 |  iteration: 3413 teacher: 1 stage: sketch lr: 0.000596\n",
      "batch 927 loss: 1.08677 acc: 0.73438 | v_loss: 1.02774 v_acc: 0.76237 |  iteration: 3414 teacher: 0 stage: sketch lr: 0.000596\n",
      "batch 928 loss: 1.18084 acc: 0.72526 | v_loss: 1.06848 v_acc: 0.76888 |  iteration: 3415 teacher: 0 stage: sketch lr: 0.000597\n",
      "batch 929 loss: 0.99608 acc: 0.75228 | v_loss: 1.06034 v_acc: 0.76042 |  iteration: 3416 teacher: 1 stage: sketch lr: 0.000597\n",
      "batch 930 loss: 1.03232 acc: 0.75163 | v_loss: 1.04888 v_acc: 0.75814 |  iteration: 3417 teacher: 1 stage: sketch lr: 0.000597\n",
      "batch 931 loss: 1.15291 acc: 0.73958 | v_loss: 1.00955 v_acc: 0.77734 |  iteration: 3418 teacher: 0 stage: sketch lr: 0.000597\n",
      "batch 932 loss: 1.12919 acc: 0.73958 | v_loss: 1.05907 v_acc: 0.73275 |  iteration: 3419 teacher: 0 stage: sketch lr: 0.000597\n",
      "batch 933 loss: 1.09628 acc: 0.75228 | v_loss: 1.10485 v_acc: 0.75944 |  iteration: 3420 teacher: 0 stage: sketch lr: 0.000597\n",
      "batch 934 loss: 1.10829 acc: 0.75781 | v_loss: 1.08468 v_acc: 0.72396 |  iteration: 3421 teacher: 0 stage: sketch lr: 0.000598\n",
      "batch 935 loss: 1.13195 acc: 0.74479 | v_loss: 0.97798 v_acc: 0.75879 |  iteration: 3422 teacher: 1 stage: sketch lr: 0.000598\n",
      "batch 936 loss: 1.10245 acc: 0.74479 | v_loss: 1.15235 v_acc: 0.74642 |  iteration: 3423 teacher: 0 stage: sketch lr: 0.000598\n",
      "batch 937 loss: 1.04883 acc: 0.73991 | v_loss: 0.96076 v_acc: 0.75911 |  iteration: 3424 teacher: 0 stage: sketch lr: 0.000598\n",
      "batch 938 loss: 1.16123 acc: 0.73535 | v_loss: 1.11653 v_acc: 0.72852 |  iteration: 3425 teacher: 1 stage: sketch lr: 0.000598\n",
      "batch 939 loss: 1.05067 acc: 0.74186 | v_loss: 1.05643 v_acc: 0.76074 |  iteration: 3426 teacher: 0 stage: sketch lr: 0.000598\n",
      "batch 940 loss: 1.10279 acc: 0.74089 | v_loss: 1.04988 v_acc: 0.76302 |  iteration: 3427 teacher: 0 stage: sketch lr: 0.000599\n",
      "batch 941 loss: 1.05896 acc: 0.75391 | v_loss: 1.02236 v_acc: 0.76009 |  iteration: 3428 teacher: 1 stage: sketch lr: 0.000599\n",
      "batch 942 loss: 1.09426 acc: 0.73405 | v_loss: 1.11459 v_acc: 0.74740 |  iteration: 3429 teacher: 0 stage: sketch lr: 0.000599\n",
      "batch 943 loss: 1.12432 acc: 0.73730 | v_loss: 0.97838 v_acc: 0.74577 |  iteration: 3430 teacher: 0 stage: sketch lr: 0.000599\n",
      "batch 944 loss: 1.08807 acc: 0.74089 | v_loss: 1.11507 v_acc: 0.74219 |  iteration: 3431 teacher: 1 stage: sketch lr: 0.000599\n",
      "batch 945 loss: 1.06069 acc: 0.75977 | v_loss: 1.08277 v_acc: 0.74870 |  iteration: 3432 teacher: 1 stage: sketch lr: 0.000600\n",
      "batch 946 loss: 1.01785 acc: 0.75911 | v_loss: 1.08316 v_acc: 0.73958 |  iteration: 3433 teacher: 1 stage: sketch lr: 0.000600\n",
      "batch 947 loss: 1.02979 acc: 0.75879 | v_loss: 1.04665 v_acc: 0.74089 |  iteration: 3434 teacher: 1 stage: sketch lr: 0.000600\n",
      "batch 948 loss: 1.03147 acc: 0.74674 | v_loss: 1.21443 v_acc: 0.73210 |  iteration: 3435 teacher: 1 stage: sketch lr: 0.000600\n",
      "batch 949 loss: 1.10544 acc: 0.74284 | v_loss: 1.04436 v_acc: 0.73177 |  iteration: 3436 teacher: 0 stage: sketch lr: 0.000600\n",
      "batch 950 loss: 1.09475 acc: 0.73665 | v_loss: 0.98856 v_acc: 0.76302 |  iteration: 3437 teacher: 0 stage: sketch lr: 0.000600\n",
      "batch 951 loss: 1.06268 acc: 0.74870 | v_loss: 1.10215 v_acc: 0.73926 |  iteration: 3438 teacher: 0 stage: sketch lr: 0.000601\n",
      "batch 952 loss: 1.03946 acc: 0.75098 | v_loss: 1.00325 v_acc: 0.77311 |  iteration: 3439 teacher: 0 stage: sketch lr: 0.000601\n",
      "batch 953 loss: 1.10402 acc: 0.74772 | v_loss: 1.10816 v_acc: 0.73079 |  iteration: 3440 teacher: 0 stage: sketch lr: 0.000601\n",
      "batch 954 loss: 1.01094 acc: 0.75488 | v_loss: 1.00650 v_acc: 0.74609 |  iteration: 3441 teacher: 1 stage: sketch lr: 0.000601\n",
      "batch 955 loss: 0.96636 acc: 0.75521 | v_loss: 0.95117 v_acc: 0.75814 |  iteration: 3442 teacher: 1 stage: sketch lr: 0.000601\n",
      "batch 956 loss: 1.01226 acc: 0.74251 | v_loss: 1.10145 v_acc: 0.73796 |  iteration: 3443 teacher: 0 stage: sketch lr: 0.000601\n",
      "batch 957 loss: 1.10392 acc: 0.72884 | v_loss: 1.03033 v_acc: 0.73958 |  iteration: 3444 teacher: 0 stage: sketch lr: 0.000602\n",
      "batch 958 loss: 1.14578 acc: 0.73470 | v_loss: 1.12695 v_acc: 0.74414 |  iteration: 3445 teacher: 0 stage: sketch lr: 0.000602\n",
      "batch 959 loss: 1.09403 acc: 0.74544 | v_loss: 1.03378 v_acc: 0.76042 |  iteration: 3446 teacher: 0 stage: sketch lr: 0.000602\n",
      "batch 960 loss: 1.02032 acc: 0.74544 | v_loss: 0.90695 v_acc: 0.75618 |  iteration: 3447 teacher: 0 stage: sketch lr: 0.000602\n",
      "batch 961 loss: 1.05975 acc: 0.75618 | v_loss: 0.99660 v_acc: 0.76465 |  iteration: 3448 teacher: 1 stage: sketch lr: 0.000602\n",
      "batch 962 loss: 1.07751 acc: 0.73372 | v_loss: 1.03675 v_acc: 0.74349 |  iteration: 3449 teacher: 1 stage: sketch lr: 0.000603\n",
      "batch 963 loss: 1.13512 acc: 0.73991 | v_loss: 1.12676 v_acc: 0.74740 |  iteration: 3450 teacher: 0 stage: sketch lr: 0.000603\n",
      "batch 964 loss: 0.99391 acc: 0.74935 | v_loss: 1.08218 v_acc: 0.73991 |  iteration: 3451 teacher: 1 stage: sketch lr: 0.000603\n",
      "batch 965 loss: 1.08919 acc: 0.74251 | v_loss: 0.94318 v_acc: 0.76400 |  iteration: 3452 teacher: 0 stage: sketch lr: 0.000603\n",
      "batch 966 loss: 1.11075 acc: 0.73405 | v_loss: 1.16313 v_acc: 0.75000 |  iteration: 3453 teacher: 1 stage: sketch lr: 0.000603\n",
      "batch 967 loss: 1.08975 acc: 0.73372 | v_loss: 1.12749 v_acc: 0.74219 |  iteration: 3454 teacher: 1 stage: sketch lr: 0.000603\n",
      "batch 968 loss: 1.01758 acc: 0.74935 | v_loss: 1.07830 v_acc: 0.75618 |  iteration: 3455 teacher: 0 stage: sketch lr: 0.000604\n",
      "batch 969 loss: 1.00216 acc: 0.75098 | v_loss: 0.92197 v_acc: 0.76237 |  iteration: 3456 teacher: 1 stage: sketch lr: 0.000604\n",
      "batch 970 loss: 1.11378 acc: 0.73698 | v_loss: 0.89338 v_acc: 0.77246 |  iteration: 3457 teacher: 0 stage: sketch lr: 0.000604\n",
      "batch 971 loss: 1.03038 acc: 0.74967 | v_loss: 0.96784 v_acc: 0.76335 |  iteration: 3458 teacher: 1 stage: sketch lr: 0.000604\n",
      "batch 972 loss: 1.07884 acc: 0.75391 | v_loss: 0.93534 v_acc: 0.75651 |  iteration: 3459 teacher: 1 stage: sketch lr: 0.000604\n",
      "batch 973 loss: 1.09409 acc: 0.74023 | v_loss: 1.11220 v_acc: 0.73307 |  iteration: 3460 teacher: 1 stage: sketch lr: 0.000604\n",
      "batch 974 loss: 1.02006 acc: 0.74447 | v_loss: 1.00668 v_acc: 0.74382 |  iteration: 3461 teacher: 1 stage: sketch lr: 0.000605\n",
      "batch 975 loss: 1.09139 acc: 0.74089 | v_loss: 0.98389 v_acc: 0.77344 |  iteration: 3462 teacher: 0 stage: sketch lr: 0.000605\n",
      "batch 976 loss: 1.14050 acc: 0.72949 | v_loss: 1.12747 v_acc: 0.73958 |  iteration: 3463 teacher: 0 stage: sketch lr: 0.000605\n",
      "batch 977 loss: 0.97157 acc: 0.75781 | v_loss: 1.21583 v_acc: 0.72852 |  iteration: 3464 teacher: 1 stage: sketch lr: 0.000605\n",
      "batch 978 loss: 0.99787 acc: 0.74609 | v_loss: 0.99754 v_acc: 0.75000 |  iteration: 3465 teacher: 0 stage: sketch lr: 0.000605\n",
      "batch 979 loss: 1.02875 acc: 0.74772 | v_loss: 1.15561 v_acc: 0.74609 |  iteration: 3466 teacher: 1 stage: sketch lr: 0.000605\n",
      "batch 980 loss: 1.00232 acc: 0.75944 | v_loss: 0.90692 v_acc: 0.76953 |  iteration: 3467 teacher: 1 stage: sketch lr: 0.000606\n",
      "batch 981 loss: 1.09114 acc: 0.74740 | v_loss: 1.03689 v_acc: 0.76172 |  iteration: 3468 teacher: 0 stage: sketch lr: 0.000606\n",
      "batch 982 loss: 1.01488 acc: 0.74967 | v_loss: 0.96612 v_acc: 0.76628 |  iteration: 3469 teacher: 1 stage: sketch lr: 0.000606\n",
      "batch 983 loss: 0.98943 acc: 0.76465 | v_loss: 1.01135 v_acc: 0.75586 |  iteration: 3470 teacher: 1 stage: sketch lr: 0.000606\n",
      "batch 984 loss: 1.07536 acc: 0.74023 | v_loss: 1.02236 v_acc: 0.75944 |  iteration: 3471 teacher: 0 stage: sketch lr: 0.000606\n",
      "batch 985 loss: 1.03327 acc: 0.75000 | v_loss: 0.98039 v_acc: 0.74935 |  iteration: 3472 teacher: 1 stage: sketch lr: 0.000607\n",
      "batch 986 loss: 0.97711 acc: 0.75195 | v_loss: 0.97108 v_acc: 0.75391 |  iteration: 3473 teacher: 1 stage: sketch lr: 0.000607\n",
      "batch 987 loss: 1.07884 acc: 0.73991 | v_loss: 1.02319 v_acc: 0.75228 |  iteration: 3474 teacher: 0 stage: sketch lr: 0.000607\n",
      "batch 988 loss: 1.06022 acc: 0.75260 | v_loss: 1.04396 v_acc: 0.71126 |  iteration: 3475 teacher: 1 stage: sketch lr: 0.000607\n",
      "batch 989 loss: 1.05524 acc: 0.74512 | v_loss: 1.05765 v_acc: 0.75423 |  iteration: 3476 teacher: 0 stage: sketch lr: 0.000607\n",
      "batch 990 loss: 0.99400 acc: 0.74544 | v_loss: 0.91426 v_acc: 0.75618 |  iteration: 3477 teacher: 1 stage: sketch lr: 0.000607\n",
      "batch 991 loss: 1.00580 acc: 0.75846 | v_loss: 0.85601 v_acc: 0.77409 |  iteration: 3478 teacher: 0 stage: sketch lr: 0.000608\n",
      "batch 992 loss: 1.02470 acc: 0.75423 | v_loss: 0.99506 v_acc: 0.75260 |  iteration: 3479 teacher: 1 stage: sketch lr: 0.000608\n",
      "batch 993 loss: 1.06215 acc: 0.75521 | v_loss: 0.91901 v_acc: 0.78092 |  iteration: 3480 teacher: 1 stage: sketch lr: 0.000608\n",
      "batch 994 loss: 1.04499 acc: 0.74935 | v_loss: 1.07178 v_acc: 0.74870 |  iteration: 3481 teacher: 1 stage: sketch lr: 0.000608\n",
      "batch 995 loss: 1.05755 acc: 0.74089 | v_loss: 0.98441 v_acc: 0.75814 |  iteration: 3482 teacher: 1 stage: sketch lr: 0.000608\n",
      "batch 996 loss: 1.09521 acc: 0.73958 | v_loss: 1.08650 v_acc: 0.73763 |  iteration: 3483 teacher: 1 stage: sketch lr: 0.000608\n",
      "batch 997 loss: 1.08592 acc: 0.73633 | v_loss: 1.06409 v_acc: 0.75033 |  iteration: 3484 teacher: 0 stage: sketch lr: 0.000609\n",
      "batch 998 loss: 0.96031 acc: 0.75358 | v_loss: 1.05830 v_acc: 0.74447 |  iteration: 3485 teacher: 0 stage: sketch lr: 0.000609\n",
      "batch 999 loss: 0.96560 acc: 0.75521 | v_loss: 1.14054 v_acc: 0.74316 |  iteration: 3486 teacher: 0 stage: sketch lr: 0.000609\n",
      "batch 1000 loss: 0.91691 acc: 0.76172 | v_loss: 0.93808 v_acc: 0.75488 |  iteration: 3487 teacher: 0 stage: sketch lr: 0.000609\n",
      "batch 1001 loss: 1.10111 acc: 0.74284 | v_loss: 1.04378 v_acc: 0.75195 |  iteration: 3488 teacher: 0 stage: sketch lr: 0.000609\n",
      "batch 1002 loss: 0.98673 acc: 0.76074 | v_loss: 0.97599 v_acc: 0.77962 |  iteration: 3489 teacher: 1 stage: sketch lr: 0.000610\n",
      "batch 1003 loss: 0.95053 acc: 0.76562 | v_loss: 0.97684 v_acc: 0.75521 |  iteration: 3490 teacher: 1 stage: sketch lr: 0.000610\n",
      "batch 1004 loss: 0.95174 acc: 0.77799 | v_loss: 0.90852 v_acc: 0.76237 |  iteration: 3491 teacher: 1 stage: sketch lr: 0.000610\n",
      "batch 1005 loss: 1.06740 acc: 0.75098 | v_loss: 1.02937 v_acc: 0.76888 |  iteration: 3492 teacher: 0 stage: sketch lr: 0.000610\n",
      "batch 1006 loss: 0.95351 acc: 0.76823 | v_loss: 0.79818 v_acc: 0.76009 |  iteration: 3493 teacher: 1 stage: sketch lr: 0.000610\n",
      "batch 1007 loss: 1.07676 acc: 0.74512 | v_loss: 0.99283 v_acc: 0.74544 |  iteration: 3494 teacher: 0 stage: sketch lr: 0.000610\n",
      "batch 1008 loss: 1.09320 acc: 0.74251 | v_loss: 1.16202 v_acc: 0.73503 |  iteration: 3495 teacher: 1 stage: sketch lr: 0.000611\n",
      "batch 1009 loss: 1.06693 acc: 0.73340 | v_loss: 1.01325 v_acc: 0.74805 |  iteration: 3496 teacher: 0 stage: sketch lr: 0.000611\n",
      "batch 1010 loss: 0.93871 acc: 0.76790 | v_loss: 1.14538 v_acc: 0.74512 |  iteration: 3497 teacher: 1 stage: sketch lr: 0.000611\n",
      "batch 1011 loss: 1.03976 acc: 0.73958 | v_loss: 0.85721 v_acc: 0.75423 |  iteration: 3498 teacher: 0 stage: sketch lr: 0.000611\n",
      "batch 1012 loss: 0.97809 acc: 0.75781 | v_loss: 0.96996 v_acc: 0.75814 |  iteration: 3499 teacher: 1 stage: sketch lr: 0.000611\n",
      "batch 1013 loss: 1.00116 acc: 0.75260 | v_loss: 1.01097 v_acc: 0.77865 |  iteration: 3500 teacher: 0 stage: sketch lr: 0.000611\n",
      "batch 1014 loss: 1.00437 acc: 0.73926 | v_loss: 0.89856 v_acc: 0.76497 |  iteration: 3501 teacher: 1 stage: sketch lr: 0.000612\n",
      "batch 1015 loss: 1.02132 acc: 0.75716 | v_loss: 1.19270 v_acc: 0.76139 |  iteration: 3502 teacher: 1 stage: sketch lr: 0.000612\n",
      "batch 1016 loss: 1.04640 acc: 0.74544 | v_loss: 0.96352 v_acc: 0.76986 |  iteration: 3503 teacher: 0 stage: sketch lr: 0.000612\n",
      "batch 1017 loss: 0.99823 acc: 0.74447 | v_loss: 1.09769 v_acc: 0.74544 |  iteration: 3504 teacher: 1 stage: sketch lr: 0.000612\n",
      "batch 1018 loss: 0.98187 acc: 0.75293 | v_loss: 0.99232 v_acc: 0.75814 |  iteration: 3505 teacher: 1 stage: sketch lr: 0.000612\n",
      "batch 1019 loss: 1.02921 acc: 0.75000 | v_loss: 1.02014 v_acc: 0.77148 |  iteration: 3506 teacher: 1 stage: sketch lr: 0.000612\n",
      "batch 1020 loss: 1.04578 acc: 0.75488 | v_loss: 0.99638 v_acc: 0.74935 |  iteration: 3507 teacher: 1 stage: sketch lr: 0.000613\n",
      "batch 1021 loss: 1.07890 acc: 0.73372 | v_loss: 1.04901 v_acc: 0.75553 |  iteration: 3508 teacher: 0 stage: sketch lr: 0.000613\n",
      "batch 1022 loss: 1.08149 acc: 0.73991 | v_loss: 0.91894 v_acc: 0.78320 |  iteration: 3509 teacher: 1 stage: sketch lr: 0.000613\n",
      "batch 1023 loss: 1.00137 acc: 0.75488 | v_loss: 0.94906 v_acc: 0.74870 |  iteration: 3510 teacher: 0 stage: sketch lr: 0.000613\n",
      "batch 1024 loss: 0.94291 acc: 0.75586 | v_loss: 1.07808 v_acc: 0.76107 |  iteration: 3511 teacher: 1 stage: sketch lr: 0.000613\n",
      "batch 1025 loss: 1.04039 acc: 0.75618 | v_loss: 1.03028 v_acc: 0.72331 |  iteration: 3512 teacher: 0 stage: sketch lr: 0.000614\n",
      "batch 1026 loss: 1.00792 acc: 0.75000 | v_loss: 0.93746 v_acc: 0.75716 |  iteration: 3513 teacher: 1 stage: sketch lr: 0.000614\n",
      "batch 1027 loss: 0.91169 acc: 0.76888 | v_loss: 1.10471 v_acc: 0.73958 |  iteration: 3514 teacher: 1 stage: sketch lr: 0.000614\n",
      "batch 1028 loss: 1.03334 acc: 0.76270 | v_loss: 0.89216 v_acc: 0.76074 |  iteration: 3515 teacher: 1 stage: sketch lr: 0.000614\n",
      "batch 1029 loss: 0.95574 acc: 0.75000 | v_loss: 1.02933 v_acc: 0.73340 |  iteration: 3516 teacher: 1 stage: sketch lr: 0.000614\n",
      "batch 1030 loss: 0.92110 acc: 0.76758 | v_loss: 1.03065 v_acc: 0.76107 |  iteration: 3517 teacher: 1 stage: sketch lr: 0.000614\n",
      "batch 1031 loss: 1.02209 acc: 0.74414 | v_loss: 0.98860 v_acc: 0.75684 |  iteration: 3518 teacher: 1 stage: sketch lr: 0.000615\n",
      "batch 1032 loss: 1.01966 acc: 0.75130 | v_loss: 0.97097 v_acc: 0.77311 |  iteration: 3519 teacher: 1 stage: sketch lr: 0.000615\n",
      "batch 1033 loss: 0.95569 acc: 0.75358 | v_loss: 1.05981 v_acc: 0.72917 |  iteration: 3520 teacher: 1 stage: sketch lr: 0.000615\n",
      "batch 1034 loss: 1.02258 acc: 0.75293 | v_loss: 0.92875 v_acc: 0.75391 |  iteration: 3521 teacher: 1 stage: sketch lr: 0.000615\n",
      "batch 1035 loss: 1.09965 acc: 0.74447 | v_loss: 1.04017 v_acc: 0.74967 |  iteration: 3522 teacher: 0 stage: sketch lr: 0.000615\n",
      "batch 1036 loss: 0.98967 acc: 0.74805 | v_loss: 1.07339 v_acc: 0.76107 |  iteration: 3523 teacher: 1 stage: sketch lr: 0.000615\n",
      "batch 1037 loss: 1.02839 acc: 0.75358 | v_loss: 1.04589 v_acc: 0.74414 |  iteration: 3524 teacher: 0 stage: sketch lr: 0.000616\n",
      "batch 1038 loss: 1.06893 acc: 0.75228 | v_loss: 1.05222 v_acc: 0.73796 |  iteration: 3525 teacher: 1 stage: sketch lr: 0.000616\n",
      "batch 1039 loss: 1.02318 acc: 0.74089 | v_loss: 1.20028 v_acc: 0.73307 |  iteration: 3526 teacher: 0 stage: sketch lr: 0.000616\n",
      "batch 1040 loss: 1.07368 acc: 0.74316 | v_loss: 0.99849 v_acc: 0.73893 |  iteration: 3527 teacher: 0 stage: sketch lr: 0.000616\n",
      "batch 1041 loss: 1.13784 acc: 0.73079 | v_loss: 0.98680 v_acc: 0.76107 |  iteration: 3528 teacher: 0 stage: sketch lr: 0.000616\n",
      "batch 1042 loss: 1.02670 acc: 0.74382 | v_loss: 1.06146 v_acc: 0.74154 |  iteration: 3529 teacher: 0 stage: sketch lr: 0.000616\n",
      "batch 1043 loss: 0.98144 acc: 0.74382 | v_loss: 0.99028 v_acc: 0.75846 |  iteration: 3530 teacher: 1 stage: sketch lr: 0.000617\n",
      "batch 1044 loss: 1.06356 acc: 0.73405 | v_loss: 1.07938 v_acc: 0.72526 |  iteration: 3531 teacher: 1 stage: sketch lr: 0.000617\n",
      "batch 1045 loss: 1.01386 acc: 0.73991 | v_loss: 0.94481 v_acc: 0.75163 |  iteration: 3532 teacher: 0 stage: sketch lr: 0.000617\n",
      "batch 1046 loss: 1.05041 acc: 0.74577 | v_loss: 0.91872 v_acc: 0.76497 |  iteration: 3533 teacher: 0 stage: sketch lr: 0.000617\n",
      "batch 1047 loss: 0.99608 acc: 0.75488 | v_loss: 1.09413 v_acc: 0.74967 |  iteration: 3534 teacher: 1 stage: sketch lr: 0.000617\n",
      "batch 1048 loss: 1.06746 acc: 0.74023 | v_loss: 0.99491 v_acc: 0.74805 |  iteration: 3535 teacher: 0 stage: sketch lr: 0.000618\n",
      "batch 1049 loss: 1.00854 acc: 0.74870 | v_loss: 1.10936 v_acc: 0.74837 |  iteration: 3536 teacher: 1 stage: sketch lr: 0.000618\n",
      "batch 1050 loss: 0.93562 acc: 0.76237 | v_loss: 1.04690 v_acc: 0.75456 |  iteration: 3537 teacher: 1 stage: sketch lr: 0.000618\n",
      "batch 1051 loss: 0.99241 acc: 0.74772 | v_loss: 0.87326 v_acc: 0.75749 |  iteration: 3538 teacher: 0 stage: sketch lr: 0.000618\n",
      "batch 1052 loss: 0.92366 acc: 0.75521 | v_loss: 0.95976 v_acc: 0.76823 |  iteration: 3539 teacher: 1 stage: sketch lr: 0.000618\n",
      "batch 1053 loss: 1.03362 acc: 0.74837 | v_loss: 1.00550 v_acc: 0.75293 |  iteration: 3540 teacher: 0 stage: sketch lr: 0.000618\n",
      "batch 1054 loss: 0.94746 acc: 0.75098 | v_loss: 1.11108 v_acc: 0.75326 |  iteration: 3541 teacher: 0 stage: sketch lr: 0.000619\n",
      "batch 1055 loss: 1.05354 acc: 0.74121 | v_loss: 1.07601 v_acc: 0.74837 |  iteration: 3542 teacher: 0 stage: sketch lr: 0.000619\n",
      "batch 1056 loss: 0.96657 acc: 0.75228 | v_loss: 0.92850 v_acc: 0.76172 |  iteration: 3543 teacher: 1 stage: sketch lr: 0.000619\n",
      "batch 1057 loss: 1.05835 acc: 0.73828 | v_loss: 1.13037 v_acc: 0.75846 |  iteration: 3544 teacher: 1 stage: sketch lr: 0.000619\n",
      "batch 1058 loss: 1.03334 acc: 0.74740 | v_loss: 1.10734 v_acc: 0.72689 |  iteration: 3545 teacher: 0 stage: sketch lr: 0.000619\n",
      "batch 1059 loss: 1.06418 acc: 0.73503 | v_loss: 1.04103 v_acc: 0.75423 |  iteration: 3546 teacher: 0 stage: sketch lr: 0.000619\n",
      "batch 1060 loss: 0.89423 acc: 0.77930 | v_loss: 0.86901 v_acc: 0.76139 |  iteration: 3547 teacher: 1 stage: sketch lr: 0.000620\n",
      "batch 1061 loss: 0.93148 acc: 0.76270 | v_loss: 0.87785 v_acc: 0.77376 |  iteration: 3548 teacher: 1 stage: sketch lr: 0.000620\n",
      "batch 1062 loss: 1.02644 acc: 0.75326 | v_loss: 0.97300 v_acc: 0.76302 |  iteration: 3549 teacher: 1 stage: sketch lr: 0.000620\n",
      "batch 1063 loss: 0.90327 acc: 0.76074 | v_loss: 0.89522 v_acc: 0.75651 |  iteration: 3550 teacher: 1 stage: sketch lr: 0.000620\n",
      "batch 1064 loss: 1.06066 acc: 0.74284 | v_loss: 1.08446 v_acc: 0.73926 |  iteration: 3551 teacher: 0 stage: sketch lr: 0.000620\n",
      "batch 1065 loss: 1.14642 acc: 0.73600 | v_loss: 0.94062 v_acc: 0.75684 |  iteration: 3552 teacher: 0 stage: sketch lr: 0.000621\n",
      "batch 1066 loss: 0.96612 acc: 0.76204 | v_loss: 0.95896 v_acc: 0.77083 |  iteration: 3553 teacher: 1 stage: sketch lr: 0.000621\n",
      "batch 1067 loss: 1.03555 acc: 0.75163 | v_loss: 1.09451 v_acc: 0.74772 |  iteration: 3554 teacher: 0 stage: sketch lr: 0.000621\n",
      "batch 1068 loss: 1.03674 acc: 0.75586 | v_loss: 1.17564 v_acc: 0.73014 |  iteration: 3555 teacher: 0 stage: sketch lr: 0.000621\n",
      "batch 1069 loss: 1.05707 acc: 0.74219 | v_loss: 0.94313 v_acc: 0.76465 |  iteration: 3556 teacher: 0 stage: sketch lr: 0.000621\n",
      "batch 1070 loss: 1.04848 acc: 0.75098 | v_loss: 1.09847 v_acc: 0.75098 |  iteration: 3557 teacher: 1 stage: sketch lr: 0.000621\n",
      "batch 1071 loss: 1.03573 acc: 0.74447 | v_loss: 0.85972 v_acc: 0.76725 |  iteration: 3558 teacher: 0 stage: sketch lr: 0.000622\n",
      "batch 1072 loss: 1.05818 acc: 0.74772 | v_loss: 1.03014 v_acc: 0.75456 |  iteration: 3559 teacher: 0 stage: sketch lr: 0.000622\n",
      "batch 1073 loss: 0.97698 acc: 0.75716 | v_loss: 0.92529 v_acc: 0.76693 |  iteration: 3560 teacher: 1 stage: sketch lr: 0.000622\n",
      "batch 1074 loss: 0.97552 acc: 0.75391 | v_loss: 1.00976 v_acc: 0.76107 |  iteration: 3561 teacher: 1 stage: sketch lr: 0.000622\n",
      "batch 1075 loss: 0.94784 acc: 0.74577 | v_loss: 1.00963 v_acc: 0.76335 |  iteration: 3562 teacher: 1 stage: sketch lr: 0.000622\n",
      "batch 1076 loss: 0.96219 acc: 0.75781 | v_loss: 0.95269 v_acc: 0.75130 |  iteration: 3563 teacher: 0 stage: sketch lr: 0.000622\n",
      "batch 1077 loss: 1.08180 acc: 0.74186 | v_loss: 0.95712 v_acc: 0.76497 |  iteration: 3564 teacher: 0 stage: sketch lr: 0.000623\n",
      "batch 1078 loss: 1.04615 acc: 0.74870 | v_loss: 0.98704 v_acc: 0.77018 |  iteration: 3565 teacher: 0 stage: sketch lr: 0.000623\n",
      "batch 1079 loss: 0.90193 acc: 0.78418 | v_loss: 1.02934 v_acc: 0.70540 |  iteration: 3566 teacher: 1 stage: sketch lr: 0.000623\n",
      "batch 1080 loss: 1.09431 acc: 0.74870 | v_loss: 1.01357 v_acc: 0.75553 |  iteration: 3567 teacher: 0 stage: sketch lr: 0.000623\n",
      "batch 1081 loss: 0.96963 acc: 0.76237 | v_loss: 0.90586 v_acc: 0.75814 |  iteration: 3568 teacher: 1 stage: sketch lr: 0.000623\n",
      "batch 1082 loss: 0.97829 acc: 0.75749 | v_loss: 0.81919 v_acc: 0.78451 |  iteration: 3569 teacher: 1 stage: sketch lr: 0.000623\n",
      "batch 1083 loss: 0.97156 acc: 0.75358 | v_loss: 0.97722 v_acc: 0.75781 |  iteration: 3570 teacher: 1 stage: sketch lr: 0.000624\n",
      "batch 1084 loss: 1.05157 acc: 0.74935 | v_loss: 0.90724 v_acc: 0.77702 |  iteration: 3571 teacher: 0 stage: sketch lr: 0.000624\n",
      "batch 1085 loss: 1.03075 acc: 0.73665 | v_loss: 1.06186 v_acc: 0.75293 |  iteration: 3572 teacher: 1 stage: sketch lr: 0.000624\n",
      "batch 1086 loss: 1.03913 acc: 0.74023 | v_loss: 0.97125 v_acc: 0.74837 |  iteration: 3573 teacher: 0 stage: sketch lr: 0.000624\n",
      "batch 1087 loss: 1.01813 acc: 0.75228 | v_loss: 1.06803 v_acc: 0.73145 |  iteration: 3574 teacher: 0 stage: sketch lr: 0.000624\n",
      "batch 1088 loss: 1.11226 acc: 0.74154 | v_loss: 1.05844 v_acc: 0.75684 |  iteration: 3575 teacher: 1 stage: sketch lr: 0.000625\n",
      "batch 1089 loss: 1.03119 acc: 0.74674 | v_loss: 1.04512 v_acc: 0.74609 |  iteration: 3576 teacher: 0 stage: sketch lr: 0.000625\n",
      "batch 1090 loss: 0.97139 acc: 0.75098 | v_loss: 1.13454 v_acc: 0.73665 |  iteration: 3577 teacher: 1 stage: sketch lr: 0.000625\n",
      "batch 1091 loss: 1.05757 acc: 0.75651 | v_loss: 0.92339 v_acc: 0.75879 |  iteration: 3578 teacher: 1 stage: sketch lr: 0.000625\n",
      "batch 1092 loss: 1.04742 acc: 0.75163 | v_loss: 1.04981 v_acc: 0.75521 |  iteration: 3579 teacher: 1 stage: sketch lr: 0.000625\n",
      "batch 1093 loss: 0.97154 acc: 0.75521 | v_loss: 0.99047 v_acc: 0.76823 |  iteration: 3580 teacher: 0 stage: sketch lr: 0.000625\n",
      "batch 1094 loss: 1.00810 acc: 0.75977 | v_loss: 0.94458 v_acc: 0.75781 |  iteration: 3581 teacher: 0 stage: sketch lr: 0.000626\n",
      "batch 1095 loss: 1.06680 acc: 0.74023 | v_loss: 0.87546 v_acc: 0.76042 |  iteration: 3582 teacher: 1 stage: sketch lr: 0.000626\n",
      "batch 1096 loss: 1.01957 acc: 0.75391 | v_loss: 1.00799 v_acc: 0.76465 |  iteration: 3583 teacher: 0 stage: sketch lr: 0.000626\n",
      "batch 1097 loss: 1.00814 acc: 0.74186 | v_loss: 0.75726 v_acc: 0.77539 |  iteration: 3584 teacher: 0 stage: sketch lr: 0.000626\n",
      "batch 1098 loss: 1.04920 acc: 0.76237 | v_loss: 0.96830 v_acc: 0.74674 |  iteration: 3585 teacher: 1 stage: sketch lr: 0.000626\n",
      "batch 1099 loss: 0.90622 acc: 0.77051 | v_loss: 1.17937 v_acc: 0.73177 |  iteration: 3586 teacher: 1 stage: sketch lr: 0.000626\n",
      "batch 1100 loss: 0.93685 acc: 0.75944 | v_loss: 1.01659 v_acc: 0.73926 |  iteration: 3587 teacher: 1 stage: sketch lr: 0.000627\n",
      "batch 1101 loss: 0.97575 acc: 0.75456 | v_loss: 1.15535 v_acc: 0.74447 |  iteration: 3588 teacher: 1 stage: sketch lr: 0.000627\n",
      "batch 1102 loss: 1.00776 acc: 0.74544 | v_loss: 0.86685 v_acc: 0.75749 |  iteration: 3589 teacher: 0 stage: sketch lr: 0.000627\n",
      "batch 1103 loss: 1.03655 acc: 0.74837 | v_loss: 0.93322 v_acc: 0.75293 |  iteration: 3590 teacher: 0 stage: sketch lr: 0.000627\n",
      "batch 1104 loss: 0.99806 acc: 0.74577 | v_loss: 0.98835 v_acc: 0.78190 |  iteration: 3591 teacher: 0 stage: sketch lr: 0.000627\n",
      "batch 1105 loss: 1.11230 acc: 0.75195 | v_loss: 0.91411 v_acc: 0.75781 |  iteration: 3592 teacher: 0 stage: sketch lr: 0.000627\n",
      "batch 1106 loss: 0.94690 acc: 0.76204 | v_loss: 1.17530 v_acc: 0.76237 |  iteration: 3593 teacher: 1 stage: sketch lr: 0.000628\n",
      "batch 1107 loss: 1.00157 acc: 0.75098 | v_loss: 0.95780 v_acc: 0.76237 |  iteration: 3594 teacher: 1 stage: sketch lr: 0.000628\n",
      "batch 1108 loss: 0.99883 acc: 0.75456 | v_loss: 1.03942 v_acc: 0.75260 |  iteration: 3595 teacher: 0 stage: sketch lr: 0.000628\n",
      "batch 1109 loss: 0.97692 acc: 0.75553 | v_loss: 0.94453 v_acc: 0.77246 |  iteration: 3596 teacher: 1 stage: sketch lr: 0.000628\n",
      "batch 1110 loss: 1.05631 acc: 0.74186 | v_loss: 1.00670 v_acc: 0.77311 |  iteration: 3597 teacher: 0 stage: sketch lr: 0.000628\n",
      "batch 1111 loss: 0.98532 acc: 0.75000 | v_loss: 0.98030 v_acc: 0.75130 |  iteration: 3598 teacher: 0 stage: sketch lr: 0.000629\n",
      "batch 1112 loss: 0.98789 acc: 0.75521 | v_loss: 1.00498 v_acc: 0.76270 |  iteration: 3599 teacher: 0 stage: sketch lr: 0.000629\n",
      "batch 1113 loss: 0.99964 acc: 0.75293 | v_loss: 0.91729 v_acc: 0.78483 |  iteration: 3600 teacher: 0 stage: sketch lr: 0.000629\n",
      "batch 1114 loss: 0.99425 acc: 0.76400 | v_loss: 0.92767 v_acc: 0.75130 |  iteration: 3601 teacher: 1 stage: sketch lr: 0.000629\n",
      "batch 1115 loss: 1.03420 acc: 0.74154 | v_loss: 1.07676 v_acc: 0.76432 |  iteration: 3602 teacher: 0 stage: sketch lr: 0.000629\n",
      "batch 1116 loss: 1.00687 acc: 0.76270 | v_loss: 0.98212 v_acc: 0.74642 |  iteration: 3603 teacher: 1 stage: sketch lr: 0.000629\n",
      "batch 1117 loss: 0.95814 acc: 0.75846 | v_loss: 0.90091 v_acc: 0.75781 |  iteration: 3604 teacher: 1 stage: sketch lr: 0.000630\n",
      "batch 1118 loss: 1.08583 acc: 0.74902 | v_loss: 1.05566 v_acc: 0.74902 |  iteration: 3605 teacher: 0 stage: sketch lr: 0.000630\n",
      "batch 1119 loss: 0.95564 acc: 0.74674 | v_loss: 0.87277 v_acc: 0.76497 |  iteration: 3606 teacher: 0 stage: sketch lr: 0.000630\n",
      "batch 1120 loss: 0.93558 acc: 0.75065 | v_loss: 0.98326 v_acc: 0.74609 |  iteration: 3607 teacher: 0 stage: sketch lr: 0.000630\n",
      "batch 1121 loss: 1.05748 acc: 0.74642 | v_loss: 1.02226 v_acc: 0.75586 |  iteration: 3608 teacher: 1 stage: sketch lr: 0.000630\n",
      "batch 1122 loss: 1.02424 acc: 0.75293 | v_loss: 0.97770 v_acc: 0.76270 |  iteration: 3609 teacher: 0 stage: sketch lr: 0.000630\n",
      "batch 1123 loss: 1.02556 acc: 0.74023 | v_loss: 0.94629 v_acc: 0.77441 |  iteration: 3610 teacher: 0 stage: sketch lr: 0.000631\n",
      "batch 1124 loss: 1.08623 acc: 0.74089 | v_loss: 1.03284 v_acc: 0.72884 |  iteration: 3611 teacher: 0 stage: sketch lr: 0.000631\n",
      "batch 1125 loss: 1.03609 acc: 0.74642 | v_loss: 0.91542 v_acc: 0.75586 |  iteration: 3612 teacher: 0 stage: sketch lr: 0.000631\n",
      "batch 1126 loss: 0.93817 acc: 0.75228 | v_loss: 1.03804 v_acc: 0.74316 |  iteration: 3613 teacher: 1 stage: sketch lr: 0.000631\n",
      "batch 1127 loss: 1.03281 acc: 0.74740 | v_loss: 1.07582 v_acc: 0.75651 |  iteration: 3614 teacher: 0 stage: sketch lr: 0.000631\n",
      "batch 1128 loss: 1.15687 acc: 0.73307 | v_loss: 1.00663 v_acc: 0.74251 |  iteration: 3615 teacher: 0 stage: sketch lr: 0.000632\n",
      "batch 1129 loss: 0.95464 acc: 0.76530 | v_loss: 0.96258 v_acc: 0.75195 |  iteration: 3616 teacher: 1 stage: sketch lr: 0.000632\n",
      "batch 1130 loss: 1.08845 acc: 0.74056 | v_loss: 1.16533 v_acc: 0.74089 |  iteration: 3617 teacher: 0 stage: sketch lr: 0.000632\n",
      "batch 1131 loss: 0.99421 acc: 0.74935 | v_loss: 0.97583 v_acc: 0.74219 |  iteration: 3618 teacher: 0 stage: sketch lr: 0.000632\n",
      "batch 1132 loss: 1.08383 acc: 0.74577 | v_loss: 0.94471 v_acc: 0.75684 |  iteration: 3619 teacher: 0 stage: sketch lr: 0.000632\n",
      "batch 1133 loss: 1.09168 acc: 0.74382 | v_loss: 1.00824 v_acc: 0.74967 |  iteration: 3620 teacher: 0 stage: sketch lr: 0.000632\n",
      "batch 1134 loss: 1.01413 acc: 0.75879 | v_loss: 0.92576 v_acc: 0.78060 |  iteration: 3621 teacher: 1 stage: sketch lr: 0.000633\n",
      "batch 1135 loss: 0.95202 acc: 0.75911 | v_loss: 1.02140 v_acc: 0.74349 |  iteration: 3622 teacher: 1 stage: sketch lr: 0.000633\n",
      "batch 1136 loss: 1.02187 acc: 0.74740 | v_loss: 0.92691 v_acc: 0.76172 |  iteration: 3623 teacher: 1 stage: sketch lr: 0.000633\n",
      "batch 1137 loss: 1.02151 acc: 0.75098 | v_loss: 0.92400 v_acc: 0.76237 |  iteration: 3624 teacher: 1 stage: sketch lr: 0.000633\n",
      "batch 1138 loss: 1.07822 acc: 0.74512 | v_loss: 1.04190 v_acc: 0.75130 |  iteration: 3625 teacher: 0 stage: sketch lr: 0.000633\n",
      "batch 1139 loss: 1.04436 acc: 0.75814 | v_loss: 0.97934 v_acc: 0.75065 |  iteration: 3626 teacher: 1 stage: sketch lr: 0.000633\n",
      "batch 1140 loss: 0.88152 acc: 0.75716 | v_loss: 1.07983 v_acc: 0.74349 |  iteration: 3627 teacher: 1 stage: sketch lr: 0.000634\n",
      "batch 1141 loss: 1.05717 acc: 0.74414 | v_loss: 1.01068 v_acc: 0.75846 |  iteration: 3628 teacher: 0 stage: sketch lr: 0.000634\n",
      "batch 1142 loss: 1.14020 acc: 0.73340 | v_loss: 0.85889 v_acc: 0.76888 |  iteration: 3629 teacher: 0 stage: sketch lr: 0.000634\n",
      "batch 1143 loss: 1.04096 acc: 0.73991 | v_loss: 0.92924 v_acc: 0.76888 |  iteration: 3630 teacher: 0 stage: sketch lr: 0.000634\n",
      "batch 1144 loss: 1.00159 acc: 0.75163 | v_loss: 0.98174 v_acc: 0.75781 |  iteration: 3631 teacher: 0 stage: sketch lr: 0.000634\n",
      "batch 1145 loss: 1.04718 acc: 0.75911 | v_loss: 1.09102 v_acc: 0.74577 |  iteration: 3632 teacher: 1 stage: sketch lr: 0.000634\n",
      "batch 1146 loss: 1.07357 acc: 0.74349 | v_loss: 1.08664 v_acc: 0.73698 |  iteration: 3633 teacher: 0 stage: sketch lr: 0.000635\n",
      "batch 1147 loss: 1.08499 acc: 0.73861 | v_loss: 0.88774 v_acc: 0.77734 |  iteration: 3634 teacher: 0 stage: sketch lr: 0.000635\n",
      "batch 1148 loss: 1.05118 acc: 0.75814 | v_loss: 1.10540 v_acc: 0.76497 |  iteration: 3635 teacher: 0 stage: sketch lr: 0.000635\n",
      "batch 1149 loss: 0.99382 acc: 0.76530 | v_loss: 1.05004 v_acc: 0.74121 |  iteration: 3636 teacher: 0 stage: sketch lr: 0.000635\n",
      "batch 1150 loss: 1.01476 acc: 0.74674 | v_loss: 1.02945 v_acc: 0.75000 |  iteration: 3637 teacher: 1 stage: sketch lr: 0.000635\n",
      "batch 1151 loss: 0.97913 acc: 0.76009 | v_loss: 0.86918 v_acc: 0.77409 |  iteration: 3638 teacher: 0 stage: sketch lr: 0.000636\n",
      "batch 1152 loss: 0.89193 acc: 0.77441 | v_loss: 0.84029 v_acc: 0.77865 |  iteration: 3639 teacher: 1 stage: sketch lr: 0.000636\n",
      "batch 1153 loss: 1.03640 acc: 0.74382 | v_loss: 0.95359 v_acc: 0.76562 |  iteration: 3640 teacher: 1 stage: sketch lr: 0.000636\n",
      "batch 1154 loss: 1.08378 acc: 0.73698 | v_loss: 0.90055 v_acc: 0.75521 |  iteration: 3641 teacher: 0 stage: sketch lr: 0.000636\n",
      "batch 1155 loss: 0.99331 acc: 0.74577 | v_loss: 1.05526 v_acc: 0.73958 |  iteration: 3642 teacher: 1 stage: sketch lr: 0.000636\n",
      "batch 1156 loss: 1.02312 acc: 0.75260 | v_loss: 0.93244 v_acc: 0.75586 |  iteration: 3643 teacher: 0 stage: sketch lr: 0.000636\n",
      "batch 1157 loss: 1.01622 acc: 0.75130 | v_loss: 0.93184 v_acc: 0.77865 |  iteration: 3644 teacher: 0 stage: sketch lr: 0.000637\n",
      "batch 1158 loss: 0.97879 acc: 0.75326 | v_loss: 1.06759 v_acc: 0.75488 |  iteration: 3645 teacher: 0 stage: sketch lr: 0.000637\n",
      "batch 1159 loss: 1.01714 acc: 0.73926 | v_loss: 1.14906 v_acc: 0.73730 |  iteration: 3646 teacher: 1 stage: sketch lr: 0.000637\n",
      "batch 1160 loss: 0.98022 acc: 0.74609 | v_loss: 0.94580 v_acc: 0.76986 |  iteration: 3647 teacher: 1 stage: sketch lr: 0.000637\n",
      "batch 1161 loss: 1.03606 acc: 0.73665 | v_loss: 1.10697 v_acc: 0.74967 |  iteration: 3648 teacher: 0 stage: sketch lr: 0.000637\n",
      "batch 1162 loss: 1.07173 acc: 0.75293 | v_loss: 0.83304 v_acc: 0.77702 |  iteration: 3649 teacher: 0 stage: sketch lr: 0.000637\n",
      "batch 1163 loss: 0.98014 acc: 0.75163 | v_loss: 0.99259 v_acc: 0.76628 |  iteration: 3650 teacher: 0 stage: sketch lr: 0.000638\n",
      "batch 1164 loss: 0.85951 acc: 0.75586 | v_loss: 0.89674 v_acc: 0.77376 |  iteration: 3651 teacher: 0 stage: sketch lr: 0.000638\n",
      "batch 1165 loss: 1.03068 acc: 0.74382 | v_loss: 0.99620 v_acc: 0.76335 |  iteration: 3652 teacher: 1 stage: sketch lr: 0.000638\n",
      "batch 1166 loss: 1.06334 acc: 0.73861 | v_loss: 0.98776 v_acc: 0.75879 |  iteration: 3653 teacher: 1 stage: sketch lr: 0.000638\n",
      "batch 1167 loss: 1.00651 acc: 0.76074 | v_loss: 0.97222 v_acc: 0.75586 |  iteration: 3654 teacher: 1 stage: sketch lr: 0.000638\n",
      "batch 1168 loss: 1.00463 acc: 0.75293 | v_loss: 0.93524 v_acc: 0.76823 |  iteration: 3655 teacher: 1 stage: sketch lr: 0.000639\n",
      "batch 1169 loss: 0.90824 acc: 0.76921 | v_loss: 0.99984 v_acc: 0.76107 |  iteration: 3656 teacher: 1 stage: sketch lr: 0.000639\n",
      "batch 1170 loss: 1.14868 acc: 0.73730 | v_loss: 1.08803 v_acc: 0.69922 |  iteration: 3657 teacher: 1 stage: sketch lr: 0.000639\n",
      "batch 1171 loss: 1.15287 acc: 0.74056 | v_loss: 1.05102 v_acc: 0.75033 |  iteration: 3658 teacher: 1 stage: sketch lr: 0.000639\n",
      "batch 1172 loss: 1.12503 acc: 0.74251 | v_loss: 0.93983 v_acc: 0.74772 |  iteration: 3659 teacher: 0 stage: sketch lr: 0.000639\n",
      "batch 1173 loss: 1.02872 acc: 0.74674 | v_loss: 0.86369 v_acc: 0.77572 |  iteration: 3660 teacher: 0 stage: sketch lr: 0.000639\n",
      "batch 1174 loss: 1.13519 acc: 0.73796 | v_loss: 0.98506 v_acc: 0.75814 |  iteration: 3661 teacher: 1 stage: sketch lr: 0.000640\n",
      "batch 1175 loss: 1.09916 acc: 0.74642 | v_loss: 0.91850 v_acc: 0.77799 |  iteration: 3662 teacher: 0 stage: sketch lr: 0.000640\n",
      "batch 1176 loss: 0.87998 acc: 0.76204 | v_loss: 1.04648 v_acc: 0.75911 |  iteration: 3663 teacher: 0 stage: sketch lr: 0.000640\n",
      "batch 1177 loss: 1.01250 acc: 0.75618 | v_loss: 0.98110 v_acc: 0.75749 |  iteration: 3664 teacher: 1 stage: sketch lr: 0.000640\n",
      "batch 1178 loss: 1.04080 acc: 0.74186 | v_loss: 1.06282 v_acc: 0.73568 |  iteration: 3665 teacher: 0 stage: sketch lr: 0.000640\n",
      "batch 1179 loss: 0.99150 acc: 0.76172 | v_loss: 1.05416 v_acc: 0.75651 |  iteration: 3666 teacher: 1 stage: sketch lr: 0.000640\n",
      "batch 1180 loss: 0.91727 acc: 0.76302 | v_loss: 1.04268 v_acc: 0.74740 |  iteration: 3667 teacher: 0 stage: sketch lr: 0.000641\n",
      "batch 1181 loss: 1.06224 acc: 0.73958 | v_loss: 1.13773 v_acc: 0.74707 |  iteration: 3668 teacher: 1 stage: sketch lr: 0.000641\n",
      "batch 1182 loss: 0.96143 acc: 0.75879 | v_loss: 0.94553 v_acc: 0.74935 |  iteration: 3669 teacher: 0 stage: sketch lr: 0.000641\n",
      "batch 1183 loss: 1.09055 acc: 0.74154 | v_loss: 1.04560 v_acc: 0.74479 |  iteration: 3670 teacher: 0 stage: sketch lr: 0.000641\n",
      "batch 1184 loss: 1.05491 acc: 0.75163 | v_loss: 0.98811 v_acc: 0.76986 |  iteration: 3671 teacher: 1 stage: sketch lr: 0.000641\n",
      "batch 1185 loss: 1.01070 acc: 0.73763 | v_loss: 0.89564 v_acc: 0.76855 |  iteration: 3672 teacher: 0 stage: sketch lr: 0.000641\n",
      "batch 1186 loss: 0.86133 acc: 0.77409 | v_loss: 0.87200 v_acc: 0.75618 |  iteration: 3673 teacher: 1 stage: sketch lr: 0.000642\n",
      "batch 1187 loss: 1.00323 acc: 0.74479 | v_loss: 0.97878 v_acc: 0.76237 |  iteration: 3674 teacher: 0 stage: sketch lr: 0.000642\n",
      "batch 1188 loss: 1.06031 acc: 0.74674 | v_loss: 0.76491 v_acc: 0.76628 |  iteration: 3675 teacher: 0 stage: sketch lr: 0.000642\n",
      "batch 1189 loss: 0.95346 acc: 0.74674 | v_loss: 0.93340 v_acc: 0.75326 |  iteration: 3676 teacher: 0 stage: sketch lr: 0.000642\n",
      "batch 1190 loss: 0.95629 acc: 0.75326 | v_loss: 1.06504 v_acc: 0.73958 |  iteration: 3677 teacher: 0 stage: sketch lr: 0.000642\n",
      "batch 1191 loss: 0.88785 acc: 0.74967 | v_loss: 0.94134 v_acc: 0.74382 |  iteration: 3678 teacher: 1 stage: sketch lr: 0.000643\n",
      "batch 1192 loss: 1.04944 acc: 0.74870 | v_loss: 1.07103 v_acc: 0.74642 |  iteration: 3679 teacher: 0 stage: sketch lr: 0.000643\n",
      "batch 1193 loss: 0.98160 acc: 0.74707 | v_loss: 0.81056 v_acc: 0.75977 |  iteration: 3680 teacher: 0 stage: sketch lr: 0.000643\n",
      "batch 1194 loss: 1.05010 acc: 0.73535 | v_loss: 0.90092 v_acc: 0.75618 |  iteration: 3681 teacher: 0 stage: sketch lr: 0.000643\n",
      "batch 1195 loss: 0.96967 acc: 0.76172 | v_loss: 0.86282 v_acc: 0.77409 |  iteration: 3682 teacher: 1 stage: sketch lr: 0.000643\n",
      "batch 1196 loss: 1.06899 acc: 0.73210 | v_loss: 0.84516 v_acc: 0.75651 |  iteration: 3683 teacher: 0 stage: sketch lr: 0.000643\n",
      "batch 1197 loss: 0.96331 acc: 0.74837 | v_loss: 1.06110 v_acc: 0.75033 |  iteration: 3684 teacher: 0 stage: sketch lr: 0.000644\n",
      "batch 1198 loss: 0.90823 acc: 0.74284 | v_loss: 0.82479 v_acc: 0.76400 |  iteration: 3685 teacher: 1 stage: sketch lr: 0.000644\n",
      "batch 1199 loss: 0.94853 acc: 0.73698 | v_loss: 0.91062 v_acc: 0.74154 |  iteration: 3686 teacher: 0 stage: sketch lr: 0.000644\n",
      "batch 1200 loss: 0.98528 acc: 0.74414 | v_loss: 0.86173 v_acc: 0.74674 |  iteration: 3687 teacher: 1 stage: sketch lr: 0.000644\n",
      "batch 1201 loss: 1.00103 acc: 0.73242 | v_loss: 0.80508 v_acc: 0.75553 |  iteration: 3688 teacher: 1 stage: sketch lr: 0.000644\n",
      "batch 1202 loss: 0.97853 acc: 0.72949 | v_loss: 0.93876 v_acc: 0.73633 |  iteration: 3689 teacher: 0 stage: sketch lr: 0.000644\n",
      "batch 1203 loss: 0.82154 acc: 0.76009 | v_loss: 0.87231 v_acc: 0.75228 |  iteration: 3690 teacher: 1 stage: sketch lr: 0.000645\n",
      "batch 1204 loss: 0.79369 acc: 0.76465 | v_loss: 0.79824 v_acc: 0.77181 |  iteration: 3691 teacher: 1 stage: sketch lr: 0.000645\n",
      "batch 1205 loss: 0.93923 acc: 0.74121 | v_loss: 0.91755 v_acc: 0.73242 |  iteration: 3692 teacher: 0 stage: sketch lr: 0.000645\n",
      "batch 1206 loss: 0.92384 acc: 0.74544 | v_loss: 0.81285 v_acc: 0.75130 |  iteration: 3693 teacher: 0 stage: sketch lr: 0.000645\n",
      "batch 1207 loss: 0.92682 acc: 0.73893 | v_loss: 0.93719 v_acc: 0.74837 |  iteration: 3694 teacher: 1 stage: sketch lr: 0.000645\n",
      "batch 1208 loss: 0.90423 acc: 0.73763 | v_loss: 0.79833 v_acc: 0.76432 |  iteration: 3695 teacher: 0 stage: sketch lr: 0.000645\n",
      "batch 1209 loss: 0.85185 acc: 0.74837 | v_loss: 0.86634 v_acc: 0.73340 |  iteration: 3696 teacher: 0 stage: sketch lr: 0.000646\n",
      "batch 1210 loss: 0.91014 acc: 0.74772 | v_loss: 0.78160 v_acc: 0.75651 |  iteration: 3697 teacher: 0 stage: sketch lr: 0.000646\n",
      "batch 1211 loss: 0.89565 acc: 0.74740 | v_loss: 0.91747 v_acc: 0.73210 |  iteration: 3698 teacher: 1 stage: sketch lr: 0.000646\n",
      "batch 1212 loss: 0.88213 acc: 0.74382 | v_loss: 0.77614 v_acc: 0.75228 |  iteration: 3699 teacher: 1 stage: sketch lr: 0.000646\n",
      "batch 1213 loss: 0.90853 acc: 0.74154 | v_loss: 0.80028 v_acc: 0.75846 |  iteration: 3700 teacher: 1 stage: sketch lr: 0.000646\n",
      "batch 1214 loss: 0.85748 acc: 0.74967 | v_loss: 0.77901 v_acc: 0.75749 |  iteration: 3701 teacher: 1 stage: sketch lr: 0.000647\n",
      "batch 1215 loss: 0.81688 acc: 0.75911 | v_loss: 0.95735 v_acc: 0.72884 |  iteration: 3702 teacher: 1 stage: sketch lr: 0.000647\n",
      "batch 1216 loss: 0.77547 acc: 0.76107 | v_loss: 0.77251 v_acc: 0.74544 |  iteration: 3703 teacher: 1 stage: sketch lr: 0.000647\n",
      "batch 1217 loss: 0.94075 acc: 0.73405 | v_loss: 0.87308 v_acc: 0.73893 |  iteration: 3704 teacher: 0 stage: sketch lr: 0.000647\n",
      "batch 1218 loss: 0.93725 acc: 0.73047 | v_loss: 0.81961 v_acc: 0.76237 |  iteration: 3705 teacher: 0 stage: sketch lr: 0.000647\n",
      "batch 1219 loss: 0.87820 acc: 0.74382 | v_loss: 0.84164 v_acc: 0.74805 |  iteration: 3706 teacher: 1 stage: sketch lr: 0.000647\n",
      "batch 1220 loss: 0.83011 acc: 0.75651 | v_loss: 0.86320 v_acc: 0.74154 |  iteration: 3707 teacher: 1 stage: sketch lr: 0.000648\n",
      "batch 1221 loss: 0.87562 acc: 0.73796 | v_loss: 0.91895 v_acc: 0.73177 |  iteration: 3708 teacher: 0 stage: sketch lr: 0.000648\n",
      "batch 1222 loss: 0.86419 acc: 0.74251 | v_loss: 0.89137 v_acc: 0.73958 |  iteration: 3709 teacher: 0 stage: sketch lr: 0.000648\n",
      "batch 1223 loss: 0.80436 acc: 0.76074 | v_loss: 0.75150 v_acc: 0.76497 |  iteration: 3710 teacher: 1 stage: sketch lr: 0.000648\n",
      "batch 1224 loss: 0.84630 acc: 0.75488 | v_loss: 0.85379 v_acc: 0.74967 |  iteration: 3711 teacher: 1 stage: sketch lr: 0.000648\n",
      "batch 1225 loss: 0.86528 acc: 0.74219 | v_loss: 0.78338 v_acc: 0.77051 |  iteration: 3712 teacher: 0 stage: sketch lr: 0.000648\n",
      "batch 1226 loss: 0.83198 acc: 0.75326 | v_loss: 0.90442 v_acc: 0.73763 |  iteration: 3713 teacher: 1 stage: sketch lr: 0.000649\n",
      "batch 1227 loss: 0.88730 acc: 0.74382 | v_loss: 0.78904 v_acc: 0.75228 |  iteration: 3714 teacher: 0 stage: sketch lr: 0.000649\n",
      "batch 1228 loss: 0.92382 acc: 0.73307 | v_loss: 0.83769 v_acc: 0.75326 |  iteration: 3715 teacher: 0 stage: sketch lr: 0.000649\n",
      "batch 1229 loss: 0.90459 acc: 0.73372 | v_loss: 0.88286 v_acc: 0.74089 |  iteration: 3716 teacher: 0 stage: sketch lr: 0.000649\n",
      "batch 1230 loss: 0.90724 acc: 0.74056 | v_loss: 0.81117 v_acc: 0.75260 |  iteration: 3717 teacher: 1 stage: sketch lr: 0.000649\n",
      "batch 1231 loss: 0.78697 acc: 0.76237 | v_loss: 0.83382 v_acc: 0.74935 |  iteration: 3718 teacher: 1 stage: sketch lr: 0.000650\n",
      "batch 1232 loss: 0.86623 acc: 0.74805 | v_loss: 0.82550 v_acc: 0.76335 |  iteration: 3719 teacher: 0 stage: sketch lr: 0.000650\n",
      "batch 1233 loss: 0.84259 acc: 0.74316 | v_loss: 0.67023 v_acc: 0.77930 |  iteration: 3720 teacher: 0 stage: sketch lr: 0.000650\n",
      "batch 1234 loss: 0.86466 acc: 0.73698 | v_loss: 0.76039 v_acc: 0.76237 |  iteration: 3721 teacher: 1 stage: sketch lr: 0.000650\n",
      "batch 1235 loss: 0.90542 acc: 0.73177 | v_loss: 0.80495 v_acc: 0.76335 |  iteration: 3722 teacher: 0 stage: sketch lr: 0.000650\n",
      "batch 1236 loss: 0.85137 acc: 0.74740 | v_loss: 0.85288 v_acc: 0.76139 |  iteration: 3723 teacher: 0 stage: sketch lr: 0.000650\n",
      "batch 1237 loss: 0.83338 acc: 0.75228 | v_loss: 0.85150 v_acc: 0.75358 |  iteration: 3724 teacher: 1 stage: sketch lr: 0.000651\n",
      "batch 1238 loss: 0.82729 acc: 0.74479 | v_loss: 0.73918 v_acc: 0.77344 |  iteration: 3725 teacher: 1 stage: sketch lr: 0.000651\n",
      "batch 1239 loss: 0.90361 acc: 0.74023 | v_loss: 0.85199 v_acc: 0.76758 |  iteration: 3726 teacher: 1 stage: sketch lr: 0.000651\n",
      "batch 1240 loss: 0.81106 acc: 0.76432 | v_loss: 0.83432 v_acc: 0.74447 |  iteration: 3727 teacher: 0 stage: sketch lr: 0.000651\n",
      "batch 1241 loss: 0.74523 acc: 0.77311 | v_loss: 0.86201 v_acc: 0.75033 |  iteration: 3728 teacher: 1 stage: sketch lr: 0.000651\n",
      "batch 1242 loss: 0.83716 acc: 0.74251 | v_loss: 0.68528 v_acc: 0.78320 |  iteration: 3729 teacher: 0 stage: sketch lr: 0.000651\n",
      "epoch 2 loss: 1.14934 acc: 0.74667 | v_loss: 1.12897 v_acc: 0.75158 \n",
      "epoch: 3\n",
      "__________________________________________\n",
      "batch 0 loss: 0.81227 acc: 0.76921 | v_loss: 0.90141 v_acc: 0.75358 |  iteration: 3730 teacher: 1 stage: sketch lr: 0.000652\n",
      "batch 1 loss: 0.76556 acc: 0.76237 | v_loss: 0.75721 v_acc: 0.77409 |  iteration: 3731 teacher: 1 stage: sketch lr: 0.000652\n",
      "batch 2 loss: 0.76726 acc: 0.76237 | v_loss: 0.80721 v_acc: 0.76432 |  iteration: 3732 teacher: 1 stage: sketch lr: 0.000652\n",
      "batch 3 loss: 0.76001 acc: 0.76237 | v_loss: 0.81188 v_acc: 0.75651 |  iteration: 3733 teacher: 1 stage: sketch lr: 0.000652\n",
      "batch 4 loss: 0.88770 acc: 0.75260 | v_loss: 0.74752 v_acc: 0.77474 |  iteration: 3734 teacher: 0 stage: sketch lr: 0.000652\n",
      "batch 5 loss: 0.83915 acc: 0.76172 | v_loss: 0.67241 v_acc: 0.77572 |  iteration: 3735 teacher: 1 stage: sketch lr: 0.000652\n",
      "batch 6 loss: 0.77674 acc: 0.76302 | v_loss: 0.85189 v_acc: 0.75163 |  iteration: 3736 teacher: 1 stage: sketch lr: 0.000653\n",
      "batch 7 loss: 0.84068 acc: 0.74870 | v_loss: 0.89133 v_acc: 0.73470 |  iteration: 3737 teacher: 0 stage: sketch lr: 0.000653\n",
      "batch 8 loss: 0.79901 acc: 0.75260 | v_loss: 0.79232 v_acc: 0.74805 |  iteration: 3738 teacher: 0 stage: sketch lr: 0.000653\n",
      "batch 9 loss: 0.77518 acc: 0.77018 | v_loss: 0.91237 v_acc: 0.73600 |  iteration: 3739 teacher: 1 stage: sketch lr: 0.000653\n",
      "batch 10 loss: 0.74182 acc: 0.76888 | v_loss: 0.71241 v_acc: 0.76888 |  iteration: 3740 teacher: 1 stage: sketch lr: 0.000653\n",
      "batch 11 loss: 0.76163 acc: 0.75944 | v_loss: 0.79606 v_acc: 0.75456 |  iteration: 3741 teacher: 1 stage: sketch lr: 0.000654\n",
      "batch 12 loss: 0.86577 acc: 0.74349 | v_loss: 0.69301 v_acc: 0.79069 |  iteration: 3742 teacher: 1 stage: sketch lr: 0.000654\n",
      "batch 13 loss: 0.82429 acc: 0.76758 | v_loss: 0.69827 v_acc: 0.78451 |  iteration: 3743 teacher: 0 stage: sketch lr: 0.000654\n",
      "batch 14 loss: 0.91113 acc: 0.74089 | v_loss: 0.87443 v_acc: 0.76888 |  iteration: 3744 teacher: 0 stage: sketch lr: 0.000654\n",
      "batch 15 loss: 0.97217 acc: 0.72884 | v_loss: 0.70211 v_acc: 0.77051 |  iteration: 3745 teacher: 0 stage: sketch lr: 0.000654\n",
      "batch 16 loss: 0.75343 acc: 0.76400 | v_loss: 0.83158 v_acc: 0.75553 |  iteration: 3746 teacher: 1 stage: sketch lr: 0.000654\n",
      "batch 17 loss: 0.84381 acc: 0.75130 | v_loss: 0.72394 v_acc: 0.76530 |  iteration: 3747 teacher: 1 stage: sketch lr: 0.000655\n",
      "batch 18 loss: 0.85583 acc: 0.74772 | v_loss: 0.72109 v_acc: 0.77344 |  iteration: 3748 teacher: 1 stage: sketch lr: 0.000655\n",
      "batch 19 loss: 0.88627 acc: 0.74154 | v_loss: 0.87603 v_acc: 0.75651 |  iteration: 3749 teacher: 0 stage: sketch lr: 0.000655\n",
      "batch 20 loss: 0.91841 acc: 0.73730 | v_loss: 0.76434 v_acc: 0.76693 |  iteration: 3750 teacher: 0 stage: sketch lr: 0.000655\n",
      "batch 21 loss: 0.82628 acc: 0.75391 | v_loss: 0.70975 v_acc: 0.79915 |  iteration: 3751 teacher: 0 stage: sketch lr: 0.000655\n",
      "batch 22 loss: 0.89070 acc: 0.74805 | v_loss: 0.80499 v_acc: 0.75358 |  iteration: 3752 teacher: 0 stage: sketch lr: 0.000655\n",
      "batch 23 loss: 0.83757 acc: 0.75228 | v_loss: 0.70188 v_acc: 0.77344 |  iteration: 3753 teacher: 0 stage: sketch lr: 0.000656\n",
      "batch 24 loss: 0.75614 acc: 0.76986 | v_loss: 0.95213 v_acc: 0.73340 |  iteration: 3754 teacher: 1 stage: sketch lr: 0.000656\n",
      "batch 25 loss: 0.65807 acc: 0.79720 | v_loss: 0.76933 v_acc: 0.77018 |  iteration: 3755 teacher: 1 stage: sketch lr: 0.000656\n",
      "batch 26 loss: 0.80035 acc: 0.75163 | v_loss: 0.78285 v_acc: 0.75456 |  iteration: 3756 teacher: 0 stage: sketch lr: 0.000656\n",
      "batch 27 loss: 0.85443 acc: 0.76270 | v_loss: 0.72261 v_acc: 0.77507 |  iteration: 3757 teacher: 0 stage: sketch lr: 0.000656\n",
      "batch 28 loss: 0.79807 acc: 0.75488 | v_loss: 0.83076 v_acc: 0.74609 |  iteration: 3758 teacher: 1 stage: sketch lr: 0.000656\n",
      "batch 29 loss: 0.72932 acc: 0.77376 | v_loss: 0.67794 v_acc: 0.77409 |  iteration: 3759 teacher: 1 stage: sketch lr: 0.000657\n",
      "batch 30 loss: 0.76431 acc: 0.77214 | v_loss: 0.75332 v_acc: 0.76823 |  iteration: 3760 teacher: 1 stage: sketch lr: 0.000657\n",
      "batch 31 loss: 0.81658 acc: 0.75391 | v_loss: 0.72819 v_acc: 0.76758 |  iteration: 3761 teacher: 1 stage: sketch lr: 0.000657\n",
      "batch 32 loss: 0.86186 acc: 0.74837 | v_loss: 0.90238 v_acc: 0.73047 |  iteration: 3762 teacher: 0 stage: sketch lr: 0.000657\n",
      "batch 33 loss: 0.84017 acc: 0.75846 | v_loss: 0.69698 v_acc: 0.77214 |  iteration: 3763 teacher: 0 stage: sketch lr: 0.000657\n",
      "batch 34 loss: 0.69030 acc: 0.77669 | v_loss: 0.83439 v_acc: 0.75260 |  iteration: 3764 teacher: 1 stage: sketch lr: 0.000658\n",
      "batch 35 loss: 0.83391 acc: 0.75423 | v_loss: 0.79711 v_acc: 0.76758 |  iteration: 3765 teacher: 1 stage: sketch lr: 0.000658\n",
      "batch 36 loss: 0.85754 acc: 0.75130 | v_loss: 0.81736 v_acc: 0.75586 |  iteration: 3766 teacher: 1 stage: sketch lr: 0.000658\n",
      "batch 37 loss: 0.82745 acc: 0.75260 | v_loss: 0.81513 v_acc: 0.75000 |  iteration: 3767 teacher: 1 stage: sketch lr: 0.000658\n",
      "batch 38 loss: 0.79332 acc: 0.76562 | v_loss: 0.87349 v_acc: 0.75195 |  iteration: 3768 teacher: 1 stage: sketch lr: 0.000658\n",
      "batch 39 loss: 0.83594 acc: 0.76172 | v_loss: 0.82378 v_acc: 0.76074 |  iteration: 3769 teacher: 0 stage: sketch lr: 0.000658\n",
      "batch 40 loss: 0.83852 acc: 0.75195 | v_loss: 0.70757 v_acc: 0.77865 |  iteration: 3770 teacher: 0 stage: sketch lr: 0.000659\n",
      "batch 41 loss: 0.79335 acc: 0.75911 | v_loss: 0.81796 v_acc: 0.76074 |  iteration: 3771 teacher: 1 stage: sketch lr: 0.000659\n",
      "batch 42 loss: 0.72172 acc: 0.76335 | v_loss: 0.73914 v_acc: 0.78190 |  iteration: 3772 teacher: 1 stage: sketch lr: 0.000659\n",
      "batch 43 loss: 0.83360 acc: 0.75358 | v_loss: 0.86528 v_acc: 0.74023 |  iteration: 3773 teacher: 0 stage: sketch lr: 0.000659\n",
      "batch 44 loss: 0.77188 acc: 0.76270 | v_loss: 0.79917 v_acc: 0.75488 |  iteration: 3774 teacher: 0 stage: sketch lr: 0.000659\n",
      "batch 45 loss: 0.81833 acc: 0.75488 | v_loss: 0.77884 v_acc: 0.76432 |  iteration: 3775 teacher: 1 stage: sketch lr: 0.000659\n",
      "batch 46 loss: 0.76556 acc: 0.75977 | v_loss: 0.85212 v_acc: 0.76335 |  iteration: 3776 teacher: 1 stage: sketch lr: 0.000660\n",
      "batch 47 loss: 0.74337 acc: 0.77376 | v_loss: 0.78466 v_acc: 0.75879 |  iteration: 3777 teacher: 0 stage: sketch lr: 0.000660\n",
      "batch 48 loss: 0.79381 acc: 0.76400 | v_loss: 0.78110 v_acc: 0.76400 |  iteration: 3778 teacher: 1 stage: sketch lr: 0.000660\n",
      "batch 49 loss: 0.81432 acc: 0.76172 | v_loss: 0.77433 v_acc: 0.76237 |  iteration: 3779 teacher: 0 stage: sketch lr: 0.000660\n",
      "batch 50 loss: 0.82579 acc: 0.74805 | v_loss: 0.64770 v_acc: 0.78809 |  iteration: 3780 teacher: 0 stage: sketch lr: 0.000660\n",
      "batch 51 loss: 0.87841 acc: 0.75423 | v_loss: 0.70257 v_acc: 0.77604 |  iteration: 3781 teacher: 1 stage: sketch lr: 0.000661\n",
      "batch 52 loss: 0.67188 acc: 0.78711 | v_loss: 0.77047 v_acc: 0.75716 |  iteration: 3782 teacher: 1 stage: sketch lr: 0.000661\n",
      "batch 53 loss: 0.67902 acc: 0.77832 | v_loss: 0.85331 v_acc: 0.75716 |  iteration: 3783 teacher: 1 stage: sketch lr: 0.000661\n",
      "batch 54 loss: 0.90148 acc: 0.73796 | v_loss: 0.84543 v_acc: 0.76009 |  iteration: 3784 teacher: 0 stage: sketch lr: 0.000661\n",
      "batch 55 loss: 0.80194 acc: 0.75781 | v_loss: 0.72271 v_acc: 0.78125 |  iteration: 3785 teacher: 0 stage: sketch lr: 0.000661\n",
      "batch 56 loss: 0.73067 acc: 0.76921 | v_loss: 0.81942 v_acc: 0.76823 |  iteration: 3786 teacher: 1 stage: sketch lr: 0.000661\n",
      "batch 57 loss: 0.77110 acc: 0.75814 | v_loss: 0.79558 v_acc: 0.76074 |  iteration: 3787 teacher: 0 stage: sketch lr: 0.000662\n",
      "batch 58 loss: 0.74820 acc: 0.77734 | v_loss: 0.79466 v_acc: 0.76823 |  iteration: 3788 teacher: 1 stage: sketch lr: 0.000662\n",
      "batch 59 loss: 0.72985 acc: 0.76562 | v_loss: 0.70672 v_acc: 0.77181 |  iteration: 3789 teacher: 1 stage: sketch lr: 0.000662\n",
      "batch 60 loss: 0.81320 acc: 0.75163 | v_loss: 0.68679 v_acc: 0.78190 |  iteration: 3790 teacher: 1 stage: sketch lr: 0.000662\n",
      "batch 61 loss: 0.85779 acc: 0.76107 | v_loss: 0.68308 v_acc: 0.78158 |  iteration: 3791 teacher: 0 stage: sketch lr: 0.000662\n",
      "batch 62 loss: 0.72652 acc: 0.78385 | v_loss: 0.76437 v_acc: 0.76921 |  iteration: 3792 teacher: 1 stage: sketch lr: 0.000662\n",
      "batch 63 loss: 0.84444 acc: 0.76009 | v_loss: 0.84604 v_acc: 0.74642 |  iteration: 3793 teacher: 0 stage: sketch lr: 0.000663\n",
      "batch 64 loss: 0.76402 acc: 0.76855 | v_loss: 0.71246 v_acc: 0.77604 |  iteration: 3794 teacher: 0 stage: sketch lr: 0.000663\n",
      "batch 65 loss: 0.75298 acc: 0.76725 | v_loss: 0.75356 v_acc: 0.78646 |  iteration: 3795 teacher: 0 stage: sketch lr: 0.000663\n",
      "batch 66 loss: 0.81723 acc: 0.76237 | v_loss: 0.84947 v_acc: 0.75488 |  iteration: 3796 teacher: 0 stage: sketch lr: 0.000663\n",
      "batch 67 loss: 0.85439 acc: 0.75488 | v_loss: 0.87726 v_acc: 0.73828 |  iteration: 3797 teacher: 0 stage: sketch lr: 0.000663\n",
      "batch 68 loss: 0.73912 acc: 0.77604 | v_loss: 0.74939 v_acc: 0.77995 |  iteration: 3798 teacher: 1 stage: sketch lr: 0.000663\n",
      "batch 69 loss: 0.74779 acc: 0.77083 | v_loss: 0.80342 v_acc: 0.76562 |  iteration: 3799 teacher: 1 stage: sketch lr: 0.000664\n",
      "batch 70 loss: 0.82020 acc: 0.76497 | v_loss: 0.65649 v_acc: 0.78613 |  iteration: 3800 teacher: 1 stage: sketch lr: 0.000664\n",
      "batch 71 loss: 0.81509 acc: 0.75716 | v_loss: 0.78450 v_acc: 0.75618 |  iteration: 3801 teacher: 1 stage: sketch lr: 0.000664\n",
      "batch 72 loss: 0.79046 acc: 0.75326 | v_loss: 0.75038 v_acc: 0.77083 |  iteration: 3802 teacher: 1 stage: sketch lr: 0.000664\n",
      "batch 73 loss: 0.84140 acc: 0.74316 | v_loss: 0.82254 v_acc: 0.76497 |  iteration: 3803 teacher: 1 stage: sketch lr: 0.000664\n",
      "batch 74 loss: 0.83943 acc: 0.74967 | v_loss: 0.78520 v_acc: 0.76465 |  iteration: 3804 teacher: 1 stage: sketch lr: 0.000665\n",
      "batch 75 loss: 0.81961 acc: 0.76139 | v_loss: 0.74538 v_acc: 0.76107 |  iteration: 3805 teacher: 1 stage: sketch lr: 0.000665\n",
      "batch 76 loss: 0.84961 acc: 0.75391 | v_loss: 0.74564 v_acc: 0.77897 |  iteration: 3806 teacher: 0 stage: sketch lr: 0.000665\n",
      "batch 77 loss: 0.81247 acc: 0.75944 | v_loss: 0.72292 v_acc: 0.77604 |  iteration: 3807 teacher: 0 stage: sketch lr: 0.000665\n",
      "batch 78 loss: 0.91248 acc: 0.73535 | v_loss: 0.93019 v_acc: 0.72168 |  iteration: 3808 teacher: 0 stage: sketch lr: 0.000665\n",
      "batch 79 loss: 0.85389 acc: 0.74186 | v_loss: 0.73903 v_acc: 0.77181 |  iteration: 3809 teacher: 0 stage: sketch lr: 0.000665\n",
      "batch 80 loss: 0.88520 acc: 0.74121 | v_loss: 0.77392 v_acc: 0.75814 |  iteration: 3810 teacher: 0 stage: sketch lr: 0.000666\n",
      "batch 81 loss: 0.82239 acc: 0.74805 | v_loss: 0.71158 v_acc: 0.77865 |  iteration: 3811 teacher: 0 stage: sketch lr: 0.000666\n",
      "batch 82 loss: 0.78936 acc: 0.76921 | v_loss: 0.77016 v_acc: 0.76107 |  iteration: 3812 teacher: 0 stage: sketch lr: 0.000666\n",
      "batch 83 loss: 0.79593 acc: 0.76270 | v_loss: 0.68812 v_acc: 0.79622 |  iteration: 3813 teacher: 1 stage: sketch lr: 0.000666\n",
      "batch 84 loss: 0.79910 acc: 0.76237 | v_loss: 0.83062 v_acc: 0.76074 |  iteration: 3814 teacher: 0 stage: sketch lr: 0.000666\n",
      "batch 85 loss: 0.75701 acc: 0.76074 | v_loss: 0.76254 v_acc: 0.76595 |  iteration: 3815 teacher: 1 stage: sketch lr: 0.000666\n",
      "batch 86 loss: 0.74663 acc: 0.77344 | v_loss: 0.95274 v_acc: 0.73503 |  iteration: 3816 teacher: 1 stage: sketch lr: 0.000667\n",
      "batch 87 loss: 0.78340 acc: 0.76725 | v_loss: 0.83987 v_acc: 0.76270 |  iteration: 3817 teacher: 1 stage: sketch lr: 0.000667\n",
      "batch 88 loss: 0.87521 acc: 0.74382 | v_loss: 0.82023 v_acc: 0.76335 |  iteration: 3818 teacher: 0 stage: sketch lr: 0.000667\n",
      "batch 89 loss: 0.82235 acc: 0.75521 | v_loss: 0.83134 v_acc: 0.75163 |  iteration: 3819 teacher: 0 stage: sketch lr: 0.000667\n",
      "batch 90 loss: 0.80426 acc: 0.75944 | v_loss: 0.78107 v_acc: 0.76400 |  iteration: 3820 teacher: 0 stage: sketch lr: 0.000667\n",
      "batch 91 loss: 0.80751 acc: 0.75260 | v_loss: 0.82469 v_acc: 0.75879 |  iteration: 3821 teacher: 0 stage: sketch lr: 0.000668\n",
      "batch 92 loss: 0.73276 acc: 0.77051 | v_loss: 0.72497 v_acc: 0.77930 |  iteration: 3822 teacher: 0 stage: sketch lr: 0.000668\n",
      "batch 93 loss: 0.86435 acc: 0.75130 | v_loss: 0.76903 v_acc: 0.77995 |  iteration: 3823 teacher: 0 stage: sketch lr: 0.000668\n",
      "batch 94 loss: 0.84550 acc: 0.74902 | v_loss: 0.75084 v_acc: 0.76725 |  iteration: 3824 teacher: 0 stage: sketch lr: 0.000668\n",
      "batch 95 loss: 0.76082 acc: 0.76725 | v_loss: 0.71205 v_acc: 0.78060 |  iteration: 3825 teacher: 0 stage: sketch lr: 0.000668\n",
      "batch 96 loss: 0.85504 acc: 0.75033 | v_loss: 0.66086 v_acc: 0.77734 |  iteration: 3826 teacher: 0 stage: sketch lr: 0.000668\n",
      "batch 97 loss: 0.81923 acc: 0.75033 | v_loss: 0.82791 v_acc: 0.75521 |  iteration: 3827 teacher: 1 stage: sketch lr: 0.000669\n",
      "batch 98 loss: 0.85802 acc: 0.75098 | v_loss: 0.86804 v_acc: 0.74577 |  iteration: 3828 teacher: 0 stage: sketch lr: 0.000669\n",
      "batch 99 loss: 0.83530 acc: 0.75814 | v_loss: 0.79642 v_acc: 0.76432 |  iteration: 3829 teacher: 1 stage: sketch lr: 0.000669\n",
      "batch 100 loss: 0.78983 acc: 0.75749 | v_loss: 0.92537 v_acc: 0.75358 |  iteration: 3830 teacher: 1 stage: sketch lr: 0.000669\n",
      "batch 101 loss: 0.91716 acc: 0.74316 | v_loss: 0.71347 v_acc: 0.76270 |  iteration: 3831 teacher: 0 stage: sketch lr: 0.000669\n",
      "batch 102 loss: 0.71459 acc: 0.77799 | v_loss: 0.79394 v_acc: 0.76855 |  iteration: 3832 teacher: 1 stage: sketch lr: 0.000669\n",
      "batch 103 loss: 0.80580 acc: 0.75391 | v_loss: 0.68287 v_acc: 0.79525 |  iteration: 3833 teacher: 1 stage: sketch lr: 0.000670\n",
      "batch 104 loss: 0.78578 acc: 0.76660 | v_loss: 0.67322 v_acc: 0.79004 |  iteration: 3834 teacher: 1 stage: sketch lr: 0.000670\n",
      "batch 105 loss: 0.77771 acc: 0.76400 | v_loss: 0.87610 v_acc: 0.76530 |  iteration: 3835 teacher: 0 stage: sketch lr: 0.000670\n",
      "batch 106 loss: 0.76423 acc: 0.77376 | v_loss: 0.70723 v_acc: 0.77083 |  iteration: 3836 teacher: 1 stage: sketch lr: 0.000670\n",
      "batch 107 loss: 0.90072 acc: 0.74740 | v_loss: 0.79554 v_acc: 0.75456 |  iteration: 3837 teacher: 0 stage: sketch lr: 0.000670\n",
      "batch 108 loss: 0.79143 acc: 0.76172 | v_loss: 0.71338 v_acc: 0.77279 |  iteration: 3838 teacher: 0 stage: sketch lr: 0.000670\n",
      "batch 109 loss: 0.80692 acc: 0.76042 | v_loss: 0.70556 v_acc: 0.77051 |  iteration: 3839 teacher: 0 stage: sketch lr: 0.000671\n",
      "batch 110 loss: 0.77379 acc: 0.76888 | v_loss: 0.85046 v_acc: 0.75098 |  iteration: 3840 teacher: 0 stage: sketch lr: 0.000671\n",
      "batch 111 loss: 0.82566 acc: 0.75716 | v_loss: 0.77182 v_acc: 0.77409 |  iteration: 3841 teacher: 0 stage: sketch lr: 0.000671\n",
      "batch 112 loss: 0.70483 acc: 0.77409 | v_loss: 0.70811 v_acc: 0.79753 |  iteration: 3842 teacher: 1 stage: sketch lr: 0.000671\n",
      "batch 113 loss: 0.95586 acc: 0.74284 | v_loss: 0.81728 v_acc: 0.75846 |  iteration: 3843 teacher: 1 stage: sketch lr: 0.000671\n",
      "batch 114 loss: 0.69352 acc: 0.77474 | v_loss: 0.71358 v_acc: 0.77637 |  iteration: 3844 teacher: 1 stage: sketch lr: 0.000672\n",
      "batch 115 loss: 0.88325 acc: 0.74284 | v_loss: 0.91408 v_acc: 0.74837 |  iteration: 3845 teacher: 0 stage: sketch lr: 0.000672\n",
      "batch 116 loss: 0.84769 acc: 0.75326 | v_loss: 0.73377 v_acc: 0.77539 |  iteration: 3846 teacher: 0 stage: sketch lr: 0.000672\n",
      "batch 117 loss: 0.78562 acc: 0.76009 | v_loss: 0.78770 v_acc: 0.74805 |  iteration: 3847 teacher: 1 stage: sketch lr: 0.000672\n",
      "batch 118 loss: 0.81717 acc: 0.74837 | v_loss: 0.73121 v_acc: 0.76758 |  iteration: 3848 teacher: 0 stage: sketch lr: 0.000672\n",
      "batch 119 loss: 0.93617 acc: 0.74512 | v_loss: 0.81066 v_acc: 0.74382 |  iteration: 3849 teacher: 0 stage: sketch lr: 0.000672\n",
      "batch 120 loss: 0.87646 acc: 0.74935 | v_loss: 0.67534 v_acc: 0.77865 |  iteration: 3850 teacher: 0 stage: sketch lr: 0.000673\n",
      "batch 121 loss: 0.75795 acc: 0.76823 | v_loss: 0.75858 v_acc: 0.76204 |  iteration: 3851 teacher: 0 stage: sketch lr: 0.000673\n",
      "batch 122 loss: 0.83726 acc: 0.74837 | v_loss: 0.70487 v_acc: 0.77962 |  iteration: 3852 teacher: 1 stage: sketch lr: 0.000673\n",
      "batch 123 loss: 0.82666 acc: 0.74935 | v_loss: 0.89055 v_acc: 0.74512 |  iteration: 3853 teacher: 0 stage: sketch lr: 0.000673\n",
      "batch 124 loss: 0.80123 acc: 0.75195 | v_loss: 0.69073 v_acc: 0.77799 |  iteration: 3854 teacher: 0 stage: sketch lr: 0.000673\n",
      "batch 125 loss: 0.80388 acc: 0.76367 | v_loss: 0.79020 v_acc: 0.75684 |  iteration: 3855 teacher: 1 stage: sketch lr: 0.000673\n",
      "batch 126 loss: 0.79717 acc: 0.75911 | v_loss: 0.77650 v_acc: 0.78288 |  iteration: 3856 teacher: 0 stage: sketch lr: 0.000674\n",
      "batch 127 loss: 0.73283 acc: 0.77148 | v_loss: 0.77355 v_acc: 0.75977 |  iteration: 3857 teacher: 1 stage: sketch lr: 0.000674\n",
      "batch 128 loss: 0.76229 acc: 0.77051 | v_loss: 0.78922 v_acc: 0.75488 |  iteration: 3858 teacher: 1 stage: sketch lr: 0.000674\n",
      "batch 129 loss: 0.83432 acc: 0.75846 | v_loss: 0.87589 v_acc: 0.75814 |  iteration: 3859 teacher: 1 stage: sketch lr: 0.000674\n",
      "batch 130 loss: 0.70873 acc: 0.77734 | v_loss: 0.83666 v_acc: 0.74967 |  iteration: 3860 teacher: 1 stage: sketch lr: 0.000674\n",
      "batch 131 loss: 0.78916 acc: 0.75879 | v_loss: 0.69937 v_acc: 0.78320 |  iteration: 3861 teacher: 1 stage: sketch lr: 0.000674\n",
      "batch 132 loss: 0.83497 acc: 0.75358 | v_loss: 0.82376 v_acc: 0.76139 |  iteration: 3862 teacher: 0 stage: sketch lr: 0.000675\n",
      "batch 133 loss: 0.85921 acc: 0.74577 | v_loss: 0.73379 v_acc: 0.78353 |  iteration: 3863 teacher: 0 stage: sketch lr: 0.000675\n",
      "batch 134 loss: 0.80449 acc: 0.76139 | v_loss: 0.85700 v_acc: 0.74837 |  iteration: 3864 teacher: 1 stage: sketch lr: 0.000675\n",
      "batch 135 loss: 0.79344 acc: 0.76921 | v_loss: 0.74265 v_acc: 0.77344 |  iteration: 3865 teacher: 1 stage: sketch lr: 0.000675\n",
      "batch 136 loss: 0.81490 acc: 0.75879 | v_loss: 0.74507 v_acc: 0.77344 |  iteration: 3866 teacher: 0 stage: sketch lr: 0.000675\n",
      "batch 137 loss: 0.78697 acc: 0.77214 | v_loss: 0.80103 v_acc: 0.76953 |  iteration: 3867 teacher: 0 stage: sketch lr: 0.000676\n",
      "batch 138 loss: 0.79692 acc: 0.75651 | v_loss: 0.78836 v_acc: 0.75944 |  iteration: 3868 teacher: 0 stage: sketch lr: 0.000676\n",
      "batch 139 loss: 0.71346 acc: 0.78451 | v_loss: 0.75675 v_acc: 0.76172 |  iteration: 3869 teacher: 1 stage: sketch lr: 0.000676\n",
      "batch 140 loss: 0.88181 acc: 0.74805 | v_loss: 0.77859 v_acc: 0.77181 |  iteration: 3870 teacher: 0 stage: sketch lr: 0.000676\n",
      "batch 141 loss: 0.80403 acc: 0.74837 | v_loss: 0.63290 v_acc: 0.79232 |  iteration: 3871 teacher: 1 stage: sketch lr: 0.000676\n",
      "batch 142 loss: 0.73900 acc: 0.77734 | v_loss: 0.69404 v_acc: 0.78711 |  iteration: 3872 teacher: 0 stage: sketch lr: 0.000676\n",
      "batch 143 loss: 0.78869 acc: 0.76139 | v_loss: 0.74963 v_acc: 0.76628 |  iteration: 3873 teacher: 1 stage: sketch lr: 0.000677\n",
      "batch 144 loss: 0.77799 acc: 0.76335 | v_loss: 0.81286 v_acc: 0.76530 |  iteration: 3874 teacher: 0 stage: sketch lr: 0.000677\n",
      "batch 145 loss: 0.75013 acc: 0.76888 | v_loss: 0.81670 v_acc: 0.76172 |  iteration: 3875 teacher: 1 stage: sketch lr: 0.000677\n",
      "batch 146 loss: 0.77772 acc: 0.76888 | v_loss: 0.69586 v_acc: 0.78711 |  iteration: 3876 teacher: 1 stage: sketch lr: 0.000677\n",
      "batch 147 loss: 0.82263 acc: 0.76107 | v_loss: 0.82388 v_acc: 0.76335 |  iteration: 3877 teacher: 1 stage: sketch lr: 0.000677\n",
      "batch 148 loss: 0.76940 acc: 0.76139 | v_loss: 0.79240 v_acc: 0.75944 |  iteration: 3878 teacher: 0 stage: sketch lr: 0.000677\n",
      "batch 149 loss: 0.75852 acc: 0.77865 | v_loss: 0.80705 v_acc: 0.75944 |  iteration: 3879 teacher: 1 stage: sketch lr: 0.000678\n",
      "batch 150 loss: 0.83094 acc: 0.75879 | v_loss: 0.67678 v_acc: 0.77702 |  iteration: 3880 teacher: 1 stage: sketch lr: 0.000678\n",
      "batch 151 loss: 0.79762 acc: 0.76628 | v_loss: 0.66409 v_acc: 0.79102 |  iteration: 3881 teacher: 0 stage: sketch lr: 0.000678\n",
      "batch 152 loss: 0.78487 acc: 0.76595 | v_loss: 0.69679 v_acc: 0.78906 |  iteration: 3882 teacher: 0 stage: sketch lr: 0.000678\n",
      "batch 153 loss: 0.72655 acc: 0.76921 | v_loss: 0.73940 v_acc: 0.77083 |  iteration: 3883 teacher: 1 stage: sketch lr: 0.000678\n",
      "batch 154 loss: 0.74220 acc: 0.76237 | v_loss: 0.83338 v_acc: 0.75260 |  iteration: 3884 teacher: 0 stage: sketch lr: 0.000679\n",
      "batch 155 loss: 0.76635 acc: 0.77507 | v_loss: 0.72561 v_acc: 0.78678 |  iteration: 3885 teacher: 1 stage: sketch lr: 0.000679\n",
      "batch 156 loss: 0.81965 acc: 0.75977 | v_loss: 0.78435 v_acc: 0.78516 |  iteration: 3886 teacher: 1 stage: sketch lr: 0.000679\n",
      "batch 157 loss: 0.80287 acc: 0.76921 | v_loss: 0.85216 v_acc: 0.75293 |  iteration: 3887 teacher: 0 stage: sketch lr: 0.000679\n",
      "batch 158 loss: 0.76712 acc: 0.76204 | v_loss: 0.87658 v_acc: 0.74349 |  iteration: 3888 teacher: 1 stage: sketch lr: 0.000679\n",
      "batch 159 loss: 0.85296 acc: 0.74902 | v_loss: 0.71409 v_acc: 0.78060 |  iteration: 3889 teacher: 0 stage: sketch lr: 0.000679\n",
      "batch 160 loss: 0.75665 acc: 0.76497 | v_loss: 0.74822 v_acc: 0.76497 |  iteration: 3890 teacher: 1 stage: sketch lr: 0.000680\n",
      "batch 161 loss: 0.71779 acc: 0.77865 | v_loss: 0.66852 v_acc: 0.78874 |  iteration: 3891 teacher: 1 stage: sketch lr: 0.000680\n",
      "batch 162 loss: 0.72396 acc: 0.77246 | v_loss: 0.77735 v_acc: 0.77507 |  iteration: 3892 teacher: 1 stage: sketch lr: 0.000680\n",
      "batch 163 loss: 0.77912 acc: 0.76530 | v_loss: 0.73709 v_acc: 0.78190 |  iteration: 3893 teacher: 1 stage: sketch lr: 0.000680\n",
      "batch 164 loss: 0.79514 acc: 0.76497 | v_loss: 0.81525 v_acc: 0.76204 |  iteration: 3894 teacher: 1 stage: sketch lr: 0.000680\n",
      "batch 165 loss: 0.69383 acc: 0.78092 | v_loss: 0.78699 v_acc: 0.76465 |  iteration: 3895 teacher: 1 stage: sketch lr: 0.000680\n",
      "batch 166 loss: 0.76793 acc: 0.76204 | v_loss: 0.76580 v_acc: 0.76465 |  iteration: 3896 teacher: 1 stage: sketch lr: 0.000681\n",
      "batch 167 loss: 0.79909 acc: 0.76172 | v_loss: 0.73785 v_acc: 0.77865 |  iteration: 3897 teacher: 0 stage: sketch lr: 0.000681\n",
      "batch 168 loss: 0.78079 acc: 0.76953 | v_loss: 0.72973 v_acc: 0.77702 |  iteration: 3898 teacher: 0 stage: sketch lr: 0.000681\n",
      "batch 169 loss: 0.81338 acc: 0.75814 | v_loss: 0.93202 v_acc: 0.72298 |  iteration: 3899 teacher: 0 stage: sketch lr: 0.000681\n",
      "batch 170 loss: 0.85012 acc: 0.74219 | v_loss: 0.73891 v_acc: 0.77539 |  iteration: 3900 teacher: 1 stage: sketch lr: 0.000681\n",
      "batch 171 loss: 0.69410 acc: 0.78027 | v_loss: 0.74606 v_acc: 0.76237 |  iteration: 3901 teacher: 1 stage: sketch lr: 0.000681\n",
      "batch 172 loss: 0.82040 acc: 0.76270 | v_loss: 0.69479 v_acc: 0.78581 |  iteration: 3902 teacher: 1 stage: sketch lr: 0.000682\n",
      "batch 173 loss: 0.74792 acc: 0.77116 | v_loss: 0.75831 v_acc: 0.76530 |  iteration: 3903 teacher: 0 stage: sketch lr: 0.000682\n",
      "batch 174 loss: 0.90522 acc: 0.74577 | v_loss: 0.65547 v_acc: 0.79525 |  iteration: 3904 teacher: 0 stage: sketch lr: 0.000682\n",
      "batch 175 loss: 0.77025 acc: 0.75781 | v_loss: 0.79781 v_acc: 0.77214 |  iteration: 3905 teacher: 0 stage: sketch lr: 0.000682\n",
      "batch 176 loss: 0.82053 acc: 0.74837 | v_loss: 0.74951 v_acc: 0.77083 |  iteration: 3906 teacher: 0 stage: sketch lr: 0.000682\n",
      "batch 177 loss: 0.87136 acc: 0.75130 | v_loss: 0.90240 v_acc: 0.73991 |  iteration: 3907 teacher: 0 stage: sketch lr: 0.000683\n",
      "batch 178 loss: 0.79758 acc: 0.76204 | v_loss: 0.83229 v_acc: 0.75684 |  iteration: 3908 teacher: 0 stage: sketch lr: 0.000683\n",
      "batch 179 loss: 0.76995 acc: 0.76628 | v_loss: 0.84269 v_acc: 0.75618 |  iteration: 3909 teacher: 0 stage: sketch lr: 0.000683\n",
      "batch 180 loss: 0.82054 acc: 0.75391 | v_loss: 0.82213 v_acc: 0.76367 |  iteration: 3910 teacher: 0 stage: sketch lr: 0.000683\n",
      "batch 181 loss: 0.86758 acc: 0.74740 | v_loss: 0.75798 v_acc: 0.76400 |  iteration: 3911 teacher: 0 stage: sketch lr: 0.000683\n",
      "batch 182 loss: 0.71120 acc: 0.77930 | v_loss: 0.85643 v_acc: 0.76595 |  iteration: 3912 teacher: 1 stage: sketch lr: 0.000683\n",
      "batch 183 loss: 0.74671 acc: 0.76693 | v_loss: 0.73668 v_acc: 0.77376 |  iteration: 3913 teacher: 0 stage: sketch lr: 0.000684\n",
      "batch 184 loss: 0.71061 acc: 0.78223 | v_loss: 0.75720 v_acc: 0.76725 |  iteration: 3914 teacher: 1 stage: sketch lr: 0.000684\n",
      "batch 185 loss: 0.77148 acc: 0.76270 | v_loss: 0.77008 v_acc: 0.76986 |  iteration: 3915 teacher: 1 stage: sketch lr: 0.000684\n",
      "batch 186 loss: 0.81385 acc: 0.75814 | v_loss: 0.71485 v_acc: 0.78255 |  iteration: 3916 teacher: 0 stage: sketch lr: 0.000684\n",
      "batch 187 loss: 0.83179 acc: 0.76237 | v_loss: 0.63531 v_acc: 0.78548 |  iteration: 3917 teacher: 0 stage: sketch lr: 0.000684\n",
      "batch 188 loss: 0.69179 acc: 0.77083 | v_loss: 0.83363 v_acc: 0.76042 |  iteration: 3918 teacher: 1 stage: sketch lr: 0.000684\n",
      "batch 189 loss: 0.75388 acc: 0.77376 | v_loss: 0.86544 v_acc: 0.74121 |  iteration: 3919 teacher: 1 stage: sketch lr: 0.000685\n",
      "batch 190 loss: 0.80600 acc: 0.75716 | v_loss: 0.76895 v_acc: 0.76367 |  iteration: 3920 teacher: 1 stage: sketch lr: 0.000685\n",
      "batch 191 loss: 0.77668 acc: 0.76530 | v_loss: 0.83629 v_acc: 0.76660 |  iteration: 3921 teacher: 1 stage: sketch lr: 0.000685\n",
      "batch 192 loss: 0.83700 acc: 0.76042 | v_loss: 0.70207 v_acc: 0.76628 |  iteration: 3922 teacher: 0 stage: sketch lr: 0.000685\n",
      "batch 193 loss: 0.75026 acc: 0.76953 | v_loss: 0.75945 v_acc: 0.76855 |  iteration: 3923 teacher: 1 stage: sketch lr: 0.000685\n",
      "batch 194 loss: 0.82915 acc: 0.75651 | v_loss: 0.69656 v_acc: 0.79395 |  iteration: 3924 teacher: 0 stage: sketch lr: 0.000685\n",
      "batch 195 loss: 0.71056 acc: 0.77962 | v_loss: 0.67662 v_acc: 0.78451 |  iteration: 3925 teacher: 1 stage: sketch lr: 0.000686\n",
      "batch 196 loss: 0.75194 acc: 0.77051 | v_loss: 0.84852 v_acc: 0.77507 |  iteration: 3926 teacher: 1 stage: sketch lr: 0.000686\n",
      "batch 197 loss: 0.87914 acc: 0.74902 | v_loss: 0.63582 v_acc: 0.78711 |  iteration: 3927 teacher: 0 stage: sketch lr: 0.000686\n",
      "batch 198 loss: 0.81707 acc: 0.76432 | v_loss: 0.78123 v_acc: 0.76953 |  iteration: 3928 teacher: 0 stage: sketch lr: 0.000686\n",
      "batch 199 loss: 0.72579 acc: 0.77995 | v_loss: 0.70711 v_acc: 0.77279 |  iteration: 3929 teacher: 1 stage: sketch lr: 0.000686\n",
      "batch 200 loss: 0.81519 acc: 0.76009 | v_loss: 0.68838 v_acc: 0.77962 |  iteration: 3930 teacher: 0 stage: sketch lr: 0.000687\n",
      "batch 201 loss: 0.72637 acc: 0.77344 | v_loss: 0.78931 v_acc: 0.76855 |  iteration: 3931 teacher: 1 stage: sketch lr: 0.000687\n",
      "batch 202 loss: 0.85107 acc: 0.75846 | v_loss: 0.76196 v_acc: 0.77799 |  iteration: 3932 teacher: 0 stage: sketch lr: 0.000687\n",
      "batch 203 loss: 0.71829 acc: 0.77604 | v_loss: 0.70987 v_acc: 0.79980 |  iteration: 3933 teacher: 1 stage: sketch lr: 0.000687\n",
      "batch 204 loss: 0.75999 acc: 0.76172 | v_loss: 0.81050 v_acc: 0.74382 |  iteration: 3934 teacher: 1 stage: sketch lr: 0.000687\n",
      "batch 205 loss: 0.85239 acc: 0.75065 | v_loss: 0.67170 v_acc: 0.79102 |  iteration: 3935 teacher: 0 stage: sketch lr: 0.000687\n",
      "batch 206 loss: 0.79374 acc: 0.76237 | v_loss: 0.89890 v_acc: 0.75326 |  iteration: 3936 teacher: 1 stage: sketch lr: 0.000688\n",
      "batch 207 loss: 0.68223 acc: 0.78320 | v_loss: 0.73168 v_acc: 0.77311 |  iteration: 3937 teacher: 1 stage: sketch lr: 0.000688\n",
      "batch 208 loss: 0.78095 acc: 0.76270 | v_loss: 0.76934 v_acc: 0.75228 |  iteration: 3938 teacher: 0 stage: sketch lr: 0.000688\n",
      "batch 209 loss: 0.80779 acc: 0.76302 | v_loss: 0.69108 v_acc: 0.77897 |  iteration: 3939 teacher: 0 stage: sketch lr: 0.000688\n",
      "batch 210 loss: 0.76201 acc: 0.77311 | v_loss: 0.80111 v_acc: 0.75651 |  iteration: 3940 teacher: 1 stage: sketch lr: 0.000688\n",
      "batch 211 loss: 0.83319 acc: 0.76335 | v_loss: 0.65977 v_acc: 0.78516 |  iteration: 3941 teacher: 1 stage: sketch lr: 0.000688\n",
      "batch 212 loss: 0.79309 acc: 0.75911 | v_loss: 0.74367 v_acc: 0.77539 |  iteration: 3942 teacher: 1 stage: sketch lr: 0.000689\n",
      "batch 213 loss: 0.71064 acc: 0.77572 | v_loss: 0.69747 v_acc: 0.78255 |  iteration: 3943 teacher: 1 stage: sketch lr: 0.000689\n",
      "batch 214 loss: 0.96669 acc: 0.72852 | v_loss: 0.87874 v_acc: 0.75293 |  iteration: 3944 teacher: 0 stage: sketch lr: 0.000689\n",
      "batch 215 loss: 0.86298 acc: 0.75033 | v_loss: 0.68842 v_acc: 0.77148 |  iteration: 3945 teacher: 0 stage: sketch lr: 0.000689\n",
      "batch 216 loss: 0.80358 acc: 0.75651 | v_loss: 0.78860 v_acc: 0.76107 |  iteration: 3946 teacher: 0 stage: sketch lr: 0.000689\n",
      "batch 217 loss: 0.82705 acc: 0.75651 | v_loss: 0.76648 v_acc: 0.77702 |  iteration: 3947 teacher: 0 stage: sketch lr: 0.000690\n",
      "batch 218 loss: 0.72172 acc: 0.77148 | v_loss: 0.79488 v_acc: 0.75977 |  iteration: 3948 teacher: 1 stage: sketch lr: 0.000690\n",
      "batch 219 loss: 0.81207 acc: 0.75293 | v_loss: 0.80621 v_acc: 0.75130 |  iteration: 3949 teacher: 1 stage: sketch lr: 0.000690\n",
      "batch 220 loss: 0.76459 acc: 0.76367 | v_loss: 0.86453 v_acc: 0.75456 |  iteration: 3950 teacher: 1 stage: sketch lr: 0.000690\n",
      "batch 221 loss: 0.66618 acc: 0.79329 | v_loss: 0.81204 v_acc: 0.75098 |  iteration: 3951 teacher: 1 stage: sketch lr: 0.000690\n",
      "batch 222 loss: 0.78196 acc: 0.76758 | v_loss: 0.70048 v_acc: 0.77832 |  iteration: 3952 teacher: 1 stage: sketch lr: 0.000690\n",
      "batch 223 loss: 0.72071 acc: 0.77702 | v_loss: 0.79907 v_acc: 0.77018 |  iteration: 3953 teacher: 1 stage: sketch lr: 0.000691\n",
      "batch 224 loss: 0.82310 acc: 0.75814 | v_loss: 0.71433 v_acc: 0.78874 |  iteration: 3954 teacher: 0 stage: sketch lr: 0.000691\n",
      "batch 225 loss: 0.72620 acc: 0.77214 | v_loss: 0.82207 v_acc: 0.75586 |  iteration: 3955 teacher: 1 stage: sketch lr: 0.000691\n",
      "batch 226 loss: 0.71214 acc: 0.76953 | v_loss: 0.75439 v_acc: 0.76725 |  iteration: 3956 teacher: 0 stage: sketch lr: 0.000691\n",
      "batch 227 loss: 0.77067 acc: 0.76432 | v_loss: 0.74238 v_acc: 0.78223 |  iteration: 3957 teacher: 0 stage: sketch lr: 0.000691\n",
      "batch 228 loss: 0.77107 acc: 0.75781 | v_loss: 0.84596 v_acc: 0.76204 |  iteration: 3958 teacher: 1 stage: sketch lr: 0.000691\n",
      "batch 229 loss: 0.69861 acc: 0.78223 | v_loss: 0.76694 v_acc: 0.76335 |  iteration: 3959 teacher: 1 stage: sketch lr: 0.000692\n",
      "batch 230 loss: 0.83694 acc: 0.75716 | v_loss: 0.75095 v_acc: 0.77344 |  iteration: 3960 teacher: 0 stage: sketch lr: 0.000692\n",
      "batch 231 loss: 0.81628 acc: 0.76204 | v_loss: 0.75183 v_acc: 0.78158 |  iteration: 3961 teacher: 1 stage: sketch lr: 0.000692\n",
      "batch 232 loss: 0.76787 acc: 0.77507 | v_loss: 0.62906 v_acc: 0.79102 |  iteration: 3962 teacher: 0 stage: sketch lr: 0.000692\n",
      "batch 233 loss: 0.71752 acc: 0.77604 | v_loss: 0.71795 v_acc: 0.78223 |  iteration: 3963 teacher: 1 stage: sketch lr: 0.000692\n",
      "batch 234 loss: 0.69120 acc: 0.78060 | v_loss: 0.75744 v_acc: 0.76139 |  iteration: 3964 teacher: 1 stage: sketch lr: 0.000692\n",
      "batch 235 loss: 0.82984 acc: 0.75586 | v_loss: 0.81426 v_acc: 0.76042 |  iteration: 3965 teacher: 0 stage: sketch lr: 0.000693\n",
      "batch 236 loss: 0.83894 acc: 0.75326 | v_loss: 0.79657 v_acc: 0.76562 |  iteration: 3966 teacher: 1 stage: sketch lr: 0.000693\n",
      "batch 237 loss: 0.68620 acc: 0.78613 | v_loss: 0.66470 v_acc: 0.79232 |  iteration: 3967 teacher: 1 stage: sketch lr: 0.000693\n",
      "batch 238 loss: 0.84669 acc: 0.75749 | v_loss: 0.77578 v_acc: 0.76888 |  iteration: 3968 teacher: 0 stage: sketch lr: 0.000693\n",
      "batch 239 loss: 0.72870 acc: 0.77865 | v_loss: 0.78163 v_acc: 0.76270 |  iteration: 3969 teacher: 1 stage: sketch lr: 0.000693\n",
      "batch 240 loss: 0.88707 acc: 0.74967 | v_loss: 0.76811 v_acc: 0.76823 |  iteration: 3970 teacher: 0 stage: sketch lr: 0.000694\n",
      "batch 241 loss: 0.75954 acc: 0.76595 | v_loss: 0.65703 v_acc: 0.78483 |  iteration: 3971 teacher: 0 stage: sketch lr: 0.000694\n",
      "batch 242 loss: 0.75272 acc: 0.77344 | v_loss: 0.64564 v_acc: 0.79785 |  iteration: 3972 teacher: 1 stage: sketch lr: 0.000694\n",
      "batch 243 loss: 0.83579 acc: 0.76367 | v_loss: 0.69007 v_acc: 0.78418 |  iteration: 3973 teacher: 0 stage: sketch lr: 0.000694\n",
      "batch 244 loss: 0.80071 acc: 0.76562 | v_loss: 0.75910 v_acc: 0.77767 |  iteration: 3974 teacher: 0 stage: sketch lr: 0.000694\n",
      "batch 245 loss: 0.73493 acc: 0.77376 | v_loss: 0.82715 v_acc: 0.75195 |  iteration: 3975 teacher: 1 stage: sketch lr: 0.000694\n",
      "batch 246 loss: 0.73699 acc: 0.77995 | v_loss: 0.72222 v_acc: 0.78125 |  iteration: 3976 teacher: 1 stage: sketch lr: 0.000695\n",
      "batch 247 loss: 0.82361 acc: 0.75195 | v_loss: 0.77436 v_acc: 0.78418 |  iteration: 3977 teacher: 1 stage: sketch lr: 0.000695\n",
      "batch 248 loss: 0.72474 acc: 0.77832 | v_loss: 0.81940 v_acc: 0.76074 |  iteration: 3978 teacher: 1 stage: sketch lr: 0.000695\n",
      "batch 249 loss: 0.79841 acc: 0.77148 | v_loss: 0.84985 v_acc: 0.75163 |  iteration: 3979 teacher: 0 stage: sketch lr: 0.000695\n",
      "batch 250 loss: 0.74874 acc: 0.78158 | v_loss: 0.74531 v_acc: 0.77116 |  iteration: 3980 teacher: 1 stage: sketch lr: 0.000695\n",
      "batch 251 loss: 0.73414 acc: 0.77507 | v_loss: 0.75798 v_acc: 0.76790 |  iteration: 3981 teacher: 1 stage: sketch lr: 0.000695\n",
      "batch 252 loss: 0.77746 acc: 0.76400 | v_loss: 0.62411 v_acc: 0.79622 |  iteration: 3982 teacher: 0 stage: sketch lr: 0.000696\n",
      "batch 253 loss: 0.76240 acc: 0.76693 | v_loss: 0.73673 v_acc: 0.77572 |  iteration: 3983 teacher: 0 stage: sketch lr: 0.000696\n",
      "batch 254 loss: 0.79338 acc: 0.75651 | v_loss: 0.70401 v_acc: 0.79036 |  iteration: 3984 teacher: 0 stage: sketch lr: 0.000696\n",
      "batch 255 loss: 0.79970 acc: 0.76270 | v_loss: 0.82228 v_acc: 0.76270 |  iteration: 3985 teacher: 0 stage: sketch lr: 0.000696\n",
      "batch 256 loss: 0.79078 acc: 0.76074 | v_loss: 0.76208 v_acc: 0.76986 |  iteration: 3986 teacher: 0 stage: sketch lr: 0.000696\n",
      "batch 257 loss: 0.79014 acc: 0.76465 | v_loss: 0.74021 v_acc: 0.77376 |  iteration: 3987 teacher: 0 stage: sketch lr: 0.000697\n",
      "batch 258 loss: 0.75153 acc: 0.76465 | v_loss: 0.71714 v_acc: 0.77734 |  iteration: 3988 teacher: 0 stage: sketch lr: 0.000697\n",
      "batch 259 loss: 0.76021 acc: 0.76725 | v_loss: 0.70578 v_acc: 0.77474 |  iteration: 3989 teacher: 1 stage: sketch lr: 0.000697\n",
      "batch 260 loss: 0.74967 acc: 0.77246 | v_loss: 0.91507 v_acc: 0.71615 |  iteration: 3990 teacher: 0 stage: sketch lr: 0.000697\n",
      "batch 261 loss: 0.87181 acc: 0.75000 | v_loss: 0.74163 v_acc: 0.77279 |  iteration: 3991 teacher: 0 stage: sketch lr: 0.000697\n",
      "batch 262 loss: 0.88845 acc: 0.74382 | v_loss: 0.74050 v_acc: 0.77832 |  iteration: 3992 teacher: 0 stage: sketch lr: 0.000697\n",
      "batch 263 loss: 0.74831 acc: 0.76888 | v_loss: 0.67372 v_acc: 0.79655 |  iteration: 3993 teacher: 1 stage: sketch lr: 0.000698\n",
      "batch 264 loss: 0.77095 acc: 0.77214 | v_loss: 0.74152 v_acc: 0.77832 |  iteration: 3994 teacher: 1 stage: sketch lr: 0.000698\n",
      "batch 265 loss: 0.77504 acc: 0.75944 | v_loss: 0.66075 v_acc: 0.79883 |  iteration: 3995 teacher: 1 stage: sketch lr: 0.000698\n",
      "batch 266 loss: 0.77361 acc: 0.77669 | v_loss: 0.80758 v_acc: 0.76888 |  iteration: 3996 teacher: 0 stage: sketch lr: 0.000698\n",
      "batch 267 loss: 0.79007 acc: 0.76302 | v_loss: 0.76585 v_acc: 0.76790 |  iteration: 3997 teacher: 1 stage: sketch lr: 0.000698\n",
      "batch 268 loss: 0.83126 acc: 0.75033 | v_loss: 0.91231 v_acc: 0.73893 |  iteration: 3998 teacher: 0 stage: sketch lr: 0.000698\n",
      "batch 269 loss: 0.78795 acc: 0.75586 | v_loss: 0.75560 v_acc: 0.77083 |  iteration: 3999 teacher: 0 stage: sketch lr: 0.000699\n",
      "batch 270 loss: 0.71213 acc: 0.78060 | v_loss: 0.80403 v_acc: 0.76497 |  iteration: 4000 teacher: 1 stage: sketch lr: 0.000699\n",
      "batch 271 loss: 0.74718 acc: 0.77311 | v_loss: 0.81198 v_acc: 0.75911 |  iteration: 4001 teacher: 1 stage: sketch lr: 0.000699\n",
      "batch 272 loss: 0.84818 acc: 0.75033 | v_loss: 0.74460 v_acc: 0.77051 |  iteration: 4002 teacher: 0 stage: sketch lr: 0.000699\n",
      "batch 273 loss: 0.74444 acc: 0.77116 | v_loss: 0.80767 v_acc: 0.76758 |  iteration: 4003 teacher: 0 stage: sketch lr: 0.000699\n",
      "batch 274 loss: 0.73738 acc: 0.77539 | v_loss: 0.69544 v_acc: 0.78776 |  iteration: 4004 teacher: 1 stage: sketch lr: 0.000698\n",
      "batch 275 loss: 0.74042 acc: 0.77148 | v_loss: 0.74913 v_acc: 0.77376 |  iteration: 4005 teacher: 1 stage: sketch lr: 0.000698\n",
      "batch 276 loss: 0.78505 acc: 0.76855 | v_loss: 0.74254 v_acc: 0.78385 |  iteration: 4006 teacher: 1 stage: sketch lr: 0.000698\n",
      "batch 277 loss: 0.89596 acc: 0.75098 | v_loss: 0.69897 v_acc: 0.78874 |  iteration: 4007 teacher: 1 stage: sketch lr: 0.000698\n",
      "batch 278 loss: 0.75310 acc: 0.76530 | v_loss: 0.64409 v_acc: 0.78158 |  iteration: 4008 teacher: 1 stage: sketch lr: 0.000698\n",
      "batch 279 loss: 0.78984 acc: 0.76107 | v_loss: 0.81705 v_acc: 0.76465 |  iteration: 4009 teacher: 1 stage: sketch lr: 0.000698\n",
      "batch 280 loss: 0.83410 acc: 0.75195 | v_loss: 0.85830 v_acc: 0.74935 |  iteration: 4010 teacher: 0 stage: sketch lr: 0.000698\n",
      "batch 281 loss: 0.83301 acc: 0.75000 | v_loss: 0.75672 v_acc: 0.75423 |  iteration: 4011 teacher: 1 stage: sketch lr: 0.000698\n",
      "batch 282 loss: 0.82163 acc: 0.75521 | v_loss: 0.82760 v_acc: 0.76628 |  iteration: 4012 teacher: 0 stage: sketch lr: 0.000698\n",
      "batch 283 loss: 0.75151 acc: 0.76009 | v_loss: 0.66371 v_acc: 0.78841 |  iteration: 4013 teacher: 0 stage: sketch lr: 0.000698\n",
      "batch 284 loss: 0.70725 acc: 0.77376 | v_loss: 0.77417 v_acc: 0.76758 |  iteration: 4014 teacher: 1 stage: sketch lr: 0.000698\n",
      "batch 285 loss: 0.80448 acc: 0.76628 | v_loss: 0.66210 v_acc: 0.79622 |  iteration: 4015 teacher: 1 stage: sketch lr: 0.000697\n",
      "batch 286 loss: 0.64751 acc: 0.78483 | v_loss: 0.64880 v_acc: 0.79264 |  iteration: 4016 teacher: 1 stage: sketch lr: 0.000697\n",
      "batch 287 loss: 0.81806 acc: 0.76465 | v_loss: 0.85791 v_acc: 0.77246 |  iteration: 4017 teacher: 0 stage: sketch lr: 0.000697\n",
      "batch 288 loss: 0.73909 acc: 0.76367 | v_loss: 0.63445 v_acc: 0.78483 |  iteration: 4018 teacher: 0 stage: sketch lr: 0.000697\n",
      "batch 289 loss: 0.75703 acc: 0.76530 | v_loss: 0.77316 v_acc: 0.77051 |  iteration: 4019 teacher: 1 stage: sketch lr: 0.000697\n",
      "batch 290 loss: 0.76684 acc: 0.76790 | v_loss: 0.68732 v_acc: 0.77865 |  iteration: 4020 teacher: 0 stage: sketch lr: 0.000697\n",
      "batch 291 loss: 0.71414 acc: 0.78320 | v_loss: 0.66050 v_acc: 0.79004 |  iteration: 4021 teacher: 1 stage: sketch lr: 0.000697\n",
      "batch 292 loss: 0.75635 acc: 0.76725 | v_loss: 0.80411 v_acc: 0.75944 |  iteration: 4022 teacher: 0 stage: sketch lr: 0.000697\n",
      "batch 293 loss: 0.76290 acc: 0.76042 | v_loss: 0.75992 v_acc: 0.77734 |  iteration: 4023 teacher: 1 stage: sketch lr: 0.000697\n",
      "batch 294 loss: 0.79033 acc: 0.76302 | v_loss: 0.68887 v_acc: 0.80013 |  iteration: 4024 teacher: 0 stage: sketch lr: 0.000697\n",
      "batch 295 loss: 0.76945 acc: 0.77441 | v_loss: 0.79273 v_acc: 0.75423 |  iteration: 4025 teacher: 0 stage: sketch lr: 0.000697\n",
      "batch 296 loss: 0.73211 acc: 0.77344 | v_loss: 0.66532 v_acc: 0.78939 |  iteration: 4026 teacher: 1 stage: sketch lr: 0.000697\n",
      "batch 297 loss: 0.68502 acc: 0.78451 | v_loss: 0.89694 v_acc: 0.75163 |  iteration: 4027 teacher: 1 stage: sketch lr: 0.000696\n",
      "batch 298 loss: 0.74699 acc: 0.77051 | v_loss: 0.73680 v_acc: 0.77083 |  iteration: 4028 teacher: 0 stage: sketch lr: 0.000696\n",
      "batch 299 loss: 0.67165 acc: 0.78841 | v_loss: 0.72688 v_acc: 0.77539 |  iteration: 4029 teacher: 1 stage: sketch lr: 0.000696\n",
      "batch 300 loss: 0.73651 acc: 0.77116 | v_loss: 0.69846 v_acc: 0.77507 |  iteration: 4030 teacher: 0 stage: sketch lr: 0.000696\n",
      "batch 301 loss: 0.75459 acc: 0.76270 | v_loss: 0.80339 v_acc: 0.75944 |  iteration: 4031 teacher: 0 stage: sketch lr: 0.000696\n",
      "batch 302 loss: 0.67980 acc: 0.79395 | v_loss: 0.65025 v_acc: 0.79622 |  iteration: 4032 teacher: 1 stage: sketch lr: 0.000696\n",
      "batch 303 loss: 0.77054 acc: 0.76628 | v_loss: 0.74351 v_acc: 0.77734 |  iteration: 4033 teacher: 0 stage: sketch lr: 0.000696\n",
      "batch 304 loss: 0.75169 acc: 0.77734 | v_loss: 0.67618 v_acc: 0.78320 |  iteration: 4034 teacher: 0 stage: sketch lr: 0.000696\n",
      "batch 305 loss: 0.73881 acc: 0.76628 | v_loss: 0.91831 v_acc: 0.74870 |  iteration: 4035 teacher: 1 stage: sketch lr: 0.000696\n",
      "batch 306 loss: 0.83615 acc: 0.76432 | v_loss: 0.68319 v_acc: 0.77637 |  iteration: 4036 teacher: 0 stage: sketch lr: 0.000696\n",
      "batch 307 loss: 0.84597 acc: 0.76042 | v_loss: 0.77370 v_acc: 0.75716 |  iteration: 4037 teacher: 0 stage: sketch lr: 0.000696\n",
      "batch 308 loss: 0.78497 acc: 0.76986 | v_loss: 0.75642 v_acc: 0.78385 |  iteration: 4038 teacher: 1 stage: sketch lr: 0.000695\n",
      "batch 309 loss: 0.83983 acc: 0.75163 | v_loss: 0.79523 v_acc: 0.76042 |  iteration: 4039 teacher: 0 stage: sketch lr: 0.000695\n",
      "batch 310 loss: 0.85392 acc: 0.75260 | v_loss: 0.77035 v_acc: 0.75033 |  iteration: 4040 teacher: 0 stage: sketch lr: 0.000695\n",
      "batch 311 loss: 0.80464 acc: 0.75228 | v_loss: 0.85405 v_acc: 0.75033 |  iteration: 4041 teacher: 0 stage: sketch lr: 0.000695\n",
      "batch 312 loss: 0.75615 acc: 0.75846 | v_loss: 0.79775 v_acc: 0.74902 |  iteration: 4042 teacher: 1 stage: sketch lr: 0.000695\n",
      "batch 313 loss: 0.77512 acc: 0.76074 | v_loss: 0.69048 v_acc: 0.79167 |  iteration: 4043 teacher: 1 stage: sketch lr: 0.000695\n",
      "batch 314 loss: 0.72410 acc: 0.77604 | v_loss: 0.81699 v_acc: 0.76562 |  iteration: 4044 teacher: 1 stage: sketch lr: 0.000695\n",
      "batch 315 loss: 0.74220 acc: 0.76855 | v_loss: 0.74270 v_acc: 0.77995 |  iteration: 4045 teacher: 1 stage: sketch lr: 0.000695\n",
      "batch 316 loss: 0.82484 acc: 0.75911 | v_loss: 0.83834 v_acc: 0.74772 |  iteration: 4046 teacher: 0 stage: sketch lr: 0.000695\n",
      "batch 317 loss: 0.78226 acc: 0.77083 | v_loss: 0.74706 v_acc: 0.76367 |  iteration: 4047 teacher: 0 stage: sketch lr: 0.000695\n",
      "batch 318 loss: 0.82401 acc: 0.75749 | v_loss: 0.75268 v_acc: 0.77669 |  iteration: 4048 teacher: 0 stage: sketch lr: 0.000695\n",
      "batch 319 loss: 0.80372 acc: 0.76432 | v_loss: 0.80660 v_acc: 0.77246 |  iteration: 4049 teacher: 0 stage: sketch lr: 0.000695\n",
      "batch 320 loss: 0.80859 acc: 0.76042 | v_loss: 0.78450 v_acc: 0.75781 |  iteration: 4050 teacher: 1 stage: sketch lr: 0.000694\n",
      "batch 321 loss: 0.75334 acc: 0.76595 | v_loss: 0.76162 v_acc: 0.77344 |  iteration: 4051 teacher: 1 stage: sketch lr: 0.000694\n",
      "batch 322 loss: 0.68255 acc: 0.78971 | v_loss: 0.73636 v_acc: 0.78613 |  iteration: 4052 teacher: 1 stage: sketch lr: 0.000694\n",
      "batch 323 loss: 0.83750 acc: 0.74740 | v_loss: 0.63431 v_acc: 0.79329 |  iteration: 4053 teacher: 0 stage: sketch lr: 0.000694\n",
      "batch 324 loss: 0.78803 acc: 0.75423 | v_loss: 0.66597 v_acc: 0.79883 |  iteration: 4054 teacher: 0 stage: sketch lr: 0.000694\n",
      "batch 325 loss: 0.74962 acc: 0.76790 | v_loss: 0.75916 v_acc: 0.76693 |  iteration: 4055 teacher: 0 stage: sketch lr: 0.000694\n",
      "batch 326 loss: 0.74463 acc: 0.76725 | v_loss: 0.82209 v_acc: 0.77116 |  iteration: 4056 teacher: 0 stage: sketch lr: 0.000694\n",
      "batch 327 loss: 0.67017 acc: 0.78939 | v_loss: 0.80984 v_acc: 0.77018 |  iteration: 4057 teacher: 1 stage: sketch lr: 0.000694\n",
      "batch 328 loss: 0.79826 acc: 0.76823 | v_loss: 0.66576 v_acc: 0.78711 |  iteration: 4058 teacher: 1 stage: sketch lr: 0.000694\n",
      "batch 329 loss: 0.69034 acc: 0.77767 | v_loss: 0.77000 v_acc: 0.77767 |  iteration: 4059 teacher: 1 stage: sketch lr: 0.000694\n",
      "batch 330 loss: 0.72107 acc: 0.77279 | v_loss: 0.77195 v_acc: 0.76204 |  iteration: 4060 teacher: 1 stage: sketch lr: 0.000694\n",
      "batch 331 loss: 0.65275 acc: 0.78288 | v_loss: 0.78406 v_acc: 0.76432 |  iteration: 4061 teacher: 1 stage: sketch lr: 0.000694\n",
      "batch 332 loss: 0.81103 acc: 0.74707 | v_loss: 0.64362 v_acc: 0.78711 |  iteration: 4062 teacher: 0 stage: sketch lr: 0.000693\n",
      "batch 333 loss: 0.76433 acc: 0.76497 | v_loss: 0.65115 v_acc: 0.79232 |  iteration: 4063 teacher: 1 stage: sketch lr: 0.000693\n",
      "batch 334 loss: 0.79203 acc: 0.75814 | v_loss: 0.69143 v_acc: 0.78092 |  iteration: 4064 teacher: 0 stage: sketch lr: 0.000693\n",
      "batch 335 loss: 0.81415 acc: 0.75749 | v_loss: 0.72202 v_acc: 0.78613 |  iteration: 4065 teacher: 0 stage: sketch lr: 0.000693\n",
      "batch 336 loss: 0.73314 acc: 0.77018 | v_loss: 0.81294 v_acc: 0.75358 |  iteration: 4066 teacher: 1 stage: sketch lr: 0.000693\n",
      "batch 337 loss: 0.83784 acc: 0.75195 | v_loss: 0.71119 v_acc: 0.77832 |  iteration: 4067 teacher: 0 stage: sketch lr: 0.000693\n",
      "batch 338 loss: 0.76060 acc: 0.76790 | v_loss: 0.75784 v_acc: 0.78711 |  iteration: 4068 teacher: 1 stage: sketch lr: 0.000693\n",
      "batch 339 loss: 0.80794 acc: 0.75358 | v_loss: 0.79216 v_acc: 0.77344 |  iteration: 4069 teacher: 0 stage: sketch lr: 0.000693\n",
      "batch 340 loss: 0.82164 acc: 0.76139 | v_loss: 0.86745 v_acc: 0.74382 |  iteration: 4070 teacher: 0 stage: sketch lr: 0.000693\n",
      "batch 341 loss: 0.67830 acc: 0.78288 | v_loss: 0.74082 v_acc: 0.77572 |  iteration: 4071 teacher: 1 stage: sketch lr: 0.000693\n",
      "batch 342 loss: 0.72736 acc: 0.77799 | v_loss: 0.75290 v_acc: 0.77083 |  iteration: 4072 teacher: 1 stage: sketch lr: 0.000693\n",
      "batch 343 loss: 0.82221 acc: 0.75846 | v_loss: 0.64330 v_acc: 0.78906 |  iteration: 4073 teacher: 0 stage: sketch lr: 0.000692\n",
      "batch 344 loss: 0.79417 acc: 0.75814 | v_loss: 0.72797 v_acc: 0.77767 |  iteration: 4074 teacher: 1 stage: sketch lr: 0.000692\n",
      "batch 345 loss: 0.69984 acc: 0.78613 | v_loss: 0.72225 v_acc: 0.77734 |  iteration: 4075 teacher: 1 stage: sketch lr: 0.000692\n",
      "batch 346 loss: 0.74547 acc: 0.77148 | v_loss: 0.78689 v_acc: 0.76823 |  iteration: 4076 teacher: 0 stage: sketch lr: 0.000692\n",
      "batch 347 loss: 0.73723 acc: 0.76855 | v_loss: 0.76456 v_acc: 0.77767 |  iteration: 4077 teacher: 0 stage: sketch lr: 0.000692\n",
      "batch 348 loss: 0.79617 acc: 0.76302 | v_loss: 0.74733 v_acc: 0.76628 |  iteration: 4078 teacher: 1 stage: sketch lr: 0.000692\n",
      "batch 349 loss: 0.66073 acc: 0.78841 | v_loss: 0.70708 v_acc: 0.79362 |  iteration: 4079 teacher: 1 stage: sketch lr: 0.000692\n",
      "batch 350 loss: 0.72920 acc: 0.76432 | v_loss: 0.71935 v_acc: 0.78158 |  iteration: 4080 teacher: 1 stage: sketch lr: 0.000692\n",
      "batch 351 loss: 0.74836 acc: 0.77148 | v_loss: 0.90776 v_acc: 0.73633 |  iteration: 4081 teacher: 0 stage: sketch lr: 0.000692\n",
      "batch 352 loss: 0.72061 acc: 0.77441 | v_loss: 0.72506 v_acc: 0.78516 |  iteration: 4082 teacher: 1 stage: sketch lr: 0.000692\n",
      "batch 353 loss: 0.71874 acc: 0.78060 | v_loss: 0.75346 v_acc: 0.77376 |  iteration: 4083 teacher: 1 stage: sketch lr: 0.000692\n",
      "batch 354 loss: 0.77937 acc: 0.77604 | v_loss: 0.66645 v_acc: 0.79720 |  iteration: 4084 teacher: 0 stage: sketch lr: 0.000692\n",
      "batch 355 loss: 0.56898 acc: 0.80924 | v_loss: 0.72983 v_acc: 0.77409 |  iteration: 4085 teacher: 1 stage: sketch lr: 0.000691\n",
      "batch 356 loss: 0.76213 acc: 0.77507 | v_loss: 0.64898 v_acc: 0.80273 |  iteration: 4086 teacher: 1 stage: sketch lr: 0.000691\n",
      "batch 357 loss: 0.80172 acc: 0.75586 | v_loss: 0.77919 v_acc: 0.76562 |  iteration: 4087 teacher: 0 stage: sketch lr: 0.000691\n",
      "batch 358 loss: 0.80007 acc: 0.75456 | v_loss: 0.73450 v_acc: 0.77702 |  iteration: 4088 teacher: 0 stage: sketch lr: 0.000691\n",
      "batch 359 loss: 0.68676 acc: 0.78613 | v_loss: 0.88277 v_acc: 0.74707 |  iteration: 4089 teacher: 1 stage: sketch lr: 0.000691\n",
      "batch 360 loss: 0.64936 acc: 0.79199 | v_loss: 0.80291 v_acc: 0.76497 |  iteration: 4090 teacher: 1 stage: sketch lr: 0.000691\n",
      "batch 361 loss: 0.74370 acc: 0.77637 | v_loss: 0.78551 v_acc: 0.76758 |  iteration: 4091 teacher: 1 stage: sketch lr: 0.000691\n",
      "batch 362 loss: 0.78025 acc: 0.76204 | v_loss: 0.77011 v_acc: 0.77962 |  iteration: 4092 teacher: 0 stage: sketch lr: 0.000691\n",
      "batch 363 loss: 0.76943 acc: 0.76855 | v_loss: 0.74536 v_acc: 0.77572 |  iteration: 4093 teacher: 1 stage: sketch lr: 0.000691\n",
      "batch 364 loss: 0.81874 acc: 0.75391 | v_loss: 0.79409 v_acc: 0.77148 |  iteration: 4094 teacher: 0 stage: sketch lr: 0.000691\n",
      "batch 365 loss: 0.84070 acc: 0.75358 | v_loss: 0.67854 v_acc: 0.78906 |  iteration: 4095 teacher: 0 stage: sketch lr: 0.000691\n",
      "batch 366 loss: 0.76035 acc: 0.76660 | v_loss: 0.73364 v_acc: 0.77572 |  iteration: 4096 teacher: 0 stage: sketch lr: 0.000691\n",
      "batch 367 loss: 0.60651 acc: 0.79785 | v_loss: 0.72608 v_acc: 0.77507 |  iteration: 4097 teacher: 1 stage: sketch lr: 0.000690\n",
      "batch 368 loss: 0.76735 acc: 0.76204 | v_loss: 0.70221 v_acc: 0.79102 |  iteration: 4098 teacher: 0 stage: sketch lr: 0.000690\n",
      "batch 369 loss: 0.81666 acc: 0.76009 | v_loss: 0.65471 v_acc: 0.78418 |  iteration: 4099 teacher: 0 stage: sketch lr: 0.000690\n",
      "batch 370 loss: 0.82145 acc: 0.75716 | v_loss: 0.81182 v_acc: 0.76107 |  iteration: 4100 teacher: 0 stage: sketch lr: 0.000690\n",
      "batch 371 loss: 0.78162 acc: 0.76497 | v_loss: 0.83780 v_acc: 0.75195 |  iteration: 4101 teacher: 1 stage: sketch lr: 0.000690\n",
      "batch 372 loss: 0.79458 acc: 0.76660 | v_loss: 0.76913 v_acc: 0.76009 |  iteration: 4102 teacher: 0 stage: sketch lr: 0.000690\n",
      "batch 373 loss: 0.80264 acc: 0.76204 | v_loss: 0.85324 v_acc: 0.76432 |  iteration: 4103 teacher: 1 stage: sketch lr: 0.000690\n",
      "batch 374 loss: 0.74474 acc: 0.76497 | v_loss: 0.68701 v_acc: 0.77930 |  iteration: 4104 teacher: 0 stage: sketch lr: 0.000690\n",
      "batch 375 loss: 0.79661 acc: 0.76270 | v_loss: 0.76289 v_acc: 0.77116 |  iteration: 4105 teacher: 0 stage: sketch lr: 0.000690\n",
      "batch 376 loss: 0.80515 acc: 0.75814 | v_loss: 0.68663 v_acc: 0.78939 |  iteration: 4106 teacher: 0 stage: sketch lr: 0.000690\n",
      "batch 377 loss: 0.76478 acc: 0.76823 | v_loss: 0.66345 v_acc: 0.78841 |  iteration: 4107 teacher: 1 stage: sketch lr: 0.000690\n",
      "batch 378 loss: 0.78230 acc: 0.76562 | v_loss: 0.84601 v_acc: 0.76953 |  iteration: 4108 teacher: 0 stage: sketch lr: 0.000690\n",
      "batch 379 loss: 0.78934 acc: 0.76855 | v_loss: 0.61215 v_acc: 0.78385 |  iteration: 4109 teacher: 0 stage: sketch lr: 0.000689\n",
      "batch 380 loss: 0.82262 acc: 0.74902 | v_loss: 0.79345 v_acc: 0.76302 |  iteration: 4110 teacher: 0 stage: sketch lr: 0.000689\n",
      "batch 381 loss: 0.82443 acc: 0.75521 | v_loss: 0.69100 v_acc: 0.78548 |  iteration: 4111 teacher: 0 stage: sketch lr: 0.000689\n",
      "batch 382 loss: 0.87838 acc: 0.74772 | v_loss: 0.67227 v_acc: 0.78385 |  iteration: 4112 teacher: 0 stage: sketch lr: 0.000689\n",
      "batch 383 loss: 0.84294 acc: 0.75228 | v_loss: 0.84043 v_acc: 0.75944 |  iteration: 4113 teacher: 0 stage: sketch lr: 0.000689\n",
      "batch 384 loss: 0.79428 acc: 0.76465 | v_loss: 0.77911 v_acc: 0.77474 |  iteration: 4114 teacher: 0 stage: sketch lr: 0.000689\n",
      "batch 385 loss: 0.74587 acc: 0.77344 | v_loss: 0.69473 v_acc: 0.79167 |  iteration: 4115 teacher: 1 stage: sketch lr: 0.000689\n",
      "batch 386 loss: 0.76153 acc: 0.77474 | v_loss: 0.78937 v_acc: 0.75488 |  iteration: 4116 teacher: 1 stage: sketch lr: 0.000689\n",
      "batch 387 loss: 0.79621 acc: 0.75846 | v_loss: 0.69252 v_acc: 0.77832 |  iteration: 4117 teacher: 1 stage: sketch lr: 0.000689\n",
      "batch 388 loss: 0.76414 acc: 0.76530 | v_loss: 0.93363 v_acc: 0.74967 |  iteration: 4118 teacher: 0 stage: sketch lr: 0.000689\n",
      "batch 389 loss: 0.77595 acc: 0.77116 | v_loss: 0.71267 v_acc: 0.78288 |  iteration: 4119 teacher: 0 stage: sketch lr: 0.000689\n",
      "batch 390 loss: 0.73049 acc: 0.78516 | v_loss: 0.73145 v_acc: 0.77116 |  iteration: 4120 teacher: 0 stage: sketch lr: 0.000689\n",
      "batch 391 loss: 0.75511 acc: 0.77865 | v_loss: 0.68321 v_acc: 0.78125 |  iteration: 4121 teacher: 0 stage: sketch lr: 0.000688\n",
      "batch 392 loss: 0.70103 acc: 0.79102 | v_loss: 0.80403 v_acc: 0.75000 |  iteration: 4122 teacher: 0 stage: sketch lr: 0.000688\n",
      "batch 393 loss: 0.76290 acc: 0.77669 | v_loss: 0.63333 v_acc: 0.79069 |  iteration: 4123 teacher: 1 stage: sketch lr: 0.000688\n",
      "batch 394 loss: 0.67659 acc: 0.79460 | v_loss: 0.71016 v_acc: 0.78320 |  iteration: 4124 teacher: 1 stage: sketch lr: 0.000688\n",
      "batch 395 loss: 0.80613 acc: 0.76465 | v_loss: 0.69543 v_acc: 0.77669 |  iteration: 4125 teacher: 0 stage: sketch lr: 0.000688\n",
      "batch 396 loss: 0.81638 acc: 0.75553 | v_loss: 0.88086 v_acc: 0.74512 |  iteration: 4126 teacher: 0 stage: sketch lr: 0.000688\n",
      "batch 397 loss: 0.79979 acc: 0.76302 | v_loss: 0.70720 v_acc: 0.76823 |  iteration: 4127 teacher: 0 stage: sketch lr: 0.000688\n",
      "batch 398 loss: 0.78506 acc: 0.76465 | v_loss: 0.76075 v_acc: 0.76628 |  iteration: 4128 teacher: 0 stage: sketch lr: 0.000688\n",
      "batch 399 loss: 0.72072 acc: 0.77539 | v_loss: 0.74058 v_acc: 0.77962 |  iteration: 4129 teacher: 1 stage: sketch lr: 0.000688\n",
      "batch 400 loss: 0.78337 acc: 0.76562 | v_loss: 0.78190 v_acc: 0.76302 |  iteration: 4130 teacher: 0 stage: sketch lr: 0.000688\n",
      "batch 401 loss: 0.83273 acc: 0.76107 | v_loss: 0.78590 v_acc: 0.75586 |  iteration: 4131 teacher: 0 stage: sketch lr: 0.000688\n",
      "batch 402 loss: 0.70651 acc: 0.78255 | v_loss: 0.82939 v_acc: 0.76497 |  iteration: 4132 teacher: 1 stage: sketch lr: 0.000688\n",
      "batch 403 loss: 0.78217 acc: 0.76367 | v_loss: 0.79796 v_acc: 0.76888 |  iteration: 4133 teacher: 1 stage: sketch lr: 0.000687\n",
      "batch 404 loss: 0.76686 acc: 0.77962 | v_loss: 0.70129 v_acc: 0.78646 |  iteration: 4134 teacher: 0 stage: sketch lr: 0.000687\n",
      "batch 405 loss: 0.84040 acc: 0.75781 | v_loss: 0.79366 v_acc: 0.75944 |  iteration: 4135 teacher: 0 stage: sketch lr: 0.000687\n",
      "batch 406 loss: 0.73689 acc: 0.77148 | v_loss: 0.72093 v_acc: 0.79297 |  iteration: 4136 teacher: 1 stage: sketch lr: 0.000687\n",
      "batch 407 loss: 0.70467 acc: 0.76888 | v_loss: 0.82291 v_acc: 0.75326 |  iteration: 4137 teacher: 1 stage: sketch lr: 0.000687\n",
      "batch 408 loss: 0.64133 acc: 0.80176 | v_loss: 0.71822 v_acc: 0.77637 |  iteration: 4138 teacher: 1 stage: sketch lr: 0.000687\n",
      "batch 409 loss: 0.77338 acc: 0.75911 | v_loss: 0.75932 v_acc: 0.77962 |  iteration: 4139 teacher: 1 stage: sketch lr: 0.000687\n",
      "batch 410 loss: 0.64890 acc: 0.79980 | v_loss: 0.83533 v_acc: 0.77148 |  iteration: 4140 teacher: 1 stage: sketch lr: 0.000687\n",
      "batch 411 loss: 0.66223 acc: 0.78841 | v_loss: 0.75856 v_acc: 0.77279 |  iteration: 4141 teacher: 1 stage: sketch lr: 0.000687\n",
      "batch 412 loss: 0.77842 acc: 0.77637 | v_loss: 0.77467 v_acc: 0.75911 |  iteration: 4142 teacher: 1 stage: sketch lr: 0.000687\n",
      "batch 413 loss: 0.67599 acc: 0.79069 | v_loss: 0.76856 v_acc: 0.78288 |  iteration: 4143 teacher: 1 stage: sketch lr: 0.000687\n",
      "batch 414 loss: 0.79970 acc: 0.76986 | v_loss: 0.61220 v_acc: 0.78711 |  iteration: 4144 teacher: 1 stage: sketch lr: 0.000687\n",
      "batch 415 loss: 0.75728 acc: 0.78223 | v_loss: 0.68759 v_acc: 0.79427 |  iteration: 4145 teacher: 1 stage: sketch lr: 0.000686\n",
      "batch 416 loss: 0.79969 acc: 0.76270 | v_loss: 0.78356 v_acc: 0.75749 |  iteration: 4146 teacher: 0 stage: sketch lr: 0.000686\n",
      "batch 417 loss: 0.78202 acc: 0.76986 | v_loss: 0.79288 v_acc: 0.77279 |  iteration: 4147 teacher: 0 stage: sketch lr: 0.000686\n",
      "batch 418 loss: 0.73761 acc: 0.76921 | v_loss: 0.79375 v_acc: 0.75977 |  iteration: 4148 teacher: 1 stage: sketch lr: 0.000686\n",
      "batch 419 loss: 0.63434 acc: 0.79134 | v_loss: 0.66001 v_acc: 0.79134 |  iteration: 4149 teacher: 1 stage: sketch lr: 0.000686\n",
      "batch 420 loss: 0.81305 acc: 0.77279 | v_loss: 0.78182 v_acc: 0.77930 |  iteration: 4150 teacher: 0 stage: sketch lr: 0.000686\n",
      "batch 421 loss: 0.71923 acc: 0.77669 | v_loss: 0.79742 v_acc: 0.75651 |  iteration: 4151 teacher: 1 stage: sketch lr: 0.000686\n",
      "batch 422 loss: 0.78173 acc: 0.76367 | v_loss: 0.82745 v_acc: 0.75130 |  iteration: 4152 teacher: 1 stage: sketch lr: 0.000686\n",
      "batch 423 loss: 0.66537 acc: 0.79264 | v_loss: 0.64075 v_acc: 0.78939 |  iteration: 4153 teacher: 1 stage: sketch lr: 0.000686\n",
      "batch 424 loss: 0.78659 acc: 0.77962 | v_loss: 0.62486 v_acc: 0.80664 |  iteration: 4154 teacher: 0 stage: sketch lr: 0.000686\n",
      "batch 425 loss: 0.85919 acc: 0.75911 | v_loss: 0.71886 v_acc: 0.77507 |  iteration: 4155 teacher: 1 stage: sketch lr: 0.000686\n",
      "batch 426 loss: 0.76317 acc: 0.75911 | v_loss: 0.73271 v_acc: 0.77214 |  iteration: 4156 teacher: 1 stage: sketch lr: 0.000686\n",
      "batch 427 loss: 0.78993 acc: 0.76888 | v_loss: 0.82360 v_acc: 0.75000 |  iteration: 4157 teacher: 1 stage: sketch lr: 0.000685\n",
      "batch 428 loss: 0.69118 acc: 0.78548 | v_loss: 0.69378 v_acc: 0.78353 |  iteration: 4158 teacher: 1 stage: sketch lr: 0.000685\n",
      "batch 429 loss: 0.74371 acc: 0.76823 | v_loss: 0.73732 v_acc: 0.78548 |  iteration: 4159 teacher: 0 stage: sketch lr: 0.000685\n",
      "batch 430 loss: 0.70621 acc: 0.78483 | v_loss: 0.81485 v_acc: 0.76400 |  iteration: 4160 teacher: 1 stage: sketch lr: 0.000685\n",
      "batch 431 loss: 0.59652 acc: 0.80957 | v_loss: 0.85522 v_acc: 0.74870 |  iteration: 4161 teacher: 1 stage: sketch lr: 0.000685\n",
      "batch 432 loss: 0.72831 acc: 0.77799 | v_loss: 0.73085 v_acc: 0.78548 |  iteration: 4162 teacher: 0 stage: sketch lr: 0.000685\n",
      "batch 433 loss: 0.79905 acc: 0.77051 | v_loss: 0.74663 v_acc: 0.78288 |  iteration: 4163 teacher: 0 stage: sketch lr: 0.000685\n",
      "batch 434 loss: 0.82726 acc: 0.75358 | v_loss: 0.61772 v_acc: 0.79915 |  iteration: 4164 teacher: 0 stage: sketch lr: 0.000685\n",
      "batch 435 loss: 0.77849 acc: 0.77116 | v_loss: 0.71789 v_acc: 0.78190 |  iteration: 4165 teacher: 1 stage: sketch lr: 0.000685\n",
      "batch 436 loss: 0.64396 acc: 0.79004 | v_loss: 0.70139 v_acc: 0.79232 |  iteration: 4166 teacher: 1 stage: sketch lr: 0.000685\n",
      "batch 437 loss: 0.82204 acc: 0.76270 | v_loss: 0.80072 v_acc: 0.75749 |  iteration: 4167 teacher: 0 stage: sketch lr: 0.000685\n",
      "batch 438 loss: 0.80238 acc: 0.76628 | v_loss: 0.76383 v_acc: 0.77083 |  iteration: 4168 teacher: 1 stage: sketch lr: 0.000685\n",
      "batch 439 loss: 0.85358 acc: 0.75130 | v_loss: 0.75766 v_acc: 0.75911 |  iteration: 4169 teacher: 0 stage: sketch lr: 0.000684\n",
      "batch 440 loss: 0.81415 acc: 0.74935 | v_loss: 0.71886 v_acc: 0.77832 |  iteration: 4170 teacher: 1 stage: sketch lr: 0.000684\n",
      "batch 441 loss: 0.77223 acc: 0.76074 | v_loss: 0.72779 v_acc: 0.77572 |  iteration: 4171 teacher: 0 stage: sketch lr: 0.000684\n",
      "batch 442 loss: 0.79864 acc: 0.76302 | v_loss: 0.85918 v_acc: 0.73177 |  iteration: 4172 teacher: 0 stage: sketch lr: 0.000684\n",
      "batch 443 loss: 0.79193 acc: 0.76302 | v_loss: 0.73282 v_acc: 0.77539 |  iteration: 4173 teacher: 0 stage: sketch lr: 0.000684\n",
      "batch 444 loss: 0.74213 acc: 0.77507 | v_loss: 0.72941 v_acc: 0.78483 |  iteration: 4174 teacher: 0 stage: sketch lr: 0.000684\n",
      "batch 445 loss: 0.67369 acc: 0.78027 | v_loss: 0.70672 v_acc: 0.79525 |  iteration: 4175 teacher: 1 stage: sketch lr: 0.000684\n",
      "batch 446 loss: 0.90978 acc: 0.74382 | v_loss: 0.74691 v_acc: 0.77311 |  iteration: 4176 teacher: 0 stage: sketch lr: 0.000684\n",
      "batch 447 loss: 0.80373 acc: 0.76139 | v_loss: 0.66096 v_acc: 0.79720 |  iteration: 4177 teacher: 0 stage: sketch lr: 0.000684\n",
      "batch 448 loss: 0.78225 acc: 0.76953 | v_loss: 0.80841 v_acc: 0.76725 |  iteration: 4178 teacher: 0 stage: sketch lr: 0.000684\n",
      "batch 449 loss: 0.81987 acc: 0.75488 | v_loss: 0.72272 v_acc: 0.77930 |  iteration: 4179 teacher: 0 stage: sketch lr: 0.000684\n",
      "batch 450 loss: 0.78153 acc: 0.76270 | v_loss: 0.89704 v_acc: 0.74902 |  iteration: 4180 teacher: 1 stage: sketch lr: 0.000684\n",
      "batch 451 loss: 0.75357 acc: 0.76693 | v_loss: 0.75599 v_acc: 0.76790 |  iteration: 4181 teacher: 0 stage: sketch lr: 0.000683\n",
      "batch 452 loss: 0.73010 acc: 0.77344 | v_loss: 0.78332 v_acc: 0.77832 |  iteration: 4182 teacher: 0 stage: sketch lr: 0.000683\n",
      "batch 453 loss: 0.68480 acc: 0.78743 | v_loss: 0.76766 v_acc: 0.77507 |  iteration: 4183 teacher: 1 stage: sketch lr: 0.000683\n",
      "batch 454 loss: 0.63098 acc: 0.80501 | v_loss: 0.73541 v_acc: 0.77832 |  iteration: 4184 teacher: 1 stage: sketch lr: 0.000683\n",
      "batch 455 loss: 0.72042 acc: 0.78581 | v_loss: 0.82531 v_acc: 0.77214 |  iteration: 4185 teacher: 1 stage: sketch lr: 0.000683\n",
      "batch 456 loss: 0.78030 acc: 0.76790 | v_loss: 0.68227 v_acc: 0.79688 |  iteration: 4186 teacher: 0 stage: sketch lr: 0.000683\n",
      "batch 457 loss: 0.79634 acc: 0.77376 | v_loss: 0.71308 v_acc: 0.77897 |  iteration: 4187 teacher: 0 stage: sketch lr: 0.000683\n",
      "batch 458 loss: 0.75521 acc: 0.77669 | v_loss: 0.73829 v_acc: 0.78516 |  iteration: 4188 teacher: 0 stage: sketch lr: 0.000683\n",
      "batch 459 loss: 0.75797 acc: 0.76790 | v_loss: 0.67723 v_acc: 0.79785 |  iteration: 4189 teacher: 1 stage: sketch lr: 0.000683\n",
      "batch 460 loss: 0.76556 acc: 0.77246 | v_loss: 0.61635 v_acc: 0.79720 |  iteration: 4190 teacher: 0 stage: sketch lr: 0.000683\n",
      "batch 461 loss: 0.69149 acc: 0.78125 | v_loss: 0.79040 v_acc: 0.78027 |  iteration: 4191 teacher: 1 stage: sketch lr: 0.000683\n",
      "batch 462 loss: 0.76592 acc: 0.77669 | v_loss: 0.80398 v_acc: 0.75911 |  iteration: 4192 teacher: 1 stage: sketch lr: 0.000683\n",
      "batch 463 loss: 0.70855 acc: 0.78190 | v_loss: 0.72921 v_acc: 0.76628 |  iteration: 4193 teacher: 1 stage: sketch lr: 0.000682\n",
      "batch 464 loss: 0.79761 acc: 0.75911 | v_loss: 0.80505 v_acc: 0.76758 |  iteration: 4194 teacher: 0 stage: sketch lr: 0.000682\n",
      "batch 465 loss: 0.82942 acc: 0.75781 | v_loss: 0.65787 v_acc: 0.77865 |  iteration: 4195 teacher: 0 stage: sketch lr: 0.000682\n",
      "batch 466 loss: 0.83954 acc: 0.74837 | v_loss: 0.73645 v_acc: 0.76921 |  iteration: 4196 teacher: 1 stage: sketch lr: 0.000682\n",
      "batch 467 loss: 0.73549 acc: 0.77702 | v_loss: 0.64748 v_acc: 0.80208 |  iteration: 4197 teacher: 0 stage: sketch lr: 0.000682\n",
      "batch 468 loss: 0.79769 acc: 0.75521 | v_loss: 0.62685 v_acc: 0.80273 |  iteration: 4198 teacher: 1 stage: sketch lr: 0.000682\n",
      "batch 469 loss: 0.73237 acc: 0.77995 | v_loss: 0.84652 v_acc: 0.76432 |  iteration: 4199 teacher: 1 stage: sketch lr: 0.000682\n",
      "batch 470 loss: 0.83221 acc: 0.76074 | v_loss: 0.63806 v_acc: 0.79102 |  iteration: 4200 teacher: 0 stage: sketch lr: 0.000682\n",
      "batch 471 loss: 0.81423 acc: 0.76888 | v_loss: 0.75578 v_acc: 0.77181 |  iteration: 4201 teacher: 0 stage: sketch lr: 0.000682\n",
      "batch 472 loss: 0.75775 acc: 0.77083 | v_loss: 0.68488 v_acc: 0.77767 |  iteration: 4202 teacher: 1 stage: sketch lr: 0.000682\n",
      "batch 473 loss: 0.79382 acc: 0.77181 | v_loss: 0.67602 v_acc: 0.78451 |  iteration: 4203 teacher: 0 stage: sketch lr: 0.000682\n",
      "batch 474 loss: 0.72484 acc: 0.77441 | v_loss: 0.79363 v_acc: 0.76888 |  iteration: 4204 teacher: 1 stage: sketch lr: 0.000682\n",
      "batch 475 loss: 0.76337 acc: 0.76530 | v_loss: 0.75322 v_acc: 0.77767 |  iteration: 4205 teacher: 0 stage: sketch lr: 0.000682\n",
      "batch 476 loss: 0.73989 acc: 0.76432 | v_loss: 0.70851 v_acc: 0.79688 |  iteration: 4206 teacher: 1 stage: sketch lr: 0.000681\n",
      "batch 477 loss: 0.76773 acc: 0.75879 | v_loss: 0.80126 v_acc: 0.76009 |  iteration: 4207 teacher: 1 stage: sketch lr: 0.000681\n",
      "batch 478 loss: 0.77618 acc: 0.77246 | v_loss: 0.71778 v_acc: 0.78613 |  iteration: 4208 teacher: 1 stage: sketch lr: 0.000681\n",
      "batch 479 loss: 0.84340 acc: 0.75749 | v_loss: 0.94645 v_acc: 0.74674 |  iteration: 4209 teacher: 0 stage: sketch lr: 0.000681\n",
      "batch 480 loss: 0.78131 acc: 0.77018 | v_loss: 0.73787 v_acc: 0.77083 |  iteration: 4210 teacher: 1 stage: sketch lr: 0.000681\n",
      "batch 481 loss: 0.70210 acc: 0.77181 | v_loss: 0.75528 v_acc: 0.76237 |  iteration: 4211 teacher: 1 stage: sketch lr: 0.000681\n",
      "batch 482 loss: 0.83362 acc: 0.75553 | v_loss: 0.69736 v_acc: 0.78320 |  iteration: 4212 teacher: 0 stage: sketch lr: 0.000681\n",
      "batch 483 loss: 0.74298 acc: 0.78385 | v_loss: 0.81424 v_acc: 0.74902 |  iteration: 4213 teacher: 1 stage: sketch lr: 0.000681\n",
      "batch 484 loss: 0.78328 acc: 0.76139 | v_loss: 0.66327 v_acc: 0.78646 |  iteration: 4214 teacher: 1 stage: sketch lr: 0.000681\n",
      "batch 485 loss: 0.87490 acc: 0.75456 | v_loss: 0.71325 v_acc: 0.78125 |  iteration: 4215 teacher: 0 stage: sketch lr: 0.000681\n",
      "batch 486 loss: 0.79559 acc: 0.77116 | v_loss: 0.69030 v_acc: 0.78158 |  iteration: 4216 teacher: 0 stage: sketch lr: 0.000681\n",
      "batch 487 loss: 0.63465 acc: 0.78548 | v_loss: 0.88655 v_acc: 0.74479 |  iteration: 4217 teacher: 1 stage: sketch lr: 0.000681\n",
      "batch 488 loss: 0.81177 acc: 0.75618 | v_loss: 0.69301 v_acc: 0.77116 |  iteration: 4218 teacher: 0 stage: sketch lr: 0.000680\n",
      "batch 489 loss: 0.84653 acc: 0.75521 | v_loss: 0.75363 v_acc: 0.76921 |  iteration: 4219 teacher: 0 stage: sketch lr: 0.000680\n",
      "batch 490 loss: 0.80840 acc: 0.75684 | v_loss: 0.73017 v_acc: 0.78516 |  iteration: 4220 teacher: 0 stage: sketch lr: 0.000680\n",
      "batch 491 loss: 0.70533 acc: 0.78483 | v_loss: 0.77329 v_acc: 0.76693 |  iteration: 4221 teacher: 1 stage: sketch lr: 0.000680\n",
      "batch 492 loss: 0.85458 acc: 0.75260 | v_loss: 0.76282 v_acc: 0.76823 |  iteration: 4222 teacher: 0 stage: sketch lr: 0.000680\n",
      "batch 493 loss: 0.79901 acc: 0.75488 | v_loss: 0.82693 v_acc: 0.76628 |  iteration: 4223 teacher: 0 stage: sketch lr: 0.000680\n",
      "batch 494 loss: 0.73355 acc: 0.77376 | v_loss: 0.79937 v_acc: 0.75228 |  iteration: 4224 teacher: 1 stage: sketch lr: 0.000680\n",
      "batch 495 loss: 0.73270 acc: 0.77702 | v_loss: 0.69626 v_acc: 0.78548 |  iteration: 4225 teacher: 1 stage: sketch lr: 0.000680\n",
      "batch 496 loss: 0.82446 acc: 0.76367 | v_loss: 0.81223 v_acc: 0.76432 |  iteration: 4226 teacher: 1 stage: sketch lr: 0.000680\n",
      "batch 497 loss: 0.72727 acc: 0.78060 | v_loss: 0.72897 v_acc: 0.78418 |  iteration: 4227 teacher: 0 stage: sketch lr: 0.000680\n",
      "batch 498 loss: 0.81186 acc: 0.77214 | v_loss: 0.84756 v_acc: 0.74967 |  iteration: 4228 teacher: 0 stage: sketch lr: 0.000680\n",
      "batch 499 loss: 0.82627 acc: 0.76660 | v_loss: 0.74235 v_acc: 0.77311 |  iteration: 4229 teacher: 0 stage: sketch lr: 0.000680\n",
      "batch 500 loss: 0.79698 acc: 0.76660 | v_loss: 0.74750 v_acc: 0.77376 |  iteration: 4230 teacher: 0 stage: sketch lr: 0.000680\n",
      "batch 501 loss: 0.80925 acc: 0.76628 | v_loss: 0.81027 v_acc: 0.76855 |  iteration: 4231 teacher: 0 stage: sketch lr: 0.000679\n",
      "batch 502 loss: 0.84941 acc: 0.75391 | v_loss: 0.77687 v_acc: 0.76530 |  iteration: 4232 teacher: 0 stage: sketch lr: 0.000679\n",
      "batch 503 loss: 0.72661 acc: 0.77930 | v_loss: 0.74446 v_acc: 0.77214 |  iteration: 4233 teacher: 1 stage: sketch lr: 0.000679\n",
      "batch 504 loss: 0.82588 acc: 0.76107 | v_loss: 0.77273 v_acc: 0.78125 |  iteration: 4234 teacher: 1 stage: sketch lr: 0.000679\n",
      "batch 505 loss: 0.80649 acc: 0.76693 | v_loss: 0.62234 v_acc: 0.79069 |  iteration: 4235 teacher: 0 stage: sketch lr: 0.000679\n",
      "batch 506 loss: 0.75624 acc: 0.76921 | v_loss: 0.68736 v_acc: 0.79036 |  iteration: 4236 teacher: 0 stage: sketch lr: 0.000679\n",
      "batch 507 loss: 0.70915 acc: 0.78288 | v_loss: 0.76344 v_acc: 0.76595 |  iteration: 4237 teacher: 1 stage: sketch lr: 0.000679\n",
      "batch 508 loss: 0.81681 acc: 0.75684 | v_loss: 0.78026 v_acc: 0.77376 |  iteration: 4238 teacher: 0 stage: sketch lr: 0.000679\n",
      "batch 509 loss: 0.72451 acc: 0.77214 | v_loss: 0.80343 v_acc: 0.76790 |  iteration: 4239 teacher: 1 stage: sketch lr: 0.000679\n",
      "batch 510 loss: 0.68052 acc: 0.79850 | v_loss: 0.65209 v_acc: 0.79720 |  iteration: 4240 teacher: 1 stage: sketch lr: 0.000679\n",
      "batch 511 loss: 0.71851 acc: 0.77865 | v_loss: 0.77748 v_acc: 0.77507 |  iteration: 4241 teacher: 0 stage: sketch lr: 0.000679\n",
      "batch 512 loss: 0.81007 acc: 0.75977 | v_loss: 0.74509 v_acc: 0.77051 |  iteration: 4242 teacher: 0 stage: sketch lr: 0.000679\n",
      "batch 513 loss: 0.78777 acc: 0.76237 | v_loss: 0.76391 v_acc: 0.77083 |  iteration: 4243 teacher: 1 stage: sketch lr: 0.000678\n",
      "batch 514 loss: 0.85053 acc: 0.76074 | v_loss: 0.63378 v_acc: 0.79948 |  iteration: 4244 teacher: 1 stage: sketch lr: 0.000678\n",
      "batch 515 loss: 0.82217 acc: 0.76042 | v_loss: 0.64247 v_acc: 0.81185 |  iteration: 4245 teacher: 0 stage: sketch lr: 0.000678\n",
      "batch 516 loss: 0.87128 acc: 0.75098 | v_loss: 0.65782 v_acc: 0.79167 |  iteration: 4246 teacher: 0 stage: sketch lr: 0.000678\n",
      "batch 517 loss: 0.71623 acc: 0.77507 | v_loss: 0.72288 v_acc: 0.77214 |  iteration: 4247 teacher: 1 stage: sketch lr: 0.000678\n",
      "batch 518 loss: 0.78117 acc: 0.75911 | v_loss: 0.82384 v_acc: 0.74447 |  iteration: 4248 teacher: 1 stage: sketch lr: 0.000678\n",
      "batch 519 loss: 0.89674 acc: 0.74349 | v_loss: 0.71093 v_acc: 0.77637 |  iteration: 4249 teacher: 0 stage: sketch lr: 0.000678\n",
      "batch 520 loss: 0.82152 acc: 0.76400 | v_loss: 0.75616 v_acc: 0.78874 |  iteration: 4250 teacher: 0 stage: sketch lr: 0.000678\n",
      "batch 521 loss: 0.72870 acc: 0.77897 | v_loss: 0.82096 v_acc: 0.76693 |  iteration: 4251 teacher: 0 stage: sketch lr: 0.000678\n",
      "batch 522 loss: 0.79206 acc: 0.77279 | v_loss: 0.85330 v_acc: 0.75195 |  iteration: 4252 teacher: 0 stage: sketch lr: 0.000678\n",
      "batch 523 loss: 0.78150 acc: 0.76921 | v_loss: 0.69892 v_acc: 0.78678 |  iteration: 4253 teacher: 1 stage: sketch lr: 0.000678\n",
      "batch 524 loss: 0.65793 acc: 0.79427 | v_loss: 0.73298 v_acc: 0.77507 |  iteration: 4254 teacher: 1 stage: sketch lr: 0.000678\n",
      "batch 525 loss: 0.78351 acc: 0.76758 | v_loss: 0.63555 v_acc: 0.79232 |  iteration: 4255 teacher: 1 stage: sketch lr: 0.000678\n",
      "batch 526 loss: 0.84205 acc: 0.75586 | v_loss: 0.72843 v_acc: 0.78255 |  iteration: 4256 teacher: 0 stage: sketch lr: 0.000677\n",
      "batch 527 loss: 0.80411 acc: 0.77181 | v_loss: 0.69804 v_acc: 0.78581 |  iteration: 4257 teacher: 0 stage: sketch lr: 0.000677\n",
      "batch 528 loss: 0.78331 acc: 0.77474 | v_loss: 0.80948 v_acc: 0.76432 |  iteration: 4258 teacher: 1 stage: sketch lr: 0.000677\n",
      "batch 529 loss: 0.75456 acc: 0.76562 | v_loss: 0.76516 v_acc: 0.76660 |  iteration: 4259 teacher: 1 stage: sketch lr: 0.000677\n",
      "batch 530 loss: 0.78049 acc: 0.76465 | v_loss: 0.72956 v_acc: 0.76693 |  iteration: 4260 teacher: 0 stage: sketch lr: 0.000677\n",
      "batch 531 loss: 0.91723 acc: 0.74251 | v_loss: 0.72653 v_acc: 0.78516 |  iteration: 4261 teacher: 0 stage: sketch lr: 0.000677\n",
      "batch 532 loss: 0.69830 acc: 0.78255 | v_loss: 0.70577 v_acc: 0.78385 |  iteration: 4262 teacher: 1 stage: sketch lr: 0.000677\n",
      "batch 533 loss: 0.81122 acc: 0.76953 | v_loss: 0.94639 v_acc: 0.71615 |  iteration: 4263 teacher: 0 stage: sketch lr: 0.000677\n",
      "batch 534 loss: 0.73682 acc: 0.77083 | v_loss: 0.73944 v_acc: 0.77474 |  iteration: 4264 teacher: 0 stage: sketch lr: 0.000677\n",
      "batch 535 loss: 0.70999 acc: 0.78027 | v_loss: 0.74103 v_acc: 0.77604 |  iteration: 4265 teacher: 1 stage: sketch lr: 0.000677\n",
      "batch 536 loss: 0.78036 acc: 0.76725 | v_loss: 0.67726 v_acc: 0.80111 |  iteration: 4266 teacher: 0 stage: sketch lr: 0.000677\n",
      "batch 537 loss: 0.83607 acc: 0.75781 | v_loss: 0.72167 v_acc: 0.78776 |  iteration: 4267 teacher: 0 stage: sketch lr: 0.000677\n",
      "batch 538 loss: 0.77709 acc: 0.76302 | v_loss: 0.65544 v_acc: 0.80436 |  iteration: 4268 teacher: 0 stage: sketch lr: 0.000676\n",
      "batch 539 loss: 0.66314 acc: 0.78646 | v_loss: 0.78888 v_acc: 0.77799 |  iteration: 4269 teacher: 1 stage: sketch lr: 0.000676\n",
      "batch 540 loss: 0.85893 acc: 0.75065 | v_loss: 0.71495 v_acc: 0.78027 |  iteration: 4270 teacher: 1 stage: sketch lr: 0.000676\n",
      "batch 541 loss: 0.77026 acc: 0.76855 | v_loss: 0.88263 v_acc: 0.74251 |  iteration: 4271 teacher: 0 stage: sketch lr: 0.000676\n",
      "batch 542 loss: 0.83973 acc: 0.75684 | v_loss: 0.78352 v_acc: 0.76953 |  iteration: 4272 teacher: 0 stage: sketch lr: 0.000676\n",
      "batch 543 loss: 0.69560 acc: 0.77767 | v_loss: 0.79881 v_acc: 0.77116 |  iteration: 4273 teacher: 1 stage: sketch lr: 0.000676\n",
      "batch 544 loss: 0.65749 acc: 0.79134 | v_loss: 0.77989 v_acc: 0.76953 |  iteration: 4274 teacher: 1 stage: sketch lr: 0.000676\n",
      "batch 545 loss: 0.69909 acc: 0.78841 | v_loss: 0.72873 v_acc: 0.77995 |  iteration: 4275 teacher: 0 stage: sketch lr: 0.000676\n",
      "batch 546 loss: 0.68755 acc: 0.78255 | v_loss: 0.80665 v_acc: 0.77018 |  iteration: 4276 teacher: 1 stage: sketch lr: 0.000676\n",
      "batch 547 loss: 0.78302 acc: 0.76758 | v_loss: 0.67460 v_acc: 0.79818 |  iteration: 4277 teacher: 0 stage: sketch lr: 0.000676\n",
      "batch 548 loss: 0.75276 acc: 0.77572 | v_loss: 0.72798 v_acc: 0.77767 |  iteration: 4278 teacher: 0 stage: sketch lr: 0.000676\n",
      "batch 549 loss: 0.76003 acc: 0.78190 | v_loss: 0.71912 v_acc: 0.77865 |  iteration: 4279 teacher: 0 stage: sketch lr: 0.000676\n",
      "batch 550 loss: 0.92672 acc: 0.74674 | v_loss: 0.67615 v_acc: 0.79329 |  iteration: 4280 teacher: 1 stage: sketch lr: 0.000676\n",
      "batch 551 loss: 0.77391 acc: 0.76497 | v_loss: 0.64548 v_acc: 0.79069 |  iteration: 4281 teacher: 0 stage: sketch lr: 0.000675\n",
      "batch 552 loss: 0.83588 acc: 0.76107 | v_loss: 0.79313 v_acc: 0.76888 |  iteration: 4282 teacher: 1 stage: sketch lr: 0.000675\n",
      "batch 553 loss: 0.77547 acc: 0.77279 | v_loss: 0.85595 v_acc: 0.75618 |  iteration: 4283 teacher: 1 stage: sketch lr: 0.000675\n",
      "batch 554 loss: 0.92532 acc: 0.73763 | v_loss: 0.74523 v_acc: 0.76009 |  iteration: 4284 teacher: 1 stage: sketch lr: 0.000675\n",
      "batch 555 loss: 0.75337 acc: 0.77604 | v_loss: 0.83207 v_acc: 0.76139 |  iteration: 4285 teacher: 1 stage: sketch lr: 0.000675\n",
      "batch 556 loss: 0.83856 acc: 0.74544 | v_loss: 0.66290 v_acc: 0.77637 |  iteration: 4286 teacher: 1 stage: sketch lr: 0.000675\n",
      "batch 557 loss: 0.71684 acc: 0.77702 | v_loss: 0.73921 v_acc: 0.78190 |  iteration: 4287 teacher: 1 stage: sketch lr: 0.000675\n",
      "batch 558 loss: 0.73673 acc: 0.77669 | v_loss: 0.66246 v_acc: 0.80208 |  iteration: 4288 teacher: 0 stage: sketch lr: 0.000675\n",
      "batch 559 loss: 0.82909 acc: 0.75065 | v_loss: 0.65573 v_acc: 0.79622 |  iteration: 4289 teacher: 0 stage: sketch lr: 0.000675\n",
      "batch 560 loss: 0.82939 acc: 0.75781 | v_loss: 0.83790 v_acc: 0.77702 |  iteration: 4290 teacher: 0 stage: sketch lr: 0.000675\n",
      "batch 561 loss: 0.73281 acc: 0.76855 | v_loss: 0.64381 v_acc: 0.79004 |  iteration: 4291 teacher: 1 stage: sketch lr: 0.000675\n",
      "batch 562 loss: 0.74567 acc: 0.77669 | v_loss: 0.73198 v_acc: 0.77637 |  iteration: 4292 teacher: 0 stage: sketch lr: 0.000675\n",
      "batch 563 loss: 0.79809 acc: 0.76335 | v_loss: 0.67748 v_acc: 0.79134 |  iteration: 4293 teacher: 0 stage: sketch lr: 0.000675\n",
      "batch 564 loss: 0.83477 acc: 0.76074 | v_loss: 0.67189 v_acc: 0.79264 |  iteration: 4294 teacher: 0 stage: sketch lr: 0.000674\n",
      "batch 565 loss: 0.76597 acc: 0.76758 | v_loss: 0.77613 v_acc: 0.77767 |  iteration: 4295 teacher: 1 stage: sketch lr: 0.000674\n",
      "batch 566 loss: 0.74756 acc: 0.77441 | v_loss: 0.75060 v_acc: 0.77507 |  iteration: 4296 teacher: 1 stage: sketch lr: 0.000674\n",
      "batch 567 loss: 0.85191 acc: 0.75879 | v_loss: 0.69747 v_acc: 0.80306 |  iteration: 4297 teacher: 0 stage: sketch lr: 0.000674\n",
      "batch 568 loss: 0.82067 acc: 0.75977 | v_loss: 0.77421 v_acc: 0.76204 |  iteration: 4298 teacher: 0 stage: sketch lr: 0.000674\n",
      "batch 569 loss: 0.86054 acc: 0.75195 | v_loss: 0.66788 v_acc: 0.79785 |  iteration: 4299 teacher: 0 stage: sketch lr: 0.000674\n",
      "batch 570 loss: 0.75185 acc: 0.76823 | v_loss: 0.89345 v_acc: 0.75586 |  iteration: 4300 teacher: 1 stage: sketch lr: 0.000674\n",
      "batch 571 loss: 0.82998 acc: 0.75684 | v_loss: 0.68783 v_acc: 0.77930 |  iteration: 4301 teacher: 0 stage: sketch lr: 0.000674\n",
      "batch 572 loss: 0.80166 acc: 0.77669 | v_loss: 0.72514 v_acc: 0.77604 |  iteration: 4302 teacher: 0 stage: sketch lr: 0.000674\n",
      "batch 573 loss: 0.87295 acc: 0.75814 | v_loss: 0.69073 v_acc: 0.79134 |  iteration: 4303 teacher: 0 stage: sketch lr: 0.000674\n",
      "batch 574 loss: 0.78250 acc: 0.76042 | v_loss: 0.80044 v_acc: 0.75488 |  iteration: 4304 teacher: 1 stage: sketch lr: 0.000674\n",
      "batch 575 loss: 0.78338 acc: 0.76823 | v_loss: 0.62746 v_acc: 0.79850 |  iteration: 4305 teacher: 1 stage: sketch lr: 0.000674\n",
      "batch 576 loss: 0.79830 acc: 0.75977 | v_loss: 0.68026 v_acc: 0.79395 |  iteration: 4306 teacher: 1 stage: sketch lr: 0.000673\n",
      "batch 577 loss: 0.63693 acc: 0.80306 | v_loss: 0.70125 v_acc: 0.77962 |  iteration: 4307 teacher: 1 stage: sketch lr: 0.000673\n",
      "batch 578 loss: 0.75883 acc: 0.77409 | v_loss: 0.84139 v_acc: 0.75293 |  iteration: 4308 teacher: 1 stage: sketch lr: 0.000673\n",
      "batch 579 loss: 0.83270 acc: 0.74740 | v_loss: 0.69472 v_acc: 0.77799 |  iteration: 4309 teacher: 0 stage: sketch lr: 0.000673\n",
      "batch 580 loss: 0.89205 acc: 0.75033 | v_loss: 0.76751 v_acc: 0.75781 |  iteration: 4310 teacher: 0 stage: sketch lr: 0.000673\n",
      "batch 581 loss: 0.60400 acc: 0.80794 | v_loss: 0.74726 v_acc: 0.78092 |  iteration: 4311 teacher: 1 stage: sketch lr: 0.000673\n",
      "batch 582 loss: 0.74309 acc: 0.77214 | v_loss: 0.78776 v_acc: 0.76335 |  iteration: 4312 teacher: 0 stage: sketch lr: 0.000673\n",
      "batch 583 loss: 0.65398 acc: 0.78971 | v_loss: 0.75095 v_acc: 0.76367 |  iteration: 4313 teacher: 1 stage: sketch lr: 0.000673\n",
      "batch 584 loss: 0.75376 acc: 0.76693 | v_loss: 0.84003 v_acc: 0.76302 |  iteration: 4314 teacher: 0 stage: sketch lr: 0.000673\n",
      "batch 585 loss: 0.75032 acc: 0.77604 | v_loss: 0.81399 v_acc: 0.75293 |  iteration: 4315 teacher: 1 stage: sketch lr: 0.000673\n",
      "batch 586 loss: 0.80449 acc: 0.76562 | v_loss: 0.68042 v_acc: 0.78451 |  iteration: 4316 teacher: 1 stage: sketch lr: 0.000673\n",
      "batch 587 loss: 0.91889 acc: 0.75618 | v_loss: 0.80522 v_acc: 0.76335 |  iteration: 4317 teacher: 1 stage: sketch lr: 0.000673\n",
      "batch 588 loss: 0.78614 acc: 0.77279 | v_loss: 0.72784 v_acc: 0.77930 |  iteration: 4318 teacher: 0 stage: sketch lr: 0.000673\n",
      "batch 589 loss: 0.77055 acc: 0.76530 | v_loss: 0.82505 v_acc: 0.75228 |  iteration: 4319 teacher: 0 stage: sketch lr: 0.000672\n",
      "batch 590 loss: 0.74412 acc: 0.77572 | v_loss: 0.72575 v_acc: 0.77930 |  iteration: 4320 teacher: 0 stage: sketch lr: 0.000672\n",
      "batch 591 loss: 0.74591 acc: 0.77214 | v_loss: 0.74044 v_acc: 0.77279 |  iteration: 4321 teacher: 0 stage: sketch lr: 0.000672\n",
      "batch 592 loss: 0.73807 acc: 0.77669 | v_loss: 0.79873 v_acc: 0.77604 |  iteration: 4322 teacher: 1 stage: sketch lr: 0.000672\n",
      "batch 593 loss: 0.70304 acc: 0.77865 | v_loss: 0.75309 v_acc: 0.76888 |  iteration: 4323 teacher: 1 stage: sketch lr: 0.000672\n",
      "batch 594 loss: 0.68607 acc: 0.78255 | v_loss: 0.71108 v_acc: 0.77865 |  iteration: 4324 teacher: 1 stage: sketch lr: 0.000672\n",
      "batch 595 loss: 0.80895 acc: 0.76204 | v_loss: 0.72289 v_acc: 0.78646 |  iteration: 4325 teacher: 0 stage: sketch lr: 0.000672\n",
      "batch 596 loss: 0.86125 acc: 0.74609 | v_loss: 0.60007 v_acc: 0.80111 |  iteration: 4326 teacher: 0 stage: sketch lr: 0.000672\n",
      "batch 597 loss: 0.80736 acc: 0.76986 | v_loss: 0.67249 v_acc: 0.79264 |  iteration: 4327 teacher: 0 stage: sketch lr: 0.000672\n",
      "batch 598 loss: 0.69145 acc: 0.78288 | v_loss: 0.73825 v_acc: 0.76855 |  iteration: 4328 teacher: 1 stage: sketch lr: 0.000672\n",
      "batch 599 loss: 0.83969 acc: 0.75977 | v_loss: 0.76509 v_acc: 0.77767 |  iteration: 4329 teacher: 0 stage: sketch lr: 0.000672\n",
      "batch 600 loss: 0.73136 acc: 0.77637 | v_loss: 0.80018 v_acc: 0.76237 |  iteration: 4330 teacher: 1 stage: sketch lr: 0.000672\n",
      "batch 601 loss: 0.81009 acc: 0.75846 | v_loss: 0.65012 v_acc: 0.78743 |  iteration: 4331 teacher: 0 stage: sketch lr: 0.000672\n",
      "batch 602 loss: 0.64103 acc: 0.79232 | v_loss: 0.75330 v_acc: 0.78190 |  iteration: 4332 teacher: 1 stage: sketch lr: 0.000671\n",
      "batch 603 loss: 0.79159 acc: 0.77311 | v_loss: 0.73262 v_acc: 0.77669 |  iteration: 4333 teacher: 1 stage: sketch lr: 0.000671\n",
      "batch 604 loss: 0.72670 acc: 0.78125 | v_loss: 0.77039 v_acc: 0.76953 |  iteration: 4334 teacher: 1 stage: sketch lr: 0.000671\n",
      "batch 605 loss: 0.80730 acc: 0.77409 | v_loss: 0.62136 v_acc: 0.79622 |  iteration: 4335 teacher: 0 stage: sketch lr: 0.000671\n",
      "batch 606 loss: 0.84724 acc: 0.76562 | v_loss: 0.62260 v_acc: 0.80534 |  iteration: 4336 teacher: 0 stage: sketch lr: 0.000671\n",
      "batch 607 loss: 0.82182 acc: 0.76042 | v_loss: 0.68048 v_acc: 0.79199 |  iteration: 4337 teacher: 0 stage: sketch lr: 0.000671\n",
      "batch 608 loss: 0.68218 acc: 0.78971 | v_loss: 0.70133 v_acc: 0.78190 |  iteration: 4338 teacher: 1 stage: sketch lr: 0.000671\n",
      "batch 609 loss: 0.73688 acc: 0.77116 | v_loss: 0.79896 v_acc: 0.75618 |  iteration: 4339 teacher: 1 stage: sketch lr: 0.000671\n",
      "batch 610 loss: 0.71917 acc: 0.77279 | v_loss: 0.67630 v_acc: 0.78743 |  iteration: 4340 teacher: 0 stage: sketch lr: 0.000671\n",
      "batch 611 loss: 0.68109 acc: 0.79427 | v_loss: 0.75719 v_acc: 0.78646 |  iteration: 4341 teacher: 1 stage: sketch lr: 0.000671\n",
      "batch 612 loss: 0.60055 acc: 0.80794 | v_loss: 0.82392 v_acc: 0.76725 |  iteration: 4342 teacher: 1 stage: sketch lr: 0.000671\n",
      "batch 613 loss: 0.77846 acc: 0.77669 | v_loss: 0.87094 v_acc: 0.74772 |  iteration: 4343 teacher: 1 stage: sketch lr: 0.000671\n",
      "batch 614 loss: 0.67227 acc: 0.79785 | v_loss: 0.69493 v_acc: 0.78906 |  iteration: 4344 teacher: 1 stage: sketch lr: 0.000671\n",
      "batch 615 loss: 0.58891 acc: 0.80827 | v_loss: 0.70506 v_acc: 0.78776 |  iteration: 4345 teacher: 1 stage: sketch lr: 0.000670\n",
      "batch 616 loss: 0.71138 acc: 0.77865 | v_loss: 0.60642 v_acc: 0.79883 |  iteration: 4346 teacher: 1 stage: sketch lr: 0.000670\n",
      "batch 617 loss: 0.82738 acc: 0.75846 | v_loss: 0.71080 v_acc: 0.78223 |  iteration: 4347 teacher: 0 stage: sketch lr: 0.000670\n",
      "batch 618 loss: 0.72788 acc: 0.77995 | v_loss: 0.68644 v_acc: 0.78711 |  iteration: 4348 teacher: 1 stage: sketch lr: 0.000670\n",
      "batch 619 loss: 0.79171 acc: 0.76400 | v_loss: 0.79357 v_acc: 0.76823 |  iteration: 4349 teacher: 0 stage: sketch lr: 0.000670\n",
      "batch 620 loss: 0.72558 acc: 0.77865 | v_loss: 0.73709 v_acc: 0.77897 |  iteration: 4350 teacher: 0 stage: sketch lr: 0.000670\n",
      "batch 621 loss: 0.85015 acc: 0.74935 | v_loss: 0.70665 v_acc: 0.78320 |  iteration: 4351 teacher: 0 stage: sketch lr: 0.000670\n",
      "batch 622 loss: 0.76403 acc: 0.77116 | v_loss: 0.70537 v_acc: 0.78841 |  iteration: 4352 teacher: 0 stage: sketch lr: 0.000670\n",
      "batch 623 loss: 0.77246 acc: 0.77507 | v_loss: 0.70168 v_acc: 0.78353 |  iteration: 4353 teacher: 0 stage: sketch lr: 0.000670\n",
      "batch 624 loss: 0.84275 acc: 0.75814 | v_loss: 0.89507 v_acc: 0.72428 |  iteration: 4354 teacher: 1 stage: sketch lr: 0.000670\n",
      "batch 625 loss: 0.82222 acc: 0.75586 | v_loss: 0.72327 v_acc: 0.77279 |  iteration: 4355 teacher: 1 stage: sketch lr: 0.000670\n",
      "batch 626 loss: 0.76152 acc: 0.76367 | v_loss: 0.76198 v_acc: 0.76530 |  iteration: 4356 teacher: 1 stage: sketch lr: 0.000670\n",
      "batch 627 loss: 0.74961 acc: 0.76172 | v_loss: 0.66951 v_acc: 0.79818 |  iteration: 4357 teacher: 0 stage: sketch lr: 0.000670\n",
      "batch 628 loss: 0.72986 acc: 0.77279 | v_loss: 0.70540 v_acc: 0.79199 |  iteration: 4358 teacher: 0 stage: sketch lr: 0.000669\n",
      "batch 629 loss: 0.81631 acc: 0.75814 | v_loss: 0.62873 v_acc: 0.80501 |  iteration: 4359 teacher: 0 stage: sketch lr: 0.000669\n",
      "batch 630 loss: 0.70345 acc: 0.77637 | v_loss: 0.77095 v_acc: 0.77604 |  iteration: 4360 teacher: 1 stage: sketch lr: 0.000669\n",
      "batch 631 loss: 0.72177 acc: 0.78646 | v_loss: 0.69796 v_acc: 0.78646 |  iteration: 4361 teacher: 1 stage: sketch lr: 0.000669\n",
      "batch 632 loss: 0.67337 acc: 0.79362 | v_loss: 0.89103 v_acc: 0.75260 |  iteration: 4362 teacher: 1 stage: sketch lr: 0.000669\n",
      "batch 633 loss: 0.84528 acc: 0.76497 | v_loss: 0.76400 v_acc: 0.76660 |  iteration: 4363 teacher: 1 stage: sketch lr: 0.000669\n",
      "batch 634 loss: 0.76161 acc: 0.77669 | v_loss: 0.76693 v_acc: 0.77246 |  iteration: 4364 teacher: 1 stage: sketch lr: 0.000669\n",
      "batch 635 loss: 0.76727 acc: 0.77572 | v_loss: 0.76147 v_acc: 0.77734 |  iteration: 4365 teacher: 0 stage: sketch lr: 0.000669\n",
      "batch 636 loss: 0.86480 acc: 0.75326 | v_loss: 0.71481 v_acc: 0.78320 |  iteration: 4366 teacher: 0 stage: sketch lr: 0.000669\n",
      "batch 637 loss: 0.69799 acc: 0.77767 | v_loss: 0.78961 v_acc: 0.77572 |  iteration: 4367 teacher: 1 stage: sketch lr: 0.000669\n",
      "batch 638 loss: 0.68654 acc: 0.78841 | v_loss: 0.68205 v_acc: 0.79460 |  iteration: 4368 teacher: 1 stage: sketch lr: 0.000669\n",
      "batch 639 loss: 0.78217 acc: 0.76400 | v_loss: 0.71738 v_acc: 0.78125 |  iteration: 4369 teacher: 0 stage: sketch lr: 0.000669\n",
      "batch 640 loss: 0.82835 acc: 0.76530 | v_loss: 0.69390 v_acc: 0.79004 |  iteration: 4370 teacher: 0 stage: sketch lr: 0.000669\n",
      "batch 641 loss: 0.68540 acc: 0.78548 | v_loss: 0.66691 v_acc: 0.79134 |  iteration: 4371 teacher: 1 stage: sketch lr: 0.000668\n",
      "batch 642 loss: 0.68861 acc: 0.78483 | v_loss: 0.60967 v_acc: 0.79785 |  iteration: 4372 teacher: 1 stage: sketch lr: 0.000668\n",
      "batch 643 loss: 0.74559 acc: 0.77897 | v_loss: 0.78793 v_acc: 0.76790 |  iteration: 4373 teacher: 1 stage: sketch lr: 0.000668\n",
      "batch 644 loss: 0.86033 acc: 0.75911 | v_loss: 0.81959 v_acc: 0.76465 |  iteration: 4374 teacher: 0 stage: sketch lr: 0.000668\n",
      "batch 645 loss: 0.81234 acc: 0.76660 | v_loss: 0.72284 v_acc: 0.76432 |  iteration: 4375 teacher: 0 stage: sketch lr: 0.000668\n",
      "batch 646 loss: 0.61942 acc: 0.79622 | v_loss: 0.81070 v_acc: 0.76790 |  iteration: 4376 teacher: 1 stage: sketch lr: 0.000668\n",
      "batch 647 loss: 0.74790 acc: 0.77962 | v_loss: 0.64448 v_acc: 0.78548 |  iteration: 4377 teacher: 0 stage: sketch lr: 0.000668\n",
      "batch 648 loss: 0.70548 acc: 0.77148 | v_loss: 0.76680 v_acc: 0.76595 |  iteration: 4378 teacher: 0 stage: sketch lr: 0.000668\n",
      "batch 649 loss: 0.76607 acc: 0.77116 | v_loss: 0.65376 v_acc: 0.79948 |  iteration: 4379 teacher: 0 stage: sketch lr: 0.000668\n",
      "batch 650 loss: 0.74295 acc: 0.76595 | v_loss: 0.62308 v_acc: 0.79460 |  iteration: 4380 teacher: 1 stage: sketch lr: 0.000668\n",
      "batch 651 loss: 0.83697 acc: 0.75814 | v_loss: 0.84387 v_acc: 0.77018 |  iteration: 4381 teacher: 0 stage: sketch lr: 0.000668\n",
      "batch 652 loss: 0.70873 acc: 0.77474 | v_loss: 0.61594 v_acc: 0.79297 |  iteration: 4382 teacher: 1 stage: sketch lr: 0.000668\n",
      "batch 653 loss: 0.74334 acc: 0.77376 | v_loss: 0.75340 v_acc: 0.78190 |  iteration: 4383 teacher: 0 stage: sketch lr: 0.000668\n",
      "batch 654 loss: 0.77002 acc: 0.77018 | v_loss: 0.67503 v_acc: 0.78353 |  iteration: 4384 teacher: 0 stage: sketch lr: 0.000667\n",
      "batch 655 loss: 0.71866 acc: 0.77441 | v_loss: 0.66331 v_acc: 0.78451 |  iteration: 4385 teacher: 1 stage: sketch lr: 0.000667\n",
      "batch 656 loss: 0.68310 acc: 0.78809 | v_loss: 0.78660 v_acc: 0.77702 |  iteration: 4386 teacher: 1 stage: sketch lr: 0.000667\n",
      "batch 657 loss: 0.58000 acc: 0.81413 | v_loss: 0.71640 v_acc: 0.79427 |  iteration: 4387 teacher: 1 stage: sketch lr: 0.000667\n",
      "batch 658 loss: 0.70215 acc: 0.77865 | v_loss: 0.66673 v_acc: 0.80404 |  iteration: 4388 teacher: 1 stage: sketch lr: 0.000667\n",
      "batch 659 loss: 0.71364 acc: 0.78288 | v_loss: 0.80794 v_acc: 0.76139 |  iteration: 4389 teacher: 1 stage: sketch lr: 0.000667\n",
      "batch 660 loss: 0.73381 acc: 0.77767 | v_loss: 0.63051 v_acc: 0.80892 |  iteration: 4390 teacher: 0 stage: sketch lr: 0.000667\n",
      "batch 661 loss: 0.78252 acc: 0.77376 | v_loss: 0.88343 v_acc: 0.76725 |  iteration: 4391 teacher: 0 stage: sketch lr: 0.000667\n",
      "batch 662 loss: 0.69596 acc: 0.78939 | v_loss: 0.68529 v_acc: 0.78516 |  iteration: 4392 teacher: 1 stage: sketch lr: 0.000667\n",
      "batch 663 loss: 0.78552 acc: 0.76725 | v_loss: 0.73675 v_acc: 0.77995 |  iteration: 4393 teacher: 0 stage: sketch lr: 0.000667\n",
      "batch 664 loss: 0.71513 acc: 0.78516 | v_loss: 0.67300 v_acc: 0.79102 |  iteration: 4394 teacher: 1 stage: sketch lr: 0.000667\n",
      "batch 665 loss: 0.68559 acc: 0.78841 | v_loss: 0.77239 v_acc: 0.75260 |  iteration: 4395 teacher: 1 stage: sketch lr: 0.000667\n",
      "batch 666 loss: 0.73833 acc: 0.78027 | v_loss: 0.62449 v_acc: 0.79915 |  iteration: 4396 teacher: 0 stage: sketch lr: 0.000667\n",
      "batch 667 loss: 0.71367 acc: 0.77897 | v_loss: 0.69427 v_acc: 0.78939 |  iteration: 4397 teacher: 1 stage: sketch lr: 0.000666\n",
      "batch 668 loss: 0.66578 acc: 0.78809 | v_loss: 0.66138 v_acc: 0.79167 |  iteration: 4398 teacher: 1 stage: sketch lr: 0.000666\n",
      "batch 669 loss: 0.74225 acc: 0.77246 | v_loss: 0.86003 v_acc: 0.75065 |  iteration: 4399 teacher: 0 stage: sketch lr: 0.000666\n",
      "batch 670 loss: 0.79763 acc: 0.75977 | v_loss: 0.66133 v_acc: 0.78874 |  iteration: 4400 teacher: 0 stage: sketch lr: 0.000666\n",
      "batch 671 loss: 0.72979 acc: 0.77539 | v_loss: 0.73617 v_acc: 0.77799 |  iteration: 4401 teacher: 0 stage: sketch lr: 0.000666\n",
      "batch 672 loss: 0.70826 acc: 0.77246 | v_loss: 0.73777 v_acc: 0.78646 |  iteration: 4402 teacher: 0 stage: sketch lr: 0.000666\n",
      "batch 673 loss: 0.70200 acc: 0.78516 | v_loss: 0.75982 v_acc: 0.76953 |  iteration: 4403 teacher: 1 stage: sketch lr: 0.000666\n",
      "batch 674 loss: 0.76299 acc: 0.77181 | v_loss: 0.75276 v_acc: 0.76497 |  iteration: 4404 teacher: 0 stage: sketch lr: 0.000666\n",
      "batch 675 loss: 0.76933 acc: 0.77995 | v_loss: 0.83464 v_acc: 0.76497 |  iteration: 4405 teacher: 0 stage: sketch lr: 0.000666\n",
      "batch 676 loss: 0.66897 acc: 0.79232 | v_loss: 0.77273 v_acc: 0.76562 |  iteration: 4406 teacher: 1 stage: sketch lr: 0.000666\n",
      "batch 677 loss: 0.78988 acc: 0.76367 | v_loss: 0.64778 v_acc: 0.79329 |  iteration: 4407 teacher: 0 stage: sketch lr: 0.000666\n",
      "batch 678 loss: 0.75848 acc: 0.77474 | v_loss: 0.77258 v_acc: 0.77702 |  iteration: 4408 teacher: 0 stage: sketch lr: 0.000666\n",
      "batch 679 loss: 0.66986 acc: 0.78874 | v_loss: 0.71000 v_acc: 0.78646 |  iteration: 4409 teacher: 1 stage: sketch lr: 0.000666\n",
      "batch 680 loss: 0.72424 acc: 0.78288 | v_loss: 0.82856 v_acc: 0.75358 |  iteration: 4410 teacher: 1 stage: sketch lr: 0.000665\n",
      "batch 681 loss: 0.80087 acc: 0.76172 | v_loss: 0.71830 v_acc: 0.77539 |  iteration: 4411 teacher: 0 stage: sketch lr: 0.000665\n",
      "batch 682 loss: 0.80007 acc: 0.76139 | v_loss: 0.72804 v_acc: 0.77865 |  iteration: 4412 teacher: 1 stage: sketch lr: 0.000665\n",
      "batch 683 loss: 0.73993 acc: 0.78255 | v_loss: 0.76991 v_acc: 0.77995 |  iteration: 4413 teacher: 1 stage: sketch lr: 0.000665\n",
      "batch 684 loss: 0.76781 acc: 0.77116 | v_loss: 0.75180 v_acc: 0.77279 |  iteration: 4414 teacher: 1 stage: sketch lr: 0.000665\n",
      "batch 685 loss: 0.73202 acc: 0.77051 | v_loss: 0.72290 v_acc: 0.78288 |  iteration: 4415 teacher: 1 stage: sketch lr: 0.000665\n",
      "batch 686 loss: 0.71396 acc: 0.78092 | v_loss: 0.71651 v_acc: 0.79329 |  iteration: 4416 teacher: 1 stage: sketch lr: 0.000665\n",
      "batch 687 loss: 0.70694 acc: 0.78288 | v_loss: 0.59949 v_acc: 0.80143 |  iteration: 4417 teacher: 1 stage: sketch lr: 0.000665\n",
      "batch 688 loss: 0.73022 acc: 0.78255 | v_loss: 0.66513 v_acc: 0.79427 |  iteration: 4418 teacher: 0 stage: sketch lr: 0.000665\n",
      "batch 689 loss: 0.74866 acc: 0.78027 | v_loss: 0.74711 v_acc: 0.77148 |  iteration: 4419 teacher: 1 stage: sketch lr: 0.000665\n",
      "batch 690 loss: 0.67772 acc: 0.78451 | v_loss: 0.75443 v_acc: 0.77344 |  iteration: 4420 teacher: 1 stage: sketch lr: 0.000665\n",
      "batch 691 loss: 0.63237 acc: 0.80013 | v_loss: 0.80780 v_acc: 0.76953 |  iteration: 4421 teacher: 1 stage: sketch lr: 0.000665\n",
      "batch 692 loss: 0.75181 acc: 0.78223 | v_loss: 0.64603 v_acc: 0.80176 |  iteration: 4422 teacher: 1 stage: sketch lr: 0.000665\n",
      "batch 693 loss: 0.67013 acc: 0.79102 | v_loss: 0.76849 v_acc: 0.77995 |  iteration: 4423 teacher: 1 stage: sketch lr: 0.000665\n",
      "batch 694 loss: 0.75602 acc: 0.77474 | v_loss: 0.76444 v_acc: 0.76823 |  iteration: 4424 teacher: 1 stage: sketch lr: 0.000664\n",
      "batch 695 loss: 0.78289 acc: 0.76139 | v_loss: 0.75738 v_acc: 0.76562 |  iteration: 4425 teacher: 1 stage: sketch lr: 0.000664\n",
      "batch 696 loss: 0.89514 acc: 0.75163 | v_loss: 0.61125 v_acc: 0.80273 |  iteration: 4426 teacher: 0 stage: sketch lr: 0.000664\n",
      "batch 697 loss: 0.83130 acc: 0.76107 | v_loss: 0.61597 v_acc: 0.80697 |  iteration: 4427 teacher: 0 stage: sketch lr: 0.000664\n",
      "batch 698 loss: 0.78219 acc: 0.76790 | v_loss: 0.64978 v_acc: 0.79395 |  iteration: 4428 teacher: 0 stage: sketch lr: 0.000664\n",
      "batch 699 loss: 0.69323 acc: 0.78646 | v_loss: 0.70100 v_acc: 0.77962 |  iteration: 4429 teacher: 1 stage: sketch lr: 0.000664\n",
      "batch 700 loss: 0.72325 acc: 0.77832 | v_loss: 0.80984 v_acc: 0.74674 |  iteration: 4430 teacher: 1 stage: sketch lr: 0.000664\n",
      "batch 701 loss: 0.75611 acc: 0.77799 | v_loss: 0.67918 v_acc: 0.79134 |  iteration: 4431 teacher: 0 stage: sketch lr: 0.000664\n",
      "batch 702 loss: 0.68441 acc: 0.77930 | v_loss: 0.76189 v_acc: 0.78288 |  iteration: 4432 teacher: 1 stage: sketch lr: 0.000664\n",
      "batch 703 loss: 0.76180 acc: 0.76888 | v_loss: 0.79587 v_acc: 0.76497 |  iteration: 4433 teacher: 0 stage: sketch lr: 0.000664\n",
      "batch 704 loss: 0.86187 acc: 0.76790 | v_loss: 0.81653 v_acc: 0.75911 |  iteration: 4434 teacher: 1 stage: sketch lr: 0.000664\n",
      "batch 705 loss: 0.76968 acc: 0.76855 | v_loss: 0.67497 v_acc: 0.79980 |  iteration: 4435 teacher: 0 stage: sketch lr: 0.000664\n",
      "batch 706 loss: 0.75886 acc: 0.77376 | v_loss: 0.72972 v_acc: 0.78158 |  iteration: 4436 teacher: 1 stage: sketch lr: 0.000664\n",
      "batch 707 loss: 0.68028 acc: 0.79492 | v_loss: 0.59697 v_acc: 0.80371 |  iteration: 4437 teacher: 1 stage: sketch lr: 0.000663\n",
      "batch 708 loss: 0.75183 acc: 0.77865 | v_loss: 0.69971 v_acc: 0.79134 |  iteration: 4438 teacher: 0 stage: sketch lr: 0.000663\n",
      "batch 709 loss: 0.78176 acc: 0.77181 | v_loss: 0.66648 v_acc: 0.79395 |  iteration: 4439 teacher: 0 stage: sketch lr: 0.000663\n",
      "batch 710 loss: 0.77470 acc: 0.76921 | v_loss: 0.79057 v_acc: 0.77539 |  iteration: 4440 teacher: 1 stage: sketch lr: 0.000663\n",
      "batch 711 loss: 0.69005 acc: 0.79264 | v_loss: 0.74482 v_acc: 0.78906 |  iteration: 4441 teacher: 1 stage: sketch lr: 0.000663\n",
      "batch 712 loss: 0.75485 acc: 0.77507 | v_loss: 0.73039 v_acc: 0.77279 |  iteration: 4442 teacher: 1 stage: sketch lr: 0.000663\n",
      "batch 713 loss: 0.80612 acc: 0.76530 | v_loss: 0.70189 v_acc: 0.79427 |  iteration: 4443 teacher: 1 stage: sketch lr: 0.000663\n",
      "batch 714 loss: 0.67362 acc: 0.78516 | v_loss: 0.71024 v_acc: 0.78451 |  iteration: 4444 teacher: 1 stage: sketch lr: 0.000663\n",
      "batch 715 loss: 0.76157 acc: 0.77409 | v_loss: 0.90962 v_acc: 0.73926 |  iteration: 4445 teacher: 0 stage: sketch lr: 0.000663\n",
      "batch 716 loss: 0.83362 acc: 0.75326 | v_loss: 0.72334 v_acc: 0.77376 |  iteration: 4446 teacher: 0 stage: sketch lr: 0.000663\n",
      "batch 717 loss: 0.73554 acc: 0.77214 | v_loss: 0.73863 v_acc: 0.77083 |  iteration: 4447 teacher: 0 stage: sketch lr: 0.000663\n",
      "batch 718 loss: 0.66483 acc: 0.79362 | v_loss: 0.67347 v_acc: 0.79167 |  iteration: 4448 teacher: 1 stage: sketch lr: 0.000663\n",
      "batch 719 loss: 0.77928 acc: 0.77246 | v_loss: 0.71968 v_acc: 0.77539 |  iteration: 4449 teacher: 0 stage: sketch lr: 0.000663\n",
      "batch 720 loss: 0.73721 acc: 0.77539 | v_loss: 0.65908 v_acc: 0.80046 |  iteration: 4450 teacher: 0 stage: sketch lr: 0.000662\n",
      "batch 721 loss: 0.79231 acc: 0.75814 | v_loss: 0.76789 v_acc: 0.77799 |  iteration: 4451 teacher: 0 stage: sketch lr: 0.000662\n",
      "batch 722 loss: 0.76149 acc: 0.77246 | v_loss: 0.71254 v_acc: 0.78678 |  iteration: 4452 teacher: 0 stage: sketch lr: 0.000662\n",
      "batch 723 loss: 0.65257 acc: 0.79297 | v_loss: 0.93058 v_acc: 0.74935 |  iteration: 4453 teacher: 1 stage: sketch lr: 0.000662\n",
      "batch 724 loss: 0.69307 acc: 0.79264 | v_loss: 0.75081 v_acc: 0.77799 |  iteration: 4454 teacher: 1 stage: sketch lr: 0.000662\n",
      "batch 725 loss: 0.68111 acc: 0.79915 | v_loss: 0.82302 v_acc: 0.77083 |  iteration: 4455 teacher: 1 stage: sketch lr: 0.000662\n",
      "batch 726 loss: 0.81096 acc: 0.78158 | v_loss: 0.78877 v_acc: 0.77018 |  iteration: 4456 teacher: 0 stage: sketch lr: 0.000662\n",
      "batch 727 loss: 0.75924 acc: 0.76400 | v_loss: 0.73736 v_acc: 0.78255 |  iteration: 4457 teacher: 1 stage: sketch lr: 0.000662\n",
      "batch 728 loss: 0.71854 acc: 0.77995 | v_loss: 0.78650 v_acc: 0.77214 |  iteration: 4458 teacher: 1 stage: sketch lr: 0.000662\n",
      "batch 729 loss: 0.66090 acc: 0.78776 | v_loss: 0.67553 v_acc: 0.79753 |  iteration: 4459 teacher: 1 stage: sketch lr: 0.000662\n",
      "batch 730 loss: 0.75926 acc: 0.77897 | v_loss: 0.71404 v_acc: 0.77767 |  iteration: 4460 teacher: 1 stage: sketch lr: 0.000662\n",
      "batch 731 loss: 0.85731 acc: 0.75684 | v_loss: 0.71764 v_acc: 0.78288 |  iteration: 4461 teacher: 0 stage: sketch lr: 0.000662\n",
      "batch 732 loss: 0.67968 acc: 0.78613 | v_loss: 0.68302 v_acc: 0.79362 |  iteration: 4462 teacher: 1 stage: sketch lr: 0.000662\n",
      "batch 733 loss: 0.63027 acc: 0.79590 | v_loss: 0.63908 v_acc: 0.78776 |  iteration: 4463 teacher: 1 stage: sketch lr: 0.000662\n",
      "batch 734 loss: 0.82136 acc: 0.76237 | v_loss: 0.79270 v_acc: 0.76855 |  iteration: 4464 teacher: 1 stage: sketch lr: 0.000661\n",
      "batch 735 loss: 0.84492 acc: 0.75293 | v_loss: 0.83823 v_acc: 0.75879 |  iteration: 4465 teacher: 0 stage: sketch lr: 0.000661\n",
      "batch 736 loss: 0.83690 acc: 0.75228 | v_loss: 0.73370 v_acc: 0.76530 |  iteration: 4466 teacher: 1 stage: sketch lr: 0.000661\n",
      "batch 737 loss: 0.84860 acc: 0.75423 | v_loss: 0.81305 v_acc: 0.77539 |  iteration: 4467 teacher: 0 stage: sketch lr: 0.000661\n",
      "batch 738 loss: 0.76081 acc: 0.76790 | v_loss: 0.64565 v_acc: 0.78581 |  iteration: 4468 teacher: 0 stage: sketch lr: 0.000661\n",
      "batch 739 loss: 0.79088 acc: 0.76302 | v_loss: 0.74541 v_acc: 0.78125 |  iteration: 4469 teacher: 0 stage: sketch lr: 0.000661\n",
      "batch 740 loss: 0.73180 acc: 0.77604 | v_loss: 0.63056 v_acc: 0.81315 |  iteration: 4470 teacher: 0 stage: sketch lr: 0.000661\n",
      "batch 741 loss: 0.76169 acc: 0.76790 | v_loss: 0.61733 v_acc: 0.79329 |  iteration: 4471 teacher: 0 stage: sketch lr: 0.000661\n",
      "batch 742 loss: 0.77168 acc: 0.76432 | v_loss: 0.84120 v_acc: 0.77018 |  iteration: 4472 teacher: 0 stage: sketch lr: 0.000661\n",
      "batch 743 loss: 0.72126 acc: 0.77897 | v_loss: 0.60878 v_acc: 0.79590 |  iteration: 4473 teacher: 1 stage: sketch lr: 0.000661\n",
      "batch 744 loss: 0.69622 acc: 0.77734 | v_loss: 0.73896 v_acc: 0.77995 |  iteration: 4474 teacher: 1 stage: sketch lr: 0.000661\n",
      "batch 745 loss: 0.65571 acc: 0.79427 | v_loss: 0.66058 v_acc: 0.78776 |  iteration: 4475 teacher: 1 stage: sketch lr: 0.000661\n",
      "batch 746 loss: 0.72603 acc: 0.77930 | v_loss: 0.64189 v_acc: 0.79785 |  iteration: 4476 teacher: 1 stage: sketch lr: 0.000661\n",
      "batch 747 loss: 0.79013 acc: 0.75944 | v_loss: 0.77788 v_acc: 0.77702 |  iteration: 4477 teacher: 0 stage: sketch lr: 0.000660\n",
      "batch 748 loss: 0.82600 acc: 0.76595 | v_loss: 0.71553 v_acc: 0.79102 |  iteration: 4478 teacher: 0 stage: sketch lr: 0.000660\n",
      "batch 749 loss: 0.78901 acc: 0.76172 | v_loss: 0.67197 v_acc: 0.79980 |  iteration: 4479 teacher: 0 stage: sketch lr: 0.000660\n",
      "batch 750 loss: 0.66544 acc: 0.79036 | v_loss: 0.74622 v_acc: 0.76921 |  iteration: 4480 teacher: 1 stage: sketch lr: 0.000660\n",
      "batch 751 loss: 0.72897 acc: 0.77799 | v_loss: 0.63696 v_acc: 0.80111 |  iteration: 4481 teacher: 1 stage: sketch lr: 0.000660\n",
      "batch 752 loss: 0.82108 acc: 0.76237 | v_loss: 0.92042 v_acc: 0.74577 |  iteration: 4482 teacher: 0 stage: sketch lr: 0.000660\n",
      "batch 753 loss: 0.80998 acc: 0.76725 | v_loss: 0.69689 v_acc: 0.77799 |  iteration: 4483 teacher: 0 stage: sketch lr: 0.000660\n",
      "batch 754 loss: 0.77688 acc: 0.77376 | v_loss: 0.73120 v_acc: 0.76855 |  iteration: 4484 teacher: 0 stage: sketch lr: 0.000660\n",
      "batch 755 loss: 0.78600 acc: 0.76790 | v_loss: 0.67653 v_acc: 0.78516 |  iteration: 4485 teacher: 0 stage: sketch lr: 0.000660\n",
      "batch 756 loss: 0.70227 acc: 0.77799 | v_loss: 0.77799 v_acc: 0.75586 |  iteration: 4486 teacher: 0 stage: sketch lr: 0.000660\n",
      "batch 757 loss: 0.67549 acc: 0.78841 | v_loss: 0.64082 v_acc: 0.79915 |  iteration: 4487 teacher: 1 stage: sketch lr: 0.000660\n",
      "batch 758 loss: 0.80274 acc: 0.76302 | v_loss: 0.69452 v_acc: 0.78906 |  iteration: 4488 teacher: 0 stage: sketch lr: 0.000660\n",
      "batch 759 loss: 0.78601 acc: 0.76270 | v_loss: 0.65918 v_acc: 0.79460 |  iteration: 4489 teacher: 1 stage: sketch lr: 0.000660\n",
      "batch 760 loss: 0.78264 acc: 0.76823 | v_loss: 0.82876 v_acc: 0.75618 |  iteration: 4490 teacher: 0 stage: sketch lr: 0.000660\n",
      "batch 761 loss: 0.70342 acc: 0.79004 | v_loss: 0.66077 v_acc: 0.78548 |  iteration: 4491 teacher: 1 stage: sketch lr: 0.000659\n",
      "batch 762 loss: 0.82015 acc: 0.76530 | v_loss: 0.73609 v_acc: 0.77311 |  iteration: 4492 teacher: 0 stage: sketch lr: 0.000659\n",
      "batch 763 loss: 0.76364 acc: 0.76660 | v_loss: 0.72610 v_acc: 0.79102 |  iteration: 4493 teacher: 1 stage: sketch lr: 0.000659\n",
      "batch 764 loss: 0.80721 acc: 0.75326 | v_loss: 0.75822 v_acc: 0.76790 |  iteration: 4494 teacher: 1 stage: sketch lr: 0.000659\n",
      "batch 765 loss: 0.67611 acc: 0.79004 | v_loss: 0.76115 v_acc: 0.76400 |  iteration: 4495 teacher: 1 stage: sketch lr: 0.000659\n",
      "batch 766 loss: 0.72162 acc: 0.77799 | v_loss: 0.84256 v_acc: 0.75977 |  iteration: 4496 teacher: 1 stage: sketch lr: 0.000659\n",
      "batch 767 loss: 0.69139 acc: 0.78060 | v_loss: 0.77413 v_acc: 0.76823 |  iteration: 4497 teacher: 1 stage: sketch lr: 0.000659\n",
      "batch 768 loss: 0.72761 acc: 0.76986 | v_loss: 0.64700 v_acc: 0.79850 |  iteration: 4498 teacher: 0 stage: sketch lr: 0.000659\n",
      "batch 769 loss: 0.83550 acc: 0.75684 | v_loss: 0.78966 v_acc: 0.77474 |  iteration: 4499 teacher: 0 stage: sketch lr: 0.000659\n",
      "batch 770 loss: 0.80672 acc: 0.77214 | v_loss: 0.69367 v_acc: 0.79362 |  iteration: 4500 teacher: 0 stage: sketch lr: 0.000659\n",
      "batch 771 loss: 0.82011 acc: 0.75749 | v_loss: 0.80778 v_acc: 0.75977 |  iteration: 4501 teacher: 0 stage: sketch lr: 0.000659\n",
      "batch 772 loss: 0.79845 acc: 0.76204 | v_loss: 0.72161 v_acc: 0.77507 |  iteration: 4502 teacher: 0 stage: sketch lr: 0.000659\n",
      "batch 773 loss: 0.73118 acc: 0.77148 | v_loss: 0.71909 v_acc: 0.77669 |  iteration: 4503 teacher: 0 stage: sketch lr: 0.000659\n",
      "batch 774 loss: 0.82236 acc: 0.76042 | v_loss: 0.83284 v_acc: 0.77148 |  iteration: 4504 teacher: 1 stage: sketch lr: 0.000659\n",
      "batch 775 loss: 0.70880 acc: 0.78906 | v_loss: 0.75461 v_acc: 0.77083 |  iteration: 4505 teacher: 1 stage: sketch lr: 0.000658\n",
      "batch 776 loss: 0.79294 acc: 0.76758 | v_loss: 0.73914 v_acc: 0.76986 |  iteration: 4506 teacher: 0 stage: sketch lr: 0.000658\n",
      "batch 777 loss: 0.68702 acc: 0.79167 | v_loss: 0.72352 v_acc: 0.78841 |  iteration: 4507 teacher: 1 stage: sketch lr: 0.000658\n",
      "batch 778 loss: 0.86010 acc: 0.74707 | v_loss: 0.61948 v_acc: 0.79590 |  iteration: 4508 teacher: 0 stage: sketch lr: 0.000658\n",
      "batch 779 loss: 0.75445 acc: 0.75879 | v_loss: 0.65673 v_acc: 0.79329 |  iteration: 4509 teacher: 0 stage: sketch lr: 0.000658\n",
      "batch 780 loss: 0.79723 acc: 0.77018 | v_loss: 0.74321 v_acc: 0.76009 |  iteration: 4510 teacher: 0 stage: sketch lr: 0.000658\n",
      "batch 781 loss: 0.87632 acc: 0.75456 | v_loss: 0.77027 v_acc: 0.77637 |  iteration: 4511 teacher: 1 stage: sketch lr: 0.000658\n",
      "batch 782 loss: 0.78646 acc: 0.76758 | v_loss: 0.79562 v_acc: 0.77507 |  iteration: 4512 teacher: 1 stage: sketch lr: 0.000658\n",
      "batch 783 loss: 0.74855 acc: 0.77409 | v_loss: 0.64152 v_acc: 0.79785 |  iteration: 4513 teacher: 0 stage: sketch lr: 0.000658\n",
      "batch 784 loss: 0.80454 acc: 0.77083 | v_loss: 0.77191 v_acc: 0.77799 |  iteration: 4514 teacher: 1 stage: sketch lr: 0.000658\n",
      "batch 785 loss: 0.64875 acc: 0.78711 | v_loss: 0.77484 v_acc: 0.76888 |  iteration: 4515 teacher: 1 stage: sketch lr: 0.000658\n",
      "batch 786 loss: 0.79786 acc: 0.77311 | v_loss: 0.77341 v_acc: 0.76693 |  iteration: 4516 teacher: 0 stage: sketch lr: 0.000658\n",
      "batch 787 loss: 0.75805 acc: 0.76172 | v_loss: 0.60450 v_acc: 0.80534 |  iteration: 4517 teacher: 0 stage: sketch lr: 0.000658\n",
      "batch 788 loss: 0.72849 acc: 0.78353 | v_loss: 0.62285 v_acc: 0.81250 |  iteration: 4518 teacher: 0 stage: sketch lr: 0.000657\n",
      "batch 789 loss: 0.75836 acc: 0.77116 | v_loss: 0.65829 v_acc: 0.79655 |  iteration: 4519 teacher: 0 stage: sketch lr: 0.000657\n",
      "batch 790 loss: 0.77075 acc: 0.76562 | v_loss: 0.68039 v_acc: 0.79557 |  iteration: 4520 teacher: 0 stage: sketch lr: 0.000657\n",
      "batch 791 loss: 0.74775 acc: 0.77539 | v_loss: 0.80834 v_acc: 0.75326 |  iteration: 4521 teacher: 1 stage: sketch lr: 0.000657\n",
      "batch 792 loss: 0.75162 acc: 0.77767 | v_loss: 0.66752 v_acc: 0.79427 |  iteration: 4522 teacher: 1 stage: sketch lr: 0.000657\n",
      "batch 793 loss: 0.70626 acc: 0.78841 | v_loss: 0.72430 v_acc: 0.79199 |  iteration: 4523 teacher: 1 stage: sketch lr: 0.000657\n",
      "batch 794 loss: 0.76592 acc: 0.77214 | v_loss: 0.78424 v_acc: 0.76888 |  iteration: 4524 teacher: 0 stage: sketch lr: 0.000657\n",
      "batch 795 loss: 0.70277 acc: 0.79069 | v_loss: 0.78900 v_acc: 0.76595 |  iteration: 4525 teacher: 1 stage: sketch lr: 0.000657\n",
      "batch 796 loss: 0.77172 acc: 0.76693 | v_loss: 0.68457 v_acc: 0.79622 |  iteration: 4526 teacher: 0 stage: sketch lr: 0.000657\n",
      "batch 797 loss: 0.86160 acc: 0.75423 | v_loss: 0.69347 v_acc: 0.79460 |  iteration: 4527 teacher: 0 stage: sketch lr: 0.000657\n",
      "batch 798 loss: 0.67035 acc: 0.78581 | v_loss: 0.60632 v_acc: 0.79720 |  iteration: 4528 teacher: 1 stage: sketch lr: 0.000657\n",
      "batch 799 loss: 0.68237 acc: 0.78678 | v_loss: 0.69998 v_acc: 0.78939 |  iteration: 4529 teacher: 1 stage: sketch lr: 0.000657\n",
      "batch 800 loss: 0.73634 acc: 0.77897 | v_loss: 0.68569 v_acc: 0.78711 |  iteration: 4530 teacher: 1 stage: sketch lr: 0.000657\n",
      "batch 801 loss: 0.73759 acc: 0.78418 | v_loss: 0.77179 v_acc: 0.77962 |  iteration: 4531 teacher: 1 stage: sketch lr: 0.000657\n",
      "batch 802 loss: 0.74698 acc: 0.77116 | v_loss: 0.73703 v_acc: 0.78288 |  iteration: 4532 teacher: 0 stage: sketch lr: 0.000656\n",
      "batch 803 loss: 0.79907 acc: 0.76335 | v_loss: 0.71286 v_acc: 0.77962 |  iteration: 4533 teacher: 0 stage: sketch lr: 0.000656\n",
      "batch 804 loss: 0.72579 acc: 0.78027 | v_loss: 0.69699 v_acc: 0.78874 |  iteration: 4534 teacher: 0 stage: sketch lr: 0.000656\n",
      "batch 805 loss: 0.74290 acc: 0.77702 | v_loss: 0.69544 v_acc: 0.78223 |  iteration: 4535 teacher: 0 stage: sketch lr: 0.000656\n",
      "batch 806 loss: 0.72481 acc: 0.77799 | v_loss: 0.86294 v_acc: 0.74967 |  iteration: 4536 teacher: 1 stage: sketch lr: 0.000656\n",
      "batch 807 loss: 0.68784 acc: 0.79427 | v_loss: 0.71632 v_acc: 0.78092 |  iteration: 4537 teacher: 1 stage: sketch lr: 0.000656\n",
      "batch 808 loss: 0.71806 acc: 0.78906 | v_loss: 0.72694 v_acc: 0.78451 |  iteration: 4538 teacher: 0 stage: sketch lr: 0.000656\n",
      "batch 809 loss: 0.74617 acc: 0.77279 | v_loss: 0.64052 v_acc: 0.80697 |  iteration: 4539 teacher: 1 stage: sketch lr: 0.000656\n",
      "batch 810 loss: 0.73782 acc: 0.77637 | v_loss: 0.72567 v_acc: 0.78646 |  iteration: 4540 teacher: 1 stage: sketch lr: 0.000656\n",
      "batch 811 loss: 0.81842 acc: 0.75553 | v_loss: 0.62872 v_acc: 0.80501 |  iteration: 4541 teacher: 0 stage: sketch lr: 0.000656\n",
      "batch 812 loss: 0.71037 acc: 0.78516 | v_loss: 0.76796 v_acc: 0.77474 |  iteration: 4542 teacher: 0 stage: sketch lr: 0.000656\n",
      "batch 813 loss: 0.84914 acc: 0.75749 | v_loss: 0.68849 v_acc: 0.79264 |  iteration: 4543 teacher: 0 stage: sketch lr: 0.000656\n",
      "batch 814 loss: 0.68283 acc: 0.78971 | v_loss: 0.87392 v_acc: 0.75618 |  iteration: 4544 teacher: 1 stage: sketch lr: 0.000656\n",
      "batch 815 loss: 0.76684 acc: 0.77734 | v_loss: 0.77646 v_acc: 0.78158 |  iteration: 4545 teacher: 1 stage: sketch lr: 0.000656\n",
      "batch 816 loss: 0.75964 acc: 0.77767 | v_loss: 0.76134 v_acc: 0.77962 |  iteration: 4546 teacher: 1 stage: sketch lr: 0.000655\n",
      "batch 817 loss: 0.65215 acc: 0.79915 | v_loss: 0.75272 v_acc: 0.78385 |  iteration: 4547 teacher: 1 stage: sketch lr: 0.000655\n",
      "batch 818 loss: 0.73797 acc: 0.78841 | v_loss: 0.69860 v_acc: 0.78451 |  iteration: 4548 teacher: 1 stage: sketch lr: 0.000655\n",
      "batch 819 loss: 0.76813 acc: 0.77474 | v_loss: 0.78336 v_acc: 0.78125 |  iteration: 4549 teacher: 0 stage: sketch lr: 0.000655\n",
      "batch 820 loss: 0.72050 acc: 0.78874 | v_loss: 0.64744 v_acc: 0.80534 |  iteration: 4550 teacher: 1 stage: sketch lr: 0.000655\n",
      "batch 821 loss: 0.82376 acc: 0.76367 | v_loss: 0.73694 v_acc: 0.78060 |  iteration: 4551 teacher: 0 stage: sketch lr: 0.000655\n",
      "batch 822 loss: 0.84474 acc: 0.76465 | v_loss: 0.72018 v_acc: 0.77995 |  iteration: 4552 teacher: 0 stage: sketch lr: 0.000655\n",
      "batch 823 loss: 0.61739 acc: 0.80273 | v_loss: 0.67461 v_acc: 0.79948 |  iteration: 4553 teacher: 1 stage: sketch lr: 0.000655\n",
      "batch 824 loss: 0.70509 acc: 0.77865 | v_loss: 0.61934 v_acc: 0.79297 |  iteration: 4554 teacher: 0 stage: sketch lr: 0.000655\n",
      "batch 825 loss: 0.59715 acc: 0.80664 | v_loss: 0.76934 v_acc: 0.77311 |  iteration: 4555 teacher: 1 stage: sketch lr: 0.000655\n",
      "batch 826 loss: 0.77746 acc: 0.76497 | v_loss: 0.81151 v_acc: 0.76758 |  iteration: 4556 teacher: 0 stage: sketch lr: 0.000655\n",
      "batch 827 loss: 0.69399 acc: 0.79004 | v_loss: 0.73207 v_acc: 0.77116 |  iteration: 4557 teacher: 1 stage: sketch lr: 0.000655\n",
      "batch 828 loss: 0.71098 acc: 0.78874 | v_loss: 0.81851 v_acc: 0.78223 |  iteration: 4558 teacher: 1 stage: sketch lr: 0.000655\n",
      "batch 829 loss: 0.73905 acc: 0.77865 | v_loss: 0.64839 v_acc: 0.80306 |  iteration: 4559 teacher: 0 stage: sketch lr: 0.000655\n",
      "batch 830 loss: 0.69975 acc: 0.79329 | v_loss: 0.76137 v_acc: 0.77669 |  iteration: 4560 teacher: 1 stage: sketch lr: 0.000654\n",
      "batch 831 loss: 0.86988 acc: 0.76270 | v_loss: 0.64140 v_acc: 0.80534 |  iteration: 4561 teacher: 0 stage: sketch lr: 0.000654\n",
      "batch 832 loss: 0.75657 acc: 0.77767 | v_loss: 0.61383 v_acc: 0.80306 |  iteration: 4562 teacher: 0 stage: sketch lr: 0.000654\n",
      "batch 833 loss: 0.56887 acc: 0.81022 | v_loss: 0.81566 v_acc: 0.78255 |  iteration: 4563 teacher: 1 stage: sketch lr: 0.000654\n",
      "batch 834 loss: 0.83621 acc: 0.75651 | v_loss: 0.59870 v_acc: 0.79525 |  iteration: 4564 teacher: 0 stage: sketch lr: 0.000654\n",
      "batch 835 loss: 0.70475 acc: 0.78320 | v_loss: 0.74070 v_acc: 0.77799 |  iteration: 4565 teacher: 1 stage: sketch lr: 0.000654\n",
      "batch 836 loss: 0.67018 acc: 0.78516 | v_loss: 0.65874 v_acc: 0.79004 |  iteration: 4566 teacher: 1 stage: sketch lr: 0.000654\n",
      "batch 837 loss: 0.70858 acc: 0.77897 | v_loss: 0.64498 v_acc: 0.79264 |  iteration: 4567 teacher: 1 stage: sketch lr: 0.000654\n",
      "batch 838 loss: 0.86165 acc: 0.75423 | v_loss: 0.79029 v_acc: 0.76074 |  iteration: 4568 teacher: 0 stage: sketch lr: 0.000654\n",
      "batch 839 loss: 0.70115 acc: 0.77962 | v_loss: 0.69617 v_acc: 0.78385 |  iteration: 4569 teacher: 1 stage: sketch lr: 0.000654\n",
      "batch 840 loss: 0.79053 acc: 0.76432 | v_loss: 0.66088 v_acc: 0.80599 |  iteration: 4570 teacher: 0 stage: sketch lr: 0.000654\n",
      "batch 841 loss: 0.70961 acc: 0.78288 | v_loss: 0.75764 v_acc: 0.76432 |  iteration: 4571 teacher: 1 stage: sketch lr: 0.000654\n",
      "batch 842 loss: 0.80681 acc: 0.75944 | v_loss: 0.63200 v_acc: 0.79460 |  iteration: 4572 teacher: 0 stage: sketch lr: 0.000654\n",
      "batch 843 loss: 0.78513 acc: 0.76660 | v_loss: 0.86520 v_acc: 0.75749 |  iteration: 4573 teacher: 0 stage: sketch lr: 0.000654\n",
      "batch 844 loss: 0.69599 acc: 0.78320 | v_loss: 0.69010 v_acc: 0.78451 |  iteration: 4574 teacher: 1 stage: sketch lr: 0.000653\n",
      "batch 845 loss: 0.71870 acc: 0.78451 | v_loss: 0.72520 v_acc: 0.76921 |  iteration: 4575 teacher: 1 stage: sketch lr: 0.000653\n",
      "batch 846 loss: 0.82016 acc: 0.74544 | v_loss: 0.63511 v_acc: 0.80371 |  iteration: 4576 teacher: 0 stage: sketch lr: 0.000653\n",
      "batch 847 loss: 0.60076 acc: 0.80306 | v_loss: 0.76823 v_acc: 0.76465 |  iteration: 4577 teacher: 1 stage: sketch lr: 0.000653\n",
      "batch 848 loss: 0.79100 acc: 0.77344 | v_loss: 0.63346 v_acc: 0.79395 |  iteration: 4578 teacher: 1 stage: sketch lr: 0.000653\n",
      "batch 849 loss: 0.67824 acc: 0.79688 | v_loss: 0.68317 v_acc: 0.79232 |  iteration: 4579 teacher: 1 stage: sketch lr: 0.000653\n",
      "batch 850 loss: 0.60538 acc: 0.79590 | v_loss: 0.69688 v_acc: 0.77702 |  iteration: 4580 teacher: 1 stage: sketch lr: 0.000653\n",
      "batch 851 loss: 0.73233 acc: 0.77409 | v_loss: 0.80641 v_acc: 0.76270 |  iteration: 4581 teacher: 0 stage: sketch lr: 0.000653\n",
      "batch 852 loss: 0.73731 acc: 0.77572 | v_loss: 0.65949 v_acc: 0.78223 |  iteration: 4582 teacher: 0 stage: sketch lr: 0.000653\n",
      "batch 853 loss: 0.77138 acc: 0.77116 | v_loss: 0.74609 v_acc: 0.76562 |  iteration: 4583 teacher: 0 stage: sketch lr: 0.000653\n",
      "batch 854 loss: 0.79272 acc: 0.75879 | v_loss: 0.71903 v_acc: 0.78548 |  iteration: 4584 teacher: 1 stage: sketch lr: 0.000653\n",
      "batch 855 loss: 0.71832 acc: 0.77767 | v_loss: 0.77653 v_acc: 0.76465 |  iteration: 4585 teacher: 1 stage: sketch lr: 0.000653\n",
      "batch 856 loss: 0.79406 acc: 0.78158 | v_loss: 0.77055 v_acc: 0.75749 |  iteration: 4586 teacher: 1 stage: sketch lr: 0.000653\n",
      "batch 857 loss: 0.78832 acc: 0.76270 | v_loss: 0.81295 v_acc: 0.76432 |  iteration: 4587 teacher: 1 stage: sketch lr: 0.000653\n",
      "batch 858 loss: 0.76949 acc: 0.77930 | v_loss: 0.77347 v_acc: 0.75911 |  iteration: 4588 teacher: 0 stage: sketch lr: 0.000652\n",
      "batch 859 loss: 0.84799 acc: 0.75260 | v_loss: 0.66670 v_acc: 0.79525 |  iteration: 4589 teacher: 0 stage: sketch lr: 0.000652\n",
      "batch 860 loss: 0.84306 acc: 0.75944 | v_loss: 0.79314 v_acc: 0.77116 |  iteration: 4590 teacher: 0 stage: sketch lr: 0.000652\n",
      "batch 861 loss: 0.77627 acc: 0.77572 | v_loss: 0.72238 v_acc: 0.78939 |  iteration: 4591 teacher: 0 stage: sketch lr: 0.000652\n",
      "batch 862 loss: 0.82756 acc: 0.76465 | v_loss: 0.83627 v_acc: 0.75651 |  iteration: 4592 teacher: 1 stage: sketch lr: 0.000652\n",
      "batch 863 loss: 0.83978 acc: 0.76074 | v_loss: 0.72571 v_acc: 0.77344 |  iteration: 4593 teacher: 0 stage: sketch lr: 0.000652\n",
      "batch 864 loss: 0.76506 acc: 0.77148 | v_loss: 0.72591 v_acc: 0.77669 |  iteration: 4594 teacher: 1 stage: sketch lr: 0.000652\n",
      "batch 865 loss: 0.76700 acc: 0.77116 | v_loss: 0.79244 v_acc: 0.78385 |  iteration: 4595 teacher: 0 stage: sketch lr: 0.000652\n",
      "batch 866 loss: 0.80672 acc: 0.76335 | v_loss: 0.75918 v_acc: 0.77669 |  iteration: 4596 teacher: 0 stage: sketch lr: 0.000652\n",
      "batch 867 loss: 0.74709 acc: 0.77702 | v_loss: 0.76090 v_acc: 0.77344 |  iteration: 4597 teacher: 1 stage: sketch lr: 0.000652\n",
      "batch 868 loss: 0.64660 acc: 0.80599 | v_loss: 0.71508 v_acc: 0.79102 |  iteration: 4598 teacher: 1 stage: sketch lr: 0.000652\n",
      "batch 869 loss: 0.79878 acc: 0.76953 | v_loss: 0.61081 v_acc: 0.79264 |  iteration: 4599 teacher: 0 stage: sketch lr: 0.000652\n",
      "batch 870 loss: 0.90176 acc: 0.75553 | v_loss: 0.66032 v_acc: 0.79460 |  iteration: 4600 teacher: 0 stage: sketch lr: 0.000652\n",
      "batch 871 loss: 0.79413 acc: 0.76302 | v_loss: 0.71912 v_acc: 0.77897 |  iteration: 4601 teacher: 0 stage: sketch lr: 0.000652\n",
      "batch 872 loss: 0.68164 acc: 0.79167 | v_loss: 0.73505 v_acc: 0.77930 |  iteration: 4602 teacher: 0 stage: sketch lr: 0.000651\n",
      "batch 873 loss: 0.64214 acc: 0.80078 | v_loss: 0.80093 v_acc: 0.77018 |  iteration: 4603 teacher: 1 stage: sketch lr: 0.000651\n",
      "batch 874 loss: 0.69620 acc: 0.78613 | v_loss: 0.64843 v_acc: 0.79688 |  iteration: 4604 teacher: 1 stage: sketch lr: 0.000651\n",
      "batch 875 loss: 0.72944 acc: 0.77604 | v_loss: 0.77546 v_acc: 0.77897 |  iteration: 4605 teacher: 1 stage: sketch lr: 0.000651\n",
      "batch 876 loss: 0.68763 acc: 0.78385 | v_loss: 0.75408 v_acc: 0.77604 |  iteration: 4606 teacher: 1 stage: sketch lr: 0.000651\n",
      "batch 877 loss: 0.73799 acc: 0.77572 | v_loss: 0.75409 v_acc: 0.77148 |  iteration: 4607 teacher: 1 stage: sketch lr: 0.000651\n",
      "batch 878 loss: 0.71271 acc: 0.78971 | v_loss: 0.60800 v_acc: 0.80697 |  iteration: 4608 teacher: 1 stage: sketch lr: 0.000651\n",
      "batch 879 loss: 0.73397 acc: 0.77865 | v_loss: 0.61515 v_acc: 0.81055 |  iteration: 4609 teacher: 0 stage: sketch lr: 0.000651\n",
      "batch 880 loss: 0.83187 acc: 0.75684 | v_loss: 0.63454 v_acc: 0.79720 |  iteration: 4610 teacher: 0 stage: sketch lr: 0.000651\n",
      "batch 881 loss: 0.83554 acc: 0.76758 | v_loss: 0.67182 v_acc: 0.78581 |  iteration: 4611 teacher: 0 stage: sketch lr: 0.000651\n",
      "batch 882 loss: 0.84865 acc: 0.75944 | v_loss: 0.79782 v_acc: 0.75553 |  iteration: 4612 teacher: 0 stage: sketch lr: 0.000651\n",
      "batch 883 loss: 0.74525 acc: 0.77962 | v_loss: 0.68255 v_acc: 0.79167 |  iteration: 4613 teacher: 1 stage: sketch lr: 0.000651\n",
      "batch 884 loss: 0.76674 acc: 0.76628 | v_loss: 0.74127 v_acc: 0.78743 |  iteration: 4614 teacher: 0 stage: sketch lr: 0.000651\n",
      "batch 885 loss: 0.65455 acc: 0.80143 | v_loss: 0.78153 v_acc: 0.77018 |  iteration: 4615 teacher: 1 stage: sketch lr: 0.000651\n",
      "batch 886 loss: 0.78483 acc: 0.76628 | v_loss: 0.83251 v_acc: 0.74902 |  iteration: 4616 teacher: 0 stage: sketch lr: 0.000650\n",
      "batch 887 loss: 0.79431 acc: 0.76400 | v_loss: 0.68850 v_acc: 0.78223 |  iteration: 4617 teacher: 0 stage: sketch lr: 0.000650\n",
      "batch 888 loss: 0.70876 acc: 0.78092 | v_loss: 0.72007 v_acc: 0.78874 |  iteration: 4618 teacher: 1 stage: sketch lr: 0.000650\n",
      "batch 889 loss: 0.74110 acc: 0.78158 | v_loss: 0.60219 v_acc: 0.80534 |  iteration: 4619 teacher: 0 stage: sketch lr: 0.000650\n",
      "batch 890 loss: 0.66509 acc: 0.80371 | v_loss: 0.68300 v_acc: 0.79427 |  iteration: 4620 teacher: 1 stage: sketch lr: 0.000650\n",
      "batch 891 loss: 0.74697 acc: 0.77116 | v_loss: 0.70027 v_acc: 0.78841 |  iteration: 4621 teacher: 1 stage: sketch lr: 0.000650\n",
      "batch 892 loss: 0.76323 acc: 0.77083 | v_loss: 0.78329 v_acc: 0.76823 |  iteration: 4622 teacher: 1 stage: sketch lr: 0.000650\n",
      "batch 893 loss: 0.78044 acc: 0.77018 | v_loss: 0.73057 v_acc: 0.78223 |  iteration: 4623 teacher: 0 stage: sketch lr: 0.000650\n",
      "batch 894 loss: 0.75570 acc: 0.77474 | v_loss: 0.72870 v_acc: 0.77083 |  iteration: 4624 teacher: 1 stage: sketch lr: 0.000650\n",
      "batch 895 loss: 0.75505 acc: 0.77018 | v_loss: 0.68438 v_acc: 0.79427 |  iteration: 4625 teacher: 1 stage: sketch lr: 0.000650\n",
      "batch 896 loss: 0.65824 acc: 0.79102 | v_loss: 0.69176 v_acc: 0.78548 |  iteration: 4626 teacher: 1 stage: sketch lr: 0.000650\n",
      "batch 897 loss: 0.78103 acc: 0.77116 | v_loss: 0.85248 v_acc: 0.73926 |  iteration: 4627 teacher: 1 stage: sketch lr: 0.000650\n",
      "batch 898 loss: 0.75491 acc: 0.77181 | v_loss: 0.69107 v_acc: 0.78678 |  iteration: 4628 teacher: 1 stage: sketch lr: 0.000650\n",
      "batch 899 loss: 0.75677 acc: 0.77832 | v_loss: 0.70858 v_acc: 0.78060 |  iteration: 4629 teacher: 0 stage: sketch lr: 0.000650\n",
      "batch 900 loss: 0.80456 acc: 0.76953 | v_loss: 0.64471 v_acc: 0.80632 |  iteration: 4630 teacher: 0 stage: sketch lr: 0.000649\n",
      "batch 901 loss: 0.70444 acc: 0.78288 | v_loss: 0.70965 v_acc: 0.79199 |  iteration: 4631 teacher: 0 stage: sketch lr: 0.000649\n",
      "batch 902 loss: 0.75722 acc: 0.77246 | v_loss: 0.63352 v_acc: 0.80469 |  iteration: 4632 teacher: 0 stage: sketch lr: 0.000649\n",
      "batch 903 loss: 0.61254 acc: 0.80957 | v_loss: 0.76726 v_acc: 0.77767 |  iteration: 4633 teacher: 1 stage: sketch lr: 0.000649\n",
      "batch 904 loss: 0.75278 acc: 0.78060 | v_loss: 0.68508 v_acc: 0.79167 |  iteration: 4634 teacher: 0 stage: sketch lr: 0.000649\n",
      "batch 905 loss: 0.69717 acc: 0.78743 | v_loss: 0.87488 v_acc: 0.75879 |  iteration: 4635 teacher: 1 stage: sketch lr: 0.000649\n",
      "batch 906 loss: 0.76438 acc: 0.76953 | v_loss: 0.74863 v_acc: 0.77799 |  iteration: 4636 teacher: 0 stage: sketch lr: 0.000649\n",
      "batch 907 loss: 0.71007 acc: 0.78971 | v_loss: 0.76449 v_acc: 0.77865 |  iteration: 4637 teacher: 0 stage: sketch lr: 0.000649\n",
      "batch 908 loss: 0.72798 acc: 0.78092 | v_loss: 0.77324 v_acc: 0.78027 |  iteration: 4638 teacher: 0 stage: sketch lr: 0.000649\n",
      "batch 909 loss: 0.63193 acc: 0.79948 | v_loss: 0.70174 v_acc: 0.78841 |  iteration: 4639 teacher: 1 stage: sketch lr: 0.000649\n",
      "batch 910 loss: 0.76294 acc: 0.77637 | v_loss: 0.78239 v_acc: 0.77669 |  iteration: 4640 teacher: 0 stage: sketch lr: 0.000649\n",
      "batch 911 loss: 0.80891 acc: 0.76562 | v_loss: 0.65248 v_acc: 0.80469 |  iteration: 4641 teacher: 1 stage: sketch lr: 0.000649\n",
      "batch 912 loss: 0.78871 acc: 0.77051 | v_loss: 0.69793 v_acc: 0.79069 |  iteration: 4642 teacher: 0 stage: sketch lr: 0.000649\n",
      "batch 913 loss: 0.74661 acc: 0.77572 | v_loss: 0.68104 v_acc: 0.79232 |  iteration: 4643 teacher: 0 stage: sketch lr: 0.000649\n",
      "batch 914 loss: 0.74967 acc: 0.77962 | v_loss: 0.67079 v_acc: 0.79427 |  iteration: 4644 teacher: 0 stage: sketch lr: 0.000649\n",
      "batch 915 loss: 0.64567 acc: 0.79622 | v_loss: 0.58579 v_acc: 0.80501 |  iteration: 4645 teacher: 1 stage: sketch lr: 0.000648\n",
      "batch 916 loss: 0.68139 acc: 0.79069 | v_loss: 0.79316 v_acc: 0.76530 |  iteration: 4646 teacher: 1 stage: sketch lr: 0.000648\n",
      "batch 917 loss: 0.86754 acc: 0.75879 | v_loss: 0.81197 v_acc: 0.76367 |  iteration: 4647 teacher: 0 stage: sketch lr: 0.000648\n",
      "batch 918 loss: 0.63364 acc: 0.80892 | v_loss: 0.73793 v_acc: 0.76758 |  iteration: 4648 teacher: 1 stage: sketch lr: 0.000648\n",
      "batch 919 loss: 0.79464 acc: 0.76465 | v_loss: 0.80745 v_acc: 0.77344 |  iteration: 4649 teacher: 0 stage: sketch lr: 0.000648\n",
      "batch 920 loss: 0.78894 acc: 0.77246 | v_loss: 0.63602 v_acc: 0.79362 |  iteration: 4650 teacher: 1 stage: sketch lr: 0.000648\n",
      "batch 921 loss: 0.75168 acc: 0.78158 | v_loss: 0.73895 v_acc: 0.77116 |  iteration: 4651 teacher: 0 stage: sketch lr: 0.000648\n",
      "batch 922 loss: 0.85056 acc: 0.75846 | v_loss: 0.63916 v_acc: 0.81250 |  iteration: 4652 teacher: 0 stage: sketch lr: 0.000648\n",
      "batch 923 loss: 0.64488 acc: 0.79460 | v_loss: 0.59335 v_acc: 0.80664 |  iteration: 4653 teacher: 1 stage: sketch lr: 0.000648\n",
      "batch 924 loss: 0.78710 acc: 0.77116 | v_loss: 0.83008 v_acc: 0.77637 |  iteration: 4654 teacher: 0 stage: sketch lr: 0.000648\n",
      "batch 925 loss: 0.90127 acc: 0.74805 | v_loss: 0.61060 v_acc: 0.79199 |  iteration: 4655 teacher: 0 stage: sketch lr: 0.000648\n",
      "batch 926 loss: 0.80991 acc: 0.75651 | v_loss: 0.76942 v_acc: 0.77799 |  iteration: 4656 teacher: 0 stage: sketch lr: 0.000648\n",
      "batch 927 loss: 0.82994 acc: 0.75781 | v_loss: 0.67507 v_acc: 0.78483 |  iteration: 4657 teacher: 0 stage: sketch lr: 0.000648\n",
      "batch 928 loss: 0.69944 acc: 0.78483 | v_loss: 0.66839 v_acc: 0.79134 |  iteration: 4658 teacher: 1 stage: sketch lr: 0.000648\n",
      "batch 929 loss: 0.80382 acc: 0.76855 | v_loss: 0.79883 v_acc: 0.75716 |  iteration: 4659 teacher: 0 stage: sketch lr: 0.000647\n",
      "batch 930 loss: 0.74002 acc: 0.77018 | v_loss: 0.73227 v_acc: 0.78158 |  iteration: 4660 teacher: 0 stage: sketch lr: 0.000647\n",
      "batch 931 loss: 0.81281 acc: 0.76628 | v_loss: 0.66298 v_acc: 0.80273 |  iteration: 4661 teacher: 0 stage: sketch lr: 0.000647\n",
      "batch 932 loss: 0.80809 acc: 0.76400 | v_loss: 0.76290 v_acc: 0.76562 |  iteration: 4662 teacher: 1 stage: sketch lr: 0.000647\n",
      "batch 933 loss: 0.65410 acc: 0.79688 | v_loss: 0.63514 v_acc: 0.80111 |  iteration: 4663 teacher: 1 stage: sketch lr: 0.000647\n",
      "batch 934 loss: 0.70254 acc: 0.78320 | v_loss: 0.90394 v_acc: 0.75391 |  iteration: 4664 teacher: 0 stage: sketch lr: 0.000647\n",
      "batch 935 loss: 0.68777 acc: 0.79102 | v_loss: 0.68333 v_acc: 0.79199 |  iteration: 4665 teacher: 1 stage: sketch lr: 0.000647\n",
      "batch 936 loss: 0.92737 acc: 0.74512 | v_loss: 0.68852 v_acc: 0.78320 |  iteration: 4666 teacher: 0 stage: sketch lr: 0.000647\n",
      "batch 937 loss: 0.73441 acc: 0.77604 | v_loss: 0.66306 v_acc: 0.79004 |  iteration: 4667 teacher: 1 stage: sketch lr: 0.000647\n",
      "batch 938 loss: 0.75624 acc: 0.77441 | v_loss: 0.81157 v_acc: 0.75358 |  iteration: 4668 teacher: 0 stage: sketch lr: 0.000647\n",
      "batch 939 loss: 0.77210 acc: 0.77018 | v_loss: 0.63167 v_acc: 0.79590 |  iteration: 4669 teacher: 0 stage: sketch lr: 0.000647\n",
      "batch 940 loss: 0.77001 acc: 0.77018 | v_loss: 0.68497 v_acc: 0.78971 |  iteration: 4670 teacher: 0 stage: sketch lr: 0.000647\n",
      "batch 941 loss: 0.61914 acc: 0.80729 | v_loss: 0.66176 v_acc: 0.79199 |  iteration: 4671 teacher: 1 stage: sketch lr: 0.000647\n",
      "batch 942 loss: 0.66563 acc: 0.79232 | v_loss: 0.80062 v_acc: 0.76530 |  iteration: 4672 teacher: 1 stage: sketch lr: 0.000647\n",
      "batch 943 loss: 0.75006 acc: 0.77507 | v_loss: 0.67643 v_acc: 0.78223 |  iteration: 4673 teacher: 1 stage: sketch lr: 0.000646\n",
      "batch 944 loss: 0.70066 acc: 0.79232 | v_loss: 0.73975 v_acc: 0.76562 |  iteration: 4674 teacher: 1 stage: sketch lr: 0.000646\n",
      "batch 945 loss: 0.85316 acc: 0.75163 | v_loss: 0.73200 v_acc: 0.77962 |  iteration: 4675 teacher: 0 stage: sketch lr: 0.000646\n",
      "batch 946 loss: 0.70212 acc: 0.78060 | v_loss: 0.76482 v_acc: 0.76497 |  iteration: 4676 teacher: 1 stage: sketch lr: 0.000646\n",
      "batch 947 loss: 0.67848 acc: 0.78483 | v_loss: 0.72873 v_acc: 0.77051 |  iteration: 4677 teacher: 1 stage: sketch lr: 0.000646\n",
      "batch 948 loss: 0.74921 acc: 0.77962 | v_loss: 0.82228 v_acc: 0.76562 |  iteration: 4678 teacher: 1 stage: sketch lr: 0.000646\n",
      "batch 949 loss: 0.74633 acc: 0.77507 | v_loss: 0.77732 v_acc: 0.76693 |  iteration: 4679 teacher: 0 stage: sketch lr: 0.000646\n",
      "batch 950 loss: 0.79430 acc: 0.76530 | v_loss: 0.64420 v_acc: 0.79850 |  iteration: 4680 teacher: 1 stage: sketch lr: 0.000646\n",
      "batch 951 loss: 0.80262 acc: 0.76465 | v_loss: 0.76133 v_acc: 0.78385 |  iteration: 4681 teacher: 0 stage: sketch lr: 0.000646\n",
      "batch 952 loss: 0.74111 acc: 0.76562 | v_loss: 0.69890 v_acc: 0.79395 |  iteration: 4682 teacher: 0 stage: sketch lr: 0.000646\n",
      "batch 953 loss: 0.80514 acc: 0.76823 | v_loss: 0.80886 v_acc: 0.76725 |  iteration: 4683 teacher: 0 stage: sketch lr: 0.000646\n",
      "batch 954 loss: 0.76394 acc: 0.77181 | v_loss: 0.72045 v_acc: 0.78516 |  iteration: 4684 teacher: 0 stage: sketch lr: 0.000646\n",
      "batch 955 loss: 0.83833 acc: 0.75684 | v_loss: 0.71758 v_acc: 0.78613 |  iteration: 4685 teacher: 0 stage: sketch lr: 0.000646\n",
      "batch 956 loss: 0.73142 acc: 0.77083 | v_loss: 0.78541 v_acc: 0.78548 |  iteration: 4686 teacher: 0 stage: sketch lr: 0.000646\n",
      "batch 957 loss: 0.57632 acc: 0.80566 | v_loss: 0.76594 v_acc: 0.76953 |  iteration: 4687 teacher: 1 stage: sketch lr: 0.000646\n",
      "batch 958 loss: 0.84346 acc: 0.76107 | v_loss: 0.76154 v_acc: 0.77116 |  iteration: 4688 teacher: 0 stage: sketch lr: 0.000645\n",
      "batch 959 loss: 0.71566 acc: 0.77507 | v_loss: 0.72616 v_acc: 0.79883 |  iteration: 4689 teacher: 1 stage: sketch lr: 0.000645\n",
      "batch 960 loss: 0.73979 acc: 0.77474 | v_loss: 0.60517 v_acc: 0.80664 |  iteration: 4690 teacher: 0 stage: sketch lr: 0.000645\n",
      "batch 961 loss: 0.73754 acc: 0.78255 | v_loss: 0.66073 v_acc: 0.80241 |  iteration: 4691 teacher: 1 stage: sketch lr: 0.000645\n",
      "batch 962 loss: 0.78975 acc: 0.76855 | v_loss: 0.73656 v_acc: 0.77507 |  iteration: 4692 teacher: 0 stage: sketch lr: 0.000645\n",
      "batch 963 loss: 0.70596 acc: 0.77930 | v_loss: 0.76908 v_acc: 0.77995 |  iteration: 4693 teacher: 0 stage: sketch lr: 0.000645\n",
      "batch 964 loss: 0.71231 acc: 0.78874 | v_loss: 0.77395 v_acc: 0.77604 |  iteration: 4694 teacher: 0 stage: sketch lr: 0.000645\n",
      "batch 965 loss: 0.77356 acc: 0.77311 | v_loss: 0.64955 v_acc: 0.80436 |  iteration: 4695 teacher: 1 stage: sketch lr: 0.000645\n",
      "batch 966 loss: 0.80147 acc: 0.77409 | v_loss: 0.76496 v_acc: 0.78092 |  iteration: 4696 teacher: 1 stage: sketch lr: 0.000645\n",
      "batch 967 loss: 0.87484 acc: 0.76270 | v_loss: 0.74004 v_acc: 0.77572 |  iteration: 4697 teacher: 0 stage: sketch lr: 0.000645\n",
      "batch 968 loss: 0.83477 acc: 0.76009 | v_loss: 0.73992 v_acc: 0.78092 |  iteration: 4698 teacher: 0 stage: sketch lr: 0.000645\n",
      "batch 969 loss: 0.74577 acc: 0.77930 | v_loss: 0.62111 v_acc: 0.80143 |  iteration: 4699 teacher: 0 stage: sketch lr: 0.000645\n",
      "batch 970 loss: 0.69379 acc: 0.77507 | v_loss: 0.62283 v_acc: 0.80371 |  iteration: 4700 teacher: 1 stage: sketch lr: 0.000645\n",
      "batch 971 loss: 0.72533 acc: 0.77604 | v_loss: 0.65242 v_acc: 0.79069 |  iteration: 4701 teacher: 1 stage: sketch lr: 0.000645\n",
      "batch 972 loss: 0.79233 acc: 0.76204 | v_loss: 0.66994 v_acc: 0.78939 |  iteration: 4702 teacher: 0 stage: sketch lr: 0.000645\n",
      "batch 973 loss: 0.71275 acc: 0.77214 | v_loss: 0.78323 v_acc: 0.76139 |  iteration: 4703 teacher: 1 stage: sketch lr: 0.000644\n",
      "batch 974 loss: 0.81705 acc: 0.77083 | v_loss: 0.68397 v_acc: 0.79883 |  iteration: 4704 teacher: 0 stage: sketch lr: 0.000644\n",
      "batch 975 loss: 0.79514 acc: 0.77246 | v_loss: 0.76974 v_acc: 0.79622 |  iteration: 4705 teacher: 1 stage: sketch lr: 0.000644\n",
      "batch 976 loss: 0.79887 acc: 0.76530 | v_loss: 0.77575 v_acc: 0.77441 |  iteration: 4706 teacher: 1 stage: sketch lr: 0.000644\n",
      "batch 977 loss: 0.63742 acc: 0.79980 | v_loss: 0.82729 v_acc: 0.76009 |  iteration: 4707 teacher: 1 stage: sketch lr: 0.000644\n",
      "batch 978 loss: 0.72488 acc: 0.78027 | v_loss: 0.70614 v_acc: 0.79036 |  iteration: 4708 teacher: 0 stage: sketch lr: 0.000644\n",
      "batch 979 loss: 0.70910 acc: 0.78581 | v_loss: 0.71311 v_acc: 0.78776 |  iteration: 4709 teacher: 1 stage: sketch lr: 0.000644\n",
      "batch 980 loss: 0.71044 acc: 0.77930 | v_loss: 0.59587 v_acc: 0.80729 |  iteration: 4710 teacher: 0 stage: sketch lr: 0.000644\n",
      "batch 981 loss: 0.79333 acc: 0.76432 | v_loss: 0.69779 v_acc: 0.79199 |  iteration: 4711 teacher: 0 stage: sketch lr: 0.000644\n",
      "batch 982 loss: 0.72384 acc: 0.77051 | v_loss: 0.68096 v_acc: 0.78906 |  iteration: 4712 teacher: 1 stage: sketch lr: 0.000644\n",
      "batch 983 loss: 0.67847 acc: 0.79753 | v_loss: 0.78956 v_acc: 0.77441 |  iteration: 4713 teacher: 1 stage: sketch lr: 0.000644\n",
      "batch 984 loss: 0.75966 acc: 0.77409 | v_loss: 0.73998 v_acc: 0.78809 |  iteration: 4714 teacher: 0 stage: sketch lr: 0.000644\n",
      "batch 985 loss: 0.68189 acc: 0.78874 | v_loss: 0.73660 v_acc: 0.77376 |  iteration: 4715 teacher: 1 stage: sketch lr: 0.000644\n",
      "batch 986 loss: 0.70185 acc: 0.77897 | v_loss: 0.73355 v_acc: 0.78971 |  iteration: 4716 teacher: 1 stage: sketch lr: 0.000644\n",
      "batch 987 loss: 0.74790 acc: 0.77637 | v_loss: 0.68855 v_acc: 0.78678 |  iteration: 4717 teacher: 1 stage: sketch lr: 0.000643\n",
      "batch 988 loss: 0.68936 acc: 0.79655 | v_loss: 0.88082 v_acc: 0.73893 |  iteration: 4718 teacher: 1 stage: sketch lr: 0.000643\n",
      "batch 989 loss: 0.80641 acc: 0.76302 | v_loss: 0.70781 v_acc: 0.79329 |  iteration: 4719 teacher: 0 stage: sketch lr: 0.000643\n",
      "batch 990 loss: 0.71301 acc: 0.78451 | v_loss: 0.72518 v_acc: 0.78385 |  iteration: 4720 teacher: 1 stage: sketch lr: 0.000643\n",
      "batch 991 loss: 0.76672 acc: 0.77734 | v_loss: 0.67475 v_acc: 0.79036 |  iteration: 4721 teacher: 1 stage: sketch lr: 0.000643\n",
      "batch 992 loss: 0.68721 acc: 0.78971 | v_loss: 0.71259 v_acc: 0.78939 |  iteration: 4722 teacher: 1 stage: sketch lr: 0.000643\n",
      "batch 993 loss: 0.73679 acc: 0.77051 | v_loss: 0.64007 v_acc: 0.80697 |  iteration: 4723 teacher: 0 stage: sketch lr: 0.000643\n",
      "batch 994 loss: 0.75418 acc: 0.77865 | v_loss: 0.76691 v_acc: 0.77702 |  iteration: 4724 teacher: 0 stage: sketch lr: 0.000643\n",
      "batch 995 loss: 0.78961 acc: 0.77018 | v_loss: 0.69317 v_acc: 0.79134 |  iteration: 4725 teacher: 0 stage: sketch lr: 0.000643\n",
      "batch 996 loss: 0.77315 acc: 0.76367 | v_loss: 0.84711 v_acc: 0.75553 |  iteration: 4726 teacher: 0 stage: sketch lr: 0.000643\n",
      "batch 997 loss: 0.78030 acc: 0.77409 | v_loss: 0.74761 v_acc: 0.77865 |  iteration: 4727 teacher: 1 stage: sketch lr: 0.000643\n",
      "batch 998 loss: 0.76512 acc: 0.77148 | v_loss: 0.78022 v_acc: 0.76921 |  iteration: 4728 teacher: 0 stage: sketch lr: 0.000643\n",
      "batch 999 loss: 0.85462 acc: 0.76204 | v_loss: 0.76363 v_acc: 0.78027 |  iteration: 4729 teacher: 0 stage: sketch lr: 0.000643\n",
      "batch 1000 loss: 0.65987 acc: 0.79720 | v_loss: 0.69243 v_acc: 0.78841 |  iteration: 4730 teacher: 1 stage: sketch lr: 0.000643\n",
      "batch 1001 loss: 0.75306 acc: 0.77376 | v_loss: 0.80973 v_acc: 0.77083 |  iteration: 4731 teacher: 0 stage: sketch lr: 0.000643\n",
      "batch 1002 loss: 0.76793 acc: 0.77409 | v_loss: 0.66625 v_acc: 0.79720 |  iteration: 4732 teacher: 0 stage: sketch lr: 0.000642\n",
      "batch 1003 loss: 0.66189 acc: 0.79557 | v_loss: 0.69882 v_acc: 0.79232 |  iteration: 4733 teacher: 1 stage: sketch lr: 0.000642\n",
      "batch 1004 loss: 0.64846 acc: 0.79655 | v_loss: 0.72141 v_acc: 0.77897 |  iteration: 4734 teacher: 1 stage: sketch lr: 0.000642\n",
      "batch 1005 loss: 0.79252 acc: 0.76953 | v_loss: 0.68592 v_acc: 0.79655 |  iteration: 4735 teacher: 0 stage: sketch lr: 0.000642\n",
      "batch 1006 loss: 0.72505 acc: 0.78060 | v_loss: 0.63588 v_acc: 0.78743 |  iteration: 4736 teacher: 0 stage: sketch lr: 0.000642\n",
      "batch 1007 loss: 0.79889 acc: 0.77051 | v_loss: 0.79261 v_acc: 0.77246 |  iteration: 4737 teacher: 1 stage: sketch lr: 0.000642\n",
      "batch 1008 loss: 0.75877 acc: 0.77962 | v_loss: 0.78253 v_acc: 0.77311 |  iteration: 4738 teacher: 0 stage: sketch lr: 0.000642\n",
      "batch 1009 loss: 0.74315 acc: 0.78646 | v_loss: 0.72063 v_acc: 0.77441 |  iteration: 4739 teacher: 0 stage: sketch lr: 0.000642\n",
      "batch 1010 loss: 0.78613 acc: 0.76823 | v_loss: 0.82305 v_acc: 0.76953 |  iteration: 4740 teacher: 1 stage: sketch lr: 0.000642\n",
      "batch 1011 loss: 0.83327 acc: 0.75911 | v_loss: 0.64373 v_acc: 0.78743 |  iteration: 4741 teacher: 1 stage: sketch lr: 0.000642\n",
      "batch 1012 loss: 0.67904 acc: 0.80143 | v_loss: 0.75313 v_acc: 0.77214 |  iteration: 4742 teacher: 1 stage: sketch lr: 0.000642\n",
      "batch 1013 loss: 0.63499 acc: 0.79460 | v_loss: 0.64977 v_acc: 0.80339 |  iteration: 4743 teacher: 1 stage: sketch lr: 0.000642\n",
      "batch 1014 loss: 0.79244 acc: 0.76237 | v_loss: 0.61728 v_acc: 0.79785 |  iteration: 4744 teacher: 0 stage: sketch lr: 0.000642\n",
      "batch 1015 loss: 0.85032 acc: 0.76595 | v_loss: 0.81635 v_acc: 0.78255 |  iteration: 4745 teacher: 0 stage: sketch lr: 0.000642\n",
      "batch 1016 loss: 0.78101 acc: 0.76758 | v_loss: 0.60575 v_acc: 0.79557 |  iteration: 4746 teacher: 0 stage: sketch lr: 0.000642\n",
      "batch 1017 loss: 0.81055 acc: 0.76660 | v_loss: 0.74396 v_acc: 0.78255 |  iteration: 4747 teacher: 0 stage: sketch lr: 0.000641\n",
      "batch 1018 loss: 0.71696 acc: 0.78418 | v_loss: 0.67018 v_acc: 0.79134 |  iteration: 4748 teacher: 1 stage: sketch lr: 0.000641\n",
      "batch 1019 loss: 0.70815 acc: 0.78809 | v_loss: 0.66914 v_acc: 0.79525 |  iteration: 4749 teacher: 1 stage: sketch lr: 0.000641\n",
      "batch 1020 loss: 0.78695 acc: 0.76628 | v_loss: 0.81154 v_acc: 0.76725 |  iteration: 4750 teacher: 0 stage: sketch lr: 0.000641\n",
      "batch 1021 loss: 0.68928 acc: 0.78646 | v_loss: 0.70522 v_acc: 0.79102 |  iteration: 4751 teacher: 1 stage: sketch lr: 0.000641\n",
      "batch 1022 loss: 0.72680 acc: 0.77799 | v_loss: 0.66447 v_acc: 0.80697 |  iteration: 4752 teacher: 0 stage: sketch lr: 0.000641\n",
      "batch 1023 loss: 0.77364 acc: 0.78255 | v_loss: 0.77050 v_acc: 0.76855 |  iteration: 4753 teacher: 1 stage: sketch lr: 0.000641\n",
      "batch 1024 loss: 0.65418 acc: 0.79915 | v_loss: 0.63800 v_acc: 0.80306 |  iteration: 4754 teacher: 1 stage: sketch lr: 0.000641\n",
      "batch 1025 loss: 0.72313 acc: 0.78743 | v_loss: 0.92078 v_acc: 0.75553 |  iteration: 4755 teacher: 0 stage: sketch lr: 0.000641\n",
      "batch 1026 loss: 0.63202 acc: 0.80664 | v_loss: 0.70254 v_acc: 0.78646 |  iteration: 4756 teacher: 1 stage: sketch lr: 0.000641\n",
      "batch 1027 loss: 0.73339 acc: 0.78320 | v_loss: 0.70704 v_acc: 0.78190 |  iteration: 4757 teacher: 0 stage: sketch lr: 0.000641\n",
      "batch 1028 loss: 0.69403 acc: 0.78320 | v_loss: 0.66290 v_acc: 0.79297 |  iteration: 4758 teacher: 0 stage: sketch lr: 0.000641\n",
      "batch 1029 loss: 0.67835 acc: 0.79036 | v_loss: 0.78584 v_acc: 0.76237 |  iteration: 4759 teacher: 1 stage: sketch lr: 0.000641\n",
      "batch 1030 loss: 0.71407 acc: 0.78418 | v_loss: 0.63004 v_acc: 0.79753 |  iteration: 4760 teacher: 1 stage: sketch lr: 0.000641\n",
      "batch 1031 loss: 0.78029 acc: 0.76660 | v_loss: 0.70027 v_acc: 0.78939 |  iteration: 4761 teacher: 0 stage: sketch lr: 0.000640\n",
      "batch 1032 loss: 0.73943 acc: 0.78060 | v_loss: 0.67159 v_acc: 0.79297 |  iteration: 4762 teacher: 1 stage: sketch lr: 0.000640\n",
      "batch 1033 loss: 0.83686 acc: 0.76595 | v_loss: 0.80834 v_acc: 0.77051 |  iteration: 4763 teacher: 0 stage: sketch lr: 0.000640\n",
      "batch 1034 loss: 0.65493 acc: 0.79232 | v_loss: 0.65033 v_acc: 0.78483 |  iteration: 4764 teacher: 1 stage: sketch lr: 0.000640\n",
      "batch 1035 loss: 0.62894 acc: 0.79980 | v_loss: 0.70148 v_acc: 0.78288 |  iteration: 4765 teacher: 1 stage: sketch lr: 0.000640\n",
      "batch 1036 loss: 0.89092 acc: 0.75814 | v_loss: 0.73255 v_acc: 0.78809 |  iteration: 4766 teacher: 0 stage: sketch lr: 0.000640\n",
      "batch 1037 loss: 0.73994 acc: 0.78060 | v_loss: 0.76259 v_acc: 0.77279 |  iteration: 4767 teacher: 1 stage: sketch lr: 0.000640\n",
      "batch 1038 loss: 0.61208 acc: 0.80306 | v_loss: 0.74431 v_acc: 0.77376 |  iteration: 4768 teacher: 1 stage: sketch lr: 0.000640\n",
      "batch 1039 loss: 0.78652 acc: 0.77409 | v_loss: 0.82424 v_acc: 0.75944 |  iteration: 4769 teacher: 1 stage: sketch lr: 0.000640\n",
      "batch 1040 loss: 0.82487 acc: 0.75879 | v_loss: 0.76866 v_acc: 0.76204 |  iteration: 4770 teacher: 1 stage: sketch lr: 0.000640\n",
      "batch 1041 loss: 0.81100 acc: 0.76432 | v_loss: 0.66430 v_acc: 0.79460 |  iteration: 4771 teacher: 0 stage: sketch lr: 0.000640\n",
      "batch 1042 loss: 0.77523 acc: 0.76009 | v_loss: 0.78251 v_acc: 0.76790 |  iteration: 4772 teacher: 0 stage: sketch lr: 0.000640\n",
      "batch 1043 loss: 0.76252 acc: 0.76367 | v_loss: 0.70922 v_acc: 0.78874 |  iteration: 4773 teacher: 0 stage: sketch lr: 0.000640\n",
      "batch 1044 loss: 0.63018 acc: 0.79525 | v_loss: 0.79690 v_acc: 0.75814 |  iteration: 4774 teacher: 1 stage: sketch lr: 0.000640\n",
      "batch 1045 loss: 0.82322 acc: 0.76400 | v_loss: 0.72554 v_acc: 0.77604 |  iteration: 4775 teacher: 0 stage: sketch lr: 0.000640\n",
      "batch 1046 loss: 0.70244 acc: 0.78353 | v_loss: 0.71907 v_acc: 0.79102 |  iteration: 4776 teacher: 0 stage: sketch lr: 0.000639\n",
      "batch 1047 loss: 0.61060 acc: 0.81348 | v_loss: 0.79814 v_acc: 0.78939 |  iteration: 4777 teacher: 1 stage: sketch lr: 0.000639\n",
      "batch 1048 loss: 0.79131 acc: 0.77051 | v_loss: 0.76084 v_acc: 0.77279 |  iteration: 4778 teacher: 0 stage: sketch lr: 0.000639\n",
      "batch 1049 loss: 0.75614 acc: 0.77311 | v_loss: 0.73705 v_acc: 0.77865 |  iteration: 4779 teacher: 0 stage: sketch lr: 0.000639\n",
      "batch 1050 loss: 0.77137 acc: 0.76530 | v_loss: 0.69364 v_acc: 0.80339 |  iteration: 4780 teacher: 0 stage: sketch lr: 0.000639\n",
      "batch 1051 loss: 0.74212 acc: 0.77832 | v_loss: 0.58605 v_acc: 0.80892 |  iteration: 4781 teacher: 0 stage: sketch lr: 0.000639\n",
      "batch 1052 loss: 0.73359 acc: 0.77279 | v_loss: 0.66130 v_acc: 0.79655 |  iteration: 4782 teacher: 1 stage: sketch lr: 0.000639\n",
      "batch 1053 loss: 0.73398 acc: 0.78743 | v_loss: 0.72398 v_acc: 0.77376 |  iteration: 4783 teacher: 0 stage: sketch lr: 0.000639\n",
      "batch 1054 loss: 0.66785 acc: 0.78613 | v_loss: 0.73735 v_acc: 0.77897 |  iteration: 4784 teacher: 1 stage: sketch lr: 0.000639\n",
      "batch 1055 loss: 0.78879 acc: 0.76562 | v_loss: 0.77928 v_acc: 0.77018 |  iteration: 4785 teacher: 1 stage: sketch lr: 0.000639\n",
      "batch 1056 loss: 0.64633 acc: 0.79622 | v_loss: 0.62612 v_acc: 0.80794 |  iteration: 4786 teacher: 1 stage: sketch lr: 0.000639\n",
      "batch 1057 loss: 0.88162 acc: 0.74316 | v_loss: 0.75726 v_acc: 0.77734 |  iteration: 4787 teacher: 0 stage: sketch lr: 0.000639\n",
      "batch 1058 loss: 0.61788 acc: 0.80501 | v_loss: 0.75202 v_acc: 0.76953 |  iteration: 4788 teacher: 1 stage: sketch lr: 0.000639\n",
      "batch 1059 loss: 0.81321 acc: 0.75326 | v_loss: 0.77705 v_acc: 0.77637 |  iteration: 4789 teacher: 0 stage: sketch lr: 0.000639\n",
      "batch 1060 loss: 0.71962 acc: 0.77507 | v_loss: 0.60094 v_acc: 0.80566 |  iteration: 4790 teacher: 1 stage: sketch lr: 0.000639\n",
      "batch 1061 loss: 0.67108 acc: 0.78711 | v_loss: 0.60261 v_acc: 0.80762 |  iteration: 4791 teacher: 0 stage: sketch lr: 0.000638\n",
      "batch 1062 loss: 0.79659 acc: 0.76823 | v_loss: 0.63228 v_acc: 0.80469 |  iteration: 4792 teacher: 0 stage: sketch lr: 0.000638\n",
      "batch 1063 loss: 0.74597 acc: 0.77441 | v_loss: 0.68944 v_acc: 0.78906 |  iteration: 4793 teacher: 0 stage: sketch lr: 0.000638\n",
      "batch 1064 loss: 0.71578 acc: 0.77799 | v_loss: 0.79192 v_acc: 0.75423 |  iteration: 4794 teacher: 1 stage: sketch lr: 0.000638\n",
      "batch 1065 loss: 0.71551 acc: 0.78418 | v_loss: 0.66907 v_acc: 0.79102 |  iteration: 4795 teacher: 0 stage: sketch lr: 0.000638\n",
      "batch 1066 loss: 0.64300 acc: 0.79850 | v_loss: 0.73704 v_acc: 0.79167 |  iteration: 4796 teacher: 1 stage: sketch lr: 0.000638\n",
      "batch 1067 loss: 0.82250 acc: 0.76400 | v_loss: 0.78717 v_acc: 0.76270 |  iteration: 4797 teacher: 0 stage: sketch lr: 0.000638\n",
      "batch 1068 loss: 0.75924 acc: 0.76888 | v_loss: 0.83301 v_acc: 0.75521 |  iteration: 4798 teacher: 0 stage: sketch lr: 0.000638\n",
      "batch 1069 loss: 0.57189 acc: 0.81608 | v_loss: 0.68700 v_acc: 0.78939 |  iteration: 4799 teacher: 1 stage: sketch lr: 0.000638\n",
      "batch 1070 loss: 0.75560 acc: 0.76562 | v_loss: 0.71261 v_acc: 0.78678 |  iteration: 4800 teacher: 0 stage: sketch lr: 0.000638\n",
      "batch 1071 loss: 0.65240 acc: 0.79525 | v_loss: 0.59720 v_acc: 0.80208 |  iteration: 4801 teacher: 1 stage: sketch lr: 0.000638\n",
      "batch 1072 loss: 0.65750 acc: 0.79915 | v_loss: 0.69687 v_acc: 0.79036 |  iteration: 4802 teacher: 1 stage: sketch lr: 0.000638\n",
      "batch 1073 loss: 0.73159 acc: 0.77572 | v_loss: 0.68031 v_acc: 0.79818 |  iteration: 4803 teacher: 0 stage: sketch lr: 0.000638\n",
      "batch 1074 loss: 0.72671 acc: 0.77637 | v_loss: 0.78158 v_acc: 0.77148 |  iteration: 4804 teacher: 0 stage: sketch lr: 0.000638\n",
      "batch 1075 loss: 0.61329 acc: 0.81152 | v_loss: 0.71987 v_acc: 0.78743 |  iteration: 4805 teacher: 1 stage: sketch lr: 0.000638\n",
      "batch 1076 loss: 0.69356 acc: 0.79069 | v_loss: 0.73190 v_acc: 0.76790 |  iteration: 4806 teacher: 1 stage: sketch lr: 0.000637\n",
      "batch 1077 loss: 0.71844 acc: 0.78320 | v_loss: 0.71312 v_acc: 0.79362 |  iteration: 4807 teacher: 1 stage: sketch lr: 0.000637\n",
      "batch 1078 loss: 0.73910 acc: 0.76953 | v_loss: 0.70781 v_acc: 0.78678 |  iteration: 4808 teacher: 1 stage: sketch lr: 0.000637\n",
      "batch 1079 loss: 0.73902 acc: 0.78385 | v_loss: 0.84343 v_acc: 0.74577 |  iteration: 4809 teacher: 0 stage: sketch lr: 0.000637\n",
      "batch 1080 loss: 0.81495 acc: 0.77116 | v_loss: 0.70821 v_acc: 0.78548 |  iteration: 4810 teacher: 0 stage: sketch lr: 0.000637\n",
      "batch 1081 loss: 0.72109 acc: 0.77897 | v_loss: 0.71069 v_acc: 0.78809 |  iteration: 4811 teacher: 0 stage: sketch lr: 0.000637\n",
      "batch 1082 loss: 0.77352 acc: 0.77507 | v_loss: 0.65538 v_acc: 0.80729 |  iteration: 4812 teacher: 0 stage: sketch lr: 0.000637\n",
      "batch 1083 loss: 0.83923 acc: 0.76693 | v_loss: 0.71929 v_acc: 0.78646 |  iteration: 4813 teacher: 0 stage: sketch lr: 0.000637\n",
      "batch 1084 loss: 0.77014 acc: 0.78255 | v_loss: 0.62752 v_acc: 0.80859 |  iteration: 4814 teacher: 1 stage: sketch lr: 0.000637\n",
      "batch 1085 loss: 0.74591 acc: 0.77539 | v_loss: 0.80098 v_acc: 0.76921 |  iteration: 4815 teacher: 1 stage: sketch lr: 0.000637\n",
      "batch 1086 loss: 0.79420 acc: 0.76367 | v_loss: 0.70424 v_acc: 0.78711 |  iteration: 4816 teacher: 0 stage: sketch lr: 0.000637\n",
      "batch 1087 loss: 0.79534 acc: 0.76660 | v_loss: 0.88585 v_acc: 0.74967 |  iteration: 4817 teacher: 0 stage: sketch lr: 0.000637\n",
      "batch 1088 loss: 0.78750 acc: 0.76400 | v_loss: 0.72877 v_acc: 0.77897 |  iteration: 4818 teacher: 0 stage: sketch lr: 0.000637\n",
      "batch 1089 loss: 0.62116 acc: 0.80729 | v_loss: 0.78794 v_acc: 0.77181 |  iteration: 4819 teacher: 1 stage: sketch lr: 0.000637\n",
      "batch 1090 loss: 0.72900 acc: 0.78451 | v_loss: 0.74555 v_acc: 0.77702 |  iteration: 4820 teacher: 1 stage: sketch lr: 0.000637\n",
      "batch 1091 loss: 0.68029 acc: 0.77897 | v_loss: 0.71425 v_acc: 0.78255 |  iteration: 4821 teacher: 1 stage: sketch lr: 0.000636\n",
      "batch 1092 loss: 0.78896 acc: 0.77474 | v_loss: 0.79683 v_acc: 0.76693 |  iteration: 4822 teacher: 0 stage: sketch lr: 0.000636\n",
      "batch 1093 loss: 0.73134 acc: 0.77507 | v_loss: 0.65862 v_acc: 0.80078 |  iteration: 4823 teacher: 0 stage: sketch lr: 0.000636\n",
      "batch 1094 loss: 0.84861 acc: 0.75195 | v_loss: 0.75995 v_acc: 0.77214 |  iteration: 4824 teacher: 0 stage: sketch lr: 0.000636\n",
      "batch 1095 loss: 0.69442 acc: 0.79102 | v_loss: 0.69925 v_acc: 0.78353 |  iteration: 4825 teacher: 1 stage: sketch lr: 0.000636\n",
      "batch 1096 loss: 0.74113 acc: 0.78190 | v_loss: 0.68438 v_acc: 0.79525 |  iteration: 4826 teacher: 0 stage: sketch lr: 0.000636\n",
      "batch 1097 loss: 0.61524 acc: 0.80664 | v_loss: 0.60614 v_acc: 0.80404 |  iteration: 4827 teacher: 1 stage: sketch lr: 0.000636\n",
      "batch 1098 loss: 0.86689 acc: 0.76042 | v_loss: 0.78427 v_acc: 0.77246 |  iteration: 4828 teacher: 0 stage: sketch lr: 0.000636\n",
      "batch 1099 loss: 0.78625 acc: 0.77148 | v_loss: 0.79235 v_acc: 0.76562 |  iteration: 4829 teacher: 0 stage: sketch lr: 0.000636\n",
      "batch 1100 loss: 0.68267 acc: 0.78711 | v_loss: 0.73534 v_acc: 0.76986 |  iteration: 4830 teacher: 0 stage: sketch lr: 0.000636\n",
      "batch 1101 loss: 0.62435 acc: 0.80599 | v_loss: 0.79190 v_acc: 0.77214 |  iteration: 4831 teacher: 1 stage: sketch lr: 0.000636\n",
      "batch 1102 loss: 0.82626 acc: 0.75423 | v_loss: 0.62970 v_acc: 0.80143 |  iteration: 4832 teacher: 0 stage: sketch lr: 0.000636\n",
      "batch 1103 loss: 0.70529 acc: 0.78385 | v_loss: 0.74353 v_acc: 0.77995 |  iteration: 4833 teacher: 1 stage: sketch lr: 0.000636\n",
      "batch 1104 loss: 0.79603 acc: 0.76725 | v_loss: 0.63004 v_acc: 0.80990 |  iteration: 4834 teacher: 0 stage: sketch lr: 0.000636\n",
      "batch 1105 loss: 0.72710 acc: 0.77246 | v_loss: 0.62766 v_acc: 0.80436 |  iteration: 4835 teacher: 1 stage: sketch lr: 0.000636\n",
      "batch 1106 loss: 0.80145 acc: 0.76758 | v_loss: 0.81411 v_acc: 0.77539 |  iteration: 4836 teacher: 1 stage: sketch lr: 0.000636\n",
      "batch 1107 loss: 0.68694 acc: 0.78743 | v_loss: 0.60978 v_acc: 0.79785 |  iteration: 4837 teacher: 0 stage: sketch lr: 0.000635\n",
      "batch 1108 loss: 0.74722 acc: 0.77669 | v_loss: 0.74199 v_acc: 0.78418 |  iteration: 4838 teacher: 0 stage: sketch lr: 0.000635\n",
      "batch 1109 loss: 0.68279 acc: 0.79720 | v_loss: 0.67710 v_acc: 0.79264 |  iteration: 4839 teacher: 1 stage: sketch lr: 0.000635\n",
      "batch 1110 loss: 0.67817 acc: 0.78776 | v_loss: 0.66243 v_acc: 0.79557 |  iteration: 4840 teacher: 1 stage: sketch lr: 0.000635\n",
      "batch 1111 loss: 0.77645 acc: 0.77572 | v_loss: 0.78968 v_acc: 0.77376 |  iteration: 4841 teacher: 0 stage: sketch lr: 0.000635\n",
      "batch 1112 loss: 0.77652 acc: 0.77279 | v_loss: 0.70579 v_acc: 0.78190 |  iteration: 4842 teacher: 0 stage: sketch lr: 0.000635\n",
      "batch 1113 loss: 0.77584 acc: 0.76921 | v_loss: 0.67127 v_acc: 0.80794 |  iteration: 4843 teacher: 0 stage: sketch lr: 0.000635\n",
      "batch 1114 loss: 0.77690 acc: 0.76790 | v_loss: 0.77978 v_acc: 0.76074 |  iteration: 4844 teacher: 0 stage: sketch lr: 0.000635\n",
      "batch 1115 loss: 0.76953 acc: 0.76497 | v_loss: 0.64183 v_acc: 0.80827 |  iteration: 4845 teacher: 0 stage: sketch lr: 0.000635\n",
      "batch 1116 loss: 0.78441 acc: 0.76628 | v_loss: 0.87766 v_acc: 0.76139 |  iteration: 4846 teacher: 0 stage: sketch lr: 0.000635\n",
      "batch 1117 loss: 0.81063 acc: 0.76107 | v_loss: 0.67750 v_acc: 0.79395 |  iteration: 4847 teacher: 1 stage: sketch lr: 0.000635\n",
      "batch 1118 loss: 0.73181 acc: 0.77539 | v_loss: 0.67881 v_acc: 0.79753 |  iteration: 4848 teacher: 0 stage: sketch lr: 0.000635\n",
      "batch 1119 loss: 0.65967 acc: 0.78743 | v_loss: 0.67503 v_acc: 0.78743 |  iteration: 4849 teacher: 1 stage: sketch lr: 0.000635\n",
      "batch 1120 loss: 0.80800 acc: 0.77148 | v_loss: 0.77828 v_acc: 0.76172 |  iteration: 4850 teacher: 0 stage: sketch lr: 0.000635\n",
      "batch 1121 loss: 0.80074 acc: 0.76204 | v_loss: 0.64895 v_acc: 0.78939 |  iteration: 4851 teacher: 0 stage: sketch lr: 0.000635\n",
      "batch 1122 loss: 0.77113 acc: 0.77311 | v_loss: 0.67160 v_acc: 0.79460 |  iteration: 4852 teacher: 1 stage: sketch lr: 0.000634\n",
      "batch 1123 loss: 0.78448 acc: 0.76204 | v_loss: 0.67073 v_acc: 0.79297 |  iteration: 4853 teacher: 1 stage: sketch lr: 0.000634\n",
      "batch 1124 loss: 0.67325 acc: 0.79362 | v_loss: 0.82295 v_acc: 0.75846 |  iteration: 4854 teacher: 1 stage: sketch lr: 0.000634\n",
      "batch 1125 loss: 0.80544 acc: 0.75977 | v_loss: 0.66388 v_acc: 0.78158 |  iteration: 4855 teacher: 0 stage: sketch lr: 0.000634\n",
      "batch 1126 loss: 0.72723 acc: 0.77897 | v_loss: 0.72337 v_acc: 0.77767 |  iteration: 4856 teacher: 1 stage: sketch lr: 0.000634\n",
      "batch 1127 loss: 0.64886 acc: 0.79134 | v_loss: 0.73530 v_acc: 0.78809 |  iteration: 4857 teacher: 1 stage: sketch lr: 0.000634\n",
      "batch 1128 loss: 0.74511 acc: 0.77311 | v_loss: 0.74249 v_acc: 0.77116 |  iteration: 4858 teacher: 0 stage: sketch lr: 0.000634\n",
      "batch 1129 loss: 0.74319 acc: 0.77311 | v_loss: 0.74800 v_acc: 0.76953 |  iteration: 4859 teacher: 1 stage: sketch lr: 0.000634\n",
      "batch 1130 loss: 0.72785 acc: 0.77311 | v_loss: 0.81665 v_acc: 0.76595 |  iteration: 4860 teacher: 0 stage: sketch lr: 0.000634\n",
      "batch 1131 loss: 0.80163 acc: 0.77116 | v_loss: 0.75421 v_acc: 0.76953 |  iteration: 4861 teacher: 0 stage: sketch lr: 0.000634\n",
      "batch 1132 loss: 0.66212 acc: 0.78776 | v_loss: 0.64257 v_acc: 0.79915 |  iteration: 4862 teacher: 1 stage: sketch lr: 0.000634\n",
      "batch 1133 loss: 0.75627 acc: 0.77507 | v_loss: 0.76741 v_acc: 0.77799 |  iteration: 4863 teacher: 0 stage: sketch lr: 0.000634\n",
      "batch 1134 loss: 0.78342 acc: 0.76855 | v_loss: 0.70159 v_acc: 0.79134 |  iteration: 4864 teacher: 0 stage: sketch lr: 0.000634\n",
      "batch 1135 loss: 0.77607 acc: 0.76855 | v_loss: 0.82072 v_acc: 0.76042 |  iteration: 4865 teacher: 1 stage: sketch lr: 0.000634\n",
      "batch 1136 loss: 0.82382 acc: 0.76074 | v_loss: 0.73637 v_acc: 0.77767 |  iteration: 4866 teacher: 0 stage: sketch lr: 0.000634\n",
      "batch 1137 loss: 0.73898 acc: 0.77604 | v_loss: 0.77060 v_acc: 0.76432 |  iteration: 4867 teacher: 1 stage: sketch lr: 0.000633\n",
      "batch 1138 loss: 0.69751 acc: 0.79036 | v_loss: 0.83029 v_acc: 0.77376 |  iteration: 4868 teacher: 1 stage: sketch lr: 0.000633\n",
      "batch 1139 loss: 0.67771 acc: 0.78841 | v_loss: 0.76006 v_acc: 0.77311 |  iteration: 4869 teacher: 1 stage: sketch lr: 0.000633\n",
      "batch 1140 loss: 0.78572 acc: 0.76823 | v_loss: 0.73376 v_acc: 0.77897 |  iteration: 4870 teacher: 0 stage: sketch lr: 0.000633\n",
      "batch 1141 loss: 0.75552 acc: 0.78060 | v_loss: 0.71082 v_acc: 0.79525 |  iteration: 4871 teacher: 0 stage: sketch lr: 0.000633\n",
      "batch 1142 loss: 0.81147 acc: 0.76725 | v_loss: 0.60808 v_acc: 0.80241 |  iteration: 4872 teacher: 0 stage: sketch lr: 0.000633\n",
      "batch 1143 loss: 0.76192 acc: 0.77409 | v_loss: 0.66289 v_acc: 0.79785 |  iteration: 4873 teacher: 0 stage: sketch lr: 0.000633\n",
      "batch 1144 loss: 0.76876 acc: 0.77897 | v_loss: 0.75041 v_acc: 0.77409 |  iteration: 4874 teacher: 0 stage: sketch lr: 0.000633\n",
      "batch 1145 loss: 0.82902 acc: 0.77441 | v_loss: 0.75308 v_acc: 0.77702 |  iteration: 4875 teacher: 1 stage: sketch lr: 0.000633\n",
      "batch 1146 loss: 0.80705 acc: 0.76921 | v_loss: 0.79251 v_acc: 0.77083 |  iteration: 4876 teacher: 0 stage: sketch lr: 0.000633\n",
      "batch 1147 loss: 0.69954 acc: 0.78776 | v_loss: 0.63539 v_acc: 0.80404 |  iteration: 4877 teacher: 0 stage: sketch lr: 0.000633\n",
      "batch 1148 loss: 0.67385 acc: 0.80013 | v_loss: 0.76964 v_acc: 0.77897 |  iteration: 4878 teacher: 1 stage: sketch lr: 0.000633\n",
      "batch 1149 loss: 0.77939 acc: 0.76888 | v_loss: 0.74647 v_acc: 0.77962 |  iteration: 4879 teacher: 0 stage: sketch lr: 0.000633\n",
      "batch 1150 loss: 0.75171 acc: 0.77018 | v_loss: 0.79649 v_acc: 0.76562 |  iteration: 4880 teacher: 1 stage: sketch lr: 0.000633\n",
      "batch 1151 loss: 0.74596 acc: 0.78223 | v_loss: 0.59801 v_acc: 0.79915 |  iteration: 4881 teacher: 0 stage: sketch lr: 0.000633\n",
      "batch 1152 loss: 0.71053 acc: 0.78353 | v_loss: 0.58724 v_acc: 0.82161 |  iteration: 4882 teacher: 1 stage: sketch lr: 0.000633\n",
      "batch 1153 loss: 0.76402 acc: 0.78125 | v_loss: 0.66211 v_acc: 0.80111 |  iteration: 4883 teacher: 1 stage: sketch lr: 0.000632\n",
      "batch 1154 loss: 0.68424 acc: 0.79102 | v_loss: 0.69005 v_acc: 0.80176 |  iteration: 4884 teacher: 1 stage: sketch lr: 0.000632\n",
      "batch 1155 loss: 0.67832 acc: 0.80273 | v_loss: 0.81487 v_acc: 0.75423 |  iteration: 4885 teacher: 1 stage: sketch lr: 0.000632\n",
      "batch 1156 loss: 0.85655 acc: 0.76172 | v_loss: 0.70141 v_acc: 0.77669 |  iteration: 4886 teacher: 0 stage: sketch lr: 0.000632\n",
      "batch 1157 loss: 0.76127 acc: 0.77507 | v_loss: 0.76210 v_acc: 0.79134 |  iteration: 4887 teacher: 0 stage: sketch lr: 0.000632\n",
      "batch 1158 loss: 0.80838 acc: 0.75814 | v_loss: 0.79751 v_acc: 0.76335 |  iteration: 4888 teacher: 0 stage: sketch lr: 0.000632\n",
      "batch 1159 loss: 0.71723 acc: 0.77637 | v_loss: 0.83213 v_acc: 0.75749 |  iteration: 4889 teacher: 1 stage: sketch lr: 0.000632\n",
      "batch 1160 loss: 0.70863 acc: 0.79427 | v_loss: 0.71181 v_acc: 0.78060 |  iteration: 4890 teacher: 1 stage: sketch lr: 0.000632\n",
      "batch 1161 loss: 0.82536 acc: 0.77246 | v_loss: 0.70182 v_acc: 0.78060 |  iteration: 4891 teacher: 1 stage: sketch lr: 0.000632\n",
      "batch 1162 loss: 0.74706 acc: 0.76693 | v_loss: 0.60564 v_acc: 0.79720 |  iteration: 4892 teacher: 1 stage: sketch lr: 0.000632\n",
      "batch 1163 loss: 0.76241 acc: 0.77897 | v_loss: 0.70508 v_acc: 0.78743 |  iteration: 4893 teacher: 0 stage: sketch lr: 0.000632\n",
      "batch 1164 loss: 0.66082 acc: 0.79883 | v_loss: 0.67746 v_acc: 0.80208 |  iteration: 4894 teacher: 1 stage: sketch lr: 0.000632\n",
      "batch 1165 loss: 0.80738 acc: 0.76790 | v_loss: 0.79504 v_acc: 0.77637 |  iteration: 4895 teacher: 0 stage: sketch lr: 0.000632\n",
      "batch 1166 loss: 0.71809 acc: 0.78158 | v_loss: 0.74843 v_acc: 0.78255 |  iteration: 4896 teacher: 0 stage: sketch lr: 0.000632\n",
      "batch 1167 loss: 0.80914 acc: 0.76725 | v_loss: 0.74578 v_acc: 0.77604 |  iteration: 4897 teacher: 0 stage: sketch lr: 0.000632\n",
      "batch 1168 loss: 0.77528 acc: 0.76790 | v_loss: 0.72284 v_acc: 0.79362 |  iteration: 4898 teacher: 0 stage: sketch lr: 0.000631\n",
      "batch 1169 loss: 0.88806 acc: 0.74902 | v_loss: 0.70040 v_acc: 0.78711 |  iteration: 4899 teacher: 0 stage: sketch lr: 0.000631\n",
      "batch 1170 loss: 0.76894 acc: 0.75846 | v_loss: 0.87721 v_acc: 0.72949 |  iteration: 4900 teacher: 1 stage: sketch lr: 0.000631\n",
      "batch 1171 loss: 0.77553 acc: 0.77148 | v_loss: 0.74108 v_acc: 0.77637 |  iteration: 4901 teacher: 1 stage: sketch lr: 0.000631\n",
      "batch 1172 loss: 0.87901 acc: 0.75033 | v_loss: 0.72256 v_acc: 0.78353 |  iteration: 4902 teacher: 0 stage: sketch lr: 0.000631\n",
      "batch 1173 loss: 0.78083 acc: 0.76595 | v_loss: 0.67132 v_acc: 0.79980 |  iteration: 4903 teacher: 0 stage: sketch lr: 0.000631\n",
      "batch 1174 loss: 0.69616 acc: 0.78353 | v_loss: 0.72611 v_acc: 0.78320 |  iteration: 4904 teacher: 1 stage: sketch lr: 0.000631\n",
      "batch 1175 loss: 0.75110 acc: 0.76693 | v_loss: 0.63696 v_acc: 0.80241 |  iteration: 4905 teacher: 0 stage: sketch lr: 0.000631\n",
      "batch 1176 loss: 0.78572 acc: 0.76497 | v_loss: 0.77117 v_acc: 0.77344 |  iteration: 4906 teacher: 1 stage: sketch lr: 0.000631\n",
      "batch 1177 loss: 0.82613 acc: 0.76367 | v_loss: 0.70098 v_acc: 0.79427 |  iteration: 4907 teacher: 0 stage: sketch lr: 0.000631\n",
      "batch 1178 loss: 0.82852 acc: 0.75098 | v_loss: 0.87744 v_acc: 0.75033 |  iteration: 4908 teacher: 0 stage: sketch lr: 0.000631\n",
      "batch 1179 loss: 0.72916 acc: 0.78092 | v_loss: 0.75580 v_acc: 0.76758 |  iteration: 4909 teacher: 1 stage: sketch lr: 0.000631\n",
      "batch 1180 loss: 0.83882 acc: 0.75098 | v_loss: 0.76389 v_acc: 0.77083 |  iteration: 4910 teacher: 0 stage: sketch lr: 0.000631\n",
      "batch 1181 loss: 0.74387 acc: 0.76758 | v_loss: 0.77294 v_acc: 0.77116 |  iteration: 4911 teacher: 1 stage: sketch lr: 0.000631\n",
      "batch 1182 loss: 0.88471 acc: 0.75553 | v_loss: 0.72036 v_acc: 0.78613 |  iteration: 4912 teacher: 0 stage: sketch lr: 0.000631\n",
      "batch 1183 loss: 0.80642 acc: 0.76465 | v_loss: 0.78723 v_acc: 0.77116 |  iteration: 4913 teacher: 0 stage: sketch lr: 0.000631\n",
      "batch 1184 loss: 0.82262 acc: 0.75846 | v_loss: 0.67011 v_acc: 0.80208 |  iteration: 4914 teacher: 0 stage: sketch lr: 0.000630\n",
      "batch 1185 loss: 0.73353 acc: 0.77637 | v_loss: 0.73965 v_acc: 0.77930 |  iteration: 4915 teacher: 1 stage: sketch lr: 0.000630\n",
      "batch 1186 loss: 0.77044 acc: 0.76986 | v_loss: 0.70729 v_acc: 0.77897 |  iteration: 4916 teacher: 0 stage: sketch lr: 0.000630\n",
      "batch 1187 loss: 0.76983 acc: 0.77734 | v_loss: 0.66545 v_acc: 0.79329 |  iteration: 4917 teacher: 1 stage: sketch lr: 0.000630\n",
      "batch 1188 loss: 0.65154 acc: 0.79102 | v_loss: 0.62921 v_acc: 0.78646 |  iteration: 4918 teacher: 1 stage: sketch lr: 0.000630\n",
      "batch 1189 loss: 0.74505 acc: 0.77734 | v_loss: 0.78915 v_acc: 0.77734 |  iteration: 4919 teacher: 0 stage: sketch lr: 0.000630\n",
      "batch 1190 loss: 0.71048 acc: 0.77637 | v_loss: 0.82557 v_acc: 0.75977 |  iteration: 4920 teacher: 0 stage: sketch lr: 0.000630\n",
      "batch 1191 loss: 0.68298 acc: 0.79655 | v_loss: 0.73409 v_acc: 0.77214 |  iteration: 4921 teacher: 1 stage: sketch lr: 0.000630\n",
      "batch 1192 loss: 0.83681 acc: 0.76530 | v_loss: 0.81305 v_acc: 0.77246 |  iteration: 4922 teacher: 0 stage: sketch lr: 0.000630\n",
      "batch 1193 loss: 0.78703 acc: 0.78027 | v_loss: 0.65263 v_acc: 0.79297 |  iteration: 4923 teacher: 1 stage: sketch lr: 0.000630\n",
      "batch 1194 loss: 0.88068 acc: 0.74642 | v_loss: 0.75462 v_acc: 0.76660 |  iteration: 4924 teacher: 0 stage: sketch lr: 0.000630\n",
      "batch 1195 loss: 0.73631 acc: 0.77930 | v_loss: 0.64202 v_acc: 0.80046 |  iteration: 4925 teacher: 0 stage: sketch lr: 0.000630\n",
      "batch 1196 loss: 0.77896 acc: 0.77376 | v_loss: 0.63757 v_acc: 0.79004 |  iteration: 4926 teacher: 0 stage: sketch lr: 0.000630\n",
      "batch 1197 loss: 0.84612 acc: 0.75260 | v_loss: 0.87273 v_acc: 0.75228 |  iteration: 4927 teacher: 0 stage: sketch lr: 0.000630\n",
      "batch 1198 loss: 0.74079 acc: 0.78320 | v_loss: 0.63805 v_acc: 0.79297 |  iteration: 4928 teacher: 1 stage: sketch lr: 0.000630\n",
      "batch 1199 loss: 0.78795 acc: 0.76562 | v_loss: 0.74527 v_acc: 0.76595 |  iteration: 4929 teacher: 0 stage: sketch lr: 0.000629\n",
      "batch 1200 loss: 0.77765 acc: 0.75781 | v_loss: 0.65815 v_acc: 0.79395 |  iteration: 4930 teacher: 1 stage: sketch lr: 0.000629\n",
      "batch 1201 loss: 0.79409 acc: 0.76986 | v_loss: 0.65684 v_acc: 0.79753 |  iteration: 4931 teacher: 1 stage: sketch lr: 0.000629\n",
      "batch 1202 loss: 0.78403 acc: 0.76270 | v_loss: 0.79834 v_acc: 0.76530 |  iteration: 4932 teacher: 0 stage: sketch lr: 0.000629\n",
      "batch 1203 loss: 0.78547 acc: 0.77279 | v_loss: 0.72097 v_acc: 0.78678 |  iteration: 4933 teacher: 1 stage: sketch lr: 0.000629\n",
      "batch 1204 loss: 0.72770 acc: 0.77507 | v_loss: 0.68191 v_acc: 0.80143 |  iteration: 4934 teacher: 0 stage: sketch lr: 0.000629\n",
      "batch 1205 loss: 0.71473 acc: 0.78874 | v_loss: 0.77025 v_acc: 0.76432 |  iteration: 4935 teacher: 1 stage: sketch lr: 0.000629\n",
      "batch 1206 loss: 0.74226 acc: 0.77799 | v_loss: 0.64799 v_acc: 0.79460 |  iteration: 4936 teacher: 1 stage: sketch lr: 0.000629\n",
      "batch 1207 loss: 0.71499 acc: 0.77962 | v_loss: 0.89239 v_acc: 0.75814 |  iteration: 4937 teacher: 0 stage: sketch lr: 0.000629\n",
      "batch 1208 loss: 0.69070 acc: 0.78451 | v_loss: 0.70683 v_acc: 0.77897 |  iteration: 4938 teacher: 1 stage: sketch lr: 0.000629\n",
      "batch 1209 loss: 0.77538 acc: 0.78190 | v_loss: 0.71706 v_acc: 0.77734 |  iteration: 4939 teacher: 1 stage: sketch lr: 0.000629\n",
      "batch 1210 loss: 0.82951 acc: 0.76107 | v_loss: 0.67321 v_acc: 0.79329 |  iteration: 4940 teacher: 0 stage: sketch lr: 0.000629\n",
      "batch 1211 loss: 0.75157 acc: 0.78060 | v_loss: 0.77721 v_acc: 0.76074 |  iteration: 4941 teacher: 1 stage: sketch lr: 0.000629\n",
      "batch 1212 loss: 0.80413 acc: 0.76628 | v_loss: 0.64181 v_acc: 0.79167 |  iteration: 4942 teacher: 0 stage: sketch lr: 0.000629\n",
      "batch 1213 loss: 0.69156 acc: 0.78255 | v_loss: 0.72180 v_acc: 0.78581 |  iteration: 4943 teacher: 1 stage: sketch lr: 0.000629\n",
      "batch 1214 loss: 0.93690 acc: 0.74349 | v_loss: 0.68147 v_acc: 0.78385 |  iteration: 4944 teacher: 0 stage: sketch lr: 0.000629\n",
      "batch 1215 loss: 0.74838 acc: 0.77376 | v_loss: 0.82786 v_acc: 0.76042 |  iteration: 4945 teacher: 1 stage: sketch lr: 0.000628\n",
      "batch 1216 loss: 0.83509 acc: 0.75879 | v_loss: 0.68887 v_acc: 0.77637 |  iteration: 4946 teacher: 0 stage: sketch lr: 0.000628\n",
      "batch 1217 loss: 0.82925 acc: 0.76042 | v_loss: 0.76155 v_acc: 0.76204 |  iteration: 4947 teacher: 0 stage: sketch lr: 0.000628\n",
      "batch 1218 loss: 0.69053 acc: 0.79655 | v_loss: 0.73659 v_acc: 0.78483 |  iteration: 4948 teacher: 0 stage: sketch lr: 0.000628\n",
      "batch 1219 loss: 0.82246 acc: 0.76074 | v_loss: 0.76958 v_acc: 0.76790 |  iteration: 4949 teacher: 0 stage: sketch lr: 0.000628\n",
      "batch 1220 loss: 0.79914 acc: 0.76335 | v_loss: 0.76610 v_acc: 0.77181 |  iteration: 4950 teacher: 0 stage: sketch lr: 0.000628\n",
      "batch 1221 loss: 0.76934 acc: 0.77832 | v_loss: 0.86259 v_acc: 0.75814 |  iteration: 4951 teacher: 1 stage: sketch lr: 0.000628\n",
      "batch 1222 loss: 0.67062 acc: 0.79069 | v_loss: 0.79428 v_acc: 0.76595 |  iteration: 4952 teacher: 1 stage: sketch lr: 0.000628\n",
      "batch 1223 loss: 0.78496 acc: 0.76693 | v_loss: 0.66213 v_acc: 0.79329 |  iteration: 4953 teacher: 0 stage: sketch lr: 0.000628\n",
      "batch 1224 loss: 0.79144 acc: 0.76562 | v_loss: 0.77019 v_acc: 0.76725 |  iteration: 4954 teacher: 0 stage: sketch lr: 0.000628\n",
      "batch 1225 loss: 0.75546 acc: 0.78158 | v_loss: 0.70401 v_acc: 0.78483 |  iteration: 4955 teacher: 1 stage: sketch lr: 0.000628\n",
      "batch 1226 loss: 0.80464 acc: 0.76562 | v_loss: 0.79930 v_acc: 0.75716 |  iteration: 4956 teacher: 0 stage: sketch lr: 0.000628\n",
      "batch 1227 loss: 0.77865 acc: 0.76595 | v_loss: 0.70431 v_acc: 0.78060 |  iteration: 4957 teacher: 0 stage: sketch lr: 0.000628\n",
      "batch 1228 loss: 0.71906 acc: 0.78646 | v_loss: 0.72407 v_acc: 0.78483 |  iteration: 4958 teacher: 1 stage: sketch lr: 0.000628\n",
      "batch 1229 loss: 0.81283 acc: 0.75814 | v_loss: 0.82062 v_acc: 0.77539 |  iteration: 4959 teacher: 0 stage: sketch lr: 0.000628\n",
      "batch 1230 loss: 0.81597 acc: 0.75977 | v_loss: 0.75618 v_acc: 0.77051 |  iteration: 4960 teacher: 1 stage: sketch lr: 0.000628\n",
      "batch 1231 loss: 0.71921 acc: 0.77214 | v_loss: 0.76148 v_acc: 0.77181 |  iteration: 4961 teacher: 1 stage: sketch lr: 0.000627\n",
      "batch 1232 loss: 0.71899 acc: 0.78451 | v_loss: 0.73239 v_acc: 0.79069 |  iteration: 4962 teacher: 1 stage: sketch lr: 0.000627\n",
      "batch 1233 loss: 0.77598 acc: 0.77344 | v_loss: 0.63183 v_acc: 0.79525 |  iteration: 4963 teacher: 1 stage: sketch lr: 0.000627\n",
      "batch 1234 loss: 0.76503 acc: 0.77051 | v_loss: 0.67219 v_acc: 0.79134 |  iteration: 4964 teacher: 1 stage: sketch lr: 0.000627\n",
      "batch 1235 loss: 0.72734 acc: 0.78158 | v_loss: 0.73850 v_acc: 0.76790 |  iteration: 4965 teacher: 1 stage: sketch lr: 0.000627\n",
      "batch 1236 loss: 0.76554 acc: 0.76758 | v_loss: 0.78164 v_acc: 0.77637 |  iteration: 4966 teacher: 0 stage: sketch lr: 0.000627\n",
      "batch 1237 loss: 0.79890 acc: 0.76693 | v_loss: 0.79680 v_acc: 0.76465 |  iteration: 4967 teacher: 0 stage: sketch lr: 0.000627\n",
      "batch 1238 loss: 0.73517 acc: 0.78190 | v_loss: 0.65582 v_acc: 0.79818 |  iteration: 4968 teacher: 0 stage: sketch lr: 0.000627\n",
      "batch 1239 loss: 0.85896 acc: 0.75488 | v_loss: 0.77926 v_acc: 0.77897 |  iteration: 4969 teacher: 0 stage: sketch lr: 0.000627\n",
      "batch 1240 loss: 0.81098 acc: 0.76660 | v_loss: 0.77337 v_acc: 0.75879 |  iteration: 4970 teacher: 0 stage: sketch lr: 0.000627\n",
      "batch 1241 loss: 0.84333 acc: 0.76302 | v_loss: 0.77960 v_acc: 0.77441 |  iteration: 4971 teacher: 0 stage: sketch lr: 0.000627\n",
      "batch 1242 loss: 0.75473 acc: 0.77344 | v_loss: 0.62082 v_acc: 0.80046 |  iteration: 4972 teacher: 1 stage: sketch lr: 0.000627\n",
      "epoch 3 loss: 0.76498 acc: 0.77082 | v_loss: 0.74032 v_acc: 0.77681 \n",
      "epoch: 4\n",
      "__________________________________________\n",
      "batch 0 loss: 0.77658 acc: 0.76530 | v_loss: 0.78537 v_acc: 0.77018 |  iteration: 4973 teacher: 0 stage: sketch lr: 0.000627\n",
      "batch 1 loss: 0.80214 acc: 0.76921 | v_loss: 0.67314 v_acc: 0.79655 |  iteration: 4974 teacher: 0 stage: sketch lr: 0.000627\n",
      "batch 2 loss: 0.78766 acc: 0.75911 | v_loss: 0.73057 v_acc: 0.77897 |  iteration: 4975 teacher: 1 stage: sketch lr: 0.000627\n",
      "batch 3 loss: 0.71710 acc: 0.77376 | v_loss: 0.70070 v_acc: 0.78743 |  iteration: 4976 teacher: 1 stage: sketch lr: 0.000627\n",
      "batch 4 loss: 0.80974 acc: 0.76855 | v_loss: 0.67429 v_acc: 0.79850 |  iteration: 4977 teacher: 0 stage: sketch lr: 0.000626\n",
      "batch 5 loss: 0.80650 acc: 0.76335 | v_loss: 0.60374 v_acc: 0.79525 |  iteration: 4978 teacher: 0 stage: sketch lr: 0.000626\n",
      "batch 6 loss: 0.70290 acc: 0.78092 | v_loss: 0.79846 v_acc: 0.78092 |  iteration: 4979 teacher: 1 stage: sketch lr: 0.000626\n",
      "batch 7 loss: 0.72115 acc: 0.78841 | v_loss: 0.84292 v_acc: 0.76139 |  iteration: 4980 teacher: 0 stage: sketch lr: 0.000626\n",
      "batch 8 loss: 0.65448 acc: 0.79199 | v_loss: 0.74314 v_acc: 0.77051 |  iteration: 4981 teacher: 1 stage: sketch lr: 0.000626\n",
      "batch 9 loss: 0.83485 acc: 0.77246 | v_loss: 0.82562 v_acc: 0.77051 |  iteration: 4982 teacher: 0 stage: sketch lr: 0.000626\n",
      "batch 10 loss: 0.73133 acc: 0.78255 | v_loss: 0.64617 v_acc: 0.78711 |  iteration: 4983 teacher: 1 stage: sketch lr: 0.000626\n",
      "batch 11 loss: 0.71334 acc: 0.78353 | v_loss: 0.76423 v_acc: 0.77116 |  iteration: 4984 teacher: 1 stage: sketch lr: 0.000626\n",
      "batch 12 loss: 0.70450 acc: 0.77832 | v_loss: 0.65280 v_acc: 0.81152 |  iteration: 4985 teacher: 1 stage: sketch lr: 0.000626\n",
      "batch 13 loss: 0.76063 acc: 0.76725 | v_loss: 0.63193 v_acc: 0.79753 |  iteration: 4986 teacher: 1 stage: sketch lr: 0.000626\n",
      "batch 14 loss: 0.75187 acc: 0.77995 | v_loss: 0.85066 v_acc: 0.75977 |  iteration: 4987 teacher: 1 stage: sketch lr: 0.000626\n",
      "batch 15 loss: 0.70704 acc: 0.78353 | v_loss: 0.61199 v_acc: 0.79688 |  iteration: 4988 teacher: 1 stage: sketch lr: 0.000626\n",
      "batch 16 loss: 0.76527 acc: 0.77799 | v_loss: 0.75812 v_acc: 0.77637 |  iteration: 4989 teacher: 0 stage: sketch lr: 0.000626\n",
      "batch 17 loss: 0.78339 acc: 0.76237 | v_loss: 0.67962 v_acc: 0.78613 |  iteration: 4990 teacher: 1 stage: sketch lr: 0.000626\n",
      "batch 18 loss: 0.79016 acc: 0.77051 | v_loss: 0.67327 v_acc: 0.78874 |  iteration: 4991 teacher: 1 stage: sketch lr: 0.000626\n",
      "batch 19 loss: 0.84967 acc: 0.74870 | v_loss: 0.78865 v_acc: 0.77083 |  iteration: 4992 teacher: 0 stage: sketch lr: 0.000626\n",
      "batch 20 loss: 0.77441 acc: 0.76725 | v_loss: 0.69640 v_acc: 0.79753 |  iteration: 4993 teacher: 0 stage: sketch lr: 0.000625\n",
      "batch 21 loss: 0.75863 acc: 0.77214 | v_loss: 0.68228 v_acc: 0.79850 |  iteration: 4994 teacher: 1 stage: sketch lr: 0.000625\n",
      "batch 22 loss: 0.73778 acc: 0.77051 | v_loss: 0.77405 v_acc: 0.76497 |  iteration: 4995 teacher: 1 stage: sketch lr: 0.000625\n",
      "batch 23 loss: 0.80752 acc: 0.76693 | v_loss: 0.66525 v_acc: 0.78971 |  iteration: 4996 teacher: 1 stage: sketch lr: 0.000625\n",
      "batch 24 loss: 0.66392 acc: 0.78939 | v_loss: 0.92402 v_acc: 0.75749 |  iteration: 4997 teacher: 1 stage: sketch lr: 0.000625\n",
      "batch 25 loss: 0.73330 acc: 0.77799 | v_loss: 0.72552 v_acc: 0.77441 |  iteration: 4998 teacher: 1 stage: sketch lr: 0.000625\n",
      "batch 26 loss: 0.76111 acc: 0.77246 | v_loss: 0.74529 v_acc: 0.76660 |  iteration: 4999 teacher: 0 stage: sketch lr: 0.000625\n",
      "batch 27 loss: 0.80502 acc: 0.76465 | v_loss: 0.69662 v_acc: 0.78809 |  iteration: 5000 teacher: 0 stage: sketch lr: 0.000625\n",
      "batch 28 loss: 0.81318 acc: 0.76107 | v_loss: 0.82317 v_acc: 0.75586 |  iteration: 5001 teacher: 1 stage: sketch lr: 0.000625\n",
      "batch 29 loss: 0.75441 acc: 0.76595 | v_loss: 0.68597 v_acc: 0.77702 |  iteration: 5002 teacher: 0 stage: sketch lr: 0.000625\n",
      "batch 30 loss: 0.74940 acc: 0.77148 | v_loss: 0.71810 v_acc: 0.78548 |  iteration: 5003 teacher: 0 stage: sketch lr: 0.000625\n",
      "batch 31 loss: 0.86266 acc: 0.73600 | v_loss: 0.71076 v_acc: 0.77474 |  iteration: 5004 teacher: 0 stage: sketch lr: 0.000625\n",
      "batch 32 loss: 0.85041 acc: 0.75456 | v_loss: 0.81140 v_acc: 0.75879 |  iteration: 5005 teacher: 0 stage: sketch lr: 0.000625\n",
      "batch 33 loss: 0.79176 acc: 0.76270 | v_loss: 0.69205 v_acc: 0.77572 |  iteration: 5006 teacher: 1 stage: sketch lr: 0.000625\n",
      "batch 34 loss: 0.77368 acc: 0.76400 | v_loss: 0.77402 v_acc: 0.75684 |  iteration: 5007 teacher: 0 stage: sketch lr: 0.000625\n",
      "batch 35 loss: 0.77549 acc: 0.76009 | v_loss: 0.76557 v_acc: 0.77018 |  iteration: 5008 teacher: 1 stage: sketch lr: 0.000625\n",
      "batch 36 loss: 0.76389 acc: 0.76139 | v_loss: 0.77742 v_acc: 0.76074 |  iteration: 5009 teacher: 1 stage: sketch lr: 0.000624\n",
      "batch 37 loss: 0.77867 acc: 0.76530 | v_loss: 0.76305 v_acc: 0.76302 |  iteration: 5010 teacher: 0 stage: sketch lr: 0.000624\n",
      "batch 38 loss: 0.80968 acc: 0.75130 | v_loss: 0.83614 v_acc: 0.74870 |  iteration: 5011 teacher: 0 stage: sketch lr: 0.000624\n",
      "batch 39 loss: 0.73305 acc: 0.77181 | v_loss: 0.80543 v_acc: 0.74967 |  iteration: 5012 teacher: 1 stage: sketch lr: 0.000624\n",
      "batch 40 loss: 0.76642 acc: 0.76400 | v_loss: 0.72240 v_acc: 0.77214 |  iteration: 5013 teacher: 1 stage: sketch lr: 0.000624\n",
      "batch 41 loss: 0.76998 acc: 0.76042 | v_loss: 0.80955 v_acc: 0.76725 |  iteration: 5014 teacher: 0 stage: sketch lr: 0.000624\n",
      "batch 42 loss: 0.87136 acc: 0.75228 | v_loss: 0.70515 v_acc: 0.79134 |  iteration: 5015 teacher: 0 stage: sketch lr: 0.000624\n",
      "batch 43 loss: 0.86550 acc: 0.76270 | v_loss: 0.85890 v_acc: 0.74479 |  iteration: 5016 teacher: 1 stage: sketch lr: 0.000624\n",
      "batch 44 loss: 0.83556 acc: 0.74707 | v_loss: 0.76375 v_acc: 0.76009 |  iteration: 5017 teacher: 1 stage: sketch lr: 0.000624\n",
      "batch 45 loss: 0.82513 acc: 0.76139 | v_loss: 0.76235 v_acc: 0.76986 |  iteration: 5018 teacher: 0 stage: sketch lr: 0.000624\n",
      "batch 46 loss: 0.78959 acc: 0.75358 | v_loss: 0.82710 v_acc: 0.77083 |  iteration: 5019 teacher: 1 stage: sketch lr: 0.000624\n",
      "batch 47 loss: 0.78375 acc: 0.76302 | v_loss: 0.78235 v_acc: 0.76530 |  iteration: 5020 teacher: 1 stage: sketch lr: 0.000624\n",
      "batch 48 loss: 0.76343 acc: 0.76400 | v_loss: 0.78716 v_acc: 0.75195 |  iteration: 5021 teacher: 1 stage: sketch lr: 0.000624\n",
      "batch 49 loss: 0.75703 acc: 0.76758 | v_loss: 0.73599 v_acc: 0.78939 |  iteration: 5022 teacher: 1 stage: sketch lr: 0.000624\n",
      "batch 50 loss: 0.74211 acc: 0.76986 | v_loss: 0.63303 v_acc: 0.79427 |  iteration: 5023 teacher: 1 stage: sketch lr: 0.000624\n",
      "batch 51 loss: 0.80195 acc: 0.75879 | v_loss: 0.69671 v_acc: 0.78483 |  iteration: 5024 teacher: 0 stage: sketch lr: 0.000624\n",
      "batch 52 loss: 0.74616 acc: 0.76823 | v_loss: 0.76658 v_acc: 0.76172 |  iteration: 5025 teacher: 1 stage: sketch lr: 0.000623\n",
      "batch 53 loss: 0.78327 acc: 0.75293 | v_loss: 0.80507 v_acc: 0.76628 |  iteration: 5026 teacher: 1 stage: sketch lr: 0.000623\n",
      "batch 54 loss: 0.77719 acc: 0.76562 | v_loss: 0.82795 v_acc: 0.75781 |  iteration: 5027 teacher: 0 stage: sketch lr: 0.000623\n",
      "batch 55 loss: 0.82400 acc: 0.75846 | v_loss: 0.65273 v_acc: 0.79525 |  iteration: 5028 teacher: 0 stage: sketch lr: 0.000623\n",
      "batch 56 loss: 0.84786 acc: 0.75260 | v_loss: 0.81145 v_acc: 0.76497 |  iteration: 5029 teacher: 0 stage: sketch lr: 0.000623\n",
      "batch 57 loss: 0.81888 acc: 0.75814 | v_loss: 0.78602 v_acc: 0.76107 |  iteration: 5030 teacher: 0 stage: sketch lr: 0.000623\n",
      "batch 58 loss: 0.82951 acc: 0.75716 | v_loss: 0.78879 v_acc: 0.77181 |  iteration: 5031 teacher: 0 stage: sketch lr: 0.000623\n",
      "batch 59 loss: 0.75046 acc: 0.76823 | v_loss: 0.65087 v_acc: 0.79036 |  iteration: 5032 teacher: 1 stage: sketch lr: 0.000623\n",
      "batch 60 loss: 0.79321 acc: 0.76335 | v_loss: 0.62774 v_acc: 0.79525 |  iteration: 5033 teacher: 0 stage: sketch lr: 0.000623\n",
      "batch 61 loss: 0.77578 acc: 0.75879 | v_loss: 0.66183 v_acc: 0.79102 |  iteration: 5034 teacher: 0 stage: sketch lr: 0.000623\n",
      "batch 62 loss: 0.71795 acc: 0.77572 | v_loss: 0.75090 v_acc: 0.77311 |  iteration: 5035 teacher: 1 stage: sketch lr: 0.000623\n",
      "batch 63 loss: 0.80427 acc: 0.75098 | v_loss: 0.81856 v_acc: 0.74316 |  iteration: 5036 teacher: 0 stage: sketch lr: 0.000623\n",
      "batch 64 loss: 0.77071 acc: 0.76432 | v_loss: 0.68862 v_acc: 0.78516 |  iteration: 5037 teacher: 1 stage: sketch lr: 0.000623\n",
      "batch 65 loss: 0.73014 acc: 0.77441 | v_loss: 0.76661 v_acc: 0.78483 |  iteration: 5038 teacher: 0 stage: sketch lr: 0.000623\n",
      "batch 66 loss: 0.71152 acc: 0.79004 | v_loss: 0.82144 v_acc: 0.76367 |  iteration: 5039 teacher: 1 stage: sketch lr: 0.000623\n",
      "batch 67 loss: 0.71942 acc: 0.77962 | v_loss: 0.84299 v_acc: 0.75553 |  iteration: 5040 teacher: 1 stage: sketch lr: 0.000623\n",
      "batch 68 loss: 0.71109 acc: 0.77669 | v_loss: 0.72703 v_acc: 0.78809 |  iteration: 5041 teacher: 1 stage: sketch lr: 0.000622\n",
      "batch 69 loss: 0.78340 acc: 0.76074 | v_loss: 0.78048 v_acc: 0.76725 |  iteration: 5042 teacher: 1 stage: sketch lr: 0.000622\n",
      "batch 70 loss: 0.83966 acc: 0.75716 | v_loss: 0.62026 v_acc: 0.79329 |  iteration: 5043 teacher: 0 stage: sketch lr: 0.000622\n",
      "batch 71 loss: 0.86540 acc: 0.74707 | v_loss: 0.74527 v_acc: 0.76823 |  iteration: 5044 teacher: 1 stage: sketch lr: 0.000622\n",
      "batch 72 loss: 0.74864 acc: 0.77962 | v_loss: 0.77545 v_acc: 0.76432 |  iteration: 5045 teacher: 1 stage: sketch lr: 0.000622\n",
      "batch 73 loss: 0.83237 acc: 0.74837 | v_loss: 0.83057 v_acc: 0.76725 |  iteration: 5046 teacher: 0 stage: sketch lr: 0.000622\n",
      "batch 74 loss: 0.79587 acc: 0.76237 | v_loss: 0.76880 v_acc: 0.77441 |  iteration: 5047 teacher: 1 stage: sketch lr: 0.000622\n",
      "batch 75 loss: 0.81452 acc: 0.75553 | v_loss: 0.77469 v_acc: 0.75879 |  iteration: 5048 teacher: 0 stage: sketch lr: 0.000622\n",
      "batch 76 loss: 0.80334 acc: 0.75814 | v_loss: 0.73381 v_acc: 0.77572 |  iteration: 5049 teacher: 0 stage: sketch lr: 0.000622\n",
      "batch 77 loss: 0.82592 acc: 0.75781 | v_loss: 0.73265 v_acc: 0.76888 |  iteration: 5050 teacher: 0 stage: sketch lr: 0.000622\n",
      "batch 78 loss: 0.84247 acc: 0.76530 | v_loss: 0.87484 v_acc: 0.73372 |  iteration: 5051 teacher: 1 stage: sketch lr: 0.000622\n",
      "batch 79 loss: 0.82687 acc: 0.75130 | v_loss: 0.73421 v_acc: 0.78190 |  iteration: 5052 teacher: 0 stage: sketch lr: 0.000622\n",
      "batch 80 loss: 0.80537 acc: 0.75781 | v_loss: 0.77787 v_acc: 0.76888 |  iteration: 5053 teacher: 1 stage: sketch lr: 0.000622\n",
      "batch 81 loss: 0.77563 acc: 0.76172 | v_loss: 0.68790 v_acc: 0.78809 |  iteration: 5054 teacher: 1 stage: sketch lr: 0.000622\n",
      "batch 82 loss: 0.84111 acc: 0.74251 | v_loss: 0.74481 v_acc: 0.77246 |  iteration: 5055 teacher: 0 stage: sketch lr: 0.000622\n",
      "batch 83 loss: 0.76628 acc: 0.77507 | v_loss: 0.65932 v_acc: 0.79883 |  iteration: 5056 teacher: 1 stage: sketch lr: 0.000622\n",
      "batch 84 loss: 0.68853 acc: 0.78288 | v_loss: 0.79681 v_acc: 0.76335 |  iteration: 5057 teacher: 1 stage: sketch lr: 0.000621\n",
      "batch 85 loss: 0.75302 acc: 0.77702 | v_loss: 0.75816 v_acc: 0.77181 |  iteration: 5058 teacher: 1 stage: sketch lr: 0.000621\n",
      "batch 86 loss: 0.82398 acc: 0.75586 | v_loss: 0.88820 v_acc: 0.74707 |  iteration: 5059 teacher: 0 stage: sketch lr: 0.000621\n",
      "batch 87 loss: 0.80667 acc: 0.76237 | v_loss: 0.79841 v_acc: 0.76204 |  iteration: 5060 teacher: 0 stage: sketch lr: 0.000621\n",
      "batch 88 loss: 0.77103 acc: 0.77148 | v_loss: 0.79389 v_acc: 0.76595 |  iteration: 5061 teacher: 1 stage: sketch lr: 0.000621\n",
      "batch 89 loss: 0.75650 acc: 0.77572 | v_loss: 0.82887 v_acc: 0.75488 |  iteration: 5062 teacher: 1 stage: sketch lr: 0.000621\n",
      "batch 90 loss: 0.85948 acc: 0.74479 | v_loss: 0.75646 v_acc: 0.77018 |  iteration: 5063 teacher: 0 stage: sketch lr: 0.000621\n",
      "batch 91 loss: 0.83365 acc: 0.75846 | v_loss: 0.83427 v_acc: 0.75651 |  iteration: 5064 teacher: 0 stage: sketch lr: 0.000621\n",
      "batch 92 loss: 0.78189 acc: 0.76107 | v_loss: 0.73414 v_acc: 0.77246 |  iteration: 5065 teacher: 0 stage: sketch lr: 0.000621\n",
      "batch 93 loss: 0.83489 acc: 0.74154 | v_loss: 0.76055 v_acc: 0.76986 |  iteration: 5066 teacher: 0 stage: sketch lr: 0.000621\n",
      "batch 94 loss: 0.81644 acc: 0.74674 | v_loss: 0.75846 v_acc: 0.77441 |  iteration: 5067 teacher: 0 stage: sketch lr: 0.000621\n",
      "batch 95 loss: 0.75870 acc: 0.77409 | v_loss: 0.68811 v_acc: 0.79232 |  iteration: 5068 teacher: 0 stage: sketch lr: 0.000621\n",
      "batch 96 loss: 0.79788 acc: 0.75130 | v_loss: 0.63570 v_acc: 0.79264 |  iteration: 5069 teacher: 0 stage: sketch lr: 0.000621\n",
      "batch 97 loss: 0.81537 acc: 0.76400 | v_loss: 0.84303 v_acc: 0.75391 |  iteration: 5070 teacher: 1 stage: sketch lr: 0.000621\n",
      "batch 98 loss: 0.75518 acc: 0.76725 | v_loss: 0.86564 v_acc: 0.74837 |  iteration: 5071 teacher: 0 stage: sketch lr: 0.000621\n",
      "batch 99 loss: 0.79673 acc: 0.76432 | v_loss: 0.77125 v_acc: 0.76009 |  iteration: 5072 teacher: 1 stage: sketch lr: 0.000621\n",
      "batch 100 loss: 0.83115 acc: 0.75456 | v_loss: 0.82212 v_acc: 0.75879 |  iteration: 5073 teacher: 0 stage: sketch lr: 0.000620\n",
      "batch 101 loss: 0.74445 acc: 0.76237 | v_loss: 0.67103 v_acc: 0.77897 |  iteration: 5074 teacher: 0 stage: sketch lr: 0.000620\n",
      "batch 102 loss: 0.76643 acc: 0.76335 | v_loss: 0.76736 v_acc: 0.76888 |  iteration: 5075 teacher: 0 stage: sketch lr: 0.000620\n",
      "batch 103 loss: 0.82114 acc: 0.76302 | v_loss: 0.67528 v_acc: 0.79720 |  iteration: 5076 teacher: 0 stage: sketch lr: 0.000620\n",
      "batch 104 loss: 0.75399 acc: 0.76921 | v_loss: 0.68506 v_acc: 0.78060 |  iteration: 5077 teacher: 0 stage: sketch lr: 0.000620\n",
      "batch 105 loss: 0.91298 acc: 0.73177 | v_loss: 0.85802 v_acc: 0.76725 |  iteration: 5078 teacher: 0 stage: sketch lr: 0.000620\n",
      "batch 106 loss: 0.73595 acc: 0.77376 | v_loss: 0.68280 v_acc: 0.76986 |  iteration: 5079 teacher: 1 stage: sketch lr: 0.000620\n",
      "batch 107 loss: 0.77244 acc: 0.77344 | v_loss: 0.79691 v_acc: 0.75456 |  iteration: 5080 teacher: 1 stage: sketch lr: 0.000620\n",
      "batch 108 loss: 0.77649 acc: 0.76432 | v_loss: 0.71926 v_acc: 0.77799 |  iteration: 5081 teacher: 1 stage: sketch lr: 0.000620\n",
      "batch 109 loss: 0.76193 acc: 0.76725 | v_loss: 0.68849 v_acc: 0.78483 |  iteration: 5082 teacher: 1 stage: sketch lr: 0.000620\n",
      "batch 110 loss: 0.82555 acc: 0.76237 | v_loss: 0.85511 v_acc: 0.75618 |  iteration: 5083 teacher: 0 stage: sketch lr: 0.000620\n",
      "batch 111 loss: 0.86216 acc: 0.74382 | v_loss: 0.75773 v_acc: 0.76986 |  iteration: 5084 teacher: 0 stage: sketch lr: 0.000620\n",
      "batch 112 loss: 0.82960 acc: 0.75293 | v_loss: 0.70069 v_acc: 0.79818 |  iteration: 5085 teacher: 0 stage: sketch lr: 0.000620\n",
      "batch 113 loss: 0.90180 acc: 0.74316 | v_loss: 0.79203 v_acc: 0.75130 |  iteration: 5086 teacher: 1 stage: sketch lr: 0.000620\n",
      "batch 114 loss: 0.75492 acc: 0.77279 | v_loss: 0.67060 v_acc: 0.79134 |  iteration: 5087 teacher: 1 stage: sketch lr: 0.000620\n",
      "batch 115 loss: 0.85682 acc: 0.74056 | v_loss: 0.91122 v_acc: 0.74870 |  iteration: 5088 teacher: 0 stage: sketch lr: 0.000620\n",
      "batch 116 loss: 0.74345 acc: 0.77148 | v_loss: 0.71424 v_acc: 0.77181 |  iteration: 5089 teacher: 0 stage: sketch lr: 0.000620\n",
      "batch 117 loss: 0.77345 acc: 0.76823 | v_loss: 0.77629 v_acc: 0.75456 |  iteration: 5090 teacher: 1 stage: sketch lr: 0.000619\n",
      "batch 118 loss: 0.80165 acc: 0.75195 | v_loss: 0.71843 v_acc: 0.77669 |  iteration: 5091 teacher: 1 stage: sketch lr: 0.000619\n",
      "batch 119 loss: 0.86261 acc: 0.74284 | v_loss: 0.81598 v_acc: 0.75456 |  iteration: 5092 teacher: 0 stage: sketch lr: 0.000619\n",
      "batch 120 loss: 0.86853 acc: 0.74316 | v_loss: 0.69752 v_acc: 0.76823 |  iteration: 5093 teacher: 1 stage: sketch lr: 0.000619\n",
      "batch 121 loss: 0.89685 acc: 0.73893 | v_loss: 0.73433 v_acc: 0.77637 |  iteration: 5094 teacher: 1 stage: sketch lr: 0.000619\n",
      "batch 122 loss: 0.89373 acc: 0.73861 | v_loss: 0.71797 v_acc: 0.77865 |  iteration: 5095 teacher: 1 stage: sketch lr: 0.000619\n",
      "batch 123 loss: 0.81209 acc: 0.75521 | v_loss: 0.92982 v_acc: 0.73991 |  iteration: 5096 teacher: 1 stage: sketch lr: 0.000619\n",
      "batch 124 loss: 0.78777 acc: 0.76139 | v_loss: 0.70268 v_acc: 0.76888 |  iteration: 5097 teacher: 0 stage: sketch lr: 0.000619\n",
      "batch 125 loss: 0.76568 acc: 0.77279 | v_loss: 0.81147 v_acc: 0.74479 |  iteration: 5098 teacher: 1 stage: sketch lr: 0.000619\n",
      "batch 126 loss: 0.81258 acc: 0.74642 | v_loss: 0.75515 v_acc: 0.77669 |  iteration: 5099 teacher: 1 stage: sketch lr: 0.000619\n",
      "batch 127 loss: 0.83752 acc: 0.75293 | v_loss: 0.82734 v_acc: 0.75423 |  iteration: 5100 teacher: 0 stage: sketch lr: 0.000619\n",
      "batch 128 loss: 0.81403 acc: 0.75228 | v_loss: 0.78899 v_acc: 0.75293 |  iteration: 5101 teacher: 0 stage: sketch lr: 0.000619\n",
      "batch 129 loss: 0.81114 acc: 0.75423 | v_loss: 0.86497 v_acc: 0.75260 |  iteration: 5102 teacher: 0 stage: sketch lr: 0.000619\n",
      "batch 130 loss: 0.81579 acc: 0.75228 | v_loss: 0.81631 v_acc: 0.74284 |  iteration: 5103 teacher: 1 stage: sketch lr: 0.000619\n",
      "batch 131 loss: 0.81574 acc: 0.76432 | v_loss: 0.72154 v_acc: 0.77637 |  iteration: 5104 teacher: 1 stage: sketch lr: 0.000619\n",
      "batch 132 loss: 0.85426 acc: 0.75195 | v_loss: 0.81658 v_acc: 0.75716 |  iteration: 5105 teacher: 0 stage: sketch lr: 0.000619\n",
      "batch 133 loss: 0.82257 acc: 0.75716 | v_loss: 0.75546 v_acc: 0.76888 |  iteration: 5106 teacher: 1 stage: sketch lr: 0.000618\n",
      "batch 134 loss: 0.87442 acc: 0.73730 | v_loss: 0.84495 v_acc: 0.75260 |  iteration: 5107 teacher: 0 stage: sketch lr: 0.000618\n",
      "batch 135 loss: 0.79866 acc: 0.76270 | v_loss: 0.77421 v_acc: 0.76074 |  iteration: 5108 teacher: 1 stage: sketch lr: 0.000618\n",
      "batch 136 loss: 0.80038 acc: 0.76139 | v_loss: 0.76606 v_acc: 0.76888 |  iteration: 5109 teacher: 0 stage: sketch lr: 0.000618\n",
      "batch 137 loss: 0.85066 acc: 0.74902 | v_loss: 0.86013 v_acc: 0.75716 |  iteration: 5110 teacher: 0 stage: sketch lr: 0.000618\n",
      "batch 138 loss: 0.77715 acc: 0.76595 | v_loss: 0.81726 v_acc: 0.75488 |  iteration: 5111 teacher: 1 stage: sketch lr: 0.000618\n",
      "batch 139 loss: 0.76721 acc: 0.75846 | v_loss: 0.79337 v_acc: 0.75781 |  iteration: 5112 teacher: 0 stage: sketch lr: 0.000618\n",
      "batch 140 loss: 0.82942 acc: 0.75065 | v_loss: 0.80968 v_acc: 0.76562 |  iteration: 5113 teacher: 1 stage: sketch lr: 0.000618\n",
      "batch 141 loss: 0.83316 acc: 0.76139 | v_loss: 0.66992 v_acc: 0.77474 |  iteration: 5114 teacher: 0 stage: sketch lr: 0.000618\n",
      "batch 142 loss: 0.79381 acc: 0.75911 | v_loss: 0.69988 v_acc: 0.78353 |  iteration: 5115 teacher: 1 stage: sketch lr: 0.000618\n",
      "batch 143 loss: 0.79908 acc: 0.75716 | v_loss: 0.76168 v_acc: 0.75586 |  iteration: 5116 teacher: 1 stage: sketch lr: 0.000618\n",
      "batch 144 loss: 0.77072 acc: 0.75553 | v_loss: 0.82308 v_acc: 0.75618 |  iteration: 5117 teacher: 1 stage: sketch lr: 0.000618\n",
      "batch 145 loss: 0.80143 acc: 0.75456 | v_loss: 0.81337 v_acc: 0.75293 |  iteration: 5118 teacher: 0 stage: sketch lr: 0.000618\n",
      "batch 146 loss: 0.80928 acc: 0.75228 | v_loss: 0.67966 v_acc: 0.78809 |  iteration: 5119 teacher: 0 stage: sketch lr: 0.000618\n",
      "batch 147 loss: 0.87720 acc: 0.73926 | v_loss: 0.79507 v_acc: 0.76367 |  iteration: 5120 teacher: 1 stage: sketch lr: 0.000618\n",
      "batch 148 loss: 0.83135 acc: 0.75260 | v_loss: 0.78550 v_acc: 0.75716 |  iteration: 5121 teacher: 0 stage: sketch lr: 0.000618\n",
      "batch 149 loss: 0.71249 acc: 0.77148 | v_loss: 0.81902 v_acc: 0.75228 |  iteration: 5122 teacher: 0 stage: sketch lr: 0.000618\n",
      "batch 150 loss: 0.85587 acc: 0.75911 | v_loss: 0.66741 v_acc: 0.78320 |  iteration: 5123 teacher: 1 stage: sketch lr: 0.000617\n",
      "batch 151 loss: 0.74268 acc: 0.76595 | v_loss: 0.65069 v_acc: 0.79069 |  iteration: 5124 teacher: 1 stage: sketch lr: 0.000617\n",
      "batch 152 loss: 0.87905 acc: 0.74154 | v_loss: 0.69989 v_acc: 0.77799 |  iteration: 5125 teacher: 0 stage: sketch lr: 0.000617\n",
      "batch 153 loss: 0.80817 acc: 0.75488 | v_loss: 0.72702 v_acc: 0.76790 |  iteration: 5126 teacher: 0 stage: sketch lr: 0.000617\n",
      "batch 154 loss: 0.86741 acc: 0.74837 | v_loss: 0.82332 v_acc: 0.73991 |  iteration: 5127 teacher: 0 stage: sketch lr: 0.000617\n",
      "batch 155 loss: 0.82442 acc: 0.75065 | v_loss: 0.75968 v_acc: 0.76628 |  iteration: 5128 teacher: 0 stage: sketch lr: 0.000617\n",
      "batch 156 loss: 0.87419 acc: 0.74316 | v_loss: 0.75683 v_acc: 0.78646 |  iteration: 5129 teacher: 0 stage: sketch lr: 0.000617\n",
      "batch 157 loss: 0.84531 acc: 0.74740 | v_loss: 0.82279 v_acc: 0.75716 |  iteration: 5130 teacher: 0 stage: sketch lr: 0.000617\n",
      "batch 158 loss: 0.90319 acc: 0.74349 | v_loss: 0.85838 v_acc: 0.74707 |  iteration: 5131 teacher: 0 stage: sketch lr: 0.000617\n",
      "batch 159 loss: 0.69303 acc: 0.78060 | v_loss: 0.76951 v_acc: 0.77507 |  iteration: 5132 teacher: 1 stage: sketch lr: 0.000617\n",
      "batch 160 loss: 0.80199 acc: 0.74805 | v_loss: 0.77763 v_acc: 0.76237 |  iteration: 5133 teacher: 0 stage: sketch lr: 0.000617\n",
      "batch 161 loss: 0.87295 acc: 0.75651 | v_loss: 0.66797 v_acc: 0.77507 |  iteration: 5134 teacher: 0 stage: sketch lr: 0.000617\n",
      "batch 162 loss: 0.73064 acc: 0.76921 | v_loss: 0.76237 v_acc: 0.76986 |  iteration: 5135 teacher: 1 stage: sketch lr: 0.000617\n",
      "batch 163 loss: 0.86027 acc: 0.76204 | v_loss: 0.77235 v_acc: 0.76953 |  iteration: 5136 teacher: 1 stage: sketch lr: 0.000617\n",
      "batch 164 loss: 0.82040 acc: 0.76107 | v_loss: 0.81607 v_acc: 0.75749 |  iteration: 5137 teacher: 0 stage: sketch lr: 0.000617\n",
      "batch 165 loss: 0.82441 acc: 0.75944 | v_loss: 0.80044 v_acc: 0.76074 |  iteration: 5138 teacher: 1 stage: sketch lr: 0.000617\n",
      "batch 166 loss: 0.71548 acc: 0.77604 | v_loss: 0.78885 v_acc: 0.75618 |  iteration: 5139 teacher: 1 stage: sketch lr: 0.000616\n",
      "batch 167 loss: 0.88516 acc: 0.74479 | v_loss: 0.77537 v_acc: 0.77246 |  iteration: 5140 teacher: 0 stage: sketch lr: 0.000616\n",
      "batch 168 loss: 0.87010 acc: 0.74186 | v_loss: 0.76037 v_acc: 0.76562 |  iteration: 5141 teacher: 0 stage: sketch lr: 0.000616\n",
      "batch 169 loss: 0.91510 acc: 0.73698 | v_loss: 0.92691 v_acc: 0.71517 |  iteration: 5142 teacher: 0 stage: sketch lr: 0.000616\n",
      "batch 170 loss: 0.88936 acc: 0.74837 | v_loss: 0.80232 v_acc: 0.75065 |  iteration: 5143 teacher: 0 stage: sketch lr: 0.000616\n",
      "batch 171 loss: 0.83548 acc: 0.74870 | v_loss: 0.83743 v_acc: 0.74772 |  iteration: 5144 teacher: 1 stage: sketch lr: 0.000616\n",
      "batch 172 loss: 0.91165 acc: 0.73275 | v_loss: 0.80785 v_acc: 0.75033 |  iteration: 5145 teacher: 1 stage: sketch lr: 0.000616\n",
      "batch 173 loss: 0.94859 acc: 0.73275 | v_loss: 0.82782 v_acc: 0.74935 |  iteration: 5146 teacher: 1 stage: sketch lr: 0.000616\n",
      "batch 174 loss: 0.98775 acc: 0.72396 | v_loss: 0.75508 v_acc: 0.77116 |  iteration: 5147 teacher: 1 stage: sketch lr: 0.000616\n",
      "batch 175 loss: 0.80449 acc: 0.75586 | v_loss: 0.87959 v_acc: 0.74512 |  iteration: 5148 teacher: 1 stage: sketch lr: 0.000616\n",
      "batch 176 loss: 0.86040 acc: 0.74284 | v_loss: 0.85203 v_acc: 0.74382 |  iteration: 5149 teacher: 0 stage: sketch lr: 0.000616\n",
      "batch 177 loss: 0.88044 acc: 0.73665 | v_loss: 0.96522 v_acc: 0.72135 |  iteration: 5150 teacher: 0 stage: sketch lr: 0.000616\n",
      "batch 178 loss: 0.92456 acc: 0.72005 | v_loss: 0.82051 v_acc: 0.75033 |  iteration: 5151 teacher: 0 stage: sketch lr: 0.000616\n",
      "batch 179 loss: 0.89598 acc: 0.72689 | v_loss: 0.86837 v_acc: 0.73796 |  iteration: 5152 teacher: 0 stage: sketch lr: 0.000616\n",
      "batch 180 loss: 0.91675 acc: 0.72917 | v_loss: 0.93302 v_acc: 0.72493 |  iteration: 5153 teacher: 1 stage: sketch lr: 0.000616\n",
      "batch 181 loss: 0.98518 acc: 0.72233 | v_loss: 0.91740 v_acc: 0.73665 |  iteration: 5154 teacher: 1 stage: sketch lr: 0.000616\n",
      "batch 182 loss: 0.99136 acc: 0.71908 | v_loss: 0.94753 v_acc: 0.73405 |  iteration: 5155 teacher: 0 stage: sketch lr: 0.000616\n",
      "batch 183 loss: 0.90558 acc: 0.73828 | v_loss: 0.82118 v_acc: 0.74967 |  iteration: 5156 teacher: 1 stage: sketch lr: 0.000615\n",
      "batch 184 loss: 0.98339 acc: 0.73405 | v_loss: 0.84079 v_acc: 0.74284 |  iteration: 5157 teacher: 0 stage: sketch lr: 0.000615\n",
      "batch 185 loss: 0.95897 acc: 0.72428 | v_loss: 0.81567 v_acc: 0.74121 |  iteration: 5158 teacher: 1 stage: sketch lr: 0.000615\n",
      "batch 186 loss: 0.95211 acc: 0.72559 | v_loss: 0.85446 v_acc: 0.75163 |  iteration: 5159 teacher: 0 stage: sketch lr: 0.000615\n",
      "batch 187 loss: 0.98022 acc: 0.73861 | v_loss: 0.79576 v_acc: 0.74284 |  iteration: 5160 teacher: 1 stage: sketch lr: 0.000615\n",
      "batch 188 loss: 1.00422 acc: 0.72038 | v_loss: 0.87478 v_acc: 0.73568 |  iteration: 5161 teacher: 1 stage: sketch lr: 0.000615\n",
      "batch 189 loss: 0.94537 acc: 0.72884 | v_loss: 0.95184 v_acc: 0.72559 |  iteration: 5162 teacher: 1 stage: sketch lr: 0.000615\n",
      "batch 190 loss: 0.89007 acc: 0.74284 | v_loss: 0.88480 v_acc: 0.72526 |  iteration: 5163 teacher: 1 stage: sketch lr: 0.000615\n",
      "batch 191 loss: 0.93752 acc: 0.73568 | v_loss: 0.90554 v_acc: 0.73926 |  iteration: 5164 teacher: 0 stage: sketch lr: 0.000615\n",
      "batch 192 loss: 1.02879 acc: 0.72201 | v_loss: 0.80141 v_acc: 0.74154 |  iteration: 5165 teacher: 0 stage: sketch lr: 0.000615\n",
      "batch 193 loss: 0.88798 acc: 0.73796 | v_loss: 0.85703 v_acc: 0.74056 |  iteration: 5166 teacher: 1 stage: sketch lr: 0.000615\n",
      "batch 194 loss: 0.93164 acc: 0.73633 | v_loss: 0.77402 v_acc: 0.77279 |  iteration: 5167 teacher: 1 stage: sketch lr: 0.000615\n",
      "batch 195 loss: 1.00055 acc: 0.72038 | v_loss: 0.87617 v_acc: 0.74284 |  iteration: 5168 teacher: 1 stage: sketch lr: 0.000615\n",
      "batch 196 loss: 0.95096 acc: 0.72396 | v_loss: 0.95072 v_acc: 0.73958 |  iteration: 5169 teacher: 0 stage: sketch lr: 0.000615\n",
      "batch 197 loss: 1.05471 acc: 0.71875 | v_loss: 0.84634 v_acc: 0.74479 |  iteration: 5170 teacher: 1 stage: sketch lr: 0.000615\n",
      "batch 198 loss: 0.98956 acc: 0.72819 | v_loss: 0.89547 v_acc: 0.73177 |  iteration: 5171 teacher: 0 stage: sketch lr: 0.000615\n",
      "batch 199 loss: 1.01691 acc: 0.72852 | v_loss: 0.84961 v_acc: 0.73698 |  iteration: 5172 teacher: 0 stage: sketch lr: 0.000615\n",
      "batch 200 loss: 0.97442 acc: 0.72884 | v_loss: 0.82863 v_acc: 0.74967 |  iteration: 5173 teacher: 0 stage: sketch lr: 0.000614\n",
      "batch 201 loss: 0.99056 acc: 0.71680 | v_loss: 0.99279 v_acc: 0.71712 |  iteration: 5174 teacher: 1 stage: sketch lr: 0.000614\n",
      "batch 202 loss: 0.97067 acc: 0.72786 | v_loss: 0.88798 v_acc: 0.74251 |  iteration: 5175 teacher: 0 stage: sketch lr: 0.000614\n",
      "batch 203 loss: 0.92030 acc: 0.73633 | v_loss: 0.82268 v_acc: 0.75716 |  iteration: 5176 teacher: 1 stage: sketch lr: 0.000614\n",
      "batch 204 loss: 1.00471 acc: 0.71680 | v_loss: 1.02943 v_acc: 0.71810 |  iteration: 5177 teacher: 1 stage: sketch lr: 0.000614\n",
      "batch 205 loss: 1.11884 acc: 0.72559 | v_loss: 0.96509 v_acc: 0.72559 |  iteration: 5178 teacher: 1 stage: sketch lr: 0.000614\n",
      "batch 206 loss: 1.05774 acc: 0.71549 | v_loss: 1.07431 v_acc: 0.70508 |  iteration: 5179 teacher: 0 stage: sketch lr: 0.000614\n",
      "batch 207 loss: 1.14776 acc: 0.71061 | v_loss: 1.00016 v_acc: 0.72493 |  iteration: 5180 teacher: 1 stage: sketch lr: 0.000614\n",
      "batch 208 loss: 1.09046 acc: 0.70540 | v_loss: 1.03173 v_acc: 0.71094 |  iteration: 5181 teacher: 0 stage: sketch lr: 0.000614\n",
      "batch 209 loss: 1.09061 acc: 0.71387 | v_loss: 1.07382 v_acc: 0.72201 |  iteration: 5182 teacher: 0 stage: sketch lr: 0.000614\n",
      "batch 210 loss: 1.17779 acc: 0.71810 | v_loss: 1.12335 v_acc: 0.70671 |  iteration: 5183 teacher: 1 stage: sketch lr: 0.000614\n",
      "batch 211 loss: 1.26430 acc: 0.69661 | v_loss: 1.03197 v_acc: 0.72363 |  iteration: 5184 teacher: 0 stage: sketch lr: 0.000614\n",
      "batch 212 loss: 1.19785 acc: 0.71647 | v_loss: 1.02102 v_acc: 0.72786 |  iteration: 5185 teacher: 0 stage: sketch lr: 0.000614\n",
      "batch 213 loss: 1.20374 acc: 0.70247 | v_loss: 1.09882 v_acc: 0.71257 |  iteration: 5186 teacher: 0 stage: sketch lr: 0.000614\n",
      "batch 214 loss: 1.32310 acc: 0.68880 | v_loss: 1.37879 v_acc: 0.69824 |  iteration: 5187 teacher: 0 stage: sketch lr: 0.000614\n",
      "batch 215 loss: 1.28550 acc: 0.70215 | v_loss: 1.37493 v_acc: 0.71094 |  iteration: 5188 teacher: 0 stage: sketch lr: 0.000614\n",
      "batch 216 loss: 1.59299 acc: 0.69987 | v_loss: 1.42314 v_acc: 0.69531 |  iteration: 5189 teacher: 1 stage: sketch lr: 0.000614\n",
      "batch 217 loss: 1.31890 acc: 0.70020 | v_loss: 1.21193 v_acc: 0.72884 |  iteration: 5190 teacher: 0 stage: sketch lr: 0.000613\n",
      "batch 218 loss: 1.34419 acc: 0.70866 | v_loss: 1.53492 v_acc: 0.67253 |  iteration: 5191 teacher: 0 stage: sketch lr: 0.000613\n",
      "batch 219 loss: 1.39024 acc: 0.69368 | v_loss: 1.51875 v_acc: 0.66374 |  iteration: 5192 teacher: 1 stage: sketch lr: 0.000613\n",
      "batch 220 loss: 1.31991 acc: 0.68978 | v_loss: 1.36747 v_acc: 0.69434 |  iteration: 5193 teacher: 1 stage: sketch lr: 0.000613\n",
      "batch 221 loss: 1.32588 acc: 0.70573 | v_loss: 1.40950 v_acc: 0.69727 |  iteration: 5194 teacher: 0 stage: sketch lr: 0.000613\n",
      "batch 222 loss: 1.33969 acc: 0.69954 | v_loss: 1.31500 v_acc: 0.70508 |  iteration: 5195 teacher: 0 stage: sketch lr: 0.000613\n",
      "batch 223 loss: 1.44552 acc: 0.69857 | v_loss: 1.30682 v_acc: 0.70182 |  iteration: 5196 teacher: 0 stage: sketch lr: 0.000613\n",
      "batch 224 loss: 1.43259 acc: 0.69954 | v_loss: 1.30391 v_acc: 0.71289 |  iteration: 5197 teacher: 1 stage: sketch lr: 0.000613\n",
      "batch 225 loss: 1.29906 acc: 0.70605 | v_loss: 1.51218 v_acc: 0.67806 |  iteration: 5198 teacher: 0 stage: sketch lr: 0.000613\n",
      "batch 226 loss: 1.37899 acc: 0.69596 | v_loss: 1.39530 v_acc: 0.70671 |  iteration: 5199 teacher: 0 stage: sketch lr: 0.000613\n",
      "batch 227 loss: 1.37273 acc: 0.70996 | v_loss: 1.25127 v_acc: 0.70801 |  iteration: 5200 teacher: 0 stage: sketch lr: 0.000613\n",
      "batch 228 loss: 1.36639 acc: 0.69727 | v_loss: 1.30974 v_acc: 0.70964 |  iteration: 5201 teacher: 0 stage: sketch lr: 0.000613\n",
      "batch 229 loss: 1.33489 acc: 0.70280 | v_loss: 1.23757 v_acc: 0.71061 |  iteration: 5202 teacher: 1 stage: sketch lr: 0.000613\n",
      "batch 230 loss: 1.46942 acc: 0.69661 | v_loss: 1.31215 v_acc: 0.69954 |  iteration: 5203 teacher: 1 stage: sketch lr: 0.000613\n",
      "batch 231 loss: 1.40888 acc: 0.70052 | v_loss: 1.27840 v_acc: 0.70964 |  iteration: 5204 teacher: 0 stage: sketch lr: 0.000613\n",
      "batch 232 loss: 1.32884 acc: 0.70247 | v_loss: 1.24067 v_acc: 0.71452 |  iteration: 5205 teacher: 0 stage: sketch lr: 0.000613\n",
      "batch 233 loss: 1.50587 acc: 0.69173 | v_loss: 1.22614 v_acc: 0.72493 |  iteration: 5206 teacher: 0 stage: sketch lr: 0.000613\n",
      "batch 234 loss: 1.41975 acc: 0.69499 | v_loss: 1.41249 v_acc: 0.70833 |  iteration: 5207 teacher: 0 stage: sketch lr: 0.000612\n",
      "batch 235 loss: 1.46224 acc: 0.69043 | v_loss: 1.28552 v_acc: 0.70736 |  iteration: 5208 teacher: 0 stage: sketch lr: 0.000612\n",
      "batch 236 loss: 1.40225 acc: 0.69368 | v_loss: 1.29670 v_acc: 0.70638 |  iteration: 5209 teacher: 1 stage: sketch lr: 0.000612\n",
      "batch 237 loss: 1.36800 acc: 0.69596 | v_loss: 1.17748 v_acc: 0.71126 |  iteration: 5210 teacher: 1 stage: sketch lr: 0.000612\n",
      "batch 238 loss: 1.34570 acc: 0.69401 | v_loss: 1.28988 v_acc: 0.72396 |  iteration: 5211 teacher: 0 stage: sketch lr: 0.000612\n",
      "batch 239 loss: 1.35434 acc: 0.70312 | v_loss: 1.38926 v_acc: 0.69336 |  iteration: 5212 teacher: 1 stage: sketch lr: 0.000612\n",
      "batch 240 loss: 1.38495 acc: 0.70475 | v_loss: 1.40255 v_acc: 0.71712 |  iteration: 5213 teacher: 0 stage: sketch lr: 0.000612\n",
      "batch 241 loss: 1.35412 acc: 0.70378 | v_loss: 1.26902 v_acc: 0.71452 |  iteration: 5214 teacher: 1 stage: sketch lr: 0.000612\n",
      "batch 242 loss: 1.48216 acc: 0.69303 | v_loss: 1.17966 v_acc: 0.72526 |  iteration: 5215 teacher: 1 stage: sketch lr: 0.000612\n",
      "batch 243 loss: 1.29164 acc: 0.70866 | v_loss: 1.16209 v_acc: 0.72428 |  iteration: 5216 teacher: 1 stage: sketch lr: 0.000612\n",
      "batch 244 loss: 1.40217 acc: 0.69792 | v_loss: 1.27717 v_acc: 0.69987 |  iteration: 5217 teacher: 1 stage: sketch lr: 0.000612\n",
      "batch 245 loss: 1.39247 acc: 0.70085 | v_loss: 1.27788 v_acc: 0.69857 |  iteration: 5218 teacher: 1 stage: sketch lr: 0.000612\n",
      "batch 246 loss: 1.33481 acc: 0.69434 | v_loss: 1.26420 v_acc: 0.69987 |  iteration: 5219 teacher: 1 stage: sketch lr: 0.000612\n",
      "batch 247 loss: 1.42226 acc: 0.70020 | v_loss: 1.35318 v_acc: 0.69141 |  iteration: 5220 teacher: 0 stage: sketch lr: 0.000612\n",
      "batch 248 loss: 1.36650 acc: 0.69368 | v_loss: 1.47637 v_acc: 0.69759 |  iteration: 5221 teacher: 0 stage: sketch lr: 0.000612\n",
      "batch 249 loss: 1.38345 acc: 0.70117 | v_loss: 1.38833 v_acc: 0.70247 |  iteration: 5222 teacher: 0 stage: sketch lr: 0.000612\n",
      "batch 250 loss: 1.36221 acc: 0.70052 | v_loss: 1.26944 v_acc: 0.71940 |  iteration: 5223 teacher: 0 stage: sketch lr: 0.000612\n",
      "batch 251 loss: 1.30799 acc: 0.70410 | v_loss: 1.22875 v_acc: 0.70638 |  iteration: 5224 teacher: 1 stage: sketch lr: 0.000611\n",
      "batch 252 loss: 1.34487 acc: 0.70671 | v_loss: 1.22042 v_acc: 0.72070 |  iteration: 5225 teacher: 1 stage: sketch lr: 0.000611\n",
      "batch 253 loss: 1.37661 acc: 0.70475 | v_loss: 1.28811 v_acc: 0.70508 |  iteration: 5226 teacher: 0 stage: sketch lr: 0.000611\n",
      "batch 254 loss: 1.31525 acc: 0.70996 | v_loss: 1.29991 v_acc: 0.71647 |  iteration: 5227 teacher: 1 stage: sketch lr: 0.000611\n",
      "batch 255 loss: 1.36441 acc: 0.70247 | v_loss: 1.23177 v_acc: 0.72526 |  iteration: 5228 teacher: 0 stage: sketch lr: 0.000611\n",
      "batch 256 loss: 1.34417 acc: 0.70410 | v_loss: 1.26997 v_acc: 0.71517 |  iteration: 5229 teacher: 1 stage: sketch lr: 0.000611\n",
      "batch 257 loss: 1.36780 acc: 0.69401 | v_loss: 1.29656 v_acc: 0.70475 |  iteration: 5230 teacher: 1 stage: sketch lr: 0.000611\n",
      "batch 258 loss: 1.32525 acc: 0.70117 | v_loss: 1.25438 v_acc: 0.72070 |  iteration: 5231 teacher: 0 stage: sketch lr: 0.000611\n",
      "batch 259 loss: 1.38072 acc: 0.68913 | v_loss: 1.22617 v_acc: 0.71680 |  iteration: 5232 teacher: 1 stage: sketch lr: 0.000611\n",
      "batch 260 loss: 1.40507 acc: 0.69271 | v_loss: 1.51988 v_acc: 0.68880 |  iteration: 5233 teacher: 0 stage: sketch lr: 0.000611\n",
      "batch 261 loss: 1.39641 acc: 0.69759 | v_loss: 1.25561 v_acc: 0.71257 |  iteration: 5234 teacher: 0 stage: sketch lr: 0.000611\n",
      "batch 262 loss: 1.26721 acc: 0.71094 | v_loss: 1.29011 v_acc: 0.71875 |  iteration: 5235 teacher: 0 stage: sketch lr: 0.000611\n",
      "batch 263 loss: 1.28864 acc: 0.71387 | v_loss: 1.28964 v_acc: 0.70736 |  iteration: 5236 teacher: 0 stage: sketch lr: 0.000611\n",
      "batch 264 loss: 1.36766 acc: 0.70410 | v_loss: 1.34680 v_acc: 0.70117 |  iteration: 5237 teacher: 0 stage: sketch lr: 0.000611\n",
      "batch 265 loss: 1.33475 acc: 0.70410 | v_loss: 1.14278 v_acc: 0.73210 |  iteration: 5238 teacher: 1 stage: sketch lr: 0.000611\n",
      "batch 266 loss: 1.43065 acc: 0.69401 | v_loss: 1.42339 v_acc: 0.70898 |  iteration: 5239 teacher: 1 stage: sketch lr: 0.000611\n",
      "batch 267 loss: 1.38162 acc: 0.69694 | v_loss: 1.23467 v_acc: 0.69954 |  iteration: 5240 teacher: 1 stage: sketch lr: 0.000611\n",
      "batch 268 loss: 1.30515 acc: 0.71191 | v_loss: 1.23285 v_acc: 0.69824 |  iteration: 5241 teacher: 1 stage: sketch lr: 0.000610\n",
      "batch 269 loss: 1.42912 acc: 0.69499 | v_loss: 1.31637 v_acc: 0.69987 |  iteration: 5242 teacher: 0 stage: sketch lr: 0.000610\n",
      "batch 270 loss: 1.37344 acc: 0.69727 | v_loss: 1.32001 v_acc: 0.69727 |  iteration: 5243 teacher: 0 stage: sketch lr: 0.000610\n",
      "batch 271 loss: 1.36227 acc: 0.70671 | v_loss: 1.36396 v_acc: 0.69727 |  iteration: 5244 teacher: 1 stage: sketch lr: 0.000610\n",
      "batch 272 loss: 1.33715 acc: 0.70215 | v_loss: 1.40509 v_acc: 0.70573 |  iteration: 5245 teacher: 1 stage: sketch lr: 0.000610\n",
      "batch 273 loss: 1.32450 acc: 0.70280 | v_loss: 1.34720 v_acc: 0.70540 |  iteration: 5246 teacher: 0 stage: sketch lr: 0.000610\n",
      "batch 274 loss: 1.23910 acc: 0.71419 | v_loss: 1.26851 v_acc: 0.70638 |  iteration: 5247 teacher: 0 stage: sketch lr: 0.000610\n",
      "batch 275 loss: 1.28727 acc: 0.70378 | v_loss: 1.36774 v_acc: 0.71029 |  iteration: 5248 teacher: 0 stage: sketch lr: 0.000610\n",
      "batch 276 loss: 1.31826 acc: 0.70833 | v_loss: 1.23890 v_acc: 0.72005 |  iteration: 5249 teacher: 1 stage: sketch lr: 0.000610\n",
      "batch 277 loss: 1.43590 acc: 0.68685 | v_loss: 1.19264 v_acc: 0.71940 |  iteration: 5250 teacher: 1 stage: sketch lr: 0.000610\n",
      "batch 278 loss: 1.35721 acc: 0.69857 | v_loss: 1.18594 v_acc: 0.70475 |  iteration: 5251 teacher: 1 stage: sketch lr: 0.000610\n",
      "batch 279 loss: 1.35364 acc: 0.69857 | v_loss: 1.29127 v_acc: 0.69954 |  iteration: 5252 teacher: 1 stage: sketch lr: 0.000610\n",
      "batch 280 loss: 1.40645 acc: 0.69694 | v_loss: 1.38938 v_acc: 0.69010 |  iteration: 5253 teacher: 0 stage: sketch lr: 0.000610\n",
      "batch 281 loss: 1.19384 acc: 0.71517 | v_loss: 1.19103 v_acc: 0.71582 |  iteration: 5254 teacher: 0 stage: sketch lr: 0.000610\n",
      "batch 282 loss: 1.28725 acc: 0.70247 | v_loss: 1.21484 v_acc: 0.69531 |  iteration: 5255 teacher: 0 stage: sketch lr: 0.000610\n",
      "batch 283 loss: 1.33630 acc: 0.69368 | v_loss: 1.25068 v_acc: 0.70573 |  iteration: 5256 teacher: 0 stage: sketch lr: 0.000610\n",
      "batch 284 loss: 1.27580 acc: 0.70345 | v_loss: 1.27710 v_acc: 0.70345 |  iteration: 5257 teacher: 1 stage: sketch lr: 0.000610\n",
      "batch 285 loss: 1.40689 acc: 0.69010 | v_loss: 1.08897 v_acc: 0.74154 |  iteration: 5258 teacher: 1 stage: sketch lr: 0.000609\n",
      "batch 286 loss: 1.30179 acc: 0.70410 | v_loss: 1.21185 v_acc: 0.71224 |  iteration: 5259 teacher: 0 stage: sketch lr: 0.000609\n",
      "batch 287 loss: 1.24633 acc: 0.70703 | v_loss: 1.18713 v_acc: 0.69303 |  iteration: 5260 teacher: 1 stage: sketch lr: 0.000609\n",
      "batch 288 loss: 1.39378 acc: 0.70150 | v_loss: 1.20138 v_acc: 0.71159 |  iteration: 5261 teacher: 0 stage: sketch lr: 0.000609\n",
      "batch 289 loss: 1.35232 acc: 0.69694 | v_loss: 1.27254 v_acc: 0.71745 |  iteration: 5262 teacher: 0 stage: sketch lr: 0.000609\n",
      "batch 290 loss: 1.27351 acc: 0.69987 | v_loss: 1.28858 v_acc: 0.71354 |  iteration: 5263 teacher: 1 stage: sketch lr: 0.000609\n",
      "batch 291 loss: 1.36789 acc: 0.70247 | v_loss: 1.21871 v_acc: 0.72038 |  iteration: 5264 teacher: 0 stage: sketch lr: 0.000609\n",
      "batch 292 loss: 1.27841 acc: 0.71061 | v_loss: 1.42569 v_acc: 0.69987 |  iteration: 5265 teacher: 1 stage: sketch lr: 0.000609\n",
      "batch 293 loss: 1.36792 acc: 0.69173 | v_loss: 1.28429 v_acc: 0.71680 |  iteration: 5266 teacher: 1 stage: sketch lr: 0.000609\n",
      "batch 294 loss: 1.37876 acc: 0.69010 | v_loss: 1.09755 v_acc: 0.73926 |  iteration: 5267 teacher: 0 stage: sketch lr: 0.000609\n",
      "batch 295 loss: 1.30157 acc: 0.69759 | v_loss: 1.25029 v_acc: 0.70996 |  iteration: 5268 teacher: 1 stage: sketch lr: 0.000609\n",
      "batch 296 loss: 1.28949 acc: 0.69857 | v_loss: 1.34949 v_acc: 0.68945 |  iteration: 5269 teacher: 1 stage: sketch lr: 0.000609\n",
      "batch 297 loss: 1.37286 acc: 0.69824 | v_loss: 1.27822 v_acc: 0.69531 |  iteration: 5270 teacher: 1 stage: sketch lr: 0.000609\n",
      "batch 298 loss: 1.44237 acc: 0.68587 | v_loss: 1.31631 v_acc: 0.70020 |  iteration: 5271 teacher: 0 stage: sketch lr: 0.000609\n",
      "batch 299 loss: 1.44154 acc: 0.69238 | v_loss: 1.28939 v_acc: 0.69629 |  iteration: 5272 teacher: 1 stage: sketch lr: 0.000609\n",
      "batch 300 loss: 1.42917 acc: 0.69434 | v_loss: 1.27406 v_acc: 0.70931 |  iteration: 5273 teacher: 0 stage: sketch lr: 0.000609\n",
      "batch 301 loss: 1.29067 acc: 0.71908 | v_loss: 1.30443 v_acc: 0.69076 |  iteration: 5274 teacher: 0 stage: sketch lr: 0.000609\n",
      "batch 302 loss: 1.31909 acc: 0.70768 | v_loss: 1.20311 v_acc: 0.71419 |  iteration: 5275 teacher: 1 stage: sketch lr: 0.000608\n",
      "batch 303 loss: 1.34464 acc: 0.70182 | v_loss: 1.20788 v_acc: 0.72493 |  iteration: 5276 teacher: 0 stage: sketch lr: 0.000608\n",
      "batch 304 loss: 1.30154 acc: 0.70996 | v_loss: 1.25275 v_acc: 0.70540 |  iteration: 5277 teacher: 0 stage: sketch lr: 0.000608\n",
      "batch 305 loss: 1.38920 acc: 0.70312 | v_loss: 1.43676 v_acc: 0.69954 |  iteration: 5278 teacher: 1 stage: sketch lr: 0.000608\n",
      "batch 306 loss: 1.39516 acc: 0.70182 | v_loss: 1.20061 v_acc: 0.70703 |  iteration: 5279 teacher: 0 stage: sketch lr: 0.000608\n",
      "batch 307 loss: 1.30770 acc: 0.70736 | v_loss: 1.44802 v_acc: 0.68099 |  iteration: 5280 teacher: 0 stage: sketch lr: 0.000608\n",
      "batch 308 loss: 1.37369 acc: 0.69792 | v_loss: 1.24757 v_acc: 0.71029 |  iteration: 5281 teacher: 1 stage: sketch lr: 0.000608\n",
      "batch 309 loss: 1.31471 acc: 0.70573 | v_loss: 1.52664 v_acc: 0.68001 |  iteration: 5282 teacher: 0 stage: sketch lr: 0.000608\n",
      "batch 310 loss: 1.34205 acc: 0.69824 | v_loss: 1.42464 v_acc: 0.68327 |  iteration: 5283 teacher: 0 stage: sketch lr: 0.000608\n",
      "batch 311 loss: 1.51761 acc: 0.68294 | v_loss: 1.37187 v_acc: 0.68945 |  iteration: 5284 teacher: 1 stage: sketch lr: 0.000608\n",
      "batch 312 loss: 1.36848 acc: 0.69336 | v_loss: 1.36735 v_acc: 0.69141 |  iteration: 5285 teacher: 1 stage: sketch lr: 0.000608\n",
      "batch 313 loss: 1.39428 acc: 0.70150 | v_loss: 1.26095 v_acc: 0.70866 |  iteration: 5286 teacher: 0 stage: sketch lr: 0.000608\n",
      "batch 314 loss: 1.27447 acc: 0.70215 | v_loss: 1.32771 v_acc: 0.70150 |  iteration: 5287 teacher: 1 stage: sketch lr: 0.000608\n",
      "batch 315 loss: 1.33375 acc: 0.70280 | v_loss: 1.29972 v_acc: 0.71549 |  iteration: 5288 teacher: 0 stage: sketch lr: 0.000608\n",
      "batch 316 loss: 1.31244 acc: 0.69857 | v_loss: 1.47474 v_acc: 0.68783 |  iteration: 5289 teacher: 0 stage: sketch lr: 0.000608\n",
      "batch 317 loss: 1.28572 acc: 0.70671 | v_loss: 1.38697 v_acc: 0.70247 |  iteration: 5290 teacher: 1 stage: sketch lr: 0.000608\n",
      "batch 318 loss: 1.39944 acc: 0.70215 | v_loss: 1.23924 v_acc: 0.71126 |  iteration: 5291 teacher: 0 stage: sketch lr: 0.000608\n",
      "batch 319 loss: 1.29483 acc: 0.71484 | v_loss: 1.27442 v_acc: 0.71224 |  iteration: 5292 teacher: 0 stage: sketch lr: 0.000608\n",
      "batch 320 loss: 1.33893 acc: 0.70247 | v_loss: 1.18940 v_acc: 0.69694 |  iteration: 5293 teacher: 0 stage: sketch lr: 0.000607\n",
      "batch 321 loss: 1.29283 acc: 0.69987 | v_loss: 1.31753 v_acc: 0.69954 |  iteration: 5294 teacher: 1 stage: sketch lr: 0.000607\n",
      "batch 322 loss: 1.34563 acc: 0.69336 | v_loss: 1.26561 v_acc: 0.71842 |  iteration: 5295 teacher: 1 stage: sketch lr: 0.000607\n",
      "batch 323 loss: 1.29419 acc: 0.70312 | v_loss: 1.18903 v_acc: 0.71712 |  iteration: 5296 teacher: 1 stage: sketch lr: 0.000607\n",
      "batch 324 loss: 1.28501 acc: 0.70085 | v_loss: 1.18418 v_acc: 0.72331 |  iteration: 5297 teacher: 1 stage: sketch lr: 0.000607\n",
      "batch 325 loss: 1.24931 acc: 0.70768 | v_loss: 1.33249 v_acc: 0.70931 |  iteration: 5298 teacher: 1 stage: sketch lr: 0.000607\n",
      "batch 326 loss: 1.40442 acc: 0.68978 | v_loss: 1.28391 v_acc: 0.70345 |  iteration: 5299 teacher: 0 stage: sketch lr: 0.000607\n",
      "batch 327 loss: 1.34696 acc: 0.69336 | v_loss: 1.27485 v_acc: 0.70736 |  iteration: 5300 teacher: 1 stage: sketch lr: 0.000607\n",
      "batch 328 loss: 1.24427 acc: 0.71224 | v_loss: 1.14842 v_acc: 0.71257 |  iteration: 5301 teacher: 0 stage: sketch lr: 0.000607\n",
      "batch 329 loss: 1.33232 acc: 0.70182 | v_loss: 1.29034 v_acc: 0.72884 |  iteration: 5302 teacher: 0 stage: sketch lr: 0.000607\n",
      "batch 330 loss: 1.26643 acc: 0.70833 | v_loss: 1.34700 v_acc: 0.70085 |  iteration: 5303 teacher: 0 stage: sketch lr: 0.000607\n",
      "batch 331 loss: 1.39101 acc: 0.70052 | v_loss: 1.31189 v_acc: 0.71875 |  iteration: 5304 teacher: 1 stage: sketch lr: 0.000607\n",
      "batch 332 loss: 1.33963 acc: 0.69206 | v_loss: 1.19982 v_acc: 0.70801 |  iteration: 5305 teacher: 0 stage: sketch lr: 0.000607\n",
      "batch 333 loss: 1.30940 acc: 0.69694 | v_loss: 1.16676 v_acc: 0.72656 |  iteration: 5306 teacher: 1 stage: sketch lr: 0.000607\n",
      "batch 334 loss: 1.41522 acc: 0.68262 | v_loss: 1.16324 v_acc: 0.71647 |  iteration: 5307 teacher: 1 stage: sketch lr: 0.000607\n",
      "batch 335 loss: 1.31062 acc: 0.70085 | v_loss: 1.23229 v_acc: 0.69922 |  iteration: 5308 teacher: 1 stage: sketch lr: 0.000607\n",
      "batch 336 loss: 1.45561 acc: 0.68978 | v_loss: 1.26192 v_acc: 0.70540 |  iteration: 5309 teacher: 1 stage: sketch lr: 0.000607\n",
      "batch 337 loss: 1.46016 acc: 0.69336 | v_loss: 1.28151 v_acc: 0.70605 |  iteration: 5310 teacher: 1 stage: sketch lr: 0.000606\n",
      "batch 338 loss: 1.30881 acc: 0.70443 | v_loss: 1.42236 v_acc: 0.68750 |  iteration: 5311 teacher: 1 stage: sketch lr: 0.000606\n",
      "batch 339 loss: 1.24977 acc: 0.70768 | v_loss: 1.51418 v_acc: 0.68978 |  iteration: 5312 teacher: 1 stage: sketch lr: 0.000606\n",
      "batch 340 loss: 1.46989 acc: 0.69434 | v_loss: 1.36435 v_acc: 0.69368 |  iteration: 5313 teacher: 1 stage: sketch lr: 0.000606\n",
      "batch 341 loss: 1.42165 acc: 0.69499 | v_loss: 1.24941 v_acc: 0.72656 |  iteration: 5314 teacher: 1 stage: sketch lr: 0.000606\n",
      "batch 342 loss: 1.32400 acc: 0.70280 | v_loss: 1.19248 v_acc: 0.70378 |  iteration: 5315 teacher: 0 stage: sketch lr: 0.000606\n",
      "batch 343 loss: 1.38537 acc: 0.70605 | v_loss: 1.18461 v_acc: 0.71484 |  iteration: 5316 teacher: 0 stage: sketch lr: 0.000606\n",
      "batch 344 loss: 1.29672 acc: 0.70898 | v_loss: 1.27144 v_acc: 0.70020 |  iteration: 5317 teacher: 1 stage: sketch lr: 0.000606\n",
      "batch 345 loss: 1.39248 acc: 0.70508 | v_loss: 1.29048 v_acc: 0.71061 |  iteration: 5318 teacher: 0 stage: sketch lr: 0.000606\n",
      "batch 346 loss: 1.27476 acc: 0.71484 | v_loss: 1.24294 v_acc: 0.72005 |  iteration: 5319 teacher: 1 stage: sketch lr: 0.000606\n",
      "batch 347 loss: 1.29941 acc: 0.71354 | v_loss: 1.28214 v_acc: 0.72201 |  iteration: 5320 teacher: 0 stage: sketch lr: 0.000606\n",
      "batch 348 loss: 1.39702 acc: 0.69792 | v_loss: 1.28563 v_acc: 0.70996 |  iteration: 5321 teacher: 1 stage: sketch lr: 0.000606\n",
      "batch 349 loss: 1.30454 acc: 0.70605 | v_loss: 1.18973 v_acc: 0.72721 |  iteration: 5322 teacher: 0 stage: sketch lr: 0.000606\n",
      "batch 350 loss: 1.33819 acc: 0.69987 | v_loss: 1.13943 v_acc: 0.72298 |  iteration: 5323 teacher: 1 stage: sketch lr: 0.000606\n",
      "batch 351 loss: 1.33430 acc: 0.70801 | v_loss: 1.50057 v_acc: 0.69043 |  iteration: 5324 teacher: 0 stage: sketch lr: 0.000606\n",
      "batch 352 loss: 1.22382 acc: 0.71094 | v_loss: 1.21012 v_acc: 0.71191 |  iteration: 5325 teacher: 1 stage: sketch lr: 0.000606\n",
      "batch 353 loss: 1.47981 acc: 0.68424 | v_loss: 1.26325 v_acc: 0.72070 |  iteration: 5326 teacher: 0 stage: sketch lr: 0.000606\n",
      "batch 354 loss: 1.41543 acc: 0.69596 | v_loss: 1.24445 v_acc: 0.71712 |  iteration: 5327 teacher: 0 stage: sketch lr: 0.000606\n",
      "batch 355 loss: 1.33510 acc: 0.70150 | v_loss: 1.31869 v_acc: 0.69434 |  iteration: 5328 teacher: 1 stage: sketch lr: 0.000605\n",
      "batch 356 loss: 1.38282 acc: 0.69303 | v_loss: 1.17648 v_acc: 0.73014 |  iteration: 5329 teacher: 1 stage: sketch lr: 0.000605\n",
      "batch 357 loss: 1.31400 acc: 0.71061 | v_loss: 1.42305 v_acc: 0.71029 |  iteration: 5330 teacher: 1 stage: sketch lr: 0.000605\n",
      "batch 358 loss: 1.38846 acc: 0.71257 | v_loss: 1.26892 v_acc: 0.69531 |  iteration: 5331 teacher: 0 stage: sketch lr: 0.000605\n",
      "batch 359 loss: 1.41889 acc: 0.69238 | v_loss: 1.23999 v_acc: 0.69661 |  iteration: 5332 teacher: 1 stage: sketch lr: 0.000605\n",
      "batch 360 loss: 1.32893 acc: 0.70638 | v_loss: 1.31573 v_acc: 0.70280 |  iteration: 5333 teacher: 0 stage: sketch lr: 0.000605\n",
      "batch 361 loss: 1.31344 acc: 0.70475 | v_loss: 1.32355 v_acc: 0.70052 |  iteration: 5334 teacher: 1 stage: sketch lr: 0.000605\n",
      "batch 362 loss: 1.34215 acc: 0.70605 | v_loss: 1.37315 v_acc: 0.69401 |  iteration: 5335 teacher: 1 stage: sketch lr: 0.000605\n",
      "batch 363 loss: 1.34147 acc: 0.69336 | v_loss: 1.40366 v_acc: 0.70540 |  iteration: 5336 teacher: 0 stage: sketch lr: 0.000605\n",
      "batch 364 loss: 1.34921 acc: 0.68848 | v_loss: 1.33275 v_acc: 0.69759 |  iteration: 5337 teacher: 1 stage: sketch lr: 0.000605\n",
      "batch 365 loss: 1.21167 acc: 0.70345 | v_loss: 1.22860 v_acc: 0.71159 |  iteration: 5338 teacher: 0 stage: sketch lr: 0.000605\n",
      "batch 366 loss: 1.32365 acc: 0.69629 | v_loss: 1.37401 v_acc: 0.70508 |  iteration: 5339 teacher: 0 stage: sketch lr: 0.000605\n",
      "batch 367 loss: 1.47038 acc: 0.68913 | v_loss: 1.23350 v_acc: 0.71777 |  iteration: 5340 teacher: 0 stage: sketch lr: 0.000605\n",
      "batch 368 loss: 1.28922 acc: 0.70898 | v_loss: 1.16568 v_acc: 0.72461 |  iteration: 5341 teacher: 1 stage: sketch lr: 0.000605\n",
      "batch 369 loss: 1.40075 acc: 0.70378 | v_loss: 1.17374 v_acc: 0.70475 |  iteration: 5342 teacher: 1 stage: sketch lr: 0.000605\n",
      "batch 370 loss: 1.35913 acc: 0.70215 | v_loss: 1.29806 v_acc: 0.70117 |  iteration: 5343 teacher: 1 stage: sketch lr: 0.000605\n",
      "batch 371 loss: 1.36886 acc: 0.69303 | v_loss: 1.36520 v_acc: 0.69824 |  iteration: 5344 teacher: 1 stage: sketch lr: 0.000605\n",
      "batch 372 loss: 1.35731 acc: 0.70117 | v_loss: 1.17857 v_acc: 0.71582 |  iteration: 5345 teacher: 1 stage: sketch lr: 0.000604\n",
      "batch 373 loss: 1.31384 acc: 0.71029 | v_loss: 1.24639 v_acc: 0.69987 |  iteration: 5346 teacher: 0 stage: sketch lr: 0.000604\n",
      "batch 374 loss: 1.18741 acc: 0.72005 | v_loss: 1.23876 v_acc: 0.70508 |  iteration: 5347 teacher: 0 stage: sketch lr: 0.000604\n",
      "batch 375 loss: 1.26082 acc: 0.70508 | v_loss: 1.23141 v_acc: 0.70540 |  iteration: 5348 teacher: 0 stage: sketch lr: 0.000604\n",
      "batch 376 loss: 1.39685 acc: 0.69727 | v_loss: 1.08506 v_acc: 0.73438 |  iteration: 5349 teacher: 0 stage: sketch lr: 0.000604\n",
      "batch 377 loss: 1.28460 acc: 0.71224 | v_loss: 1.21176 v_acc: 0.71777 |  iteration: 5350 teacher: 1 stage: sketch lr: 0.000604\n",
      "batch 378 loss: 1.30502 acc: 0.71029 | v_loss: 1.19339 v_acc: 0.70085 |  iteration: 5351 teacher: 0 stage: sketch lr: 0.000604\n",
      "batch 379 loss: 1.40734 acc: 0.68685 | v_loss: 1.16400 v_acc: 0.72005 |  iteration: 5352 teacher: 0 stage: sketch lr: 0.000604\n",
      "batch 380 loss: 1.28764 acc: 0.69987 | v_loss: 1.23022 v_acc: 0.71582 |  iteration: 5353 teacher: 1 stage: sketch lr: 0.000604\n",
      "batch 381 loss: 1.33245 acc: 0.69141 | v_loss: 1.25119 v_acc: 0.72168 |  iteration: 5354 teacher: 0 stage: sketch lr: 0.000604\n",
      "batch 382 loss: 1.34350 acc: 0.69206 | v_loss: 1.24671 v_acc: 0.72721 |  iteration: 5355 teacher: 1 stage: sketch lr: 0.000604\n",
      "batch 383 loss: 1.30354 acc: 0.69466 | v_loss: 1.44545 v_acc: 0.69466 |  iteration: 5356 teacher: 0 stage: sketch lr: 0.000604\n",
      "batch 384 loss: 1.30422 acc: 0.70052 | v_loss: 1.31234 v_acc: 0.72233 |  iteration: 5357 teacher: 1 stage: sketch lr: 0.000604\n",
      "batch 385 loss: 1.37216 acc: 0.68978 | v_loss: 1.07836 v_acc: 0.74316 |  iteration: 5358 teacher: 1 stage: sketch lr: 0.000604\n",
      "batch 386 loss: 1.24655 acc: 0.71289 | v_loss: 1.23022 v_acc: 0.70508 |  iteration: 5359 teacher: 0 stage: sketch lr: 0.000604\n",
      "batch 387 loss: 1.35812 acc: 0.69303 | v_loss: 1.31778 v_acc: 0.69043 |  iteration: 5360 teacher: 0 stage: sketch lr: 0.000604\n",
      "batch 388 loss: 1.21955 acc: 0.70833 | v_loss: 1.19390 v_acc: 0.68978 |  iteration: 5361 teacher: 1 stage: sketch lr: 0.000604\n",
      "batch 389 loss: 1.42900 acc: 0.68587 | v_loss: 1.26776 v_acc: 0.71029 |  iteration: 5362 teacher: 0 stage: sketch lr: 0.000604\n",
      "batch 390 loss: 1.29876 acc: 0.70182 | v_loss: 1.26808 v_acc: 0.69368 |  iteration: 5363 teacher: 1 stage: sketch lr: 0.000603\n",
      "batch 391 loss: 1.33754 acc: 0.69694 | v_loss: 1.24087 v_acc: 0.71810 |  iteration: 5364 teacher: 1 stage: sketch lr: 0.000603\n",
      "batch 392 loss: 1.36615 acc: 0.69759 | v_loss: 1.28182 v_acc: 0.69922 |  iteration: 5365 teacher: 0 stage: sketch lr: 0.000603\n",
      "batch 393 loss: 1.25377 acc: 0.70736 | v_loss: 1.19224 v_acc: 0.72070 |  iteration: 5366 teacher: 1 stage: sketch lr: 0.000603\n",
      "batch 394 loss: 1.38945 acc: 0.69499 | v_loss: 1.19895 v_acc: 0.72624 |  iteration: 5367 teacher: 0 stage: sketch lr: 0.000603\n",
      "batch 395 loss: 1.31498 acc: 0.70964 | v_loss: 1.25747 v_acc: 0.70378 |  iteration: 5368 teacher: 1 stage: sketch lr: 0.000603\n",
      "batch 396 loss: 1.27853 acc: 0.70345 | v_loss: 1.34838 v_acc: 0.69206 |  iteration: 5369 teacher: 0 stage: sketch lr: 0.000603\n",
      "batch 397 loss: 1.31973 acc: 0.70540 | v_loss: 1.18622 v_acc: 0.70768 |  iteration: 5370 teacher: 1 stage: sketch lr: 0.000603\n",
      "batch 398 loss: 1.27971 acc: 0.70768 | v_loss: 1.44704 v_acc: 0.68099 |  iteration: 5371 teacher: 1 stage: sketch lr: 0.000603\n",
      "batch 399 loss: 1.23042 acc: 0.71159 | v_loss: 1.20703 v_acc: 0.71940 |  iteration: 5372 teacher: 1 stage: sketch lr: 0.000603\n",
      "batch 400 loss: 1.29231 acc: 0.70247 | v_loss: 1.51704 v_acc: 0.67383 |  iteration: 5373 teacher: 0 stage: sketch lr: 0.000603\n",
      "batch 401 loss: 1.28420 acc: 0.70671 | v_loss: 1.38781 v_acc: 0.69336 |  iteration: 5374 teacher: 0 stage: sketch lr: 0.000603\n",
      "batch 402 loss: 1.35391 acc: 0.70866 | v_loss: 1.36644 v_acc: 0.69531 |  iteration: 5375 teacher: 1 stage: sketch lr: 0.000603\n",
      "batch 403 loss: 1.43656 acc: 0.69727 | v_loss: 1.32869 v_acc: 0.69661 |  iteration: 5376 teacher: 0 stage: sketch lr: 0.000603\n",
      "batch 404 loss: 1.26716 acc: 0.71061 | v_loss: 1.23802 v_acc: 0.70410 |  iteration: 5377 teacher: 1 stage: sketch lr: 0.000603\n",
      "batch 405 loss: 1.31636 acc: 0.71029 | v_loss: 1.29244 v_acc: 0.69857 |  iteration: 5378 teacher: 1 stage: sketch lr: 0.000603\n",
      "batch 406 loss: 1.44815 acc: 0.69206 | v_loss: 1.26168 v_acc: 0.71452 |  iteration: 5379 teacher: 0 stage: sketch lr: 0.000603\n",
      "batch 407 loss: 1.24871 acc: 0.71289 | v_loss: 1.44719 v_acc: 0.68164 |  iteration: 5380 teacher: 1 stage: sketch lr: 0.000603\n",
      "batch 408 loss: 1.37683 acc: 0.70215 | v_loss: 1.35760 v_acc: 0.70117 |  iteration: 5381 teacher: 1 stage: sketch lr: 0.000602\n",
      "batch 409 loss: 1.33059 acc: 0.69824 | v_loss: 1.21242 v_acc: 0.71094 |  iteration: 5382 teacher: 1 stage: sketch lr: 0.000602\n",
      "batch 410 loss: 1.34726 acc: 0.69499 | v_loss: 1.27341 v_acc: 0.71354 |  iteration: 5383 teacher: 0 stage: sketch lr: 0.000602\n",
      "batch 411 loss: 1.36207 acc: 0.69661 | v_loss: 1.19470 v_acc: 0.70052 |  iteration: 5384 teacher: 1 stage: sketch lr: 0.000602\n",
      "batch 412 loss: 1.37955 acc: 0.69238 | v_loss: 1.28085 v_acc: 0.69857 |  iteration: 5385 teacher: 0 stage: sketch lr: 0.000602\n",
      "batch 413 loss: 1.34614 acc: 0.69694 | v_loss: 1.23993 v_acc: 0.71908 |  iteration: 5386 teacher: 0 stage: sketch lr: 0.000602\n",
      "batch 414 loss: 1.34897 acc: 0.70215 | v_loss: 1.17471 v_acc: 0.71549 |  iteration: 5387 teacher: 1 stage: sketch lr: 0.000602\n",
      "batch 415 loss: 1.26513 acc: 0.70345 | v_loss: 1.14649 v_acc: 0.72103 |  iteration: 5388 teacher: 1 stage: sketch lr: 0.000602\n",
      "batch 416 loss: 1.27665 acc: 0.71159 | v_loss: 1.27857 v_acc: 0.71745 |  iteration: 5389 teacher: 1 stage: sketch lr: 0.000602\n",
      "batch 417 loss: 1.43787 acc: 0.68880 | v_loss: 1.26774 v_acc: 0.70345 |  iteration: 5390 teacher: 0 stage: sketch lr: 0.000602\n",
      "batch 418 loss: 1.33920 acc: 0.71387 | v_loss: 1.27406 v_acc: 0.71159 |  iteration: 5391 teacher: 0 stage: sketch lr: 0.000602\n",
      "batch 419 loss: 1.33993 acc: 0.70280 | v_loss: 1.14209 v_acc: 0.72331 |  iteration: 5392 teacher: 1 stage: sketch lr: 0.000602\n",
      "batch 420 loss: 1.37527 acc: 0.69564 | v_loss: 1.24432 v_acc: 0.72917 |  iteration: 5393 teacher: 1 stage: sketch lr: 0.000602\n",
      "batch 421 loss: 1.24777 acc: 0.70768 | v_loss: 1.31017 v_acc: 0.69434 |  iteration: 5394 teacher: 0 stage: sketch lr: 0.000602\n",
      "batch 422 loss: 1.28341 acc: 0.70540 | v_loss: 1.32527 v_acc: 0.71680 |  iteration: 5395 teacher: 0 stage: sketch lr: 0.000602\n",
      "batch 423 loss: 1.39380 acc: 0.69694 | v_loss: 1.17651 v_acc: 0.71647 |  iteration: 5396 teacher: 1 stage: sketch lr: 0.000602\n",
      "batch 424 loss: 1.35020 acc: 0.69303 | v_loss: 1.14158 v_acc: 0.73698 |  iteration: 5397 teacher: 0 stage: sketch lr: 0.000602\n",
      "batch 425 loss: 1.40047 acc: 0.69499 | v_loss: 1.13979 v_acc: 0.71745 |  iteration: 5398 teacher: 0 stage: sketch lr: 0.000602\n",
      "batch 426 loss: 1.35575 acc: 0.69206 | v_loss: 1.20165 v_acc: 0.70475 |  iteration: 5399 teacher: 0 stage: sketch lr: 0.000601\n",
      "batch 427 loss: 1.26360 acc: 0.69466 | v_loss: 1.24214 v_acc: 0.69987 |  iteration: 5400 teacher: 1 stage: sketch lr: 0.000601\n",
      "batch 428 loss: 1.35725 acc: 0.70085 | v_loss: 1.20950 v_acc: 0.71419 |  iteration: 5401 teacher: 1 stage: sketch lr: 0.000601\n",
      "batch 429 loss: 1.44770 acc: 0.68783 | v_loss: 1.33487 v_acc: 0.68685 |  iteration: 5402 teacher: 1 stage: sketch lr: 0.000601\n",
      "batch 430 loss: 1.28737 acc: 0.70475 | v_loss: 1.47822 v_acc: 0.69499 |  iteration: 5403 teacher: 1 stage: sketch lr: 0.000601\n",
      "batch 431 loss: 1.30223 acc: 0.71029 | v_loss: 1.36820 v_acc: 0.70052 |  iteration: 5404 teacher: 0 stage: sketch lr: 0.000601\n",
      "batch 432 loss: 1.31600 acc: 0.70312 | v_loss: 1.20384 v_acc: 0.72103 |  iteration: 5405 teacher: 0 stage: sketch lr: 0.000601\n",
      "batch 433 loss: 1.36338 acc: 0.70150 | v_loss: 1.18334 v_acc: 0.71029 |  iteration: 5406 teacher: 1 stage: sketch lr: 0.000601\n",
      "batch 434 loss: 1.31065 acc: 0.71257 | v_loss: 1.16550 v_acc: 0.72103 |  iteration: 5407 teacher: 1 stage: sketch lr: 0.000601\n",
      "batch 435 loss: 1.25235 acc: 0.71029 | v_loss: 1.23870 v_acc: 0.70443 |  iteration: 5408 teacher: 0 stage: sketch lr: 0.000601\n",
      "batch 436 loss: 1.28219 acc: 0.70443 | v_loss: 1.25922 v_acc: 0.71842 |  iteration: 5409 teacher: 1 stage: sketch lr: 0.000601\n",
      "batch 437 loss: 1.29294 acc: 0.70345 | v_loss: 1.23443 v_acc: 0.72884 |  iteration: 5410 teacher: 0 stage: sketch lr: 0.000601\n",
      "batch 438 loss: 1.29850 acc: 0.70280 | v_loss: 1.26568 v_acc: 0.71647 |  iteration: 5411 teacher: 0 stage: sketch lr: 0.000601\n",
      "batch 439 loss: 1.27910 acc: 0.70150 | v_loss: 1.24876 v_acc: 0.71322 |  iteration: 5412 teacher: 1 stage: sketch lr: 0.000601\n",
      "batch 440 loss: 1.22025 acc: 0.70996 | v_loss: 1.17783 v_acc: 0.72168 |  iteration: 5413 teacher: 1 stage: sketch lr: 0.000601\n",
      "batch 441 loss: 1.21943 acc: 0.70736 | v_loss: 1.14520 v_acc: 0.72201 |  iteration: 5414 teacher: 1 stage: sketch lr: 0.000601\n",
      "batch 442 loss: 1.41947 acc: 0.68522 | v_loss: 1.45322 v_acc: 0.69010 |  iteration: 5415 teacher: 1 stage: sketch lr: 0.000601\n",
      "batch 443 loss: 1.33422 acc: 0.70996 | v_loss: 1.21238 v_acc: 0.71191 |  iteration: 5416 teacher: 0 stage: sketch lr: 0.000601\n",
      "batch 444 loss: 1.25056 acc: 0.71322 | v_loss: 1.24982 v_acc: 0.71257 |  iteration: 5417 teacher: 0 stage: sketch lr: 0.000600\n",
      "batch 445 loss: 1.36050 acc: 0.69336 | v_loss: 1.25265 v_acc: 0.70671 |  iteration: 5418 teacher: 0 stage: sketch lr: 0.000600\n",
      "batch 446 loss: 1.23264 acc: 0.71517 | v_loss: 1.30734 v_acc: 0.70247 |  iteration: 5419 teacher: 0 stage: sketch lr: 0.000600\n",
      "batch 447 loss: 1.28404 acc: 0.71354 | v_loss: 1.16381 v_acc: 0.72917 |  iteration: 5420 teacher: 0 stage: sketch lr: 0.000600\n",
      "batch 448 loss: 1.39600 acc: 0.69759 | v_loss: 1.41300 v_acc: 0.70898 |  iteration: 5421 teacher: 1 stage: sketch lr: 0.000600\n",
      "batch 449 loss: 1.32446 acc: 0.70280 | v_loss: 1.20963 v_acc: 0.69661 |  iteration: 5422 teacher: 0 stage: sketch lr: 0.000600\n",
      "batch 450 loss: 1.29732 acc: 0.70833 | v_loss: 1.21036 v_acc: 0.70052 |  iteration: 5423 teacher: 1 stage: sketch lr: 0.000600\n",
      "batch 451 loss: 1.28167 acc: 0.70312 | v_loss: 1.28170 v_acc: 0.70540 |  iteration: 5424 teacher: 0 stage: sketch lr: 0.000600\n",
      "batch 452 loss: 1.25549 acc: 0.70996 | v_loss: 1.28922 v_acc: 0.70312 |  iteration: 5425 teacher: 1 stage: sketch lr: 0.000600\n",
      "batch 453 loss: 1.37186 acc: 0.69824 | v_loss: 1.35347 v_acc: 0.69857 |  iteration: 5426 teacher: 1 stage: sketch lr: 0.000600\n",
      "batch 454 loss: 1.34060 acc: 0.70117 | v_loss: 1.39242 v_acc: 0.70378 |  iteration: 5427 teacher: 1 stage: sketch lr: 0.000600\n",
      "batch 455 loss: 1.25465 acc: 0.69954 | v_loss: 1.31750 v_acc: 0.70215 |  iteration: 5428 teacher: 1 stage: sketch lr: 0.000600\n",
      "batch 456 loss: 1.28036 acc: 0.70703 | v_loss: 1.20555 v_acc: 0.71484 |  iteration: 5429 teacher: 1 stage: sketch lr: 0.000600\n",
      "batch 457 loss: 1.41054 acc: 0.69141 | v_loss: 1.36813 v_acc: 0.70215 |  iteration: 5430 teacher: 1 stage: sketch lr: 0.000600\n",
      "batch 458 loss: 1.25565 acc: 0.71419 | v_loss: 1.25456 v_acc: 0.71126 |  iteration: 5431 teacher: 0 stage: sketch lr: 0.000600\n",
      "batch 459 loss: 1.28693 acc: 0.70638 | v_loss: 1.15353 v_acc: 0.72526 |  iteration: 5432 teacher: 0 stage: sketch lr: 0.000600\n",
      "batch 460 loss: 1.24240 acc: 0.70508 | v_loss: 1.15767 v_acc: 0.70410 |  iteration: 5433 teacher: 0 stage: sketch lr: 0.000600\n",
      "batch 461 loss: 1.31854 acc: 0.69694 | v_loss: 1.26475 v_acc: 0.70443 |  iteration: 5434 teacher: 1 stage: sketch lr: 0.000600\n",
      "batch 462 loss: 1.23685 acc: 0.70475 | v_loss: 1.34789 v_acc: 0.69694 |  iteration: 5435 teacher: 0 stage: sketch lr: 0.000599\n",
      "batch 463 loss: 1.31443 acc: 0.70215 | v_loss: 1.17534 v_acc: 0.71094 |  iteration: 5436 teacher: 1 stage: sketch lr: 0.000599\n",
      "batch 464 loss: 1.27094 acc: 0.70312 | v_loss: 1.19784 v_acc: 0.70671 |  iteration: 5437 teacher: 1 stage: sketch lr: 0.000599\n",
      "batch 465 loss: 1.31174 acc: 0.70345 | v_loss: 1.19294 v_acc: 0.71517 |  iteration: 5438 teacher: 1 stage: sketch lr: 0.000599\n",
      "batch 466 loss: 1.23149 acc: 0.70931 | v_loss: 1.20295 v_acc: 0.70638 |  iteration: 5439 teacher: 0 stage: sketch lr: 0.000599\n",
      "batch 467 loss: 1.31402 acc: 0.70736 | v_loss: 1.10853 v_acc: 0.73112 |  iteration: 5440 teacher: 0 stage: sketch lr: 0.000599\n",
      "batch 468 loss: 1.24960 acc: 0.70605 | v_loss: 1.19684 v_acc: 0.71680 |  iteration: 5441 teacher: 1 stage: sketch lr: 0.000599\n",
      "batch 469 loss: 1.33112 acc: 0.69857 | v_loss: 1.21332 v_acc: 0.70312 |  iteration: 5442 teacher: 0 stage: sketch lr: 0.000599\n",
      "batch 470 loss: 1.19375 acc: 0.71680 | v_loss: 1.14734 v_acc: 0.72298 |  iteration: 5443 teacher: 0 stage: sketch lr: 0.000599\n",
      "batch 471 loss: 1.31041 acc: 0.70085 | v_loss: 1.21223 v_acc: 0.71810 |  iteration: 5444 teacher: 1 stage: sketch lr: 0.000599\n",
      "batch 472 loss: 1.28431 acc: 0.70540 | v_loss: 1.24235 v_acc: 0.71419 |  iteration: 5445 teacher: 1 stage: sketch lr: 0.000599\n",
      "batch 473 loss: 1.34862 acc: 0.70703 | v_loss: 1.20079 v_acc: 0.72428 |  iteration: 5446 teacher: 1 stage: sketch lr: 0.000599\n",
      "batch 474 loss: 1.30185 acc: 0.70605 | v_loss: 1.41420 v_acc: 0.69629 |  iteration: 5447 teacher: 0 stage: sketch lr: 0.000599\n",
      "batch 475 loss: 1.35089 acc: 0.69466 | v_loss: 1.29027 v_acc: 0.72363 |  iteration: 5448 teacher: 1 stage: sketch lr: 0.000599\n",
      "batch 476 loss: 1.35563 acc: 0.70410 | v_loss: 1.08086 v_acc: 0.74186 |  iteration: 5449 teacher: 0 stage: sketch lr: 0.000599\n",
      "batch 477 loss: 1.37838 acc: 0.69596 | v_loss: 1.26066 v_acc: 0.70085 |  iteration: 5450 teacher: 1 stage: sketch lr: 0.000599\n",
      "batch 478 loss: 1.31779 acc: 0.70443 | v_loss: 1.29512 v_acc: 0.69824 |  iteration: 5451 teacher: 1 stage: sketch lr: 0.000599\n",
      "batch 479 loss: 1.43048 acc: 0.68685 | v_loss: 1.21648 v_acc: 0.68620 |  iteration: 5452 teacher: 0 stage: sketch lr: 0.000599\n",
      "batch 480 loss: 1.26212 acc: 0.70475 | v_loss: 1.28005 v_acc: 0.70605 |  iteration: 5453 teacher: 1 stage: sketch lr: 0.000598\n",
      "batch 481 loss: 1.28140 acc: 0.69629 | v_loss: 1.26081 v_acc: 0.68652 |  iteration: 5454 teacher: 1 stage: sketch lr: 0.000598\n",
      "batch 482 loss: 1.44338 acc: 0.69010 | v_loss: 1.22340 v_acc: 0.71387 |  iteration: 5455 teacher: 0 stage: sketch lr: 0.000598\n",
      "batch 483 loss: 1.37953 acc: 0.70117 | v_loss: 1.26423 v_acc: 0.70150 |  iteration: 5456 teacher: 0 stage: sketch lr: 0.000598\n",
      "batch 484 loss: 1.29191 acc: 0.70638 | v_loss: 1.20607 v_acc: 0.72070 |  iteration: 5457 teacher: 0 stage: sketch lr: 0.000598\n",
      "batch 485 loss: 1.25821 acc: 0.70475 | v_loss: 1.20294 v_acc: 0.72754 |  iteration: 5458 teacher: 0 stage: sketch lr: 0.000598\n",
      "batch 486 loss: 1.30720 acc: 0.70312 | v_loss: 1.24210 v_acc: 0.70085 |  iteration: 5459 teacher: 0 stage: sketch lr: 0.000598\n",
      "batch 487 loss: 1.28501 acc: 0.71126 | v_loss: 1.38043 v_acc: 0.69076 |  iteration: 5460 teacher: 0 stage: sketch lr: 0.000598\n",
      "batch 488 loss: 1.42405 acc: 0.68848 | v_loss: 1.16809 v_acc: 0.70964 |  iteration: 5461 teacher: 1 stage: sketch lr: 0.000598\n",
      "batch 489 loss: 1.28681 acc: 0.70410 | v_loss: 1.43024 v_acc: 0.67969 |  iteration: 5462 teacher: 1 stage: sketch lr: 0.000598\n",
      "batch 490 loss: 1.39492 acc: 0.69401 | v_loss: 1.19235 v_acc: 0.72363 |  iteration: 5463 teacher: 0 stage: sketch lr: 0.000598\n",
      "batch 491 loss: 1.21465 acc: 0.71322 | v_loss: 1.48825 v_acc: 0.68620 |  iteration: 5464 teacher: 1 stage: sketch lr: 0.000598\n",
      "batch 492 loss: 1.26041 acc: 0.70833 | v_loss: 1.36386 v_acc: 0.70215 |  iteration: 5465 teacher: 1 stage: sketch lr: 0.000598\n",
      "batch 493 loss: 1.30806 acc: 0.70085 | v_loss: 1.34627 v_acc: 0.69076 |  iteration: 5466 teacher: 0 stage: sketch lr: 0.000598\n",
      "batch 494 loss: 1.23941 acc: 0.71159 | v_loss: 1.31762 v_acc: 0.70345 |  iteration: 5467 teacher: 0 stage: sketch lr: 0.000598\n",
      "batch 495 loss: 1.34081 acc: 0.70378 | v_loss: 1.24146 v_acc: 0.70573 |  iteration: 5468 teacher: 0 stage: sketch lr: 0.000598\n",
      "batch 496 loss: 1.26282 acc: 0.70182 | v_loss: 1.26304 v_acc: 0.70345 |  iteration: 5469 teacher: 0 stage: sketch lr: 0.000598\n",
      "batch 497 loss: 1.30613 acc: 0.69922 | v_loss: 1.22400 v_acc: 0.71582 |  iteration: 5470 teacher: 0 stage: sketch lr: 0.000598\n",
      "batch 498 loss: 1.26449 acc: 0.70052 | v_loss: 1.48288 v_acc: 0.67806 |  iteration: 5471 teacher: 1 stage: sketch lr: 0.000597\n",
      "batch 499 loss: 1.34948 acc: 0.70671 | v_loss: 1.34353 v_acc: 0.69954 |  iteration: 5472 teacher: 0 stage: sketch lr: 0.000597\n",
      "batch 500 loss: 1.31407 acc: 0.70182 | v_loss: 1.16867 v_acc: 0.70866 |  iteration: 5473 teacher: 0 stage: sketch lr: 0.000597\n",
      "batch 501 loss: 1.41646 acc: 0.69303 | v_loss: 1.29543 v_acc: 0.70605 |  iteration: 5474 teacher: 0 stage: sketch lr: 0.000597\n",
      "batch 502 loss: 1.30658 acc: 0.70638 | v_loss: 1.18969 v_acc: 0.70508 |  iteration: 5475 teacher: 0 stage: sketch lr: 0.000597\n",
      "batch 503 loss: 1.25746 acc: 0.70475 | v_loss: 1.27932 v_acc: 0.70085 |  iteration: 5476 teacher: 0 stage: sketch lr: 0.000597\n",
      "batch 504 loss: 1.26099 acc: 0.70605 | v_loss: 1.24474 v_acc: 0.71777 |  iteration: 5477 teacher: 0 stage: sketch lr: 0.000597\n",
      "batch 505 loss: 1.26316 acc: 0.70247 | v_loss: 1.18366 v_acc: 0.71875 |  iteration: 5478 teacher: 1 stage: sketch lr: 0.000597\n",
      "batch 506 loss: 1.30997 acc: 0.69466 | v_loss: 1.15286 v_acc: 0.72559 |  iteration: 5479 teacher: 0 stage: sketch lr: 0.000597\n",
      "batch 507 loss: 1.33316 acc: 0.69792 | v_loss: 1.27619 v_acc: 0.71484 |  iteration: 5480 teacher: 0 stage: sketch lr: 0.000597\n",
      "batch 508 loss: 1.33133 acc: 0.69694 | v_loss: 1.27402 v_acc: 0.69987 |  iteration: 5481 teacher: 1 stage: sketch lr: 0.000597\n",
      "batch 509 loss: 1.41716 acc: 0.68457 | v_loss: 1.27572 v_acc: 0.70182 |  iteration: 5482 teacher: 1 stage: sketch lr: 0.000597\n",
      "batch 510 loss: 1.33453 acc: 0.70182 | v_loss: 1.13908 v_acc: 0.71777 |  iteration: 5483 teacher: 0 stage: sketch lr: 0.000597\n",
      "batch 511 loss: 1.32079 acc: 0.69759 | v_loss: 1.24764 v_acc: 0.73307 |  iteration: 5484 teacher: 0 stage: sketch lr: 0.000597\n",
      "batch 512 loss: 1.29702 acc: 0.70671 | v_loss: 1.31111 v_acc: 0.69499 |  iteration: 5485 teacher: 0 stage: sketch lr: 0.000597\n",
      "batch 513 loss: 1.32334 acc: 0.70443 | v_loss: 1.32950 v_acc: 0.71777 |  iteration: 5486 teacher: 1 stage: sketch lr: 0.000597\n",
      "batch 514 loss: 1.28175 acc: 0.71029 | v_loss: 1.17442 v_acc: 0.71745 |  iteration: 5487 teacher: 1 stage: sketch lr: 0.000597\n",
      "batch 515 loss: 1.32985 acc: 0.70150 | v_loss: 1.11253 v_acc: 0.73665 |  iteration: 5488 teacher: 0 stage: sketch lr: 0.000597\n",
      "batch 516 loss: 1.34686 acc: 0.69759 | v_loss: 1.11278 v_acc: 0.72266 |  iteration: 5489 teacher: 0 stage: sketch lr: 0.000597\n",
      "batch 517 loss: 1.34605 acc: 0.69759 | v_loss: 1.19018 v_acc: 0.71289 |  iteration: 5490 teacher: 1 stage: sketch lr: 0.000596\n",
      "batch 518 loss: 1.29135 acc: 0.70280 | v_loss: 1.26152 v_acc: 0.70020 |  iteration: 5491 teacher: 0 stage: sketch lr: 0.000596\n",
      "batch 519 loss: 1.37128 acc: 0.69368 | v_loss: 1.21925 v_acc: 0.70736 |  iteration: 5492 teacher: 1 stage: sketch lr: 0.000596\n",
      "batch 520 loss: 1.30735 acc: 0.70768 | v_loss: 1.34812 v_acc: 0.71289 |  iteration: 5493 teacher: 0 stage: sketch lr: 0.000596\n",
      "batch 521 loss: 1.33182 acc: 0.70443 | v_loss: 1.50644 v_acc: 0.69043 |  iteration: 5494 teacher: 0 stage: sketch lr: 0.000596\n",
      "batch 522 loss: 1.24711 acc: 0.71159 | v_loss: 1.37268 v_acc: 0.70085 |  iteration: 5495 teacher: 1 stage: sketch lr: 0.000596\n",
      "batch 523 loss: 1.29520 acc: 0.70964 | v_loss: 1.20872 v_acc: 0.71875 |  iteration: 5496 teacher: 0 stage: sketch lr: 0.000596\n",
      "batch 524 loss: 1.28494 acc: 0.70866 | v_loss: 1.18894 v_acc: 0.69987 |  iteration: 5497 teacher: 0 stage: sketch lr: 0.000596\n",
      "batch 525 loss: 1.21547 acc: 0.72461 | v_loss: 1.16789 v_acc: 0.72201 |  iteration: 5498 teacher: 1 stage: sketch lr: 0.000596\n",
      "batch 526 loss: 1.16998 acc: 0.72689 | v_loss: 1.23830 v_acc: 0.70443 |  iteration: 5499 teacher: 1 stage: sketch lr: 0.000596\n",
      "batch 527 loss: 1.22185 acc: 0.71908 | v_loss: 1.26160 v_acc: 0.71842 |  iteration: 5500 teacher: 0 stage: sketch lr: 0.000596\n",
      "batch 528 loss: 1.34182 acc: 0.71191 | v_loss: 1.21790 v_acc: 0.72754 |  iteration: 5501 teacher: 1 stage: sketch lr: 0.000596\n",
      "batch 529 loss: 1.27667 acc: 0.70378 | v_loss: 1.23862 v_acc: 0.71875 |  iteration: 5502 teacher: 1 stage: sketch lr: 0.000596\n",
      "batch 530 loss: 1.30511 acc: 0.69792 | v_loss: 1.23131 v_acc: 0.71908 |  iteration: 5503 teacher: 1 stage: sketch lr: 0.000596\n",
      "batch 531 loss: 1.31543 acc: 0.69824 | v_loss: 1.18534 v_acc: 0.72070 |  iteration: 5504 teacher: 1 stage: sketch lr: 0.000596\n",
      "batch 532 loss: 1.38283 acc: 0.68262 | v_loss: 1.14845 v_acc: 0.72103 |  iteration: 5505 teacher: 1 stage: sketch lr: 0.000596\n",
      "batch 533 loss: 1.32040 acc: 0.70117 | v_loss: 1.46923 v_acc: 0.68750 |  iteration: 5506 teacher: 1 stage: sketch lr: 0.000596\n",
      "batch 534 loss: 1.30457 acc: 0.69727 | v_loss: 1.21596 v_acc: 0.70768 |  iteration: 5507 teacher: 0 stage: sketch lr: 0.000596\n",
      "batch 535 loss: 1.26773 acc: 0.70801 | v_loss: 1.25415 v_acc: 0.71257 |  iteration: 5508 teacher: 0 stage: sketch lr: 0.000595\n",
      "batch 536 loss: 1.26325 acc: 0.70410 | v_loss: 1.26251 v_acc: 0.69401 |  iteration: 5509 teacher: 0 stage: sketch lr: 0.000595\n",
      "batch 537 loss: 1.26902 acc: 0.70410 | v_loss: 1.31169 v_acc: 0.69173 |  iteration: 5510 teacher: 1 stage: sketch lr: 0.000595\n",
      "batch 538 loss: 1.27092 acc: 0.71582 | v_loss: 1.14043 v_acc: 0.73014 |  iteration: 5511 teacher: 1 stage: sketch lr: 0.000595\n",
      "batch 539 loss: 1.36443 acc: 0.70085 | v_loss: 1.39936 v_acc: 0.71387 |  iteration: 5512 teacher: 0 stage: sketch lr: 0.000595\n",
      "batch 540 loss: 1.34577 acc: 0.69661 | v_loss: 1.22863 v_acc: 0.69206 |  iteration: 5513 teacher: 0 stage: sketch lr: 0.000595\n",
      "batch 541 loss: 1.27079 acc: 0.70638 | v_loss: 1.22439 v_acc: 0.70247 |  iteration: 5514 teacher: 0 stage: sketch lr: 0.000595\n",
      "batch 542 loss: 1.35162 acc: 0.70312 | v_loss: 1.26734 v_acc: 0.70312 |  iteration: 5515 teacher: 1 stage: sketch lr: 0.000595\n",
      "batch 543 loss: 1.38086 acc: 0.70736 | v_loss: 1.29761 v_acc: 0.69889 |  iteration: 5516 teacher: 1 stage: sketch lr: 0.000595\n",
      "batch 544 loss: 1.30856 acc: 0.70150 | v_loss: 1.37676 v_acc: 0.69238 |  iteration: 5517 teacher: 0 stage: sketch lr: 0.000595\n",
      "batch 545 loss: 1.27661 acc: 0.70475 | v_loss: 1.39526 v_acc: 0.70410 |  iteration: 5518 teacher: 0 stage: sketch lr: 0.000595\n",
      "batch 546 loss: 1.30070 acc: 0.69368 | v_loss: 1.33801 v_acc: 0.69759 |  iteration: 5519 teacher: 0 stage: sketch lr: 0.000595\n",
      "batch 547 loss: 1.29275 acc: 0.70085 | v_loss: 1.28225 v_acc: 0.70573 |  iteration: 5520 teacher: 0 stage: sketch lr: 0.000595\n",
      "batch 548 loss: 1.24923 acc: 0.70703 | v_loss: 1.30985 v_acc: 0.71257 |  iteration: 5521 teacher: 0 stage: sketch lr: 0.000595\n",
      "batch 549 loss: 1.24832 acc: 0.70768 | v_loss: 1.21483 v_acc: 0.71908 |  iteration: 5522 teacher: 1 stage: sketch lr: 0.000595\n",
      "batch 550 loss: 1.27400 acc: 0.70508 | v_loss: 1.15350 v_acc: 0.72526 |  iteration: 5523 teacher: 1 stage: sketch lr: 0.000595\n",
      "batch 551 loss: 1.31699 acc: 0.70801 | v_loss: 1.17603 v_acc: 0.71289 |  iteration: 5524 teacher: 1 stage: sketch lr: 0.000595\n",
      "batch 552 loss: 1.26613 acc: 0.70768 | v_loss: 1.29412 v_acc: 0.70508 |  iteration: 5525 teacher: 1 stage: sketch lr: 0.000595\n",
      "batch 553 loss: 1.32591 acc: 0.70182 | v_loss: 1.35207 v_acc: 0.69141 |  iteration: 5526 teacher: 1 stage: sketch lr: 0.000595\n",
      "batch 554 loss: 1.20419 acc: 0.71908 | v_loss: 1.15253 v_acc: 0.71159 |  iteration: 5527 teacher: 1 stage: sketch lr: 0.000594\n",
      "batch 555 loss: 1.34725 acc: 0.70736 | v_loss: 1.22423 v_acc: 0.69889 |  iteration: 5528 teacher: 1 stage: sketch lr: 0.000594\n",
      "batch 556 loss: 1.30970 acc: 0.71257 | v_loss: 1.20407 v_acc: 0.70866 |  iteration: 5529 teacher: 0 stage: sketch lr: 0.000594\n",
      "batch 557 loss: 1.25219 acc: 0.72331 | v_loss: 1.20041 v_acc: 0.70540 |  iteration: 5530 teacher: 0 stage: sketch lr: 0.000594\n",
      "batch 558 loss: 1.23805 acc: 0.70312 | v_loss: 1.10318 v_acc: 0.73079 |  iteration: 5531 teacher: 0 stage: sketch lr: 0.000594\n",
      "batch 559 loss: 1.35965 acc: 0.69727 | v_loss: 1.18390 v_acc: 0.71257 |  iteration: 5532 teacher: 0 stage: sketch lr: 0.000594\n",
      "batch 560 loss: 1.30219 acc: 0.70052 | v_loss: 1.21525 v_acc: 0.70410 |  iteration: 5533 teacher: 0 stage: sketch lr: 0.000594\n",
      "batch 561 loss: 1.25700 acc: 0.71094 | v_loss: 1.13320 v_acc: 0.73210 |  iteration: 5534 teacher: 1 stage: sketch lr: 0.000594\n",
      "batch 562 loss: 1.32166 acc: 0.70540 | v_loss: 1.20259 v_acc: 0.71289 |  iteration: 5535 teacher: 1 stage: sketch lr: 0.000594\n",
      "batch 563 loss: 1.24884 acc: 0.70801 | v_loss: 1.23029 v_acc: 0.71029 |  iteration: 5536 teacher: 1 stage: sketch lr: 0.000594\n",
      "batch 564 loss: 1.36924 acc: 0.70280 | v_loss: 1.19780 v_acc: 0.72168 |  iteration: 5537 teacher: 0 stage: sketch lr: 0.000594\n",
      "batch 565 loss: 1.26308 acc: 0.70833 | v_loss: 1.41630 v_acc: 0.69661 |  iteration: 5538 teacher: 0 stage: sketch lr: 0.000594\n",
      "batch 566 loss: 1.30296 acc: 0.69564 | v_loss: 1.25586 v_acc: 0.71908 |  iteration: 5539 teacher: 1 stage: sketch lr: 0.000594\n",
      "batch 567 loss: 1.44499 acc: 0.69434 | v_loss: 1.07719 v_acc: 0.74186 |  iteration: 5540 teacher: 1 stage: sketch lr: 0.000594\n",
      "batch 568 loss: 1.38128 acc: 0.70117 | v_loss: 1.26370 v_acc: 0.70182 |  iteration: 5541 teacher: 1 stage: sketch lr: 0.000594\n",
      "batch 569 loss: 1.23266 acc: 0.70703 | v_loss: 1.27789 v_acc: 0.70280 |  iteration: 5542 teacher: 1 stage: sketch lr: 0.000594\n",
      "batch 570 loss: 1.26261 acc: 0.70378 | v_loss: 1.21151 v_acc: 0.70605 |  iteration: 5543 teacher: 1 stage: sketch lr: 0.000594\n",
      "batch 571 loss: 1.34936 acc: 0.71094 | v_loss: 1.27102 v_acc: 0.70085 |  iteration: 5544 teacher: 1 stage: sketch lr: 0.000594\n",
      "batch 572 loss: 1.26357 acc: 0.70508 | v_loss: 1.25688 v_acc: 0.68945 |  iteration: 5545 teacher: 0 stage: sketch lr: 0.000593\n",
      "batch 573 loss: 1.20738 acc: 0.70508 | v_loss: 1.22362 v_acc: 0.71549 |  iteration: 5546 teacher: 0 stage: sketch lr: 0.000593\n",
      "batch 574 loss: 1.30903 acc: 0.70052 | v_loss: 1.26839 v_acc: 0.70150 |  iteration: 5547 teacher: 0 stage: sketch lr: 0.000593\n",
      "batch 575 loss: 1.35697 acc: 0.70052 | v_loss: 1.20896 v_acc: 0.71257 |  iteration: 5548 teacher: 1 stage: sketch lr: 0.000593\n",
      "batch 576 loss: 1.30942 acc: 0.69889 | v_loss: 1.21055 v_acc: 0.71875 |  iteration: 5549 teacher: 1 stage: sketch lr: 0.000593\n",
      "batch 577 loss: 1.40530 acc: 0.69792 | v_loss: 1.25169 v_acc: 0.69727 |  iteration: 5550 teacher: 0 stage: sketch lr: 0.000593\n",
      "batch 578 loss: 1.27799 acc: 0.70671 | v_loss: 1.35977 v_acc: 0.69141 |  iteration: 5551 teacher: 0 stage: sketch lr: 0.000593\n",
      "batch 579 loss: 1.26135 acc: 0.71191 | v_loss: 1.17606 v_acc: 0.70898 |  iteration: 5552 teacher: 1 stage: sketch lr: 0.000593\n",
      "batch 580 loss: 1.17269 acc: 0.71908 | v_loss: 1.43711 v_acc: 0.68522 |  iteration: 5553 teacher: 1 stage: sketch lr: 0.000593\n",
      "batch 581 loss: 1.36620 acc: 0.70052 | v_loss: 1.17759 v_acc: 0.72233 |  iteration: 5554 teacher: 0 stage: sketch lr: 0.000593\n",
      "batch 582 loss: 1.26386 acc: 0.71029 | v_loss: 1.50334 v_acc: 0.68164 |  iteration: 5555 teacher: 0 stage: sketch lr: 0.000593\n",
      "batch 583 loss: 1.37717 acc: 0.69043 | v_loss: 1.37835 v_acc: 0.69857 |  iteration: 5556 teacher: 1 stage: sketch lr: 0.000593\n",
      "batch 584 loss: 1.21199 acc: 0.71419 | v_loss: 1.35025 v_acc: 0.69759 |  iteration: 5557 teacher: 1 stage: sketch lr: 0.000593\n",
      "batch 585 loss: 1.34696 acc: 0.70117 | v_loss: 1.32591 v_acc: 0.69694 |  iteration: 5558 teacher: 0 stage: sketch lr: 0.000593\n",
      "batch 586 loss: 1.24077 acc: 0.70247 | v_loss: 1.22733 v_acc: 0.70605 |  iteration: 5559 teacher: 1 stage: sketch lr: 0.000593\n",
      "batch 587 loss: 1.28322 acc: 0.70866 | v_loss: 1.26956 v_acc: 0.70443 |  iteration: 5560 teacher: 0 stage: sketch lr: 0.000593\n",
      "batch 588 loss: 1.29092 acc: 0.69922 | v_loss: 1.23295 v_acc: 0.72103 |  iteration: 5561 teacher: 1 stage: sketch lr: 0.000593\n",
      "batch 589 loss: 1.29716 acc: 0.70898 | v_loss: 1.45511 v_acc: 0.68945 |  iteration: 5562 teacher: 1 stage: sketch lr: 0.000593\n",
      "batch 590 loss: 1.36494 acc: 0.70052 | v_loss: 1.31491 v_acc: 0.71289 |  iteration: 5563 teacher: 1 stage: sketch lr: 0.000593\n",
      "batch 591 loss: 1.30629 acc: 0.70605 | v_loss: 1.19382 v_acc: 0.70410 |  iteration: 5564 teacher: 0 stage: sketch lr: 0.000592\n",
      "batch 592 loss: 1.28891 acc: 0.71126 | v_loss: 1.30700 v_acc: 0.70703 |  iteration: 5565 teacher: 1 stage: sketch lr: 0.000592\n",
      "batch 593 loss: 1.30653 acc: 0.70671 | v_loss: 1.20501 v_acc: 0.70020 |  iteration: 5566 teacher: 0 stage: sketch lr: 0.000592\n",
      "batch 594 loss: 1.35042 acc: 0.70052 | v_loss: 1.27925 v_acc: 0.70150 |  iteration: 5567 teacher: 0 stage: sketch lr: 0.000592\n",
      "batch 595 loss: 1.31816 acc: 0.69987 | v_loss: 1.23737 v_acc: 0.71257 |  iteration: 5568 teacher: 1 stage: sketch lr: 0.000592\n",
      "batch 596 loss: 1.25389 acc: 0.70312 | v_loss: 1.17952 v_acc: 0.71973 |  iteration: 5569 teacher: 0 stage: sketch lr: 0.000592\n",
      "batch 597 loss: 1.30255 acc: 0.70247 | v_loss: 1.14298 v_acc: 0.72396 |  iteration: 5570 teacher: 0 stage: sketch lr: 0.000592\n",
      "batch 598 loss: 1.22526 acc: 0.70475 | v_loss: 1.26774 v_acc: 0.71810 |  iteration: 5571 teacher: 1 stage: sketch lr: 0.000592\n",
      "batch 599 loss: 1.36243 acc: 0.69368 | v_loss: 1.25281 v_acc: 0.70280 |  iteration: 5572 teacher: 0 stage: sketch lr: 0.000592\n",
      "batch 600 loss: 1.24307 acc: 0.71452 | v_loss: 1.26596 v_acc: 0.70801 |  iteration: 5573 teacher: 0 stage: sketch lr: 0.000592\n",
      "batch 601 loss: 1.33121 acc: 0.69889 | v_loss: 1.13567 v_acc: 0.70996 |  iteration: 5574 teacher: 1 stage: sketch lr: 0.000592\n",
      "batch 602 loss: 1.23876 acc: 0.71647 | v_loss: 1.25325 v_acc: 0.72721 |  iteration: 5575 teacher: 0 stage: sketch lr: 0.000592\n",
      "batch 603 loss: 1.33535 acc: 0.69434 | v_loss: 1.31888 v_acc: 0.69727 |  iteration: 5576 teacher: 1 stage: sketch lr: 0.000592\n",
      "batch 604 loss: 1.29478 acc: 0.70410 | v_loss: 1.32037 v_acc: 0.71680 |  iteration: 5577 teacher: 0 stage: sketch lr: 0.000592\n",
      "batch 605 loss: 1.32351 acc: 0.69987 | v_loss: 1.16520 v_acc: 0.71712 |  iteration: 5578 teacher: 0 stage: sketch lr: 0.000592\n",
      "batch 606 loss: 1.24326 acc: 0.71777 | v_loss: 1.11135 v_acc: 0.73665 |  iteration: 5579 teacher: 0 stage: sketch lr: 0.000592\n",
      "batch 607 loss: 1.39517 acc: 0.68815 | v_loss: 1.11369 v_acc: 0.72103 |  iteration: 5580 teacher: 1 stage: sketch lr: 0.000592\n",
      "batch 608 loss: 1.28109 acc: 0.70833 | v_loss: 1.21232 v_acc: 0.70768 |  iteration: 5581 teacher: 0 stage: sketch lr: 0.000592\n",
      "batch 609 loss: 1.39264 acc: 0.69466 | v_loss: 1.23084 v_acc: 0.70443 |  iteration: 5582 teacher: 1 stage: sketch lr: 0.000592\n",
      "batch 610 loss: 1.32067 acc: 0.70280 | v_loss: 1.21813 v_acc: 0.71484 |  iteration: 5583 teacher: 1 stage: sketch lr: 0.000591\n",
      "batch 611 loss: 1.30775 acc: 0.70052 | v_loss: 1.33561 v_acc: 0.70671 |  iteration: 5584 teacher: 0 stage: sketch lr: 0.000591\n",
      "batch 612 loss: 1.28304 acc: 0.70964 | v_loss: 1.45967 v_acc: 0.69466 |  iteration: 5585 teacher: 0 stage: sketch lr: 0.000591\n",
      "batch 613 loss: 1.29566 acc: 0.70931 | v_loss: 1.34994 v_acc: 0.70540 |  iteration: 5586 teacher: 1 stage: sketch lr: 0.000591\n",
      "batch 614 loss: 1.32005 acc: 0.69727 | v_loss: 1.20295 v_acc: 0.71875 |  iteration: 5587 teacher: 0 stage: sketch lr: 0.000591\n",
      "batch 615 loss: 1.32831 acc: 0.70117 | v_loss: 1.17573 v_acc: 0.69987 |  iteration: 5588 teacher: 0 stage: sketch lr: 0.000591\n",
      "batch 616 loss: 1.30322 acc: 0.71387 | v_loss: 1.17170 v_acc: 0.71810 |  iteration: 5589 teacher: 0 stage: sketch lr: 0.000591\n",
      "batch 617 loss: 1.34871 acc: 0.70312 | v_loss: 1.23086 v_acc: 0.70247 |  iteration: 5590 teacher: 1 stage: sketch lr: 0.000591\n",
      "batch 618 loss: 1.26811 acc: 0.71647 | v_loss: 1.26264 v_acc: 0.71875 |  iteration: 5591 teacher: 0 stage: sketch lr: 0.000591\n",
      "batch 619 loss: 1.38415 acc: 0.69694 | v_loss: 1.21158 v_acc: 0.73145 |  iteration: 5592 teacher: 0 stage: sketch lr: 0.000591\n",
      "batch 620 loss: 1.31596 acc: 0.70182 | v_loss: 1.24777 v_acc: 0.71875 |  iteration: 5593 teacher: 0 stage: sketch lr: 0.000591\n",
      "batch 621 loss: 1.37757 acc: 0.68815 | v_loss: 1.24133 v_acc: 0.71419 |  iteration: 5594 teacher: 0 stage: sketch lr: 0.000591\n",
      "batch 622 loss: 1.22837 acc: 0.71029 | v_loss: 1.17938 v_acc: 0.72461 |  iteration: 5595 teacher: 0 stage: sketch lr: 0.000591\n",
      "batch 623 loss: 1.33982 acc: 0.69694 | v_loss: 1.13587 v_acc: 0.72363 |  iteration: 5596 teacher: 0 stage: sketch lr: 0.000591\n",
      "batch 624 loss: 1.19424 acc: 0.71777 | v_loss: 1.52321 v_acc: 0.68848 |  iteration: 5597 teacher: 1 stage: sketch lr: 0.000591\n",
      "batch 625 loss: 1.33394 acc: 0.69954 | v_loss: 1.20118 v_acc: 0.71029 |  iteration: 5598 teacher: 1 stage: sketch lr: 0.000591\n",
      "batch 626 loss: 1.35872 acc: 0.68913 | v_loss: 1.25214 v_acc: 0.71224 |  iteration: 5599 teacher: 0 stage: sketch lr: 0.000591\n",
      "batch 627 loss: 1.36620 acc: 0.69401 | v_loss: 1.25073 v_acc: 0.70671 |  iteration: 5600 teacher: 0 stage: sketch lr: 0.000591\n",
      "batch 628 loss: 1.35860 acc: 0.68945 | v_loss: 1.31005 v_acc: 0.70378 |  iteration: 5601 teacher: 0 stage: sketch lr: 0.000591\n",
      "batch 629 loss: 1.26560 acc: 0.70898 | v_loss: 1.14358 v_acc: 0.72917 |  iteration: 5602 teacher: 0 stage: sketch lr: 0.000590\n",
      "batch 630 loss: 1.28141 acc: 0.70052 | v_loss: 1.40440 v_acc: 0.70801 |  iteration: 5603 teacher: 1 stage: sketch lr: 0.000590\n",
      "batch 631 loss: 1.39718 acc: 0.69564 | v_loss: 1.20793 v_acc: 0.69792 |  iteration: 5604 teacher: 0 stage: sketch lr: 0.000590\n",
      "batch 632 loss: 1.34721 acc: 0.69987 | v_loss: 1.20513 v_acc: 0.69857 |  iteration: 5605 teacher: 0 stage: sketch lr: 0.000590\n",
      "batch 633 loss: 1.22285 acc: 0.71647 | v_loss: 1.27734 v_acc: 0.70215 |  iteration: 5606 teacher: 1 stage: sketch lr: 0.000590\n",
      "batch 634 loss: 1.21097 acc: 0.71387 | v_loss: 1.29220 v_acc: 0.69792 |  iteration: 5607 teacher: 0 stage: sketch lr: 0.000590\n",
      "batch 635 loss: 1.33745 acc: 0.69499 | v_loss: 1.35821 v_acc: 0.69206 |  iteration: 5608 teacher: 0 stage: sketch lr: 0.000590\n",
      "batch 636 loss: 1.32130 acc: 0.70443 | v_loss: 1.39305 v_acc: 0.70768 |  iteration: 5609 teacher: 1 stage: sketch lr: 0.000590\n",
      "batch 637 loss: 1.31322 acc: 0.69889 | v_loss: 1.29833 v_acc: 0.70540 |  iteration: 5610 teacher: 0 stage: sketch lr: 0.000590\n",
      "batch 638 loss: 1.26839 acc: 0.70215 | v_loss: 1.20119 v_acc: 0.70866 |  iteration: 5611 teacher: 0 stage: sketch lr: 0.000590\n",
      "batch 639 loss: 1.37366 acc: 0.69206 | v_loss: 1.34665 v_acc: 0.70671 |  iteration: 5612 teacher: 0 stage: sketch lr: 0.000590\n",
      "batch 640 loss: 1.41748 acc: 0.69206 | v_loss: 1.24364 v_acc: 0.71680 |  iteration: 5613 teacher: 1 stage: sketch lr: 0.000590\n",
      "batch 641 loss: 1.25365 acc: 0.71029 | v_loss: 1.14462 v_acc: 0.72266 |  iteration: 5614 teacher: 1 stage: sketch lr: 0.000590\n",
      "batch 642 loss: 1.31814 acc: 0.71289 | v_loss: 1.17163 v_acc: 0.71029 |  iteration: 5615 teacher: 1 stage: sketch lr: 0.000590\n",
      "batch 643 loss: 1.30244 acc: 0.70280 | v_loss: 1.27483 v_acc: 0.70931 |  iteration: 5616 teacher: 1 stage: sketch lr: 0.000590\n",
      "batch 644 loss: 1.28461 acc: 0.70703 | v_loss: 1.34761 v_acc: 0.68880 |  iteration: 5617 teacher: 0 stage: sketch lr: 0.000590\n",
      "batch 645 loss: 1.25500 acc: 0.71875 | v_loss: 1.19171 v_acc: 0.71029 |  iteration: 5618 teacher: 0 stage: sketch lr: 0.000590\n",
      "batch 646 loss: 1.31066 acc: 0.69661 | v_loss: 1.20008 v_acc: 0.70182 |  iteration: 5619 teacher: 1 stage: sketch lr: 0.000590\n",
      "batch 647 loss: 1.34314 acc: 0.70150 | v_loss: 1.20802 v_acc: 0.71322 |  iteration: 5620 teacher: 1 stage: sketch lr: 0.000590\n",
      "batch 648 loss: 1.33557 acc: 0.69499 | v_loss: 1.18325 v_acc: 0.70638 |  iteration: 5621 teacher: 1 stage: sketch lr: 0.000589\n",
      "batch 649 loss: 1.29726 acc: 0.70736 | v_loss: 1.09387 v_acc: 0.73177 |  iteration: 5622 teacher: 0 stage: sketch lr: 0.000589\n",
      "batch 650 loss: 1.32961 acc: 0.69303 | v_loss: 1.19051 v_acc: 0.72005 |  iteration: 5623 teacher: 1 stage: sketch lr: 0.000589\n",
      "batch 651 loss: 1.26915 acc: 0.70247 | v_loss: 1.14329 v_acc: 0.72493 |  iteration: 5624 teacher: 1 stage: sketch lr: 0.000589\n",
      "batch 652 loss: 1.40468 acc: 0.68913 | v_loss: 1.11618 v_acc: 0.72396 |  iteration: 5625 teacher: 0 stage: sketch lr: 0.000589\n",
      "batch 653 loss: 1.35850 acc: 0.70150 | v_loss: 1.20223 v_acc: 0.72201 |  iteration: 5626 teacher: 1 stage: sketch lr: 0.000589\n",
      "batch 654 loss: 1.31974 acc: 0.69824 | v_loss: 1.22934 v_acc: 0.71745 |  iteration: 5627 teacher: 0 stage: sketch lr: 0.000589\n",
      "batch 655 loss: 1.44419 acc: 0.69010 | v_loss: 1.20699 v_acc: 0.72526 |  iteration: 5628 teacher: 0 stage: sketch lr: 0.000589\n",
      "batch 656 loss: 1.37797 acc: 0.69336 | v_loss: 1.39579 v_acc: 0.69661 |  iteration: 5629 teacher: 0 stage: sketch lr: 0.000589\n",
      "batch 657 loss: 1.27392 acc: 0.70247 | v_loss: 1.27710 v_acc: 0.71517 |  iteration: 5630 teacher: 1 stage: sketch lr: 0.000589\n",
      "batch 658 loss: 1.30069 acc: 0.69857 | v_loss: 1.07138 v_acc: 0.74121 |  iteration: 5631 teacher: 1 stage: sketch lr: 0.000589\n",
      "batch 659 loss: 1.29059 acc: 0.70020 | v_loss: 1.22431 v_acc: 0.70703 |  iteration: 5632 teacher: 1 stage: sketch lr: 0.000589\n",
      "batch 660 loss: 1.27113 acc: 0.71094 | v_loss: 1.27609 v_acc: 0.69922 |  iteration: 5633 teacher: 0 stage: sketch lr: 0.000589\n",
      "batch 661 loss: 1.28332 acc: 0.70508 | v_loss: 1.20491 v_acc: 0.70215 |  iteration: 5634 teacher: 0 stage: sketch lr: 0.000589\n",
      "batch 662 loss: 1.32643 acc: 0.70247 | v_loss: 1.26638 v_acc: 0.70150 |  iteration: 5635 teacher: 1 stage: sketch lr: 0.000589\n",
      "batch 663 loss: 1.27481 acc: 0.70833 | v_loss: 1.25001 v_acc: 0.69271 |  iteration: 5636 teacher: 1 stage: sketch lr: 0.000589\n",
      "batch 664 loss: 1.30882 acc: 0.69759 | v_loss: 1.25410 v_acc: 0.71549 |  iteration: 5637 teacher: 1 stage: sketch lr: 0.000589\n",
      "batch 665 loss: 1.31413 acc: 0.70964 | v_loss: 1.29314 v_acc: 0.69922 |  iteration: 5638 teacher: 0 stage: sketch lr: 0.000589\n",
      "batch 666 loss: 1.25637 acc: 0.70671 | v_loss: 1.20304 v_acc: 0.72201 |  iteration: 5639 teacher: 0 stage: sketch lr: 0.000589\n",
      "batch 667 loss: 1.34526 acc: 0.69889 | v_loss: 1.21105 v_acc: 0.72428 |  iteration: 5640 teacher: 1 stage: sketch lr: 0.000588\n",
      "batch 668 loss: 1.20501 acc: 0.70964 | v_loss: 1.27686 v_acc: 0.69727 |  iteration: 5641 teacher: 0 stage: sketch lr: 0.000588\n",
      "batch 669 loss: 1.21306 acc: 0.70898 | v_loss: 1.33322 v_acc: 0.69173 |  iteration: 5642 teacher: 0 stage: sketch lr: 0.000588\n",
      "batch 670 loss: 1.29868 acc: 0.70540 | v_loss: 1.17387 v_acc: 0.70736 |  iteration: 5643 teacher: 0 stage: sketch lr: 0.000588\n",
      "batch 671 loss: 1.39380 acc: 0.69531 | v_loss: 1.43316 v_acc: 0.68229 |  iteration: 5644 teacher: 0 stage: sketch lr: 0.000588\n",
      "batch 672 loss: 1.21280 acc: 0.71094 | v_loss: 1.19390 v_acc: 0.71517 |  iteration: 5645 teacher: 1 stage: sketch lr: 0.000588\n",
      "batch 673 loss: 1.33856 acc: 0.70768 | v_loss: 1.49094 v_acc: 0.67611 |  iteration: 5646 teacher: 0 stage: sketch lr: 0.000588\n",
      "batch 674 loss: 1.29551 acc: 0.70247 | v_loss: 1.36822 v_acc: 0.69564 |  iteration: 5647 teacher: 0 stage: sketch lr: 0.000588\n",
      "batch 675 loss: 1.30924 acc: 0.70117 | v_loss: 1.34239 v_acc: 0.69629 |  iteration: 5648 teacher: 0 stage: sketch lr: 0.000588\n",
      "batch 676 loss: 1.32836 acc: 0.71061 | v_loss: 1.32071 v_acc: 0.69889 |  iteration: 5649 teacher: 1 stage: sketch lr: 0.000588\n",
      "batch 677 loss: 1.27432 acc: 0.70931 | v_loss: 1.22970 v_acc: 0.70605 |  iteration: 5650 teacher: 1 stage: sketch lr: 0.000588\n",
      "batch 678 loss: 1.25436 acc: 0.70443 | v_loss: 1.26817 v_acc: 0.70410 |  iteration: 5651 teacher: 1 stage: sketch lr: 0.000588\n",
      "batch 679 loss: 1.35380 acc: 0.69792 | v_loss: 1.22314 v_acc: 0.72201 |  iteration: 5652 teacher: 1 stage: sketch lr: 0.000588\n",
      "batch 680 loss: 1.31502 acc: 0.70703 | v_loss: 1.43815 v_acc: 0.68880 |  iteration: 5653 teacher: 0 stage: sketch lr: 0.000588\n",
      "batch 681 loss: 1.34781 acc: 0.69661 | v_loss: 1.30594 v_acc: 0.71289 |  iteration: 5654 teacher: 1 stage: sketch lr: 0.000588\n",
      "batch 682 loss: 1.25589 acc: 0.70964 | v_loss: 1.19771 v_acc: 0.70573 |  iteration: 5655 teacher: 1 stage: sketch lr: 0.000588\n",
      "batch 683 loss: 1.29848 acc: 0.69824 | v_loss: 1.26611 v_acc: 0.70866 |  iteration: 5656 teacher: 1 stage: sketch lr: 0.000588\n",
      "batch 684 loss: 1.26592 acc: 0.70931 | v_loss: 1.16539 v_acc: 0.71159 |  iteration: 5657 teacher: 0 stage: sketch lr: 0.000588\n",
      "batch 685 loss: 1.33868 acc: 0.69434 | v_loss: 1.27463 v_acc: 0.69954 |  iteration: 5658 teacher: 1 stage: sketch lr: 0.000588\n",
      "batch 686 loss: 1.37378 acc: 0.70312 | v_loss: 1.23541 v_acc: 0.71452 |  iteration: 5659 teacher: 0 stage: sketch lr: 0.000587\n",
      "batch 687 loss: 1.33524 acc: 0.70768 | v_loss: 1.17342 v_acc: 0.72005 |  iteration: 5660 teacher: 1 stage: sketch lr: 0.000587\n",
      "batch 688 loss: 1.35491 acc: 0.69499 | v_loss: 1.14862 v_acc: 0.72656 |  iteration: 5661 teacher: 1 stage: sketch lr: 0.000587\n",
      "batch 689 loss: 1.30852 acc: 0.69922 | v_loss: 1.26606 v_acc: 0.71810 |  iteration: 5662 teacher: 0 stage: sketch lr: 0.000587\n",
      "batch 690 loss: 1.25858 acc: 0.71126 | v_loss: 1.26528 v_acc: 0.70280 |  iteration: 5663 teacher: 0 stage: sketch lr: 0.000587\n",
      "batch 691 loss: 1.24318 acc: 0.70898 | v_loss: 1.27391 v_acc: 0.71257 |  iteration: 5664 teacher: 0 stage: sketch lr: 0.000587\n",
      "batch 692 loss: 1.31194 acc: 0.70475 | v_loss: 1.12141 v_acc: 0.72428 |  iteration: 5665 teacher: 0 stage: sketch lr: 0.000587\n",
      "batch 693 loss: 1.31552 acc: 0.70020 | v_loss: 1.23915 v_acc: 0.73210 |  iteration: 5666 teacher: 0 stage: sketch lr: 0.000587\n",
      "batch 694 loss: 1.28671 acc: 0.69401 | v_loss: 1.30462 v_acc: 0.69792 |  iteration: 5667 teacher: 0 stage: sketch lr: 0.000587\n",
      "batch 695 loss: 1.26355 acc: 0.70150 | v_loss: 1.33282 v_acc: 0.71940 |  iteration: 5668 teacher: 1 stage: sketch lr: 0.000587\n",
      "batch 696 loss: 1.33412 acc: 0.70540 | v_loss: 1.17300 v_acc: 0.71908 |  iteration: 5669 teacher: 0 stage: sketch lr: 0.000587\n",
      "batch 697 loss: 1.27609 acc: 0.70964 | v_loss: 1.13894 v_acc: 0.73926 |  iteration: 5670 teacher: 0 stage: sketch lr: 0.000587\n",
      "batch 698 loss: 1.41507 acc: 0.69434 | v_loss: 1.10698 v_acc: 0.72266 |  iteration: 5671 teacher: 0 stage: sketch lr: 0.000587\n",
      "batch 699 loss: 1.37104 acc: 0.70215 | v_loss: 1.19908 v_acc: 0.70866 |  iteration: 5672 teacher: 0 stage: sketch lr: 0.000587\n",
      "batch 700 loss: 1.25329 acc: 0.71615 | v_loss: 1.27261 v_acc: 0.69596 |  iteration: 5673 teacher: 1 stage: sketch lr: 0.000587\n",
      "batch 701 loss: 1.26739 acc: 0.69727 | v_loss: 1.21104 v_acc: 0.71322 |  iteration: 5674 teacher: 0 stage: sketch lr: 0.000587\n",
      "batch 702 loss: 1.28329 acc: 0.70410 | v_loss: 1.32315 v_acc: 0.70605 |  iteration: 5675 teacher: 1 stage: sketch lr: 0.000587\n",
      "batch 703 loss: 1.24936 acc: 0.70964 | v_loss: 1.53361 v_acc: 0.68392 |  iteration: 5676 teacher: 0 stage: sketch lr: 0.000587\n",
      "batch 704 loss: 1.37871 acc: 0.69987 | v_loss: 1.38726 v_acc: 0.68945 |  iteration: 5677 teacher: 0 stage: sketch lr: 0.000587\n",
      "batch 705 loss: 1.34861 acc: 0.70378 | v_loss: 1.19586 v_acc: 0.72331 |  iteration: 5678 teacher: 0 stage: sketch lr: 0.000586\n",
      "batch 706 loss: 1.40738 acc: 0.69434 | v_loss: 1.17254 v_acc: 0.70638 |  iteration: 5679 teacher: 0 stage: sketch lr: 0.000586\n",
      "batch 707 loss: 1.25370 acc: 0.70312 | v_loss: 1.16412 v_acc: 0.71712 |  iteration: 5680 teacher: 1 stage: sketch lr: 0.000586\n",
      "batch 708 loss: 1.37816 acc: 0.69629 | v_loss: 1.22308 v_acc: 0.70345 |  iteration: 5681 teacher: 0 stage: sketch lr: 0.000586\n",
      "batch 709 loss: 1.27876 acc: 0.70540 | v_loss: 1.28408 v_acc: 0.71159 |  iteration: 5682 teacher: 0 stage: sketch lr: 0.000586\n",
      "batch 710 loss: 1.29615 acc: 0.69792 | v_loss: 1.22589 v_acc: 0.72526 |  iteration: 5683 teacher: 0 stage: sketch lr: 0.000586\n",
      "batch 711 loss: 1.33253 acc: 0.68783 | v_loss: 1.24442 v_acc: 0.72428 |  iteration: 5684 teacher: 1 stage: sketch lr: 0.000586\n",
      "batch 712 loss: 1.40242 acc: 0.68848 | v_loss: 1.24016 v_acc: 0.71419 |  iteration: 5685 teacher: 1 stage: sketch lr: 0.000586\n",
      "batch 713 loss: 1.38894 acc: 0.68522 | v_loss: 1.16916 v_acc: 0.72201 |  iteration: 5686 teacher: 1 stage: sketch lr: 0.000586\n",
      "batch 714 loss: 1.30831 acc: 0.69694 | v_loss: 1.14027 v_acc: 0.71973 |  iteration: 5687 teacher: 1 stage: sketch lr: 0.000586\n",
      "batch 715 loss: 1.30501 acc: 0.71094 | v_loss: 1.47772 v_acc: 0.68685 |  iteration: 5688 teacher: 0 stage: sketch lr: 0.000586\n",
      "batch 716 loss: 1.38904 acc: 0.69596 | v_loss: 1.22107 v_acc: 0.70931 |  iteration: 5689 teacher: 1 stage: sketch lr: 0.000586\n",
      "batch 717 loss: 1.27865 acc: 0.71517 | v_loss: 1.24936 v_acc: 0.71257 |  iteration: 5690 teacher: 0 stage: sketch lr: 0.000586\n",
      "batch 718 loss: 1.33768 acc: 0.69434 | v_loss: 1.22703 v_acc: 0.72363 |  iteration: 5691 teacher: 1 stage: sketch lr: 0.000586\n",
      "batch 719 loss: 1.31434 acc: 0.70866 | v_loss: 1.30661 v_acc: 0.70215 |  iteration: 5692 teacher: 0 stage: sketch lr: 0.000586\n",
      "batch 720 loss: 1.32278 acc: 0.70540 | v_loss: 1.13136 v_acc: 0.72982 |  iteration: 5693 teacher: 1 stage: sketch lr: 0.000586\n",
      "batch 721 loss: 1.26012 acc: 0.71680 | v_loss: 1.38586 v_acc: 0.71549 |  iteration: 5694 teacher: 0 stage: sketch lr: 0.000586\n",
      "batch 722 loss: 1.33504 acc: 0.70898 | v_loss: 1.19865 v_acc: 0.69922 |  iteration: 5695 teacher: 0 stage: sketch lr: 0.000586\n",
      "batch 723 loss: 1.33499 acc: 0.70312 | v_loss: 1.21383 v_acc: 0.70150 |  iteration: 5696 teacher: 0 stage: sketch lr: 0.000586\n",
      "batch 724 loss: 1.25709 acc: 0.69857 | v_loss: 1.28124 v_acc: 0.70150 |  iteration: 5697 teacher: 1 stage: sketch lr: 0.000586\n",
      "batch 725 loss: 1.21625 acc: 0.71517 | v_loss: 1.29579 v_acc: 0.69661 |  iteration: 5698 teacher: 0 stage: sketch lr: 0.000585\n",
      "batch 726 loss: 1.36506 acc: 0.69824 | v_loss: 1.33901 v_acc: 0.69792 |  iteration: 5699 teacher: 0 stage: sketch lr: 0.000585\n",
      "batch 727 loss: 1.33779 acc: 0.69564 | v_loss: 1.37599 v_acc: 0.70540 |  iteration: 5700 teacher: 1 stage: sketch lr: 0.000585\n",
      "batch 728 loss: 1.30079 acc: 0.69401 | v_loss: 1.29331 v_acc: 0.70215 |  iteration: 5701 teacher: 1 stage: sketch lr: 0.000585\n",
      "batch 729 loss: 1.34095 acc: 0.69954 | v_loss: 1.20486 v_acc: 0.71387 |  iteration: 5702 teacher: 0 stage: sketch lr: 0.000585\n",
      "batch 730 loss: 1.28006 acc: 0.70833 | v_loss: 1.31945 v_acc: 0.70280 |  iteration: 5703 teacher: 0 stage: sketch lr: 0.000585\n",
      "batch 731 loss: 1.23300 acc: 0.72201 | v_loss: 1.25068 v_acc: 0.71029 |  iteration: 5704 teacher: 0 stage: sketch lr: 0.000585\n",
      "batch 732 loss: 1.31101 acc: 0.70247 | v_loss: 1.14741 v_acc: 0.72721 |  iteration: 5705 teacher: 1 stage: sketch lr: 0.000585\n",
      "batch 733 loss: 1.35304 acc: 0.69792 | v_loss: 1.17505 v_acc: 0.70638 |  iteration: 5706 teacher: 1 stage: sketch lr: 0.000585\n",
      "batch 734 loss: 1.32942 acc: 0.70573 | v_loss: 1.27108 v_acc: 0.70605 |  iteration: 5707 teacher: 0 stage: sketch lr: 0.000585\n",
      "batch 735 loss: 1.26192 acc: 0.70964 | v_loss: 1.33523 v_acc: 0.69629 |  iteration: 5708 teacher: 1 stage: sketch lr: 0.000585\n",
      "batch 736 loss: 1.25370 acc: 0.71680 | v_loss: 1.16690 v_acc: 0.71159 |  iteration: 5709 teacher: 1 stage: sketch lr: 0.000585\n",
      "batch 737 loss: 1.32505 acc: 0.70345 | v_loss: 1.20852 v_acc: 0.70150 |  iteration: 5710 teacher: 1 stage: sketch lr: 0.000585\n",
      "batch 738 loss: 1.25938 acc: 0.70866 | v_loss: 1.19041 v_acc: 0.71712 |  iteration: 5711 teacher: 1 stage: sketch lr: 0.000585\n",
      "batch 739 loss: 1.31303 acc: 0.70378 | v_loss: 1.19396 v_acc: 0.70768 |  iteration: 5712 teacher: 1 stage: sketch lr: 0.000585\n",
      "batch 740 loss: 1.38951 acc: 0.68913 | v_loss: 1.08668 v_acc: 0.73307 |  iteration: 5713 teacher: 0 stage: sketch lr: 0.000585\n",
      "batch 741 loss: 1.29225 acc: 0.69792 | v_loss: 1.18998 v_acc: 0.72070 |  iteration: 5714 teacher: 1 stage: sketch lr: 0.000585\n",
      "batch 742 loss: 1.32785 acc: 0.69434 | v_loss: 1.17389 v_acc: 0.72461 |  iteration: 5715 teacher: 1 stage: sketch lr: 0.000585\n",
      "batch 743 loss: 1.29439 acc: 0.70931 | v_loss: 1.12507 v_acc: 0.72298 |  iteration: 5716 teacher: 0 stage: sketch lr: 0.000585\n",
      "batch 744 loss: 1.39959 acc: 0.69564 | v_loss: 1.20169 v_acc: 0.72070 |  iteration: 5717 teacher: 1 stage: sketch lr: 0.000584\n",
      "batch 745 loss: 1.26351 acc: 0.72233 | v_loss: 1.22736 v_acc: 0.71484 |  iteration: 5718 teacher: 1 stage: sketch lr: 0.000584\n",
      "batch 746 loss: 1.34903 acc: 0.69792 | v_loss: 1.20271 v_acc: 0.72168 |  iteration: 5719 teacher: 1 stage: sketch lr: 0.000584\n",
      "batch 747 loss: 1.35925 acc: 0.69401 | v_loss: 1.38968 v_acc: 0.69629 |  iteration: 5720 teacher: 1 stage: sketch lr: 0.000584\n",
      "batch 748 loss: 1.31733 acc: 0.70540 | v_loss: 1.27384 v_acc: 0.72005 |  iteration: 5721 teacher: 1 stage: sketch lr: 0.000584\n",
      "batch 749 loss: 1.34724 acc: 0.69792 | v_loss: 1.07365 v_acc: 0.74609 |  iteration: 5722 teacher: 1 stage: sketch lr: 0.000584\n",
      "batch 750 loss: 1.27447 acc: 0.70964 | v_loss: 1.22014 v_acc: 0.70605 |  iteration: 5723 teacher: 0 stage: sketch lr: 0.000584\n",
      "batch 751 loss: 1.36533 acc: 0.69954 | v_loss: 1.31578 v_acc: 0.68880 |  iteration: 5724 teacher: 1 stage: sketch lr: 0.000584\n",
      "batch 752 loss: 1.26252 acc: 0.71354 | v_loss: 1.20963 v_acc: 0.69173 |  iteration: 5725 teacher: 1 stage: sketch lr: 0.000584\n",
      "batch 753 loss: 1.30259 acc: 0.71224 | v_loss: 1.26368 v_acc: 0.70280 |  iteration: 5726 teacher: 1 stage: sketch lr: 0.000584\n",
      "batch 754 loss: 1.27798 acc: 0.70280 | v_loss: 1.25636 v_acc: 0.69303 |  iteration: 5727 teacher: 1 stage: sketch lr: 0.000584\n",
      "batch 755 loss: 1.34288 acc: 0.70117 | v_loss: 1.21427 v_acc: 0.71680 |  iteration: 5728 teacher: 1 stage: sketch lr: 0.000584\n",
      "batch 756 loss: 1.34252 acc: 0.70345 | v_loss: 1.26478 v_acc: 0.70215 |  iteration: 5729 teacher: 0 stage: sketch lr: 0.000584\n",
      "batch 757 loss: 1.23127 acc: 0.71191 | v_loss: 1.18715 v_acc: 0.72852 |  iteration: 5730 teacher: 1 stage: sketch lr: 0.000584\n",
      "batch 758 loss: 1.26548 acc: 0.71875 | v_loss: 1.18507 v_acc: 0.72591 |  iteration: 5731 teacher: 0 stage: sketch lr: 0.000584\n",
      "batch 759 loss: 1.28360 acc: 0.70345 | v_loss: 1.23560 v_acc: 0.70410 |  iteration: 5732 teacher: 0 stage: sketch lr: 0.000584\n",
      "batch 760 loss: 1.32146 acc: 0.70182 | v_loss: 1.35057 v_acc: 0.70020 |  iteration: 5733 teacher: 0 stage: sketch lr: 0.000584\n",
      "batch 761 loss: 1.33892 acc: 0.69694 | v_loss: 1.17596 v_acc: 0.70801 |  iteration: 5734 teacher: 0 stage: sketch lr: 0.000584\n",
      "batch 762 loss: 1.21137 acc: 0.72233 | v_loss: 1.40480 v_acc: 0.69434 |  iteration: 5735 teacher: 0 stage: sketch lr: 0.000584\n",
      "batch 763 loss: 1.24931 acc: 0.70736 | v_loss: 1.18305 v_acc: 0.72461 |  iteration: 5736 teacher: 0 stage: sketch lr: 0.000584\n",
      "batch 764 loss: 1.37389 acc: 0.69824 | v_loss: 1.50151 v_acc: 0.69043 |  iteration: 5737 teacher: 1 stage: sketch lr: 0.000583\n",
      "batch 765 loss: 1.21206 acc: 0.70605 | v_loss: 1.36581 v_acc: 0.70215 |  iteration: 5738 teacher: 1 stage: sketch lr: 0.000583\n",
      "batch 766 loss: 1.35172 acc: 0.69694 | v_loss: 1.34455 v_acc: 0.69206 |  iteration: 5739 teacher: 0 stage: sketch lr: 0.000583\n",
      "batch 767 loss: 1.16676 acc: 0.72038 | v_loss: 1.31329 v_acc: 0.70443 |  iteration: 5740 teacher: 0 stage: sketch lr: 0.000583\n",
      "batch 768 loss: 1.24808 acc: 0.71387 | v_loss: 1.25427 v_acc: 0.70280 |  iteration: 5741 teacher: 1 stage: sketch lr: 0.000583\n",
      "batch 769 loss: 1.23945 acc: 0.70833 | v_loss: 1.25528 v_acc: 0.70378 |  iteration: 5742 teacher: 1 stage: sketch lr: 0.000583\n",
      "batch 770 loss: 1.35110 acc: 0.70443 | v_loss: 1.22377 v_acc: 0.72298 |  iteration: 5743 teacher: 1 stage: sketch lr: 0.000583\n",
      "batch 771 loss: 1.19227 acc: 0.71484 | v_loss: 1.44741 v_acc: 0.68815 |  iteration: 5744 teacher: 1 stage: sketch lr: 0.000583\n",
      "batch 772 loss: 1.32886 acc: 0.69759 | v_loss: 1.31552 v_acc: 0.71289 |  iteration: 5745 teacher: 0 stage: sketch lr: 0.000583\n",
      "batch 773 loss: 1.29124 acc: 0.69661 | v_loss: 1.18223 v_acc: 0.70866 |  iteration: 5746 teacher: 0 stage: sketch lr: 0.000583\n",
      "batch 774 loss: 1.32156 acc: 0.69694 | v_loss: 1.28463 v_acc: 0.70605 |  iteration: 5747 teacher: 1 stage: sketch lr: 0.000583\n",
      "batch 775 loss: 1.32956 acc: 0.70215 | v_loss: 1.19091 v_acc: 0.70020 |  iteration: 5748 teacher: 1 stage: sketch lr: 0.000583\n",
      "batch 776 loss: 1.29857 acc: 0.70247 | v_loss: 1.28167 v_acc: 0.70150 |  iteration: 5749 teacher: 0 stage: sketch lr: 0.000583\n",
      "batch 777 loss: 1.30721 acc: 0.70020 | v_loss: 1.25551 v_acc: 0.71549 |  iteration: 5750 teacher: 0 stage: sketch lr: 0.000583\n",
      "batch 778 loss: 1.29044 acc: 0.69661 | v_loss: 1.18943 v_acc: 0.71647 |  iteration: 5751 teacher: 1 stage: sketch lr: 0.000583\n",
      "batch 779 loss: 1.29610 acc: 0.70768 | v_loss: 1.16598 v_acc: 0.72233 |  iteration: 5752 teacher: 1 stage: sketch lr: 0.000583\n",
      "batch 780 loss: 1.31021 acc: 0.70768 | v_loss: 1.28086 v_acc: 0.71224 |  iteration: 5753 teacher: 0 stage: sketch lr: 0.000583\n",
      "batch 781 loss: 1.23295 acc: 0.71126 | v_loss: 1.25997 v_acc: 0.70182 |  iteration: 5754 teacher: 1 stage: sketch lr: 0.000583\n",
      "batch 782 loss: 1.27414 acc: 0.70508 | v_loss: 1.26858 v_acc: 0.70866 |  iteration: 5755 teacher: 1 stage: sketch lr: 0.000583\n",
      "batch 783 loss: 1.37452 acc: 0.70703 | v_loss: 1.14580 v_acc: 0.71257 |  iteration: 5756 teacher: 0 stage: sketch lr: 0.000583\n",
      "batch 784 loss: 1.27914 acc: 0.70508 | v_loss: 1.27543 v_acc: 0.72493 |  iteration: 5757 teacher: 1 stage: sketch lr: 0.000582\n",
      "batch 785 loss: 1.24333 acc: 0.71029 | v_loss: 1.31396 v_acc: 0.70150 |  iteration: 5758 teacher: 1 stage: sketch lr: 0.000582\n",
      "batch 786 loss: 1.39334 acc: 0.70638 | v_loss: 1.30050 v_acc: 0.72526 |  iteration: 5759 teacher: 0 stage: sketch lr: 0.000582\n",
      "batch 787 loss: 1.37919 acc: 0.69238 | v_loss: 1.16593 v_acc: 0.72005 |  iteration: 5760 teacher: 1 stage: sketch lr: 0.000582\n",
      "batch 788 loss: 1.22443 acc: 0.71549 | v_loss: 1.11107 v_acc: 0.73340 |  iteration: 5761 teacher: 0 stage: sketch lr: 0.000582\n",
      "batch 789 loss: 1.22983 acc: 0.71061 | v_loss: 1.10314 v_acc: 0.72103 |  iteration: 5762 teacher: 0 stage: sketch lr: 0.000582\n",
      "batch 790 loss: 1.27597 acc: 0.72070 | v_loss: 1.20174 v_acc: 0.70768 |  iteration: 5763 teacher: 1 stage: sketch lr: 0.000582\n",
      "batch 791 loss: 1.24584 acc: 0.71289 | v_loss: 1.25280 v_acc: 0.70443 |  iteration: 5764 teacher: 0 stage: sketch lr: 0.000582\n",
      "batch 792 loss: 1.38233 acc: 0.69499 | v_loss: 1.22403 v_acc: 0.71647 |  iteration: 5765 teacher: 0 stage: sketch lr: 0.000582\n",
      "batch 793 loss: 1.25953 acc: 0.70768 | v_loss: 1.36939 v_acc: 0.69043 |  iteration: 5766 teacher: 1 stage: sketch lr: 0.000582\n",
      "batch 794 loss: 1.44269 acc: 0.69336 | v_loss: 1.48960 v_acc: 0.69043 |  iteration: 5767 teacher: 0 stage: sketch lr: 0.000582\n",
      "batch 795 loss: 1.26433 acc: 0.71126 | v_loss: 1.35167 v_acc: 0.69922 |  iteration: 5768 teacher: 1 stage: sketch lr: 0.000582\n",
      "batch 796 loss: 1.36575 acc: 0.69792 | v_loss: 1.21068 v_acc: 0.71908 |  iteration: 5769 teacher: 1 stage: sketch lr: 0.000582\n",
      "batch 797 loss: 1.30362 acc: 0.70508 | v_loss: 1.18765 v_acc: 0.69824 |  iteration: 5770 teacher: 1 stage: sketch lr: 0.000582\n",
      "batch 798 loss: 1.25008 acc: 0.70898 | v_loss: 1.17658 v_acc: 0.71842 |  iteration: 5771 teacher: 1 stage: sketch lr: 0.000582\n",
      "batch 799 loss: 1.39957 acc: 0.69759 | v_loss: 1.27526 v_acc: 0.69564 |  iteration: 5772 teacher: 0 stage: sketch lr: 0.000582\n",
      "batch 800 loss: 1.31017 acc: 0.70312 | v_loss: 1.25773 v_acc: 0.70866 |  iteration: 5773 teacher: 1 stage: sketch lr: 0.000582\n",
      "batch 801 loss: 1.29749 acc: 0.70964 | v_loss: 1.21948 v_acc: 0.73079 |  iteration: 5774 teacher: 1 stage: sketch lr: 0.000582\n",
      "batch 802 loss: 1.47890 acc: 0.68848 | v_loss: 1.23406 v_acc: 0.71745 |  iteration: 5775 teacher: 1 stage: sketch lr: 0.000582\n",
      "batch 803 loss: 1.28533 acc: 0.69661 | v_loss: 1.23643 v_acc: 0.71615 |  iteration: 5776 teacher: 0 stage: sketch lr: 0.000582\n",
      "batch 804 loss: 1.34204 acc: 0.70280 | v_loss: 1.16887 v_acc: 0.72493 |  iteration: 5777 teacher: 0 stage: sketch lr: 0.000581\n",
      "batch 805 loss: 1.22294 acc: 0.71126 | v_loss: 1.13326 v_acc: 0.72298 |  iteration: 5778 teacher: 1 stage: sketch lr: 0.000581\n",
      "batch 806 loss: 1.27252 acc: 0.70150 | v_loss: 1.49119 v_acc: 0.69043 |  iteration: 5779 teacher: 1 stage: sketch lr: 0.000581\n",
      "batch 807 loss: 1.38491 acc: 0.68783 | v_loss: 1.19741 v_acc: 0.71224 |  iteration: 5780 teacher: 1 stage: sketch lr: 0.000581\n",
      "batch 808 loss: 1.31517 acc: 0.70052 | v_loss: 1.24530 v_acc: 0.71484 |  iteration: 5781 teacher: 1 stage: sketch lr: 0.000581\n",
      "batch 809 loss: 1.28963 acc: 0.70638 | v_loss: 1.24804 v_acc: 0.70508 |  iteration: 5782 teacher: 0 stage: sketch lr: 0.000581\n",
      "batch 810 loss: 1.27218 acc: 0.69759 | v_loss: 1.31180 v_acc: 0.70052 |  iteration: 5783 teacher: 0 stage: sketch lr: 0.000581\n",
      "batch 811 loss: 1.22706 acc: 0.71061 | v_loss: 1.14151 v_acc: 0.72917 |  iteration: 5784 teacher: 0 stage: sketch lr: 0.000581\n",
      "batch 812 loss: 1.30316 acc: 0.69466 | v_loss: 1.40102 v_acc: 0.71712 |  iteration: 5785 teacher: 1 stage: sketch lr: 0.000581\n",
      "batch 813 loss: 1.30315 acc: 0.70996 | v_loss: 1.19080 v_acc: 0.69694 |  iteration: 5786 teacher: 0 stage: sketch lr: 0.000581\n",
      "batch 814 loss: 1.30196 acc: 0.70182 | v_loss: 1.21178 v_acc: 0.70117 |  iteration: 5787 teacher: 0 stage: sketch lr: 0.000581\n",
      "batch 815 loss: 1.31621 acc: 0.70410 | v_loss: 1.27179 v_acc: 0.70703 |  iteration: 5788 teacher: 1 stage: sketch lr: 0.000581\n",
      "batch 816 loss: 1.24696 acc: 0.71549 | v_loss: 1.28027 v_acc: 0.70573 |  iteration: 5789 teacher: 0 stage: sketch lr: 0.000581\n",
      "batch 817 loss: 1.29611 acc: 0.70573 | v_loss: 1.34700 v_acc: 0.68978 |  iteration: 5790 teacher: 0 stage: sketch lr: 0.000581\n",
      "batch 818 loss: 1.22209 acc: 0.70931 | v_loss: 1.37378 v_acc: 0.70736 |  iteration: 5791 teacher: 1 stage: sketch lr: 0.000581\n",
      "batch 819 loss: 1.28419 acc: 0.71257 | v_loss: 1.29004 v_acc: 0.70182 |  iteration: 5792 teacher: 0 stage: sketch lr: 0.000581\n",
      "batch 820 loss: 1.31035 acc: 0.70312 | v_loss: 1.19579 v_acc: 0.70898 |  iteration: 5793 teacher: 0 stage: sketch lr: 0.000581\n",
      "batch 821 loss: 1.23888 acc: 0.70931 | v_loss: 1.33189 v_acc: 0.70605 |  iteration: 5794 teacher: 0 stage: sketch lr: 0.000581\n",
      "batch 822 loss: 1.32264 acc: 0.69727 | v_loss: 1.22120 v_acc: 0.71875 |  iteration: 5795 teacher: 1 stage: sketch lr: 0.000581\n",
      "batch 823 loss: 1.30774 acc: 0.70475 | v_loss: 1.14756 v_acc: 0.72721 |  iteration: 5796 teacher: 0 stage: sketch lr: 0.000580\n",
      "batch 824 loss: 1.34861 acc: 0.69368 | v_loss: 1.14122 v_acc: 0.70833 |  iteration: 5797 teacher: 1 stage: sketch lr: 0.000580\n",
      "batch 825 loss: 1.29581 acc: 0.69499 | v_loss: 1.25355 v_acc: 0.70996 |  iteration: 5798 teacher: 0 stage: sketch lr: 0.000580\n",
      "batch 826 loss: 1.30355 acc: 0.70768 | v_loss: 1.34917 v_acc: 0.69141 |  iteration: 5799 teacher: 0 stage: sketch lr: 0.000580\n",
      "batch 827 loss: 1.27054 acc: 0.69889 | v_loss: 1.17314 v_acc: 0.70410 |  iteration: 5800 teacher: 1 stage: sketch lr: 0.000580\n",
      "batch 828 loss: 1.24536 acc: 0.70052 | v_loss: 1.19117 v_acc: 0.69987 |  iteration: 5801 teacher: 1 stage: sketch lr: 0.000580\n",
      "batch 829 loss: 1.23399 acc: 0.71647 | v_loss: 1.20105 v_acc: 0.71224 |  iteration: 5802 teacher: 0 stage: sketch lr: 0.000580\n",
      "batch 830 loss: 1.28860 acc: 0.70443 | v_loss: 1.22268 v_acc: 0.70605 |  iteration: 5803 teacher: 0 stage: sketch lr: 0.000580\n",
      "batch 831 loss: 1.29171 acc: 0.69596 | v_loss: 1.05571 v_acc: 0.73991 |  iteration: 5804 teacher: 0 stage: sketch lr: 0.000580\n",
      "batch 832 loss: 1.25552 acc: 0.70833 | v_loss: 1.18622 v_acc: 0.72038 |  iteration: 5805 teacher: 0 stage: sketch lr: 0.000580\n",
      "batch 833 loss: 1.18355 acc: 0.71191 | v_loss: 1.13245 v_acc: 0.72559 |  iteration: 5806 teacher: 1 stage: sketch lr: 0.000580\n",
      "batch 834 loss: 1.32998 acc: 0.70215 | v_loss: 1.12082 v_acc: 0.72396 |  iteration: 5807 teacher: 1 stage: sketch lr: 0.000580\n",
      "batch 835 loss: 1.47969 acc: 0.69661 | v_loss: 1.20285 v_acc: 0.72005 |  iteration: 5808 teacher: 1 stage: sketch lr: 0.000580\n",
      "batch 836 loss: 1.40070 acc: 0.69661 | v_loss: 1.23361 v_acc: 0.71615 |  iteration: 5809 teacher: 1 stage: sketch lr: 0.000580\n",
      "batch 837 loss: 1.35815 acc: 0.69499 | v_loss: 1.21483 v_acc: 0.72526 |  iteration: 5810 teacher: 1 stage: sketch lr: 0.000580\n",
      "batch 838 loss: 1.35342 acc: 0.70085 | v_loss: 1.39276 v_acc: 0.69857 |  iteration: 5811 teacher: 1 stage: sketch lr: 0.000580\n",
      "batch 839 loss: 1.30897 acc: 0.69954 | v_loss: 1.27551 v_acc: 0.72168 |  iteration: 5812 teacher: 0 stage: sketch lr: 0.000580\n",
      "batch 840 loss: 1.24511 acc: 0.71126 | v_loss: 1.07133 v_acc: 0.74512 |  iteration: 5813 teacher: 1 stage: sketch lr: 0.000580\n",
      "batch 841 loss: 1.30060 acc: 0.70638 | v_loss: 1.24732 v_acc: 0.70475 |  iteration: 5814 teacher: 0 stage: sketch lr: 0.000580\n",
      "batch 842 loss: 1.28168 acc: 0.70182 | v_loss: 1.27380 v_acc: 0.70378 |  iteration: 5815 teacher: 1 stage: sketch lr: 0.000580\n",
      "batch 843 loss: 1.38673 acc: 0.70378 | v_loss: 1.23704 v_acc: 0.70215 |  iteration: 5816 teacher: 1 stage: sketch lr: 0.000579\n",
      "batch 844 loss: 1.25900 acc: 0.71224 | v_loss: 1.27679 v_acc: 0.71159 |  iteration: 5817 teacher: 0 stage: sketch lr: 0.000579\n",
      "batch 845 loss: 1.26820 acc: 0.70345 | v_loss: 1.26911 v_acc: 0.69303 |  iteration: 5818 teacher: 1 stage: sketch lr: 0.000579\n",
      "batch 846 loss: 1.33367 acc: 0.69792 | v_loss: 1.23413 v_acc: 0.71810 |  iteration: 5819 teacher: 0 stage: sketch lr: 0.000579\n",
      "batch 847 loss: 1.36565 acc: 0.70117 | v_loss: 1.27367 v_acc: 0.69889 |  iteration: 5820 teacher: 0 stage: sketch lr: 0.000579\n",
      "batch 848 loss: 1.29111 acc: 0.69564 | v_loss: 1.21025 v_acc: 0.71484 |  iteration: 5821 teacher: 1 stage: sketch lr: 0.000579\n",
      "batch 849 loss: 1.29970 acc: 0.70931 | v_loss: 1.20663 v_acc: 0.72591 |  iteration: 5822 teacher: 1 stage: sketch lr: 0.000579\n",
      "batch 850 loss: 1.34826 acc: 0.71029 | v_loss: 1.28741 v_acc: 0.70312 |  iteration: 5823 teacher: 0 stage: sketch lr: 0.000579\n",
      "batch 851 loss: 1.29756 acc: 0.71224 | v_loss: 1.32183 v_acc: 0.70508 |  iteration: 5824 teacher: 1 stage: sketch lr: 0.000579\n",
      "batch 852 loss: 1.26641 acc: 0.70768 | v_loss: 1.17782 v_acc: 0.70508 |  iteration: 5825 teacher: 1 stage: sketch lr: 0.000579\n",
      "batch 853 loss: 1.30772 acc: 0.69661 | v_loss: 1.43349 v_acc: 0.68327 |  iteration: 5826 teacher: 0 stage: sketch lr: 0.000579\n",
      "batch 854 loss: 1.39922 acc: 0.68717 | v_loss: 1.18560 v_acc: 0.71582 |  iteration: 5827 teacher: 0 stage: sketch lr: 0.000579\n",
      "batch 855 loss: 1.31224 acc: 0.70605 | v_loss: 1.51663 v_acc: 0.67513 |  iteration: 5828 teacher: 0 stage: sketch lr: 0.000579\n",
      "batch 856 loss: 1.29602 acc: 0.71354 | v_loss: 1.41730 v_acc: 0.68815 |  iteration: 5829 teacher: 0 stage: sketch lr: 0.000579\n",
      "batch 857 loss: 1.27963 acc: 0.69889 | v_loss: 1.34030 v_acc: 0.69368 |  iteration: 5830 teacher: 1 stage: sketch lr: 0.000579\n",
      "batch 858 loss: 1.33364 acc: 0.70052 | v_loss: 1.36862 v_acc: 0.69108 |  iteration: 5831 teacher: 1 stage: sketch lr: 0.000579\n",
      "batch 859 loss: 1.47400 acc: 0.68978 | v_loss: 1.25816 v_acc: 0.70866 |  iteration: 5832 teacher: 1 stage: sketch lr: 0.000579\n",
      "batch 860 loss: 1.25144 acc: 0.70931 | v_loss: 1.29633 v_acc: 0.70150 |  iteration: 5833 teacher: 0 stage: sketch lr: 0.000579\n",
      "batch 861 loss: 1.31574 acc: 0.69954 | v_loss: 1.26769 v_acc: 0.71419 |  iteration: 5834 teacher: 1 stage: sketch lr: 0.000579\n",
      "batch 862 loss: 1.29712 acc: 0.70866 | v_loss: 1.44493 v_acc: 0.68327 |  iteration: 5835 teacher: 1 stage: sketch lr: 0.000579\n",
      "batch 863 loss: 1.32405 acc: 0.69857 | v_loss: 1.32603 v_acc: 0.70117 |  iteration: 5836 teacher: 1 stage: sketch lr: 0.000579\n",
      "batch 864 loss: 1.34795 acc: 0.70964 | v_loss: 1.19251 v_acc: 0.71029 |  iteration: 5837 teacher: 1 stage: sketch lr: 0.000578\n",
      "batch 865 loss: 1.28333 acc: 0.70085 | v_loss: 1.27199 v_acc: 0.71549 |  iteration: 5838 teacher: 1 stage: sketch lr: 0.000578\n",
      "batch 866 loss: 1.31477 acc: 0.70703 | v_loss: 1.19507 v_acc: 0.69759 |  iteration: 5839 teacher: 0 stage: sketch lr: 0.000578\n",
      "batch 867 loss: 1.31056 acc: 0.69661 | v_loss: 1.27380 v_acc: 0.69368 |  iteration: 5840 teacher: 1 stage: sketch lr: 0.000578\n",
      "batch 868 loss: 1.40789 acc: 0.70117 | v_loss: 1.22945 v_acc: 0.71777 |  iteration: 5841 teacher: 0 stage: sketch lr: 0.000578\n",
      "batch 869 loss: 1.30109 acc: 0.70931 | v_loss: 1.17979 v_acc: 0.71680 |  iteration: 5842 teacher: 1 stage: sketch lr: 0.000578\n",
      "batch 870 loss: 1.37515 acc: 0.68945 | v_loss: 1.13262 v_acc: 0.72656 |  iteration: 5843 teacher: 1 stage: sketch lr: 0.000578\n",
      "batch 871 loss: 1.27466 acc: 0.70833 | v_loss: 1.26452 v_acc: 0.71452 |  iteration: 5844 teacher: 0 stage: sketch lr: 0.000578\n",
      "batch 872 loss: 1.35799 acc: 0.69141 | v_loss: 1.25732 v_acc: 0.70345 |  iteration: 5845 teacher: 1 stage: sketch lr: 0.000578\n",
      "batch 873 loss: 1.20964 acc: 0.71452 | v_loss: 1.26576 v_acc: 0.71159 |  iteration: 5846 teacher: 0 stage: sketch lr: 0.000578\n",
      "batch 874 loss: 1.33951 acc: 0.70150 | v_loss: 1.11851 v_acc: 0.72396 |  iteration: 5847 teacher: 0 stage: sketch lr: 0.000578\n",
      "batch 875 loss: 1.35603 acc: 0.70117 | v_loss: 1.24357 v_acc: 0.73210 |  iteration: 5848 teacher: 0 stage: sketch lr: 0.000578\n",
      "batch 876 loss: 1.29780 acc: 0.70736 | v_loss: 1.31416 v_acc: 0.69661 |  iteration: 5849 teacher: 0 stage: sketch lr: 0.000578\n",
      "batch 877 loss: 1.33298 acc: 0.69727 | v_loss: 1.32040 v_acc: 0.71842 |  iteration: 5850 teacher: 0 stage: sketch lr: 0.000578\n",
      "batch 878 loss: 1.23143 acc: 0.70736 | v_loss: 1.16971 v_acc: 0.72233 |  iteration: 5851 teacher: 0 stage: sketch lr: 0.000578\n",
      "batch 879 loss: 1.41728 acc: 0.69238 | v_loss: 1.12455 v_acc: 0.73047 |  iteration: 5852 teacher: 0 stage: sketch lr: 0.000578\n",
      "batch 880 loss: 1.26651 acc: 0.70931 | v_loss: 1.12525 v_acc: 0.72396 |  iteration: 5853 teacher: 1 stage: sketch lr: 0.000578\n",
      "batch 881 loss: 1.22694 acc: 0.71257 | v_loss: 1.20517 v_acc: 0.70540 |  iteration: 5854 teacher: 0 stage: sketch lr: 0.000578\n",
      "batch 882 loss: 1.30516 acc: 0.70182 | v_loss: 1.25771 v_acc: 0.69596 |  iteration: 5855 teacher: 0 stage: sketch lr: 0.000578\n",
      "batch 883 loss: 1.32530 acc: 0.69824 | v_loss: 1.20042 v_acc: 0.71582 |  iteration: 5856 teacher: 0 stage: sketch lr: 0.000578\n",
      "batch 884 loss: 1.39732 acc: 0.69564 | v_loss: 1.30048 v_acc: 0.74479 |  iteration: 5857 teacher: 0 stage: sketch lr: 0.000577\n",
      "batch 885 loss: 1.27732 acc: 0.70996 | v_loss: 1.47223 v_acc: 0.69466 |  iteration: 5858 teacher: 1 stage: sketch lr: 0.000577\n",
      "batch 886 loss: 1.30108 acc: 0.70378 | v_loss: 1.35699 v_acc: 0.70020 |  iteration: 5859 teacher: 0 stage: sketch lr: 0.000577\n",
      "batch 887 loss: 1.24293 acc: 0.71029 | v_loss: 1.18925 v_acc: 0.72298 |  iteration: 5860 teacher: 1 stage: sketch lr: 0.000577\n",
      "batch 888 loss: 1.24192 acc: 0.71354 | v_loss: 1.16778 v_acc: 0.70833 |  iteration: 5861 teacher: 0 stage: sketch lr: 0.000577\n",
      "batch 889 loss: 1.29910 acc: 0.70052 | v_loss: 1.14948 v_acc: 0.72103 |  iteration: 5862 teacher: 1 stage: sketch lr: 0.000577\n",
      "batch 890 loss: 1.32760 acc: 0.70964 | v_loss: 1.23430 v_acc: 0.70312 |  iteration: 5863 teacher: 0 stage: sketch lr: 0.000577\n",
      "batch 891 loss: 1.37054 acc: 0.69889 | v_loss: 1.25570 v_acc: 0.71908 |  iteration: 5864 teacher: 1 stage: sketch lr: 0.000577\n",
      "batch 892 loss: 1.32821 acc: 0.69857 | v_loss: 1.21840 v_acc: 0.72884 |  iteration: 5865 teacher: 0 stage: sketch lr: 0.000577\n",
      "batch 893 loss: 1.29925 acc: 0.70443 | v_loss: 1.24804 v_acc: 0.71875 |  iteration: 5866 teacher: 0 stage: sketch lr: 0.000577\n",
      "batch 894 loss: 1.33429 acc: 0.70117 | v_loss: 1.24719 v_acc: 0.71745 |  iteration: 5867 teacher: 0 stage: sketch lr: 0.000577\n",
      "batch 895 loss: 1.33754 acc: 0.70443 | v_loss: 1.16384 v_acc: 0.72461 |  iteration: 5868 teacher: 1 stage: sketch lr: 0.000577\n",
      "batch 896 loss: 1.28733 acc: 0.70671 | v_loss: 1.14232 v_acc: 0.72103 |  iteration: 5869 teacher: 1 stage: sketch lr: 0.000577\n",
      "batch 897 loss: 1.28155 acc: 0.70866 | v_loss: 1.44205 v_acc: 0.68652 |  iteration: 5870 teacher: 0 stage: sketch lr: 0.000577\n",
      "batch 898 loss: 1.24722 acc: 0.71419 | v_loss: 1.21456 v_acc: 0.70996 |  iteration: 5871 teacher: 0 stage: sketch lr: 0.000577\n",
      "batch 899 loss: 1.26595 acc: 0.70475 | v_loss: 1.24444 v_acc: 0.71647 |  iteration: 5872 teacher: 1 stage: sketch lr: 0.000577\n",
      "batch 900 loss: 1.31104 acc: 0.70475 | v_loss: 1.22497 v_acc: 0.72201 |  iteration: 5873 teacher: 1 stage: sketch lr: 0.000577\n",
      "batch 901 loss: 1.31649 acc: 0.69857 | v_loss: 1.29218 v_acc: 0.70768 |  iteration: 5874 teacher: 1 stage: sketch lr: 0.000577\n",
      "batch 902 loss: 1.31532 acc: 0.70345 | v_loss: 1.15336 v_acc: 0.72819 |  iteration: 5875 teacher: 0 stage: sketch lr: 0.000577\n",
      "batch 903 loss: 1.29614 acc: 0.69857 | v_loss: 1.42360 v_acc: 0.71517 |  iteration: 5876 teacher: 1 stage: sketch lr: 0.000577\n",
      "batch 904 loss: 1.35634 acc: 0.69499 | v_loss: 1.18481 v_acc: 0.69987 |  iteration: 5877 teacher: 0 stage: sketch lr: 0.000576\n",
      "batch 905 loss: 1.25285 acc: 0.70247 | v_loss: 1.21441 v_acc: 0.70312 |  iteration: 5878 teacher: 1 stage: sketch lr: 0.000576\n",
      "batch 906 loss: 1.26846 acc: 0.70410 | v_loss: 1.26368 v_acc: 0.70247 |  iteration: 5879 teacher: 0 stage: sketch lr: 0.000576\n",
      "batch 907 loss: 1.20506 acc: 0.70801 | v_loss: 1.27821 v_acc: 0.70312 |  iteration: 5880 teacher: 1 stage: sketch lr: 0.000576\n",
      "batch 908 loss: 1.38499 acc: 0.69531 | v_loss: 1.33837 v_acc: 0.69954 |  iteration: 5881 teacher: 0 stage: sketch lr: 0.000576\n",
      "batch 909 loss: 1.36562 acc: 0.69987 | v_loss: 1.36138 v_acc: 0.70964 |  iteration: 5882 teacher: 0 stage: sketch lr: 0.000576\n",
      "batch 910 loss: 1.37950 acc: 0.69434 | v_loss: 1.29580 v_acc: 0.70020 |  iteration: 5883 teacher: 1 stage: sketch lr: 0.000576\n",
      "batch 911 loss: 1.28068 acc: 0.70736 | v_loss: 1.20428 v_acc: 0.71191 |  iteration: 5884 teacher: 1 stage: sketch lr: 0.000576\n",
      "batch 912 loss: 1.35707 acc: 0.70150 | v_loss: 1.31675 v_acc: 0.70378 |  iteration: 5885 teacher: 1 stage: sketch lr: 0.000576\n",
      "batch 913 loss: 1.35926 acc: 0.69173 | v_loss: 1.25880 v_acc: 0.71126 |  iteration: 5886 teacher: 1 stage: sketch lr: 0.000576\n",
      "batch 914 loss: 1.21427 acc: 0.71094 | v_loss: 1.14984 v_acc: 0.72493 |  iteration: 5887 teacher: 0 stage: sketch lr: 0.000576\n",
      "batch 915 loss: 1.35358 acc: 0.69271 | v_loss: 1.16804 v_acc: 0.70573 |  iteration: 5888 teacher: 1 stage: sketch lr: 0.000576\n",
      "batch 916 loss: 1.25004 acc: 0.69857 | v_loss: 1.26616 v_acc: 0.70378 |  iteration: 5889 teacher: 0 stage: sketch lr: 0.000576\n",
      "batch 917 loss: 1.39062 acc: 0.69954 | v_loss: 1.32482 v_acc: 0.69987 |  iteration: 5890 teacher: 0 stage: sketch lr: 0.000576\n",
      "batch 918 loss: 1.28178 acc: 0.69857 | v_loss: 1.17294 v_acc: 0.70540 |  iteration: 5891 teacher: 0 stage: sketch lr: 0.000576\n",
      "batch 919 loss: 1.31797 acc: 0.70410 | v_loss: 1.20406 v_acc: 0.70215 |  iteration: 5892 teacher: 0 stage: sketch lr: 0.000576\n",
      "batch 920 loss: 1.31172 acc: 0.69564 | v_loss: 1.19435 v_acc: 0.71387 |  iteration: 5893 teacher: 1 stage: sketch lr: 0.000576\n",
      "batch 921 loss: 1.37069 acc: 0.69434 | v_loss: 1.19465 v_acc: 0.70410 |  iteration: 5894 teacher: 0 stage: sketch lr: 0.000576\n",
      "batch 922 loss: 1.23273 acc: 0.70215 | v_loss: 1.06757 v_acc: 0.73796 |  iteration: 5895 teacher: 1 stage: sketch lr: 0.000576\n",
      "batch 923 loss: 1.27447 acc: 0.70378 | v_loss: 1.17612 v_acc: 0.71712 |  iteration: 5896 teacher: 1 stage: sketch lr: 0.000576\n",
      "batch 924 loss: 1.32275 acc: 0.70312 | v_loss: 1.15927 v_acc: 0.70638 |  iteration: 5897 teacher: 0 stage: sketch lr: 0.000576\n",
      "batch 925 loss: 1.30983 acc: 0.70410 | v_loss: 1.12630 v_acc: 0.73242 |  iteration: 5898 teacher: 0 stage: sketch lr: 0.000575\n",
      "batch 926 loss: 1.29233 acc: 0.71061 | v_loss: 1.21436 v_acc: 0.71452 |  iteration: 5899 teacher: 0 stage: sketch lr: 0.000575\n",
      "batch 927 loss: 1.30266 acc: 0.71191 | v_loss: 1.23282 v_acc: 0.71159 |  iteration: 5900 teacher: 0 stage: sketch lr: 0.000575\n",
      "batch 928 loss: 1.32715 acc: 0.70215 | v_loss: 1.21579 v_acc: 0.72233 |  iteration: 5901 teacher: 1 stage: sketch lr: 0.000575\n",
      "batch 929 loss: 1.27023 acc: 0.71452 | v_loss: 1.39172 v_acc: 0.69694 |  iteration: 5902 teacher: 0 stage: sketch lr: 0.000575\n",
      "batch 930 loss: 1.23306 acc: 0.71647 | v_loss: 1.26852 v_acc: 0.71875 |  iteration: 5903 teacher: 1 stage: sketch lr: 0.000575\n",
      "batch 931 loss: 1.31037 acc: 0.70638 | v_loss: 1.06733 v_acc: 0.74349 |  iteration: 5904 teacher: 1 stage: sketch lr: 0.000575\n",
      "batch 932 loss: 1.27835 acc: 0.70475 | v_loss: 1.21716 v_acc: 0.70833 |  iteration: 5905 teacher: 1 stage: sketch lr: 0.000575\n",
      "batch 933 loss: 1.37664 acc: 0.69368 | v_loss: 1.30058 v_acc: 0.69661 |  iteration: 5906 teacher: 1 stage: sketch lr: 0.000575\n",
      "batch 934 loss: 1.39832 acc: 0.69368 | v_loss: 1.19665 v_acc: 0.70866 |  iteration: 5907 teacher: 0 stage: sketch lr: 0.000575\n",
      "batch 935 loss: 1.30577 acc: 0.70443 | v_loss: 1.26720 v_acc: 0.71191 |  iteration: 5908 teacher: 0 stage: sketch lr: 0.000575\n",
      "batch 936 loss: 1.22491 acc: 0.71257 | v_loss: 1.26706 v_acc: 0.69173 |  iteration: 5909 teacher: 0 stage: sketch lr: 0.000575\n",
      "batch 937 loss: 1.33349 acc: 0.70410 | v_loss: 1.21549 v_acc: 0.71615 |  iteration: 5910 teacher: 1 stage: sketch lr: 0.000575\n",
      "batch 938 loss: 1.27533 acc: 0.70703 | v_loss: 1.26192 v_acc: 0.69792 |  iteration: 5911 teacher: 1 stage: sketch lr: 0.000575\n",
      "batch 939 loss: 1.32902 acc: 0.70605 | v_loss: 1.19744 v_acc: 0.71777 |  iteration: 5912 teacher: 1 stage: sketch lr: 0.000575\n",
      "batch 940 loss: 1.30682 acc: 0.70410 | v_loss: 1.18277 v_acc: 0.72624 |  iteration: 5913 teacher: 1 stage: sketch lr: 0.000575\n",
      "batch 941 loss: 1.34485 acc: 0.70150 | v_loss: 1.22688 v_acc: 0.70280 |  iteration: 5914 teacher: 1 stage: sketch lr: 0.000575\n",
      "batch 942 loss: 1.28426 acc: 0.70312 | v_loss: 1.39737 v_acc: 0.69336 |  iteration: 5915 teacher: 0 stage: sketch lr: 0.000575\n",
      "batch 943 loss: 1.41996 acc: 0.69173 | v_loss: 1.17052 v_acc: 0.71029 |  iteration: 5916 teacher: 0 stage: sketch lr: 0.000575\n",
      "batch 944 loss: 1.25277 acc: 0.70475 | v_loss: 1.43883 v_acc: 0.68034 |  iteration: 5917 teacher: 1 stage: sketch lr: 0.000575\n",
      "batch 945 loss: 1.37323 acc: 0.69531 | v_loss: 1.16824 v_acc: 0.72461 |  iteration: 5918 teacher: 0 stage: sketch lr: 0.000574\n",
      "batch 946 loss: 1.32173 acc: 0.70378 | v_loss: 1.48812 v_acc: 0.68424 |  iteration: 5919 teacher: 0 stage: sketch lr: 0.000574\n",
      "batch 947 loss: 1.29753 acc: 0.70150 | v_loss: 1.35970 v_acc: 0.70215 |  iteration: 5920 teacher: 1 stage: sketch lr: 0.000574\n",
      "batch 948 loss: 1.28636 acc: 0.70638 | v_loss: 1.34236 v_acc: 0.68750 |  iteration: 5921 teacher: 1 stage: sketch lr: 0.000574\n",
      "batch 949 loss: 1.27467 acc: 0.70736 | v_loss: 1.31649 v_acc: 0.69792 |  iteration: 5922 teacher: 1 stage: sketch lr: 0.000574\n",
      "batch 950 loss: 1.31009 acc: 0.70345 | v_loss: 1.25331 v_acc: 0.70020 |  iteration: 5923 teacher: 1 stage: sketch lr: 0.000574\n",
      "batch 951 loss: 1.27543 acc: 0.70801 | v_loss: 1.26913 v_acc: 0.69759 |  iteration: 5924 teacher: 0 stage: sketch lr: 0.000574\n",
      "batch 952 loss: 1.27295 acc: 0.70540 | v_loss: 1.23288 v_acc: 0.71354 |  iteration: 5925 teacher: 0 stage: sketch lr: 0.000574\n",
      "batch 953 loss: 1.34936 acc: 0.69857 | v_loss: 1.43691 v_acc: 0.68457 |  iteration: 5926 teacher: 1 stage: sketch lr: 0.000574\n",
      "batch 954 loss: 1.38384 acc: 0.68880 | v_loss: 1.29450 v_acc: 0.71257 |  iteration: 5927 teacher: 1 stage: sketch lr: 0.000574\n",
      "batch 955 loss: 1.26096 acc: 0.70280 | v_loss: 1.19120 v_acc: 0.70638 |  iteration: 5928 teacher: 1 stage: sketch lr: 0.000574\n",
      "batch 956 loss: 1.36830 acc: 0.69889 | v_loss: 1.27635 v_acc: 0.70866 |  iteration: 5929 teacher: 0 stage: sketch lr: 0.000574\n",
      "batch 957 loss: 1.30334 acc: 0.70736 | v_loss: 1.17365 v_acc: 0.70638 |  iteration: 5930 teacher: 0 stage: sketch lr: 0.000574\n",
      "batch 958 loss: 1.24855 acc: 0.70768 | v_loss: 1.27680 v_acc: 0.70052 |  iteration: 5931 teacher: 0 stage: sketch lr: 0.000574\n",
      "batch 959 loss: 1.26328 acc: 0.70638 | v_loss: 1.24551 v_acc: 0.71452 |  iteration: 5932 teacher: 1 stage: sketch lr: 0.000574\n",
      "batch 960 loss: 1.32455 acc: 0.69173 | v_loss: 1.18142 v_acc: 0.71810 |  iteration: 5933 teacher: 1 stage: sketch lr: 0.000574\n",
      "batch 961 loss: 1.40745 acc: 0.70052 | v_loss: 1.14289 v_acc: 0.72103 |  iteration: 5934 teacher: 0 stage: sketch lr: 0.000574\n",
      "batch 962 loss: 1.29727 acc: 0.70410 | v_loss: 1.26426 v_acc: 0.71322 |  iteration: 5935 teacher: 1 stage: sketch lr: 0.000574\n",
      "batch 963 loss: 1.27245 acc: 0.69661 | v_loss: 1.25878 v_acc: 0.70052 |  iteration: 5936 teacher: 1 stage: sketch lr: 0.000574\n",
      "batch 964 loss: 1.28558 acc: 0.70931 | v_loss: 1.27660 v_acc: 0.70378 |  iteration: 5937 teacher: 0 stage: sketch lr: 0.000574\n",
      "batch 965 loss: 1.37487 acc: 0.70020 | v_loss: 1.13515 v_acc: 0.71257 |  iteration: 5938 teacher: 1 stage: sketch lr: 0.000574\n",
      "batch 966 loss: 1.29288 acc: 0.70247 | v_loss: 1.25869 v_acc: 0.72884 |  iteration: 5939 teacher: 0 stage: sketch lr: 0.000573\n",
      "batch 967 loss: 1.31803 acc: 0.70247 | v_loss: 1.31586 v_acc: 0.69987 |  iteration: 5940 teacher: 0 stage: sketch lr: 0.000573\n",
      "batch 968 loss: 1.25854 acc: 0.71029 | v_loss: 1.31969 v_acc: 0.72298 |  iteration: 5941 teacher: 1 stage: sketch lr: 0.000573\n",
      "batch 969 loss: 1.33402 acc: 0.68848 | v_loss: 1.17395 v_acc: 0.71484 |  iteration: 5942 teacher: 0 stage: sketch lr: 0.000573\n",
      "batch 970 loss: 1.26699 acc: 0.70312 | v_loss: 1.11956 v_acc: 0.73828 |  iteration: 5943 teacher: 0 stage: sketch lr: 0.000573\n",
      "batch 971 loss: 1.25557 acc: 0.70931 | v_loss: 1.10214 v_acc: 0.72005 |  iteration: 5944 teacher: 0 stage: sketch lr: 0.000573\n",
      "batch 972 loss: 1.28964 acc: 0.70768 | v_loss: 1.20715 v_acc: 0.70475 |  iteration: 5945 teacher: 0 stage: sketch lr: 0.000573\n",
      "batch 973 loss: 1.31894 acc: 0.70117 | v_loss: 1.23679 v_acc: 0.70345 |  iteration: 5946 teacher: 0 stage: sketch lr: 0.000573\n",
      "batch 974 loss: 1.30196 acc: 0.70475 | v_loss: 1.22571 v_acc: 0.71159 |  iteration: 5947 teacher: 1 stage: sketch lr: 0.000573\n",
      "batch 975 loss: 1.31018 acc: 0.70638 | v_loss: 1.34858 v_acc: 0.71842 |  iteration: 5948 teacher: 1 stage: sketch lr: 0.000573\n",
      "batch 976 loss: 1.26508 acc: 0.69987 | v_loss: 1.47949 v_acc: 0.69303 |  iteration: 5949 teacher: 1 stage: sketch lr: 0.000573\n",
      "batch 977 loss: 1.33628 acc: 0.70410 | v_loss: 1.35968 v_acc: 0.69434 |  iteration: 5950 teacher: 0 stage: sketch lr: 0.000573\n",
      "batch 978 loss: 1.39569 acc: 0.70540 | v_loss: 1.20284 v_acc: 0.71973 |  iteration: 5951 teacher: 1 stage: sketch lr: 0.000573\n",
      "batch 979 loss: 1.34203 acc: 0.69043 | v_loss: 1.18858 v_acc: 0.69499 |  iteration: 5952 teacher: 1 stage: sketch lr: 0.000573\n",
      "batch 980 loss: 1.29324 acc: 0.69694 | v_loss: 1.16349 v_acc: 0.71419 |  iteration: 5953 teacher: 1 stage: sketch lr: 0.000573\n",
      "batch 981 loss: 1.32521 acc: 0.69271 | v_loss: 1.26547 v_acc: 0.69238 |  iteration: 5954 teacher: 1 stage: sketch lr: 0.000573\n",
      "batch 982 loss: 1.29842 acc: 0.69499 | v_loss: 1.25937 v_acc: 0.70768 |  iteration: 5955 teacher: 0 stage: sketch lr: 0.000573\n",
      "batch 983 loss: 1.36818 acc: 0.69141 | v_loss: 1.22639 v_acc: 0.72331 |  iteration: 5956 teacher: 1 stage: sketch lr: 0.000573\n",
      "batch 984 loss: 1.20977 acc: 0.70768 | v_loss: 1.23806 v_acc: 0.71517 |  iteration: 5957 teacher: 1 stage: sketch lr: 0.000573\n",
      "batch 985 loss: 1.28534 acc: 0.70703 | v_loss: 1.23040 v_acc: 0.71419 |  iteration: 5958 teacher: 1 stage: sketch lr: 0.000573\n",
      "batch 986 loss: 1.29469 acc: 0.70410 | v_loss: 1.17017 v_acc: 0.72526 |  iteration: 5959 teacher: 0 stage: sketch lr: 0.000573\n",
      "batch 987 loss: 1.31132 acc: 0.71061 | v_loss: 1.13533 v_acc: 0.72298 |  iteration: 5960 teacher: 0 stage: sketch lr: 0.000572\n",
      "batch 988 loss: 1.32696 acc: 0.70866 | v_loss: 1.49591 v_acc: 0.68848 |  iteration: 5961 teacher: 0 stage: sketch lr: 0.000572\n",
      "batch 989 loss: 1.31344 acc: 0.70410 | v_loss: 1.21196 v_acc: 0.71061 |  iteration: 5962 teacher: 1 stage: sketch lr: 0.000572\n",
      "batch 990 loss: 1.33562 acc: 0.69987 | v_loss: 1.23917 v_acc: 0.71517 |  iteration: 5963 teacher: 0 stage: sketch lr: 0.000572\n",
      "batch 991 loss: 1.30962 acc: 0.70443 | v_loss: 1.24219 v_acc: 0.71387 |  iteration: 5964 teacher: 1 stage: sketch lr: 0.000572\n",
      "batch 992 loss: 1.31124 acc: 0.69889 | v_loss: 1.30651 v_acc: 0.69434 |  iteration: 5965 teacher: 0 stage: sketch lr: 0.000572\n",
      "batch 993 loss: 1.25165 acc: 0.71712 | v_loss: 1.14066 v_acc: 0.72656 |  iteration: 5966 teacher: 0 stage: sketch lr: 0.000572\n",
      "batch 994 loss: 1.29847 acc: 0.70931 | v_loss: 1.38650 v_acc: 0.70573 |  iteration: 5967 teacher: 0 stage: sketch lr: 0.000572\n",
      "batch 995 loss: 1.23240 acc: 0.70443 | v_loss: 1.19872 v_acc: 0.69792 |  iteration: 5968 teacher: 1 stage: sketch lr: 0.000572\n",
      "batch 996 loss: 1.25999 acc: 0.71582 | v_loss: 1.20501 v_acc: 0.70150 |  iteration: 5969 teacher: 1 stage: sketch lr: 0.000572\n",
      "batch 997 loss: 1.27486 acc: 0.70833 | v_loss: 1.27891 v_acc: 0.70312 |  iteration: 5970 teacher: 0 stage: sketch lr: 0.000572\n",
      "batch 998 loss: 1.31421 acc: 0.69954 | v_loss: 1.28413 v_acc: 0.70345 |  iteration: 5971 teacher: 1 stage: sketch lr: 0.000572\n",
      "batch 999 loss: 1.28919 acc: 0.70052 | v_loss: 1.33676 v_acc: 0.69271 |  iteration: 5972 teacher: 1 stage: sketch lr: 0.000572\n",
      "batch 1000 loss: 1.23096 acc: 0.70703 | v_loss: 1.37982 v_acc: 0.70638 |  iteration: 5973 teacher: 0 stage: sketch lr: 0.000572\n",
      "batch 1001 loss: 1.40200 acc: 0.68815 | v_loss: 1.29523 v_acc: 0.69694 |  iteration: 5974 teacher: 0 stage: sketch lr: 0.000572\n",
      "batch 1002 loss: 1.25303 acc: 0.70475 | v_loss: 1.18381 v_acc: 0.70996 |  iteration: 5975 teacher: 0 stage: sketch lr: 0.000572\n",
      "batch 1003 loss: 1.39923 acc: 0.69629 | v_loss: 1.34253 v_acc: 0.70573 |  iteration: 5976 teacher: 1 stage: sketch lr: 0.000572\n",
      "batch 1004 loss: 1.28412 acc: 0.71257 | v_loss: 1.23173 v_acc: 0.71777 |  iteration: 5977 teacher: 1 stage: sketch lr: 0.000572\n",
      "batch 1005 loss: 1.42276 acc: 0.68880 | v_loss: 1.15913 v_acc: 0.72428 |  iteration: 5978 teacher: 0 stage: sketch lr: 0.000572\n",
      "batch 1006 loss: 1.29148 acc: 0.69889 | v_loss: 1.13453 v_acc: 0.70931 |  iteration: 5979 teacher: 0 stage: sketch lr: 0.000572\n",
      "batch 1007 loss: 1.27590 acc: 0.70247 | v_loss: 1.28469 v_acc: 0.70540 |  iteration: 5980 teacher: 1 stage: sketch lr: 0.000571\n",
      "batch 1008 loss: 1.32367 acc: 0.70085 | v_loss: 1.37125 v_acc: 0.69271 |  iteration: 5981 teacher: 0 stage: sketch lr: 0.000571\n",
      "batch 1009 loss: 1.32380 acc: 0.70410 | v_loss: 1.19792 v_acc: 0.70215 |  iteration: 5982 teacher: 0 stage: sketch lr: 0.000571\n",
      "batch 1010 loss: 1.28333 acc: 0.70280 | v_loss: 1.19983 v_acc: 0.70085 |  iteration: 5983 teacher: 1 stage: sketch lr: 0.000571\n",
      "batch 1011 loss: 1.28776 acc: 0.70443 | v_loss: 1.20059 v_acc: 0.71354 |  iteration: 5984 teacher: 1 stage: sketch lr: 0.000571\n",
      "batch 1012 loss: 1.29698 acc: 0.70117 | v_loss: 1.19606 v_acc: 0.70866 |  iteration: 5985 teacher: 1 stage: sketch lr: 0.000571\n",
      "batch 1013 loss: 1.26824 acc: 0.70801 | v_loss: 1.05816 v_acc: 0.73275 |  iteration: 5986 teacher: 1 stage: sketch lr: 0.000571\n",
      "batch 1014 loss: 1.35329 acc: 0.69206 | v_loss: 1.19717 v_acc: 0.71615 |  iteration: 5987 teacher: 1 stage: sketch lr: 0.000571\n",
      "batch 1015 loss: 1.20150 acc: 0.72135 | v_loss: 1.12913 v_acc: 0.71029 |  iteration: 5988 teacher: 1 stage: sketch lr: 0.000571\n",
      "batch 1016 loss: 1.30144 acc: 0.69954 | v_loss: 1.11878 v_acc: 0.72233 |  iteration: 5989 teacher: 1 stage: sketch lr: 0.000571\n",
      "batch 1017 loss: 1.29757 acc: 0.69922 | v_loss: 1.19937 v_acc: 0.71582 |  iteration: 5990 teacher: 0 stage: sketch lr: 0.000571\n",
      "batch 1018 loss: 1.18776 acc: 0.71029 | v_loss: 1.21773 v_acc: 0.71549 |  iteration: 5991 teacher: 0 stage: sketch lr: 0.000571\n",
      "batch 1019 loss: 1.37948 acc: 0.70052 | v_loss: 1.20079 v_acc: 0.72526 |  iteration: 5992 teacher: 0 stage: sketch lr: 0.000571\n",
      "batch 1020 loss: 1.27957 acc: 0.70247 | v_loss: 1.40384 v_acc: 0.69889 |  iteration: 5993 teacher: 1 stage: sketch lr: 0.000571\n",
      "batch 1021 loss: 1.36284 acc: 0.69010 | v_loss: 1.26407 v_acc: 0.72005 |  iteration: 5994 teacher: 1 stage: sketch lr: 0.000571\n",
      "batch 1022 loss: 1.23553 acc: 0.70898 | v_loss: 1.06034 v_acc: 0.74837 |  iteration: 5995 teacher: 0 stage: sketch lr: 0.000571\n",
      "batch 1023 loss: 1.28922 acc: 0.70247 | v_loss: 1.22118 v_acc: 0.70638 |  iteration: 5996 teacher: 1 stage: sketch lr: 0.000571\n",
      "batch 1024 loss: 1.24697 acc: 0.71159 | v_loss: 1.29198 v_acc: 0.69499 |  iteration: 5997 teacher: 0 stage: sketch lr: 0.000571\n",
      "batch 1025 loss: 1.36112 acc: 0.69401 | v_loss: 1.18764 v_acc: 0.68815 |  iteration: 5998 teacher: 1 stage: sketch lr: 0.000571\n",
      "batch 1026 loss: 1.29807 acc: 0.70573 | v_loss: 1.26601 v_acc: 0.70215 |  iteration: 5999 teacher: 1 stage: sketch lr: 0.000571\n",
      "batch 1027 loss: 1.31305 acc: 0.70052 | v_loss: 1.25611 v_acc: 0.69076 |  iteration: 6000 teacher: 1 stage: sketch lr: 0.000571\n",
      "batch 1028 loss: 1.26138 acc: 0.70280 | v_loss: 1.21704 v_acc: 0.71354 |  iteration: 6001 teacher: 1 stage: sketch lr: 0.000570\n",
      "batch 1029 loss: 1.29534 acc: 0.70475 | v_loss: 1.25757 v_acc: 0.70150 |  iteration: 6002 teacher: 1 stage: sketch lr: 0.000570\n",
      "batch 1030 loss: 1.31591 acc: 0.69922 | v_loss: 1.20286 v_acc: 0.72005 |  iteration: 6003 teacher: 0 stage: sketch lr: 0.000570\n",
      "batch 1031 loss: 1.27312 acc: 0.70410 | v_loss: 1.18840 v_acc: 0.72786 |  iteration: 6004 teacher: 1 stage: sketch lr: 0.000570\n",
      "batch 1032 loss: 1.33962 acc: 0.71094 | v_loss: 1.24782 v_acc: 0.70085 |  iteration: 6005 teacher: 1 stage: sketch lr: 0.000570\n",
      "batch 1033 loss: 1.27591 acc: 0.70801 | v_loss: 1.35780 v_acc: 0.69076 |  iteration: 6006 teacher: 0 stage: sketch lr: 0.000570\n",
      "batch 1034 loss: 1.27403 acc: 0.70378 | v_loss: 1.16286 v_acc: 0.71029 |  iteration: 6007 teacher: 0 stage: sketch lr: 0.000570\n",
      "batch 1035 loss: 1.24814 acc: 0.71842 | v_loss: 1.44556 v_acc: 0.68066 |  iteration: 6008 teacher: 1 stage: sketch lr: 0.000570\n",
      "batch 1036 loss: 1.33488 acc: 0.69759 | v_loss: 1.17788 v_acc: 0.72038 |  iteration: 6009 teacher: 1 stage: sketch lr: 0.000570\n",
      "batch 1037 loss: 1.32529 acc: 0.70573 | v_loss: 1.51211 v_acc: 0.67611 |  iteration: 6010 teacher: 0 stage: sketch lr: 0.000570\n",
      "batch 1038 loss: 1.28940 acc: 0.70638 | v_loss: 1.38656 v_acc: 0.69759 |  iteration: 6011 teacher: 0 stage: sketch lr: 0.000570\n",
      "batch 1039 loss: 1.26586 acc: 0.70671 | v_loss: 1.34994 v_acc: 0.68880 |  iteration: 6012 teacher: 1 stage: sketch lr: 0.000570\n",
      "batch 1040 loss: 1.30512 acc: 0.70671 | v_loss: 1.31780 v_acc: 0.69889 |  iteration: 6013 teacher: 0 stage: sketch lr: 0.000570\n",
      "batch 1041 loss: 1.25441 acc: 0.71322 | v_loss: 1.24886 v_acc: 0.70052 |  iteration: 6014 teacher: 1 stage: sketch lr: 0.000570\n",
      "batch 1042 loss: 1.36853 acc: 0.69792 | v_loss: 1.27844 v_acc: 0.69889 |  iteration: 6015 teacher: 1 stage: sketch lr: 0.000570\n",
      "batch 1043 loss: 1.28972 acc: 0.70898 | v_loss: 1.22780 v_acc: 0.71419 |  iteration: 6016 teacher: 0 stage: sketch lr: 0.000570\n",
      "batch 1044 loss: 1.30499 acc: 0.70312 | v_loss: 1.41552 v_acc: 0.69173 |  iteration: 6017 teacher: 0 stage: sketch lr: 0.000570\n",
      "batch 1045 loss: 1.23104 acc: 0.72266 | v_loss: 1.30653 v_acc: 0.71387 |  iteration: 6018 teacher: 0 stage: sketch lr: 0.000570\n",
      "batch 1046 loss: 1.33487 acc: 0.70443 | v_loss: 1.18195 v_acc: 0.70866 |  iteration: 6019 teacher: 0 stage: sketch lr: 0.000570\n",
      "batch 1047 loss: 1.32084 acc: 0.70312 | v_loss: 1.27204 v_acc: 0.71354 |  iteration: 6020 teacher: 1 stage: sketch lr: 0.000570\n",
      "batch 1048 loss: 1.35756 acc: 0.70215 | v_loss: 1.18455 v_acc: 0.70703 |  iteration: 6021 teacher: 0 stage: sketch lr: 0.000570\n",
      "batch 1049 loss: 1.27799 acc: 0.70182 | v_loss: 1.26957 v_acc: 0.69987 |  iteration: 6022 teacher: 1 stage: sketch lr: 0.000570\n",
      "batch 1050 loss: 1.32061 acc: 0.69922 | v_loss: 1.23216 v_acc: 0.71322 |  iteration: 6023 teacher: 0 stage: sketch lr: 0.000569\n",
      "batch 1051 loss: 1.32200 acc: 0.69727 | v_loss: 1.16536 v_acc: 0.71875 |  iteration: 6024 teacher: 0 stage: sketch lr: 0.000569\n",
      "batch 1052 loss: 1.42973 acc: 0.69271 | v_loss: 1.13867 v_acc: 0.72298 |  iteration: 6025 teacher: 1 stage: sketch lr: 0.000569\n",
      "batch 1053 loss: 1.28061 acc: 0.70345 | v_loss: 1.26050 v_acc: 0.71940 |  iteration: 6026 teacher: 0 stage: sketch lr: 0.000569\n",
      "batch 1054 loss: 1.19870 acc: 0.70996 | v_loss: 1.25520 v_acc: 0.70345 |  iteration: 6027 teacher: 0 stage: sketch lr: 0.000569\n",
      "batch 1055 loss: 1.32096 acc: 0.70117 | v_loss: 1.26349 v_acc: 0.71257 |  iteration: 6028 teacher: 0 stage: sketch lr: 0.000569\n",
      "batch 1056 loss: 1.37764 acc: 0.69824 | v_loss: 1.11658 v_acc: 0.72233 |  iteration: 6029 teacher: 0 stage: sketch lr: 0.000569\n",
      "batch 1057 loss: 1.34903 acc: 0.70052 | v_loss: 1.25399 v_acc: 0.72754 |  iteration: 6030 teacher: 0 stage: sketch lr: 0.000569\n",
      "batch 1058 loss: 1.32921 acc: 0.70085 | v_loss: 1.31036 v_acc: 0.69596 |  iteration: 6031 teacher: 1 stage: sketch lr: 0.000569\n",
      "batch 1059 loss: 1.34895 acc: 0.69596 | v_loss: 1.30671 v_acc: 0.72201 |  iteration: 6032 teacher: 1 stage: sketch lr: 0.000569\n",
      "batch 1060 loss: 1.42076 acc: 0.68750 | v_loss: 1.16433 v_acc: 0.71875 |  iteration: 6033 teacher: 1 stage: sketch lr: 0.000569\n",
      "batch 1061 loss: 1.26526 acc: 0.71289 | v_loss: 1.11374 v_acc: 0.73600 |  iteration: 6034 teacher: 0 stage: sketch lr: 0.000569\n",
      "batch 1062 loss: 1.30839 acc: 0.69694 | v_loss: 1.11413 v_acc: 0.72591 |  iteration: 6035 teacher: 0 stage: sketch lr: 0.000569\n",
      "batch 1063 loss: 1.25051 acc: 0.71159 | v_loss: 1.19542 v_acc: 0.71387 |  iteration: 6036 teacher: 0 stage: sketch lr: 0.000569\n",
      "batch 1064 loss: 1.26716 acc: 0.70931 | v_loss: 1.24544 v_acc: 0.70247 |  iteration: 6037 teacher: 0 stage: sketch lr: 0.000569\n",
      "batch 1065 loss: 1.28734 acc: 0.69987 | v_loss: 1.19780 v_acc: 0.71452 |  iteration: 6038 teacher: 1 stage: sketch lr: 0.000569\n",
      "batch 1066 loss: 1.29884 acc: 0.70117 | v_loss: 1.35712 v_acc: 0.68848 |  iteration: 6039 teacher: 1 stage: sketch lr: 0.000569\n",
      "batch 1067 loss: 1.31778 acc: 0.69596 | v_loss: 1.49116 v_acc: 0.69108 |  iteration: 6040 teacher: 0 stage: sketch lr: 0.000569\n",
      "batch 1068 loss: 1.24830 acc: 0.70280 | v_loss: 1.36398 v_acc: 0.69336 |  iteration: 6041 teacher: 0 stage: sketch lr: 0.000569\n",
      "batch 1069 loss: 1.25731 acc: 0.70736 | v_loss: 1.18976 v_acc: 0.72526 |  iteration: 6042 teacher: 0 stage: sketch lr: 0.000569\n",
      "batch 1070 loss: 1.30456 acc: 0.69792 | v_loss: 1.16050 v_acc: 0.70833 |  iteration: 6043 teacher: 0 stage: sketch lr: 0.000569\n",
      "batch 1071 loss: 1.40577 acc: 0.69043 | v_loss: 1.15587 v_acc: 0.71810 |  iteration: 6044 teacher: 0 stage: sketch lr: 0.000568\n",
      "batch 1072 loss: 1.27226 acc: 0.69954 | v_loss: 1.23987 v_acc: 0.70443 |  iteration: 6045 teacher: 1 stage: sketch lr: 0.000568\n",
      "batch 1073 loss: 1.29865 acc: 0.70378 | v_loss: 1.24939 v_acc: 0.70703 |  iteration: 6046 teacher: 1 stage: sketch lr: 0.000568\n",
      "batch 1074 loss: 1.36534 acc: 0.68978 | v_loss: 1.22191 v_acc: 0.72819 |  iteration: 6047 teacher: 0 stage: sketch lr: 0.000568\n",
      "batch 1075 loss: 1.28868 acc: 0.70052 | v_loss: 1.24254 v_acc: 0.71615 |  iteration: 6048 teacher: 1 stage: sketch lr: 0.000568\n",
      "batch 1076 loss: 1.44780 acc: 0.69303 | v_loss: 1.24887 v_acc: 0.70182 |  iteration: 6049 teacher: 0 stage: sketch lr: 0.000568\n",
      "batch 1077 loss: 1.31309 acc: 0.70508 | v_loss: 1.17040 v_acc: 0.72396 |  iteration: 6050 teacher: 1 stage: sketch lr: 0.000568\n",
      "batch 1078 loss: 1.35925 acc: 0.70410 | v_loss: 1.14283 v_acc: 0.72233 |  iteration: 6051 teacher: 0 stage: sketch lr: 0.000568\n",
      "batch 1079 loss: 1.29918 acc: 0.70475 | v_loss: 1.45529 v_acc: 0.68783 |  iteration: 6052 teacher: 1 stage: sketch lr: 0.000568\n",
      "batch 1080 loss: 1.23331 acc: 0.70150 | v_loss: 1.21396 v_acc: 0.70801 |  iteration: 6053 teacher: 1 stage: sketch lr: 0.000568\n",
      "batch 1081 loss: 1.32869 acc: 0.70020 | v_loss: 1.23100 v_acc: 0.71582 |  iteration: 6054 teacher: 1 stage: sketch lr: 0.000568\n",
      "batch 1082 loss: 1.31852 acc: 0.70312 | v_loss: 1.22961 v_acc: 0.70898 |  iteration: 6055 teacher: 1 stage: sketch lr: 0.000568\n",
      "batch 1083 loss: 1.28317 acc: 0.70671 | v_loss: 1.29805 v_acc: 0.70671 |  iteration: 6056 teacher: 1 stage: sketch lr: 0.000568\n",
      "batch 1084 loss: 1.33597 acc: 0.70801 | v_loss: 1.13343 v_acc: 0.73210 |  iteration: 6057 teacher: 1 stage: sketch lr: 0.000568\n",
      "batch 1085 loss: 1.31096 acc: 0.69238 | v_loss: 1.38793 v_acc: 0.71647 |  iteration: 6058 teacher: 1 stage: sketch lr: 0.000568\n",
      "batch 1086 loss: 1.28265 acc: 0.70671 | v_loss: 1.19213 v_acc: 0.69987 |  iteration: 6059 teacher: 0 stage: sketch lr: 0.000568\n",
      "batch 1087 loss: 1.32576 acc: 0.70410 | v_loss: 1.21647 v_acc: 0.70182 |  iteration: 6060 teacher: 1 stage: sketch lr: 0.000568\n",
      "batch 1088 loss: 1.52540 acc: 0.68066 | v_loss: 1.25588 v_acc: 0.70345 |  iteration: 6061 teacher: 0 stage: sketch lr: 0.000568\n",
      "batch 1089 loss: 1.33522 acc: 0.70768 | v_loss: 1.27093 v_acc: 0.70182 |  iteration: 6062 teacher: 0 stage: sketch lr: 0.000568\n",
      "batch 1090 loss: 1.31620 acc: 0.69303 | v_loss: 1.33517 v_acc: 0.69922 |  iteration: 6063 teacher: 0 stage: sketch lr: 0.000568\n",
      "batch 1091 loss: 1.27890 acc: 0.70443 | v_loss: 1.36761 v_acc: 0.70280 |  iteration: 6064 teacher: 0 stage: sketch lr: 0.000568\n",
      "batch 1092 loss: 1.26249 acc: 0.70964 | v_loss: 1.29968 v_acc: 0.70378 |  iteration: 6065 teacher: 1 stage: sketch lr: 0.000567\n",
      "batch 1093 loss: 1.30932 acc: 0.70378 | v_loss: 1.20128 v_acc: 0.70964 |  iteration: 6066 teacher: 0 stage: sketch lr: 0.000567\n",
      "batch 1094 loss: 1.38573 acc: 0.69336 | v_loss: 1.32782 v_acc: 0.70671 |  iteration: 6067 teacher: 0 stage: sketch lr: 0.000567\n",
      "batch 1095 loss: 1.31400 acc: 0.69499 | v_loss: 1.23567 v_acc: 0.71257 |  iteration: 6068 teacher: 0 stage: sketch lr: 0.000567\n",
      "batch 1096 loss: 1.27050 acc: 0.70508 | v_loss: 1.14310 v_acc: 0.72656 |  iteration: 6069 teacher: 0 stage: sketch lr: 0.000567\n",
      "batch 1097 loss: 1.27204 acc: 0.70605 | v_loss: 1.14485 v_acc: 0.70736 |  iteration: 6070 teacher: 0 stage: sketch lr: 0.000567\n",
      "batch 1098 loss: 1.21737 acc: 0.71354 | v_loss: 1.25455 v_acc: 0.70801 |  iteration: 6071 teacher: 0 stage: sketch lr: 0.000567\n",
      "batch 1099 loss: 1.29011 acc: 0.70247 | v_loss: 1.33645 v_acc: 0.69206 |  iteration: 6072 teacher: 1 stage: sketch lr: 0.000567\n",
      "batch 1100 loss: 1.33870 acc: 0.70052 | v_loss: 1.15845 v_acc: 0.71387 |  iteration: 6073 teacher: 1 stage: sketch lr: 0.000567\n",
      "batch 1101 loss: 1.27886 acc: 0.70736 | v_loss: 1.18754 v_acc: 0.70801 |  iteration: 6074 teacher: 1 stage: sketch lr: 0.000567\n",
      "batch 1102 loss: 1.31074 acc: 0.70085 | v_loss: 1.19069 v_acc: 0.71354 |  iteration: 6075 teacher: 1 stage: sketch lr: 0.000567\n",
      "batch 1103 loss: 1.21266 acc: 0.71745 | v_loss: 1.22032 v_acc: 0.70540 |  iteration: 6076 teacher: 1 stage: sketch lr: 0.000567\n",
      "batch 1104 loss: 1.38480 acc: 0.70345 | v_loss: 1.06071 v_acc: 0.73470 |  iteration: 6077 teacher: 1 stage: sketch lr: 0.000567\n",
      "batch 1105 loss: 1.19729 acc: 0.71322 | v_loss: 1.18119 v_acc: 0.71875 |  iteration: 6078 teacher: 0 stage: sketch lr: 0.000567\n",
      "batch 1106 loss: 1.29898 acc: 0.70768 | v_loss: 1.14241 v_acc: 0.70736 |  iteration: 6079 teacher: 0 stage: sketch lr: 0.000567\n",
      "batch 1107 loss: 1.33773 acc: 0.70182 | v_loss: 1.12100 v_acc: 0.72786 |  iteration: 6080 teacher: 1 stage: sketch lr: 0.000567\n",
      "batch 1108 loss: 1.29103 acc: 0.70247 | v_loss: 1.20632 v_acc: 0.72070 |  iteration: 6081 teacher: 0 stage: sketch lr: 0.000567\n",
      "batch 1109 loss: 1.27425 acc: 0.70410 | v_loss: 1.22509 v_acc: 0.71615 |  iteration: 6082 teacher: 1 stage: sketch lr: 0.000567\n",
      "batch 1110 loss: 1.32135 acc: 0.69987 | v_loss: 1.21488 v_acc: 0.72526 |  iteration: 6083 teacher: 0 stage: sketch lr: 0.000567\n",
      "batch 1111 loss: 1.36109 acc: 0.69499 | v_loss: 1.38823 v_acc: 0.69922 |  iteration: 6084 teacher: 0 stage: sketch lr: 0.000567\n",
      "batch 1112 loss: 1.26315 acc: 0.69889 | v_loss: 1.27126 v_acc: 0.72168 |  iteration: 6085 teacher: 1 stage: sketch lr: 0.000567\n",
      "batch 1113 loss: 1.38758 acc: 0.69336 | v_loss: 1.06623 v_acc: 0.74740 |  iteration: 6086 teacher: 0 stage: sketch lr: 0.000566\n",
      "batch 1114 loss: 1.37096 acc: 0.69108 | v_loss: 1.20227 v_acc: 0.70833 |  iteration: 6087 teacher: 1 stage: sketch lr: 0.000566\n",
      "batch 1115 loss: 1.44723 acc: 0.68197 | v_loss: 1.29695 v_acc: 0.69661 |  iteration: 6088 teacher: 0 stage: sketch lr: 0.000566\n",
      "batch 1116 loss: 1.33605 acc: 0.70117 | v_loss: 1.21284 v_acc: 0.69661 |  iteration: 6089 teacher: 1 stage: sketch lr: 0.000566\n",
      "batch 1117 loss: 1.29442 acc: 0.70345 | v_loss: 1.26369 v_acc: 0.70150 |  iteration: 6090 teacher: 1 stage: sketch lr: 0.000566\n",
      "batch 1118 loss: 1.27100 acc: 0.70312 | v_loss: 1.26043 v_acc: 0.69271 |  iteration: 6091 teacher: 0 stage: sketch lr: 0.000566\n",
      "batch 1119 loss: 1.30582 acc: 0.69922 | v_loss: 1.23385 v_acc: 0.71842 |  iteration: 6092 teacher: 0 stage: sketch lr: 0.000566\n",
      "batch 1120 loss: 1.27770 acc: 0.70638 | v_loss: 1.27022 v_acc: 0.70052 |  iteration: 6093 teacher: 1 stage: sketch lr: 0.000566\n",
      "batch 1121 loss: 1.36111 acc: 0.70671 | v_loss: 1.18155 v_acc: 0.71582 |  iteration: 6094 teacher: 0 stage: sketch lr: 0.000566\n",
      "batch 1122 loss: 1.35182 acc: 0.68945 | v_loss: 1.18328 v_acc: 0.72786 |  iteration: 6095 teacher: 1 stage: sketch lr: 0.000566\n",
      "batch 1123 loss: 1.27657 acc: 0.70866 | v_loss: 1.24474 v_acc: 0.70410 |  iteration: 6096 teacher: 0 stage: sketch lr: 0.000566\n",
      "batch 1124 loss: 1.31682 acc: 0.70378 | v_loss: 1.35597 v_acc: 0.69954 |  iteration: 6097 teacher: 1 stage: sketch lr: 0.000566\n",
      "batch 1125 loss: 1.23269 acc: 0.71224 | v_loss: 1.16772 v_acc: 0.70768 |  iteration: 6098 teacher: 0 stage: sketch lr: 0.000566\n",
      "batch 1126 loss: 1.34954 acc: 0.70378 | v_loss: 1.42618 v_acc: 0.68392 |  iteration: 6099 teacher: 1 stage: sketch lr: 0.000566\n",
      "batch 1127 loss: 1.21440 acc: 0.71322 | v_loss: 1.17794 v_acc: 0.72819 |  iteration: 6100 teacher: 0 stage: sketch lr: 0.000566\n",
      "batch 1128 loss: 1.33259 acc: 0.70540 | v_loss: 1.48451 v_acc: 0.68457 |  iteration: 6101 teacher: 1 stage: sketch lr: 0.000566\n",
      "batch 1129 loss: 1.41433 acc: 0.68815 | v_loss: 1.36581 v_acc: 0.69727 |  iteration: 6102 teacher: 1 stage: sketch lr: 0.000566\n",
      "batch 1130 loss: 1.30016 acc: 0.71289 | v_loss: 1.33689 v_acc: 0.68913 |  iteration: 6103 teacher: 0 stage: sketch lr: 0.000566\n",
      "batch 1131 loss: 1.31585 acc: 0.70964 | v_loss: 1.32041 v_acc: 0.69759 |  iteration: 6104 teacher: 1 stage: sketch lr: 0.000566\n",
      "batch 1132 loss: 1.29201 acc: 0.71224 | v_loss: 1.25481 v_acc: 0.70052 |  iteration: 6105 teacher: 0 stage: sketch lr: 0.000566\n",
      "batch 1133 loss: 1.34447 acc: 0.69889 | v_loss: 1.27893 v_acc: 0.69954 |  iteration: 6106 teacher: 1 stage: sketch lr: 0.000566\n",
      "batch 1134 loss: 1.29764 acc: 0.71191 | v_loss: 1.22758 v_acc: 0.71875 |  iteration: 6107 teacher: 0 stage: sketch lr: 0.000566\n",
      "batch 1135 loss: 1.23039 acc: 0.71875 | v_loss: 1.42347 v_acc: 0.69076 |  iteration: 6108 teacher: 1 stage: sketch lr: 0.000565\n",
      "batch 1136 loss: 1.24495 acc: 0.70996 | v_loss: 1.30654 v_acc: 0.71517 |  iteration: 6109 teacher: 0 stage: sketch lr: 0.000565\n",
      "batch 1137 loss: 1.34328 acc: 0.70345 | v_loss: 1.18154 v_acc: 0.70443 |  iteration: 6110 teacher: 1 stage: sketch lr: 0.000565\n",
      "batch 1138 loss: 1.40955 acc: 0.70117 | v_loss: 1.28140 v_acc: 0.70866 |  iteration: 6111 teacher: 1 stage: sketch lr: 0.000565\n",
      "batch 1139 loss: 1.27862 acc: 0.71029 | v_loss: 1.17745 v_acc: 0.71159 |  iteration: 6112 teacher: 1 stage: sketch lr: 0.000565\n",
      "batch 1140 loss: 1.31805 acc: 0.70378 | v_loss: 1.26989 v_acc: 0.69954 |  iteration: 6113 teacher: 1 stage: sketch lr: 0.000565\n",
      "batch 1141 loss: 1.27803 acc: 0.70736 | v_loss: 1.23438 v_acc: 0.71322 |  iteration: 6114 teacher: 1 stage: sketch lr: 0.000565\n",
      "batch 1142 loss: 1.27824 acc: 0.71387 | v_loss: 1.17092 v_acc: 0.71615 |  iteration: 6115 teacher: 0 stage: sketch lr: 0.000565\n",
      "batch 1143 loss: 1.25060 acc: 0.71126 | v_loss: 1.14172 v_acc: 0.72266 |  iteration: 6116 teacher: 0 stage: sketch lr: 0.000565\n",
      "batch 1144 loss: 1.31391 acc: 0.69857 | v_loss: 1.25561 v_acc: 0.71452 |  iteration: 6117 teacher: 0 stage: sketch lr: 0.000565\n",
      "batch 1145 loss: 1.31537 acc: 0.70410 | v_loss: 1.25417 v_acc: 0.70280 |  iteration: 6118 teacher: 1 stage: sketch lr: 0.000565\n",
      "batch 1146 loss: 1.36799 acc: 0.70215 | v_loss: 1.26565 v_acc: 0.71257 |  iteration: 6119 teacher: 0 stage: sketch lr: 0.000565\n",
      "batch 1147 loss: 1.26461 acc: 0.70996 | v_loss: 1.11639 v_acc: 0.72493 |  iteration: 6120 teacher: 0 stage: sketch lr: 0.000565\n",
      "batch 1148 loss: 1.29773 acc: 0.71224 | v_loss: 1.23399 v_acc: 0.73145 |  iteration: 6121 teacher: 0 stage: sketch lr: 0.000565\n",
      "batch 1149 loss: 1.32301 acc: 0.69857 | v_loss: 1.30075 v_acc: 0.69759 |  iteration: 6122 teacher: 0 stage: sketch lr: 0.000565\n",
      "batch 1150 loss: 1.24040 acc: 0.70996 | v_loss: 1.29763 v_acc: 0.71842 |  iteration: 6123 teacher: 1 stage: sketch lr: 0.000565\n",
      "batch 1151 loss: 1.38986 acc: 0.69596 | v_loss: 1.17830 v_acc: 0.71615 |  iteration: 6124 teacher: 0 stage: sketch lr: 0.000565\n",
      "batch 1152 loss: 1.27430 acc: 0.70736 | v_loss: 1.13047 v_acc: 0.72819 |  iteration: 6125 teacher: 1 stage: sketch lr: 0.000565\n",
      "batch 1153 loss: 1.31233 acc: 0.70931 | v_loss: 1.12018 v_acc: 0.72559 |  iteration: 6126 teacher: 1 stage: sketch lr: 0.000565\n",
      "batch 1154 loss: 1.27428 acc: 0.70345 | v_loss: 1.20677 v_acc: 0.70540 |  iteration: 6127 teacher: 0 stage: sketch lr: 0.000565\n",
      "batch 1155 loss: 1.25844 acc: 0.71061 | v_loss: 1.25345 v_acc: 0.69596 |  iteration: 6128 teacher: 0 stage: sketch lr: 0.000565\n",
      "batch 1156 loss: 1.35319 acc: 0.70345 | v_loss: 1.19724 v_acc: 0.71484 |  iteration: 6129 teacher: 0 stage: sketch lr: 0.000565\n",
      "batch 1157 loss: 1.28313 acc: 0.70150 | v_loss: 1.32692 v_acc: 0.71777 |  iteration: 6130 teacher: 0 stage: sketch lr: 0.000564\n",
      "batch 1158 loss: 1.26990 acc: 0.70345 | v_loss: 1.50894 v_acc: 0.69108 |  iteration: 6131 teacher: 1 stage: sketch lr: 0.000564\n",
      "batch 1159 loss: 1.28953 acc: 0.69889 | v_loss: 1.37634 v_acc: 0.69238 |  iteration: 6132 teacher: 1 stage: sketch lr: 0.000564\n",
      "batch 1160 loss: 1.34501 acc: 0.68783 | v_loss: 1.19785 v_acc: 0.72331 |  iteration: 6133 teacher: 1 stage: sketch lr: 0.000564\n",
      "batch 1161 loss: 1.38908 acc: 0.69987 | v_loss: 1.16899 v_acc: 0.70964 |  iteration: 6134 teacher: 0 stage: sketch lr: 0.000564\n",
      "batch 1162 loss: 1.25346 acc: 0.71517 | v_loss: 1.16395 v_acc: 0.72103 |  iteration: 6135 teacher: 0 stage: sketch lr: 0.000564\n",
      "batch 1163 loss: 1.33415 acc: 0.70150 | v_loss: 1.22305 v_acc: 0.70443 |  iteration: 6136 teacher: 1 stage: sketch lr: 0.000564\n",
      "batch 1164 loss: 1.34788 acc: 0.70312 | v_loss: 1.26304 v_acc: 0.71908 |  iteration: 6137 teacher: 1 stage: sketch lr: 0.000564\n",
      "batch 1165 loss: 1.33964 acc: 0.70378 | v_loss: 1.22181 v_acc: 0.72624 |  iteration: 6138 teacher: 1 stage: sketch lr: 0.000564\n",
      "batch 1166 loss: 1.24754 acc: 0.70150 | v_loss: 1.24702 v_acc: 0.72005 |  iteration: 6139 teacher: 1 stage: sketch lr: 0.000564\n",
      "batch 1167 loss: 1.23367 acc: 0.71387 | v_loss: 1.25062 v_acc: 0.71419 |  iteration: 6140 teacher: 0 stage: sketch lr: 0.000564\n",
      "batch 1168 loss: 1.34480 acc: 0.70996 | v_loss: 1.16160 v_acc: 0.72201 |  iteration: 6141 teacher: 1 stage: sketch lr: 0.000564\n",
      "batch 1169 loss: 1.27459 acc: 0.70020 | v_loss: 1.13481 v_acc: 0.72266 |  iteration: 6142 teacher: 0 stage: sketch lr: 0.000564\n",
      "batch 1170 loss: 1.33736 acc: 0.69987 | v_loss: 1.47093 v_acc: 0.69141 |  iteration: 6143 teacher: 0 stage: sketch lr: 0.000564\n",
      "batch 1171 loss: 1.33512 acc: 0.70280 | v_loss: 1.21744 v_acc: 0.70833 |  iteration: 6144 teacher: 0 stage: sketch lr: 0.000564\n",
      "batch 1172 loss: 1.34853 acc: 0.69857 | v_loss: 1.23761 v_acc: 0.71680 |  iteration: 6145 teacher: 0 stage: sketch lr: 0.000564\n",
      "batch 1173 loss: 1.23430 acc: 0.70866 | v_loss: 1.21110 v_acc: 0.72038 |  iteration: 6146 teacher: 0 stage: sketch lr: 0.000564\n",
      "batch 1174 loss: 1.36187 acc: 0.70443 | v_loss: 1.29787 v_acc: 0.70312 |  iteration: 6147 teacher: 0 stage: sketch lr: 0.000564\n",
      "batch 1175 loss: 1.28337 acc: 0.70280 | v_loss: 1.13974 v_acc: 0.73079 |  iteration: 6148 teacher: 1 stage: sketch lr: 0.000564\n",
      "batch 1176 loss: 1.24738 acc: 0.70736 | v_loss: 1.38599 v_acc: 0.71615 |  iteration: 6149 teacher: 1 stage: sketch lr: 0.000564\n",
      "batch 1177 loss: 1.28513 acc: 0.70052 | v_loss: 1.18978 v_acc: 0.70150 |  iteration: 6150 teacher: 0 stage: sketch lr: 0.000564\n",
      "batch 1178 loss: 1.30399 acc: 0.69857 | v_loss: 1.20913 v_acc: 0.70345 |  iteration: 6151 teacher: 1 stage: sketch lr: 0.000563\n",
      "batch 1179 loss: 1.28344 acc: 0.70573 | v_loss: 1.25887 v_acc: 0.70475 |  iteration: 6152 teacher: 0 stage: sketch lr: 0.000563\n",
      "batch 1180 loss: 1.36096 acc: 0.69238 | v_loss: 1.26769 v_acc: 0.70085 |  iteration: 6153 teacher: 0 stage: sketch lr: 0.000563\n",
      "batch 1181 loss: 1.28494 acc: 0.70378 | v_loss: 1.32743 v_acc: 0.69564 |  iteration: 6154 teacher: 1 stage: sketch lr: 0.000563\n",
      "batch 1182 loss: 1.39183 acc: 0.69401 | v_loss: 1.37488 v_acc: 0.70378 |  iteration: 6155 teacher: 0 stage: sketch lr: 0.000563\n",
      "batch 1183 loss: 1.29470 acc: 0.69954 | v_loss: 1.29365 v_acc: 0.70573 |  iteration: 6156 teacher: 1 stage: sketch lr: 0.000563\n",
      "batch 1184 loss: 1.37055 acc: 0.69824 | v_loss: 1.21113 v_acc: 0.71387 |  iteration: 6157 teacher: 1 stage: sketch lr: 0.000563\n",
      "batch 1185 loss: 1.34300 acc: 0.69759 | v_loss: 1.31842 v_acc: 0.70996 |  iteration: 6158 teacher: 0 stage: sketch lr: 0.000563\n",
      "batch 1186 loss: 1.28832 acc: 0.70801 | v_loss: 1.21333 v_acc: 0.71549 |  iteration: 6159 teacher: 1 stage: sketch lr: 0.000563\n",
      "batch 1187 loss: 1.22189 acc: 0.69922 | v_loss: 1.18052 v_acc: 0.71712 |  iteration: 6160 teacher: 1 stage: sketch lr: 0.000563\n",
      "batch 1188 loss: 1.26489 acc: 0.70768 | v_loss: 1.12168 v_acc: 0.70573 |  iteration: 6161 teacher: 0 stage: sketch lr: 0.000563\n",
      "batch 1189 loss: 1.25657 acc: 0.71419 | v_loss: 1.25124 v_acc: 0.70378 |  iteration: 6162 teacher: 1 stage: sketch lr: 0.000563\n",
      "batch 1190 loss: 1.35969 acc: 0.69987 | v_loss: 1.33994 v_acc: 0.69629 |  iteration: 6163 teacher: 1 stage: sketch lr: 0.000563\n",
      "batch 1191 loss: 1.33024 acc: 0.70508 | v_loss: 1.16358 v_acc: 0.71484 |  iteration: 6164 teacher: 1 stage: sketch lr: 0.000563\n",
      "batch 1192 loss: 1.26688 acc: 0.70150 | v_loss: 1.20502 v_acc: 0.70801 |  iteration: 6165 teacher: 0 stage: sketch lr: 0.000563\n",
      "batch 1193 loss: 1.32656 acc: 0.70540 | v_loss: 1.18737 v_acc: 0.71973 |  iteration: 6166 teacher: 0 stage: sketch lr: 0.000563\n",
      "batch 1194 loss: 1.31385 acc: 0.70345 | v_loss: 1.21972 v_acc: 0.70833 |  iteration: 6167 teacher: 0 stage: sketch lr: 0.000563\n",
      "batch 1195 loss: 1.26657 acc: 0.70866 | v_loss: 1.06184 v_acc: 0.73372 |  iteration: 6168 teacher: 1 stage: sketch lr: 0.000563\n",
      "batch 1196 loss: 1.18405 acc: 0.71810 | v_loss: 1.17751 v_acc: 0.72135 |  iteration: 6169 teacher: 0 stage: sketch lr: 0.000563\n",
      "batch 1197 loss: 1.29827 acc: 0.69857 | v_loss: 1.13927 v_acc: 0.70638 |  iteration: 6170 teacher: 0 stage: sketch lr: 0.000563\n",
      "batch 1198 loss: 1.30521 acc: 0.70736 | v_loss: 1.12676 v_acc: 0.72233 |  iteration: 6171 teacher: 1 stage: sketch lr: 0.000563\n",
      "batch 1199 loss: 1.25779 acc: 0.71582 | v_loss: 1.20627 v_acc: 0.71582 |  iteration: 6172 teacher: 0 stage: sketch lr: 0.000563\n",
      "batch 1200 loss: 1.39077 acc: 0.69336 | v_loss: 1.22851 v_acc: 0.72168 |  iteration: 6173 teacher: 0 stage: sketch lr: 0.000562\n",
      "batch 1201 loss: 1.19927 acc: 0.72038 | v_loss: 1.21087 v_acc: 0.72721 |  iteration: 6174 teacher: 1 stage: sketch lr: 0.000562\n",
      "batch 1202 loss: 1.29069 acc: 0.70768 | v_loss: 1.38327 v_acc: 0.69466 |  iteration: 6175 teacher: 1 stage: sketch lr: 0.000562\n",
      "batch 1203 loss: 1.31669 acc: 0.69889 | v_loss: 1.27017 v_acc: 0.72363 |  iteration: 6176 teacher: 1 stage: sketch lr: 0.000562\n",
      "batch 1204 loss: 1.31145 acc: 0.70573 | v_loss: 1.06099 v_acc: 0.74544 |  iteration: 6177 teacher: 0 stage: sketch lr: 0.000562\n",
      "batch 1205 loss: 1.37119 acc: 0.69661 | v_loss: 1.22862 v_acc: 0.70443 |  iteration: 6178 teacher: 0 stage: sketch lr: 0.000562\n",
      "batch 1206 loss: 1.31662 acc: 0.70833 | v_loss: 1.27351 v_acc: 0.70182 |  iteration: 6179 teacher: 1 stage: sketch lr: 0.000562\n",
      "batch 1207 loss: 1.33795 acc: 0.69629 | v_loss: 1.20629 v_acc: 0.70768 |  iteration: 6180 teacher: 0 stage: sketch lr: 0.000562\n",
      "batch 1208 loss: 1.32616 acc: 0.69238 | v_loss: 1.25374 v_acc: 0.71126 |  iteration: 6181 teacher: 0 stage: sketch lr: 0.000562\n",
      "batch 1209 loss: 1.32740 acc: 0.70117 | v_loss: 1.24630 v_acc: 0.69303 |  iteration: 6182 teacher: 0 stage: sketch lr: 0.000562\n",
      "batch 1210 loss: 1.28740 acc: 0.70247 | v_loss: 1.22543 v_acc: 0.71810 |  iteration: 6183 teacher: 0 stage: sketch lr: 0.000562\n",
      "batch 1211 loss: 1.33338 acc: 0.69108 | v_loss: 1.26146 v_acc: 0.69922 |  iteration: 6184 teacher: 0 stage: sketch lr: 0.000562\n",
      "batch 1212 loss: 1.19828 acc: 0.72070 | v_loss: 1.17305 v_acc: 0.72852 |  iteration: 6185 teacher: 0 stage: sketch lr: 0.000562\n",
      "batch 1213 loss: 1.38663 acc: 0.68587 | v_loss: 1.17800 v_acc: 0.72656 |  iteration: 6186 teacher: 1 stage: sketch lr: 0.000562\n",
      "batch 1214 loss: 1.25101 acc: 0.71582 | v_loss: 1.24253 v_acc: 0.69954 |  iteration: 6187 teacher: 0 stage: sketch lr: 0.000562\n",
      "batch 1215 loss: 1.30221 acc: 0.69336 | v_loss: 1.34340 v_acc: 0.69076 |  iteration: 6188 teacher: 1 stage: sketch lr: 0.000562\n",
      "batch 1216 loss: 1.20628 acc: 0.72038 | v_loss: 1.16732 v_acc: 0.70768 |  iteration: 6189 teacher: 0 stage: sketch lr: 0.000562\n",
      "batch 1217 loss: 1.31624 acc: 0.70215 | v_loss: 1.43170 v_acc: 0.68132 |  iteration: 6190 teacher: 1 stage: sketch lr: 0.000562\n",
      "batch 1218 loss: 1.27847 acc: 0.70573 | v_loss: 1.17523 v_acc: 0.71517 |  iteration: 6191 teacher: 0 stage: sketch lr: 0.000562\n",
      "batch 1219 loss: 1.26158 acc: 0.71973 | v_loss: 1.49916 v_acc: 0.68197 |  iteration: 6192 teacher: 0 stage: sketch lr: 0.000562\n",
      "batch 1220 loss: 1.26511 acc: 0.71029 | v_loss: 1.38099 v_acc: 0.69792 |  iteration: 6193 teacher: 1 stage: sketch lr: 0.000562\n",
      "batch 1221 loss: 1.29809 acc: 0.70312 | v_loss: 1.33882 v_acc: 0.69043 |  iteration: 6194 teacher: 0 stage: sketch lr: 0.000562\n",
      "batch 1222 loss: 1.23499 acc: 0.71322 | v_loss: 1.32152 v_acc: 0.69954 |  iteration: 6195 teacher: 1 stage: sketch lr: 0.000561\n",
      "batch 1223 loss: 1.21345 acc: 0.70898 | v_loss: 1.23869 v_acc: 0.70508 |  iteration: 6196 teacher: 0 stage: sketch lr: 0.000561\n",
      "batch 1224 loss: 1.24475 acc: 0.71582 | v_loss: 1.26957 v_acc: 0.70280 |  iteration: 6197 teacher: 0 stage: sketch lr: 0.000561\n",
      "batch 1225 loss: 1.33180 acc: 0.69889 | v_loss: 1.21932 v_acc: 0.71777 |  iteration: 6198 teacher: 1 stage: sketch lr: 0.000561\n",
      "batch 1226 loss: 1.38905 acc: 0.69303 | v_loss: 1.41268 v_acc: 0.69173 |  iteration: 6199 teacher: 0 stage: sketch lr: 0.000561\n",
      "batch 1227 loss: 1.26897 acc: 0.70378 | v_loss: 1.30163 v_acc: 0.70247 |  iteration: 6200 teacher: 1 stage: sketch lr: 0.000561\n",
      "batch 1228 loss: 1.18936 acc: 0.71875 | v_loss: 1.19501 v_acc: 0.71126 |  iteration: 6201 teacher: 1 stage: sketch lr: 0.000561\n",
      "batch 1229 loss: 1.24973 acc: 0.70898 | v_loss: 1.26353 v_acc: 0.71712 |  iteration: 6202 teacher: 1 stage: sketch lr: 0.000561\n",
      "batch 1230 loss: 1.33934 acc: 0.69368 | v_loss: 1.17449 v_acc: 0.70540 |  iteration: 6203 teacher: 1 stage: sketch lr: 0.000561\n",
      "batch 1231 loss: 1.24617 acc: 0.70703 | v_loss: 1.26538 v_acc: 0.69727 |  iteration: 6204 teacher: 1 stage: sketch lr: 0.000561\n",
      "batch 1232 loss: 1.37941 acc: 0.69759 | v_loss: 1.22661 v_acc: 0.71517 |  iteration: 6205 teacher: 0 stage: sketch lr: 0.000561\n",
      "batch 1233 loss: 1.26684 acc: 0.70768 | v_loss: 1.17863 v_acc: 0.71419 |  iteration: 6206 teacher: 0 stage: sketch lr: 0.000561\n",
      "batch 1234 loss: 1.24880 acc: 0.70736 | v_loss: 1.14151 v_acc: 0.72656 |  iteration: 6207 teacher: 0 stage: sketch lr: 0.000561\n",
      "batch 1235 loss: 1.19326 acc: 0.71191 | v_loss: 1.26843 v_acc: 0.71647 |  iteration: 6208 teacher: 0 stage: sketch lr: 0.000561\n",
      "batch 1236 loss: 1.25881 acc: 0.71257 | v_loss: 1.24946 v_acc: 0.70280 |  iteration: 6209 teacher: 0 stage: sketch lr: 0.000561\n",
      "batch 1237 loss: 1.25611 acc: 0.71322 | v_loss: 1.26163 v_acc: 0.71257 |  iteration: 6210 teacher: 1 stage: sketch lr: 0.000561\n",
      "batch 1238 loss: 1.30680 acc: 0.70540 | v_loss: 1.11499 v_acc: 0.72526 |  iteration: 6211 teacher: 1 stage: sketch lr: 0.000561\n",
      "batch 1239 loss: 1.20688 acc: 0.70508 | v_loss: 1.24077 v_acc: 0.73112 |  iteration: 6212 teacher: 1 stage: sketch lr: 0.000561\n",
      "batch 1240 loss: 1.31768 acc: 0.70605 | v_loss: 1.31360 v_acc: 0.69271 |  iteration: 6213 teacher: 0 stage: sketch lr: 0.000561\n",
      "batch 1241 loss: 1.33978 acc: 0.69596 | v_loss: 1.32203 v_acc: 0.71940 |  iteration: 6214 teacher: 0 stage: sketch lr: 0.000561\n",
      "batch 1242 loss: 1.29301 acc: 0.70605 | v_loss: 1.15463 v_acc: 0.71908 |  iteration: 6215 teacher: 0 stage: sketch lr: 0.000561\n",
      "epoch 4 loss: 1.23169 acc: 0.71169 | v_loss: 1.17551 v_acc: 0.71844 \n",
      "epoch: 5\n",
      "__________________________________________\n",
      "batch 0 loss: 1.20481 acc: 0.71810 | v_loss: 1.29402 v_acc: 0.69792 |  iteration: 6216 teacher: 1 stage: sketch lr: 0.000561\n",
      "batch 1 loss: 1.19401 acc: 0.71126 | v_loss: 1.19803 v_acc: 0.71159 |  iteration: 6217 teacher: 1 stage: sketch lr: 0.000560\n",
      "batch 2 loss: 1.31890 acc: 0.70117 | v_loss: 1.32251 v_acc: 0.70508 |  iteration: 6218 teacher: 0 stage: sketch lr: 0.000560\n",
      "batch 3 loss: 1.21915 acc: 0.71387 | v_loss: 1.21852 v_acc: 0.71875 |  iteration: 6219 teacher: 0 stage: sketch lr: 0.000560\n",
      "batch 4 loss: 1.29030 acc: 0.71322 | v_loss: 1.14470 v_acc: 0.72591 |  iteration: 6220 teacher: 0 stage: sketch lr: 0.000560\n",
      "batch 5 loss: 1.34830 acc: 0.69434 | v_loss: 1.13829 v_acc: 0.70801 |  iteration: 6221 teacher: 1 stage: sketch lr: 0.000560\n",
      "batch 6 loss: 1.33178 acc: 0.70345 | v_loss: 1.25755 v_acc: 0.70736 |  iteration: 6222 teacher: 1 stage: sketch lr: 0.000560\n",
      "batch 7 loss: 1.24165 acc: 0.70768 | v_loss: 1.33390 v_acc: 0.69824 |  iteration: 6223 teacher: 1 stage: sketch lr: 0.000560\n",
      "batch 8 loss: 1.28475 acc: 0.70345 | v_loss: 1.15329 v_acc: 0.71452 |  iteration: 6224 teacher: 0 stage: sketch lr: 0.000560\n",
      "batch 9 loss: 1.22642 acc: 0.70801 | v_loss: 1.21697 v_acc: 0.70215 |  iteration: 6225 teacher: 1 stage: sketch lr: 0.000560\n",
      "batch 10 loss: 1.29601 acc: 0.69987 | v_loss: 1.20178 v_acc: 0.71126 |  iteration: 6226 teacher: 0 stage: sketch lr: 0.000560\n",
      "batch 11 loss: 1.29392 acc: 0.70247 | v_loss: 1.22417 v_acc: 0.70768 |  iteration: 6227 teacher: 0 stage: sketch lr: 0.000560\n",
      "batch 12 loss: 1.38681 acc: 0.69434 | v_loss: 1.07314 v_acc: 0.73470 |  iteration: 6228 teacher: 1 stage: sketch lr: 0.000560\n",
      "batch 13 loss: 1.25248 acc: 0.70345 | v_loss: 1.18323 v_acc: 0.71615 |  iteration: 6229 teacher: 1 stage: sketch lr: 0.000560\n",
      "batch 14 loss: 1.28050 acc: 0.70020 | v_loss: 1.13443 v_acc: 0.72949 |  iteration: 6230 teacher: 1 stage: sketch lr: 0.000560\n",
      "batch 15 loss: 1.33694 acc: 0.69824 | v_loss: 1.12268 v_acc: 0.72396 |  iteration: 6231 teacher: 0 stage: sketch lr: 0.000560\n",
      "batch 16 loss: 1.31143 acc: 0.69857 | v_loss: 1.20835 v_acc: 0.72070 |  iteration: 6232 teacher: 1 stage: sketch lr: 0.000560\n",
      "batch 17 loss: 1.28072 acc: 0.70378 | v_loss: 1.24103 v_acc: 0.71615 |  iteration: 6233 teacher: 1 stage: sketch lr: 0.000560\n",
      "batch 18 loss: 1.34265 acc: 0.70085 | v_loss: 1.23455 v_acc: 0.72135 |  iteration: 6234 teacher: 0 stage: sketch lr: 0.000560\n",
      "batch 19 loss: 1.28593 acc: 0.70247 | v_loss: 1.39416 v_acc: 0.69694 |  iteration: 6235 teacher: 1 stage: sketch lr: 0.000560\n",
      "batch 20 loss: 1.28361 acc: 0.69629 | v_loss: 1.27844 v_acc: 0.71582 |  iteration: 6236 teacher: 1 stage: sketch lr: 0.000560\n",
      "batch 21 loss: 1.30855 acc: 0.69889 | v_loss: 1.05361 v_acc: 0.74284 |  iteration: 6237 teacher: 0 stage: sketch lr: 0.000560\n",
      "batch 22 loss: 1.33596 acc: 0.70605 | v_loss: 1.21926 v_acc: 0.70833 |  iteration: 6238 teacher: 1 stage: sketch lr: 0.000560\n",
      "batch 23 loss: 1.33893 acc: 0.70671 | v_loss: 1.27990 v_acc: 0.69922 |  iteration: 6239 teacher: 1 stage: sketch lr: 0.000560\n",
      "batch 24 loss: 1.33403 acc: 0.70540 | v_loss: 1.20688 v_acc: 0.70573 |  iteration: 6240 teacher: 1 stage: sketch lr: 0.000559\n",
      "batch 25 loss: 1.26118 acc: 0.71029 | v_loss: 1.26128 v_acc: 0.71126 |  iteration: 6241 teacher: 1 stage: sketch lr: 0.000559\n",
      "batch 26 loss: 1.27438 acc: 0.70996 | v_loss: 1.26290 v_acc: 0.69303 |  iteration: 6242 teacher: 0 stage: sketch lr: 0.000559\n",
      "batch 27 loss: 1.32283 acc: 0.70247 | v_loss: 1.22264 v_acc: 0.71810 |  iteration: 6243 teacher: 0 stage: sketch lr: 0.000559\n",
      "batch 28 loss: 1.41234 acc: 0.69368 | v_loss: 1.26183 v_acc: 0.69922 |  iteration: 6244 teacher: 1 stage: sketch lr: 0.000559\n",
      "batch 29 loss: 1.28703 acc: 0.70768 | v_loss: 1.18342 v_acc: 0.72852 |  iteration: 6245 teacher: 1 stage: sketch lr: 0.000559\n",
      "batch 30 loss: 1.28099 acc: 0.70475 | v_loss: 1.18270 v_acc: 0.72493 |  iteration: 6246 teacher: 0 stage: sketch lr: 0.000559\n",
      "batch 31 loss: 1.21584 acc: 0.70768 | v_loss: 1.24745 v_acc: 0.70280 |  iteration: 6247 teacher: 0 stage: sketch lr: 0.000559\n",
      "batch 32 loss: 1.36464 acc: 0.69629 | v_loss: 1.39413 v_acc: 0.69303 |  iteration: 6248 teacher: 0 stage: sketch lr: 0.000559\n",
      "batch 33 loss: 1.40361 acc: 0.69466 | v_loss: 1.17807 v_acc: 0.71029 |  iteration: 6249 teacher: 0 stage: sketch lr: 0.000559\n",
      "batch 34 loss: 1.35455 acc: 0.69466 | v_loss: 1.44331 v_acc: 0.68066 |  iteration: 6250 teacher: 0 stage: sketch lr: 0.000559\n",
      "batch 35 loss: 1.26612 acc: 0.70638 | v_loss: 1.16409 v_acc: 0.72559 |  iteration: 6251 teacher: 1 stage: sketch lr: 0.000559\n",
      "batch 36 loss: 1.43354 acc: 0.68392 | v_loss: 1.50999 v_acc: 0.67611 |  iteration: 6252 teacher: 0 stage: sketch lr: 0.000559\n",
      "batch 37 loss: 1.36660 acc: 0.69303 | v_loss: 1.37986 v_acc: 0.69336 |  iteration: 6253 teacher: 1 stage: sketch lr: 0.000559\n",
      "batch 38 loss: 1.33819 acc: 0.69531 | v_loss: 1.32748 v_acc: 0.68913 |  iteration: 6254 teacher: 1 stage: sketch lr: 0.000559\n",
      "batch 39 loss: 1.35661 acc: 0.69010 | v_loss: 1.32064 v_acc: 0.69759 |  iteration: 6255 teacher: 0 stage: sketch lr: 0.000559\n",
      "batch 40 loss: 1.27116 acc: 0.71354 | v_loss: 1.23446 v_acc: 0.70215 |  iteration: 6256 teacher: 0 stage: sketch lr: 0.000559\n",
      "batch 41 loss: 1.32337 acc: 0.70443 | v_loss: 1.27619 v_acc: 0.69889 |  iteration: 6257 teacher: 0 stage: sketch lr: 0.000559\n",
      "batch 42 loss: 1.36860 acc: 0.69336 | v_loss: 1.21840 v_acc: 0.71419 |  iteration: 6258 teacher: 0 stage: sketch lr: 0.000559\n",
      "batch 43 loss: 1.32044 acc: 0.70182 | v_loss: 1.41553 v_acc: 0.69173 |  iteration: 6259 teacher: 0 stage: sketch lr: 0.000559\n",
      "batch 44 loss: 1.26499 acc: 0.69727 | v_loss: 1.30227 v_acc: 0.71061 |  iteration: 6260 teacher: 1 stage: sketch lr: 0.000559\n",
      "batch 45 loss: 1.19357 acc: 0.71517 | v_loss: 1.19459 v_acc: 0.71159 |  iteration: 6261 teacher: 0 stage: sketch lr: 0.000559\n",
      "batch 46 loss: 1.32160 acc: 0.69368 | v_loss: 1.27203 v_acc: 0.70866 |  iteration: 6262 teacher: 1 stage: sketch lr: 0.000558\n",
      "batch 47 loss: 1.21503 acc: 0.71159 | v_loss: 1.16366 v_acc: 0.71159 |  iteration: 6263 teacher: 1 stage: sketch lr: 0.000558\n",
      "batch 48 loss: 1.30669 acc: 0.70605 | v_loss: 1.27104 v_acc: 0.69954 |  iteration: 6264 teacher: 1 stage: sketch lr: 0.000558\n",
      "batch 49 loss: 1.30193 acc: 0.70638 | v_loss: 1.23600 v_acc: 0.71322 |  iteration: 6265 teacher: 0 stage: sketch lr: 0.000558\n",
      "batch 50 loss: 1.35236 acc: 0.69531 | v_loss: 1.17401 v_acc: 0.71615 |  iteration: 6266 teacher: 0 stage: sketch lr: 0.000558\n",
      "batch 51 loss: 1.27227 acc: 0.70866 | v_loss: 1.13971 v_acc: 0.72493 |  iteration: 6267 teacher: 0 stage: sketch lr: 0.000558\n",
      "batch 52 loss: 1.26911 acc: 0.71094 | v_loss: 1.25990 v_acc: 0.71517 |  iteration: 6268 teacher: 1 stage: sketch lr: 0.000558\n",
      "batch 53 loss: 1.41824 acc: 0.70475 | v_loss: 1.25222 v_acc: 0.70280 |  iteration: 6269 teacher: 1 stage: sketch lr: 0.000558\n",
      "batch 54 loss: 1.30720 acc: 0.70638 | v_loss: 1.26664 v_acc: 0.70931 |  iteration: 6270 teacher: 0 stage: sketch lr: 0.000558\n",
      "batch 55 loss: 1.32545 acc: 0.70443 | v_loss: 1.13488 v_acc: 0.71452 |  iteration: 6271 teacher: 1 stage: sketch lr: 0.000558\n",
      "batch 56 loss: 1.33311 acc: 0.70540 | v_loss: 1.24642 v_acc: 0.72721 |  iteration: 6272 teacher: 0 stage: sketch lr: 0.000558\n",
      "batch 57 loss: 1.30364 acc: 0.70247 | v_loss: 1.30448 v_acc: 0.69759 |  iteration: 6273 teacher: 0 stage: sketch lr: 0.000558\n",
      "batch 58 loss: 1.27827 acc: 0.71322 | v_loss: 1.29818 v_acc: 0.72103 |  iteration: 6274 teacher: 1 stage: sketch lr: 0.000558\n",
      "batch 59 loss: 1.30488 acc: 0.70703 | v_loss: 1.17517 v_acc: 0.71712 |  iteration: 6275 teacher: 1 stage: sketch lr: 0.000558\n",
      "batch 60 loss: 1.33716 acc: 0.70280 | v_loss: 1.12576 v_acc: 0.72819 |  iteration: 6276 teacher: 1 stage: sketch lr: 0.000558\n",
      "batch 61 loss: 1.22157 acc: 0.71517 | v_loss: 1.10717 v_acc: 0.72331 |  iteration: 6277 teacher: 0 stage: sketch lr: 0.000558\n",
      "batch 62 loss: 1.33034 acc: 0.70182 | v_loss: 1.19644 v_acc: 0.70736 |  iteration: 6278 teacher: 1 stage: sketch lr: 0.000558\n",
      "batch 63 loss: 1.31343 acc: 0.70410 | v_loss: 1.25379 v_acc: 0.70182 |  iteration: 6279 teacher: 1 stage: sketch lr: 0.000558\n",
      "batch 64 loss: 1.21481 acc: 0.70898 | v_loss: 1.19108 v_acc: 0.71452 |  iteration: 6280 teacher: 1 stage: sketch lr: 0.000558\n",
      "batch 65 loss: 1.32298 acc: 0.69368 | v_loss: 1.34789 v_acc: 0.70475 |  iteration: 6281 teacher: 0 stage: sketch lr: 0.000558\n",
      "batch 66 loss: 1.26042 acc: 0.70312 | v_loss: 1.50081 v_acc: 0.69043 |  iteration: 6282 teacher: 0 stage: sketch lr: 0.000558\n",
      "batch 67 loss: 1.29200 acc: 0.71029 | v_loss: 1.36802 v_acc: 0.69336 |  iteration: 6283 teacher: 0 stage: sketch lr: 0.000558\n",
      "batch 68 loss: 1.35311 acc: 0.70150 | v_loss: 1.19177 v_acc: 0.72396 |  iteration: 6284 teacher: 1 stage: sketch lr: 0.000558\n",
      "batch 69 loss: 1.24660 acc: 0.70801 | v_loss: 1.14988 v_acc: 0.70996 |  iteration: 6285 teacher: 0 stage: sketch lr: 0.000557\n",
      "batch 70 loss: 1.26002 acc: 0.70573 | v_loss: 1.15833 v_acc: 0.72201 |  iteration: 6286 teacher: 1 stage: sketch lr: 0.000557\n",
      "batch 71 loss: 1.20864 acc: 0.70736 | v_loss: 1.21595 v_acc: 0.70378 |  iteration: 6287 teacher: 1 stage: sketch lr: 0.000557\n",
      "batch 72 loss: 1.28574 acc: 0.70117 | v_loss: 1.26116 v_acc: 0.71810 |  iteration: 6288 teacher: 1 stage: sketch lr: 0.000557\n",
      "batch 73 loss: 1.30719 acc: 0.70768 | v_loss: 1.20950 v_acc: 0.73014 |  iteration: 6289 teacher: 1 stage: sketch lr: 0.000557\n",
      "batch 74 loss: 1.24208 acc: 0.71159 | v_loss: 1.24129 v_acc: 0.71973 |  iteration: 6290 teacher: 1 stage: sketch lr: 0.000557\n",
      "batch 75 loss: 1.30282 acc: 0.70736 | v_loss: 1.25675 v_acc: 0.70768 |  iteration: 6291 teacher: 0 stage: sketch lr: 0.000557\n",
      "batch 76 loss: 1.28011 acc: 0.69857 | v_loss: 1.17292 v_acc: 0.72363 |  iteration: 6292 teacher: 0 stage: sketch lr: 0.000557\n",
      "batch 77 loss: 1.18008 acc: 0.72298 | v_loss: 1.14496 v_acc: 0.72005 |  iteration: 6293 teacher: 0 stage: sketch lr: 0.000557\n",
      "batch 78 loss: 1.26918 acc: 0.70573 | v_loss: 1.47917 v_acc: 0.68652 |  iteration: 6294 teacher: 1 stage: sketch lr: 0.000557\n",
      "batch 79 loss: 1.21139 acc: 0.70931 | v_loss: 1.21408 v_acc: 0.71159 |  iteration: 6295 teacher: 0 stage: sketch lr: 0.000557\n",
      "batch 80 loss: 1.24689 acc: 0.71061 | v_loss: 1.24542 v_acc: 0.71452 |  iteration: 6296 teacher: 1 stage: sketch lr: 0.000557\n",
      "batch 81 loss: 1.24943 acc: 0.71582 | v_loss: 1.22822 v_acc: 0.71875 |  iteration: 6297 teacher: 1 stage: sketch lr: 0.000557\n",
      "batch 82 loss: 1.32296 acc: 0.70475 | v_loss: 1.28258 v_acc: 0.70410 |  iteration: 6298 teacher: 0 stage: sketch lr: 0.000557\n",
      "batch 83 loss: 1.23030 acc: 0.70736 | v_loss: 1.13358 v_acc: 0.73145 |  iteration: 6299 teacher: 0 stage: sketch lr: 0.000557\n",
      "batch 84 loss: 1.25752 acc: 0.70605 | v_loss: 1.38524 v_acc: 0.71452 |  iteration: 6300 teacher: 1 stage: sketch lr: 0.000557\n",
      "batch 85 loss: 1.17391 acc: 0.71289 | v_loss: 1.19477 v_acc: 0.70085 |  iteration: 6301 teacher: 1 stage: sketch lr: 0.000557\n",
      "batch 86 loss: 1.26703 acc: 0.70508 | v_loss: 1.20868 v_acc: 0.70410 |  iteration: 6302 teacher: 1 stage: sketch lr: 0.000557\n",
      "batch 87 loss: 1.36020 acc: 0.69401 | v_loss: 1.25302 v_acc: 0.70410 |  iteration: 6303 teacher: 1 stage: sketch lr: 0.000557\n",
      "batch 88 loss: 1.29782 acc: 0.70052 | v_loss: 1.27471 v_acc: 0.70345 |  iteration: 6304 teacher: 0 stage: sketch lr: 0.000557\n",
      "batch 89 loss: 1.30352 acc: 0.69954 | v_loss: 1.33583 v_acc: 0.69661 |  iteration: 6305 teacher: 0 stage: sketch lr: 0.000557\n",
      "batch 90 loss: 1.32042 acc: 0.69857 | v_loss: 1.37170 v_acc: 0.70605 |  iteration: 6306 teacher: 1 stage: sketch lr: 0.000557\n",
      "batch 91 loss: 1.31148 acc: 0.70182 | v_loss: 1.28912 v_acc: 0.70020 |  iteration: 6307 teacher: 1 stage: sketch lr: 0.000556\n",
      "batch 92 loss: 1.32910 acc: 0.70085 | v_loss: 1.20345 v_acc: 0.70736 |  iteration: 6308 teacher: 0 stage: sketch lr: 0.000556\n",
      "batch 93 loss: 1.25460 acc: 0.71322 | v_loss: 1.32069 v_acc: 0.70671 |  iteration: 6309 teacher: 1 stage: sketch lr: 0.000556\n",
      "batch 94 loss: 1.33819 acc: 0.69336 | v_loss: 1.22513 v_acc: 0.71680 |  iteration: 6310 teacher: 0 stage: sketch lr: 0.000556\n",
      "batch 95 loss: 1.32352 acc: 0.70247 | v_loss: 1.14938 v_acc: 0.72266 |  iteration: 6311 teacher: 0 stage: sketch lr: 0.000556\n",
      "batch 96 loss: 1.26953 acc: 0.70768 | v_loss: 1.13701 v_acc: 0.70866 |  iteration: 6312 teacher: 1 stage: sketch lr: 0.000556\n",
      "batch 97 loss: 1.29778 acc: 0.70605 | v_loss: 1.25561 v_acc: 0.70638 |  iteration: 6313 teacher: 1 stage: sketch lr: 0.000556\n",
      "batch 98 loss: 1.30582 acc: 0.70736 | v_loss: 1.32855 v_acc: 0.69694 |  iteration: 6314 teacher: 1 stage: sketch lr: 0.000556\n",
      "batch 99 loss: 1.27062 acc: 0.71549 | v_loss: 1.16757 v_acc: 0.71126 |  iteration: 6315 teacher: 0 stage: sketch lr: 0.000556\n",
      "batch 100 loss: 1.25201 acc: 0.70703 | v_loss: 1.20144 v_acc: 0.70182 |  iteration: 6316 teacher: 0 stage: sketch lr: 0.000556\n",
      "batch 101 loss: 1.26420 acc: 0.70508 | v_loss: 1.19864 v_acc: 0.71126 |  iteration: 6317 teacher: 1 stage: sketch lr: 0.000556\n",
      "batch 102 loss: 1.34402 acc: 0.70866 | v_loss: 1.21596 v_acc: 0.70605 |  iteration: 6318 teacher: 1 stage: sketch lr: 0.000556\n",
      "batch 103 loss: 1.26795 acc: 0.70280 | v_loss: 1.06956 v_acc: 0.73568 |  iteration: 6319 teacher: 0 stage: sketch lr: 0.000556\n",
      "batch 104 loss: 1.39500 acc: 0.69792 | v_loss: 1.18483 v_acc: 0.72005 |  iteration: 6320 teacher: 0 stage: sketch lr: 0.000556\n",
      "batch 105 loss: 1.37599 acc: 0.69987 | v_loss: 1.14669 v_acc: 0.72591 |  iteration: 6321 teacher: 1 stage: sketch lr: 0.000556\n",
      "batch 106 loss: 1.37061 acc: 0.70020 | v_loss: 1.13195 v_acc: 0.72461 |  iteration: 6322 teacher: 0 stage: sketch lr: 0.000556\n",
      "batch 107 loss: 1.32452 acc: 0.69596 | v_loss: 1.21113 v_acc: 0.71842 |  iteration: 6323 teacher: 0 stage: sketch lr: 0.000556\n",
      "batch 108 loss: 1.34495 acc: 0.69564 | v_loss: 1.24721 v_acc: 0.70964 |  iteration: 6324 teacher: 0 stage: sketch lr: 0.000556\n",
      "batch 109 loss: 1.29422 acc: 0.70247 | v_loss: 1.21810 v_acc: 0.72363 |  iteration: 6325 teacher: 1 stage: sketch lr: 0.000556\n",
      "batch 110 loss: 1.31797 acc: 0.71094 | v_loss: 1.37136 v_acc: 0.70150 |  iteration: 6326 teacher: 0 stage: sketch lr: 0.000556\n",
      "batch 111 loss: 1.39391 acc: 0.69824 | v_loss: 1.25856 v_acc: 0.72135 |  iteration: 6327 teacher: 0 stage: sketch lr: 0.000556\n",
      "batch 112 loss: 1.26954 acc: 0.70312 | v_loss: 1.06142 v_acc: 0.74740 |  iteration: 6328 teacher: 0 stage: sketch lr: 0.000556\n",
      "batch 113 loss: 1.33299 acc: 0.69889 | v_loss: 1.24550 v_acc: 0.70833 |  iteration: 6329 teacher: 1 stage: sketch lr: 0.000556\n",
      "batch 114 loss: 1.26442 acc: 0.69857 | v_loss: 1.26891 v_acc: 0.69922 |  iteration: 6330 teacher: 1 stage: sketch lr: 0.000555\n",
      "batch 115 loss: 1.27644 acc: 0.70378 | v_loss: 1.23697 v_acc: 0.70573 |  iteration: 6331 teacher: 0 stage: sketch lr: 0.000555\n",
      "batch 116 loss: 1.26252 acc: 0.70638 | v_loss: 1.26479 v_acc: 0.71126 |  iteration: 6332 teacher: 1 stage: sketch lr: 0.000555\n",
      "batch 117 loss: 1.29050 acc: 0.70964 | v_loss: 1.26204 v_acc: 0.69303 |  iteration: 6333 teacher: 1 stage: sketch lr: 0.000555\n",
      "batch 118 loss: 1.32870 acc: 0.70475 | v_loss: 1.24263 v_acc: 0.71810 |  iteration: 6334 teacher: 0 stage: sketch lr: 0.000555\n",
      "batch 119 loss: 1.34843 acc: 0.70052 | v_loss: 1.27134 v_acc: 0.70052 |  iteration: 6335 teacher: 1 stage: sketch lr: 0.000555\n",
      "batch 120 loss: 1.25631 acc: 0.71387 | v_loss: 1.18628 v_acc: 0.72331 |  iteration: 6336 teacher: 0 stage: sketch lr: 0.000555\n",
      "batch 121 loss: 1.29691 acc: 0.71354 | v_loss: 1.18923 v_acc: 0.72266 |  iteration: 6337 teacher: 1 stage: sketch lr: 0.000555\n",
      "batch 122 loss: 1.29918 acc: 0.70085 | v_loss: 1.24446 v_acc: 0.70345 |  iteration: 6338 teacher: 0 stage: sketch lr: 0.000555\n",
      "batch 123 loss: 1.23951 acc: 0.71452 | v_loss: 1.36670 v_acc: 0.69303 |  iteration: 6339 teacher: 0 stage: sketch lr: 0.000555\n",
      "batch 124 loss: 1.33115 acc: 0.70150 | v_loss: 1.16965 v_acc: 0.71029 |  iteration: 6340 teacher: 1 stage: sketch lr: 0.000555\n",
      "batch 125 loss: 1.25144 acc: 0.70833 | v_loss: 1.44081 v_acc: 0.68132 |  iteration: 6341 teacher: 1 stage: sketch lr: 0.000555\n",
      "batch 126 loss: 1.45166 acc: 0.69336 | v_loss: 1.17676 v_acc: 0.72070 |  iteration: 6342 teacher: 0 stage: sketch lr: 0.000555\n",
      "batch 127 loss: 1.32573 acc: 0.70150 | v_loss: 1.49468 v_acc: 0.67741 |  iteration: 6343 teacher: 0 stage: sketch lr: 0.000555\n",
      "batch 128 loss: 1.20049 acc: 0.71094 | v_loss: 1.39017 v_acc: 0.69857 |  iteration: 6344 teacher: 0 stage: sketch lr: 0.000555\n",
      "batch 129 loss: 1.43403 acc: 0.69531 | v_loss: 1.34560 v_acc: 0.69043 |  iteration: 6345 teacher: 0 stage: sketch lr: 0.000555\n",
      "batch 130 loss: 1.25052 acc: 0.71452 | v_loss: 1.31686 v_acc: 0.69727 |  iteration: 6346 teacher: 0 stage: sketch lr: 0.000555\n",
      "batch 131 loss: 1.23161 acc: 0.71615 | v_loss: 1.24199 v_acc: 0.70247 |  iteration: 6347 teacher: 0 stage: sketch lr: 0.000555\n",
      "batch 132 loss: 1.33741 acc: 0.69694 | v_loss: 1.26720 v_acc: 0.69889 |  iteration: 6348 teacher: 0 stage: sketch lr: 0.000555\n",
      "batch 133 loss: 1.30794 acc: 0.69238 | v_loss: 1.21692 v_acc: 0.71973 |  iteration: 6349 teacher: 0 stage: sketch lr: 0.000555\n",
      "batch 134 loss: 1.27646 acc: 0.70605 | v_loss: 1.41448 v_acc: 0.69076 |  iteration: 6350 teacher: 0 stage: sketch lr: 0.000555\n",
      "batch 135 loss: 1.28366 acc: 0.70866 | v_loss: 1.29636 v_acc: 0.71387 |  iteration: 6351 teacher: 1 stage: sketch lr: 0.000555\n",
      "batch 136 loss: 1.28975 acc: 0.70247 | v_loss: 1.19288 v_acc: 0.70443 |  iteration: 6352 teacher: 1 stage: sketch lr: 0.000555\n",
      "batch 137 loss: 1.29896 acc: 0.70996 | v_loss: 1.26269 v_acc: 0.70736 |  iteration: 6353 teacher: 1 stage: sketch lr: 0.000554\n",
      "batch 138 loss: 1.33438 acc: 0.70150 | v_loss: 1.16447 v_acc: 0.71159 |  iteration: 6354 teacher: 0 stage: sketch lr: 0.000554\n",
      "batch 139 loss: 1.27430 acc: 0.71224 | v_loss: 1.26480 v_acc: 0.70150 |  iteration: 6355 teacher: 1 stage: sketch lr: 0.000554\n",
      "batch 140 loss: 1.25798 acc: 0.70475 | v_loss: 1.24159 v_acc: 0.71224 |  iteration: 6356 teacher: 0 stage: sketch lr: 0.000554\n",
      "batch 141 loss: 1.33903 acc: 0.69629 | v_loss: 1.16827 v_acc: 0.72005 |  iteration: 6357 teacher: 1 stage: sketch lr: 0.000554\n",
      "batch 142 loss: 1.23347 acc: 0.71126 | v_loss: 1.15228 v_acc: 0.72461 |  iteration: 6358 teacher: 0 stage: sketch lr: 0.000554\n",
      "batch 143 loss: 1.33119 acc: 0.70247 | v_loss: 1.28459 v_acc: 0.71029 |  iteration: 6359 teacher: 1 stage: sketch lr: 0.000554\n",
      "batch 144 loss: 1.26988 acc: 0.70638 | v_loss: 1.26238 v_acc: 0.70475 |  iteration: 6360 teacher: 1 stage: sketch lr: 0.000554\n",
      "batch 145 loss: 1.25953 acc: 0.71094 | v_loss: 1.26710 v_acc: 0.70996 |  iteration: 6361 teacher: 0 stage: sketch lr: 0.000554\n",
      "batch 146 loss: 1.27379 acc: 0.70508 | v_loss: 1.11248 v_acc: 0.71615 |  iteration: 6362 teacher: 1 stage: sketch lr: 0.000554\n",
      "batch 147 loss: 1.36351 acc: 0.69987 | v_loss: 1.23484 v_acc: 0.73307 |  iteration: 6363 teacher: 0 stage: sketch lr: 0.000554\n",
      "batch 148 loss: 1.27404 acc: 0.70964 | v_loss: 1.30355 v_acc: 0.69759 |  iteration: 6364 teacher: 0 stage: sketch lr: 0.000554\n",
      "batch 149 loss: 1.22091 acc: 0.70964 | v_loss: 1.30439 v_acc: 0.72135 |  iteration: 6365 teacher: 1 stage: sketch lr: 0.000554\n",
      "batch 150 loss: 1.23285 acc: 0.70671 | v_loss: 1.16654 v_acc: 0.71973 |  iteration: 6366 teacher: 0 stage: sketch lr: 0.000554\n",
      "batch 151 loss: 1.31710 acc: 0.70052 | v_loss: 1.11944 v_acc: 0.73535 |  iteration: 6367 teacher: 1 stage: sketch lr: 0.000554\n",
      "batch 152 loss: 1.41435 acc: 0.69759 | v_loss: 1.10079 v_acc: 0.72656 |  iteration: 6368 teacher: 0 stage: sketch lr: 0.000554\n",
      "batch 153 loss: 1.28890 acc: 0.71159 | v_loss: 1.20616 v_acc: 0.70703 |  iteration: 6369 teacher: 1 stage: sketch lr: 0.000554\n",
      "batch 154 loss: 1.28405 acc: 0.70703 | v_loss: 1.22972 v_acc: 0.69466 |  iteration: 6370 teacher: 1 stage: sketch lr: 0.000554\n",
      "batch 155 loss: 1.27987 acc: 0.70964 | v_loss: 1.20202 v_acc: 0.71419 |  iteration: 6371 teacher: 1 stage: sketch lr: 0.000554\n",
      "batch 156 loss: 1.25085 acc: 0.70866 | v_loss: 1.33458 v_acc: 0.70671 |  iteration: 6372 teacher: 1 stage: sketch lr: 0.000554\n",
      "batch 157 loss: 1.28796 acc: 0.70703 | v_loss: 1.49028 v_acc: 0.69043 |  iteration: 6373 teacher: 1 stage: sketch lr: 0.000554\n",
      "batch 158 loss: 1.36804 acc: 0.68945 | v_loss: 1.36432 v_acc: 0.69238 |  iteration: 6374 teacher: 0 stage: sketch lr: 0.000554\n",
      "batch 159 loss: 1.36135 acc: 0.69759 | v_loss: 1.19869 v_acc: 0.72233 |  iteration: 6375 teacher: 0 stage: sketch lr: 0.000554\n",
      "batch 160 loss: 1.34677 acc: 0.70671 | v_loss: 1.15707 v_acc: 0.70703 |  iteration: 6376 teacher: 0 stage: sketch lr: 0.000553\n",
      "batch 161 loss: 1.20314 acc: 0.70768 | v_loss: 1.16271 v_acc: 0.71517 |  iteration: 6377 teacher: 0 stage: sketch lr: 0.000553\n",
      "batch 162 loss: 1.30407 acc: 0.71029 | v_loss: 1.22096 v_acc: 0.70345 |  iteration: 6378 teacher: 0 stage: sketch lr: 0.000553\n",
      "batch 163 loss: 1.37085 acc: 0.69824 | v_loss: 1.25495 v_acc: 0.71257 |  iteration: 6379 teacher: 1 stage: sketch lr: 0.000553\n",
      "batch 164 loss: 1.36014 acc: 0.69694 | v_loss: 1.21169 v_acc: 0.72721 |  iteration: 6380 teacher: 1 stage: sketch lr: 0.000553\n",
      "batch 165 loss: 1.24288 acc: 0.71257 | v_loss: 1.22238 v_acc: 0.71875 |  iteration: 6381 teacher: 0 stage: sketch lr: 0.000553\n",
      "batch 166 loss: 1.32730 acc: 0.70573 | v_loss: 1.24115 v_acc: 0.71061 |  iteration: 6382 teacher: 1 stage: sketch lr: 0.000553\n",
      "batch 167 loss: 1.36716 acc: 0.70150 | v_loss: 1.16031 v_acc: 0.72461 |  iteration: 6383 teacher: 1 stage: sketch lr: 0.000553\n",
      "batch 168 loss: 1.26181 acc: 0.71126 | v_loss: 1.14026 v_acc: 0.71908 |  iteration: 6384 teacher: 0 stage: sketch lr: 0.000553\n",
      "batch 169 loss: 1.26885 acc: 0.71322 | v_loss: 1.44829 v_acc: 0.68945 |  iteration: 6385 teacher: 1 stage: sketch lr: 0.000553\n",
      "batch 170 loss: 1.27721 acc: 0.70508 | v_loss: 1.21403 v_acc: 0.70964 |  iteration: 6386 teacher: 1 stage: sketch lr: 0.000553\n",
      "batch 171 loss: 1.42043 acc: 0.68490 | v_loss: 1.22493 v_acc: 0.71973 |  iteration: 6387 teacher: 1 stage: sketch lr: 0.000553\n",
      "batch 172 loss: 1.22713 acc: 0.71289 | v_loss: 1.22178 v_acc: 0.70638 |  iteration: 6388 teacher: 1 stage: sketch lr: 0.000553\n",
      "batch 173 loss: 1.26515 acc: 0.70605 | v_loss: 1.28765 v_acc: 0.70508 |  iteration: 6389 teacher: 1 stage: sketch lr: 0.000553\n",
      "batch 174 loss: 1.26221 acc: 0.70605 | v_loss: 1.14737 v_acc: 0.73079 |  iteration: 6390 teacher: 0 stage: sketch lr: 0.000553\n",
      "batch 175 loss: 1.29087 acc: 0.70378 | v_loss: 1.39435 v_acc: 0.71419 |  iteration: 6391 teacher: 1 stage: sketch lr: 0.000553\n",
      "batch 176 loss: 1.28355 acc: 0.70605 | v_loss: 1.19174 v_acc: 0.69857 |  iteration: 6392 teacher: 0 stage: sketch lr: 0.000553\n",
      "batch 177 loss: 1.30952 acc: 0.70703 | v_loss: 1.22143 v_acc: 0.70345 |  iteration: 6393 teacher: 0 stage: sketch lr: 0.000553\n",
      "batch 178 loss: 1.29666 acc: 0.70085 | v_loss: 1.26477 v_acc: 0.70312 |  iteration: 6394 teacher: 1 stage: sketch lr: 0.000553\n",
      "batch 179 loss: 1.30206 acc: 0.70801 | v_loss: 1.27609 v_acc: 0.70345 |  iteration: 6395 teacher: 1 stage: sketch lr: 0.000553\n",
      "batch 180 loss: 1.35555 acc: 0.69466 | v_loss: 1.34191 v_acc: 0.69661 |  iteration: 6396 teacher: 1 stage: sketch lr: 0.000553\n",
      "batch 181 loss: 1.38858 acc: 0.69889 | v_loss: 1.36376 v_acc: 0.70671 |  iteration: 6397 teacher: 1 stage: sketch lr: 0.000553\n",
      "batch 182 loss: 1.33687 acc: 0.71224 | v_loss: 1.29604 v_acc: 0.70215 |  iteration: 6398 teacher: 1 stage: sketch lr: 0.000553\n",
      "batch 183 loss: 1.27994 acc: 0.71061 | v_loss: 1.21019 v_acc: 0.70931 |  iteration: 6399 teacher: 1 stage: sketch lr: 0.000552\n",
      "batch 184 loss: 1.29909 acc: 0.70508 | v_loss: 1.31133 v_acc: 0.70964 |  iteration: 6400 teacher: 0 stage: sketch lr: 0.000552\n",
      "batch 185 loss: 1.35628 acc: 0.69727 | v_loss: 1.23016 v_acc: 0.71191 |  iteration: 6401 teacher: 1 stage: sketch lr: 0.000552\n",
      "batch 186 loss: 1.22288 acc: 0.70931 | v_loss: 1.14682 v_acc: 0.72363 |  iteration: 6402 teacher: 1 stage: sketch lr: 0.000552\n",
      "batch 187 loss: 1.24159 acc: 0.70605 | v_loss: 1.14685 v_acc: 0.70736 |  iteration: 6403 teacher: 1 stage: sketch lr: 0.000552\n",
      "batch 188 loss: 1.30774 acc: 0.70573 | v_loss: 1.25718 v_acc: 0.70801 |  iteration: 6404 teacher: 0 stage: sketch lr: 0.000552\n",
      "batch 189 loss: 1.22303 acc: 0.71387 | v_loss: 1.32598 v_acc: 0.69857 |  iteration: 6405 teacher: 1 stage: sketch lr: 0.000552\n",
      "batch 190 loss: 1.22395 acc: 0.71419 | v_loss: 1.14769 v_acc: 0.71582 |  iteration: 6406 teacher: 1 stage: sketch lr: 0.000552\n",
      "batch 191 loss: 1.36587 acc: 0.68717 | v_loss: 1.21203 v_acc: 0.70020 |  iteration: 6407 teacher: 0 stage: sketch lr: 0.000552\n",
      "batch 192 loss: 1.35523 acc: 0.69368 | v_loss: 1.20738 v_acc: 0.70996 |  iteration: 6408 teacher: 1 stage: sketch lr: 0.000552\n",
      "batch 193 loss: 1.28217 acc: 0.70150 | v_loss: 1.23040 v_acc: 0.70312 |  iteration: 6409 teacher: 0 stage: sketch lr: 0.000552\n",
      "batch 194 loss: 1.24193 acc: 0.70085 | v_loss: 1.06087 v_acc: 0.74284 |  iteration: 6410 teacher: 0 stage: sketch lr: 0.000552\n",
      "batch 195 loss: 1.31794 acc: 0.69303 | v_loss: 1.18022 v_acc: 0.72038 |  iteration: 6411 teacher: 0 stage: sketch lr: 0.000552\n",
      "batch 196 loss: 1.29879 acc: 0.69759 | v_loss: 1.12641 v_acc: 0.72559 |  iteration: 6412 teacher: 1 stage: sketch lr: 0.000552\n",
      "batch 197 loss: 1.26503 acc: 0.70605 | v_loss: 1.12383 v_acc: 0.72428 |  iteration: 6413 teacher: 0 stage: sketch lr: 0.000552\n",
      "batch 198 loss: 1.18422 acc: 0.71582 | v_loss: 1.20890 v_acc: 0.71680 |  iteration: 6414 teacher: 1 stage: sketch lr: 0.000552\n",
      "batch 199 loss: 1.33790 acc: 0.70312 | v_loss: 1.24761 v_acc: 0.71289 |  iteration: 6415 teacher: 0 stage: sketch lr: 0.000552\n",
      "batch 200 loss: 1.27441 acc: 0.70638 | v_loss: 1.22306 v_acc: 0.72168 |  iteration: 6416 teacher: 1 stage: sketch lr: 0.000552\n",
      "batch 201 loss: 1.31430 acc: 0.70247 | v_loss: 1.38019 v_acc: 0.70150 |  iteration: 6417 teacher: 0 stage: sketch lr: 0.000552\n",
      "batch 202 loss: 1.26971 acc: 0.70801 | v_loss: 1.28772 v_acc: 0.71940 |  iteration: 6418 teacher: 0 stage: sketch lr: 0.000552\n",
      "batch 203 loss: 1.35784 acc: 0.69271 | v_loss: 1.06176 v_acc: 0.74316 |  iteration: 6419 teacher: 1 stage: sketch lr: 0.000552\n",
      "batch 204 loss: 1.31591 acc: 0.70312 | v_loss: 1.21726 v_acc: 0.70833 |  iteration: 6420 teacher: 0 stage: sketch lr: 0.000552\n",
      "batch 205 loss: 1.29214 acc: 0.70410 | v_loss: 1.27539 v_acc: 0.69922 |  iteration: 6421 teacher: 0 stage: sketch lr: 0.000552\n",
      "batch 206 loss: 1.31967 acc: 0.70996 | v_loss: 1.22162 v_acc: 0.70573 |  iteration: 6422 teacher: 1 stage: sketch lr: 0.000551\n",
      "batch 207 loss: 1.19330 acc: 0.71842 | v_loss: 1.27225 v_acc: 0.71126 |  iteration: 6423 teacher: 1 stage: sketch lr: 0.000551\n",
      "batch 208 loss: 1.24863 acc: 0.71061 | v_loss: 1.26474 v_acc: 0.69759 |  iteration: 6424 teacher: 0 stage: sketch lr: 0.000551\n",
      "batch 209 loss: 1.26644 acc: 0.71484 | v_loss: 1.24771 v_acc: 0.71061 |  iteration: 6425 teacher: 1 stage: sketch lr: 0.000551\n",
      "batch 210 loss: 1.25374 acc: 0.71680 | v_loss: 1.27479 v_acc: 0.69303 |  iteration: 6426 teacher: 1 stage: sketch lr: 0.000551\n",
      "batch 211 loss: 1.38128 acc: 0.70280 | v_loss: 1.19437 v_acc: 0.70931 |  iteration: 6427 teacher: 1 stage: sketch lr: 0.000551\n",
      "batch 212 loss: 1.29189 acc: 0.70150 | v_loss: 1.18500 v_acc: 0.72363 |  iteration: 6428 teacher: 0 stage: sketch lr: 0.000551\n",
      "batch 213 loss: 1.30261 acc: 0.71322 | v_loss: 1.26011 v_acc: 0.70117 |  iteration: 6429 teacher: 0 stage: sketch lr: 0.000551\n",
      "batch 214 loss: 1.25518 acc: 0.71029 | v_loss: 1.32529 v_acc: 0.70020 |  iteration: 6430 teacher: 1 stage: sketch lr: 0.000551\n",
      "batch 215 loss: 1.33115 acc: 0.69466 | v_loss: 1.16436 v_acc: 0.70898 |  iteration: 6431 teacher: 1 stage: sketch lr: 0.000551\n",
      "batch 216 loss: 1.27057 acc: 0.70573 | v_loss: 1.41590 v_acc: 0.68392 |  iteration: 6432 teacher: 1 stage: sketch lr: 0.000551\n",
      "batch 217 loss: 1.27942 acc: 0.70736 | v_loss: 1.16770 v_acc: 0.72461 |  iteration: 6433 teacher: 1 stage: sketch lr: 0.000551\n",
      "batch 218 loss: 1.32669 acc: 0.70020 | v_loss: 1.49708 v_acc: 0.67448 |  iteration: 6434 teacher: 1 stage: sketch lr: 0.000551\n",
      "batch 219 loss: 1.30704 acc: 0.70085 | v_loss: 1.38779 v_acc: 0.69271 |  iteration: 6435 teacher: 1 stage: sketch lr: 0.000551\n",
      "batch 220 loss: 1.37888 acc: 0.70020 | v_loss: 1.33099 v_acc: 0.69694 |  iteration: 6436 teacher: 1 stage: sketch lr: 0.000551\n",
      "batch 221 loss: 1.28870 acc: 0.70475 | v_loss: 1.33077 v_acc: 0.69531 |  iteration: 6437 teacher: 0 stage: sketch lr: 0.000551\n",
      "batch 222 loss: 1.28543 acc: 0.69987 | v_loss: 1.23230 v_acc: 0.70703 |  iteration: 6438 teacher: 1 stage: sketch lr: 0.000551\n",
      "batch 223 loss: 1.26096 acc: 0.71094 | v_loss: 1.27678 v_acc: 0.70280 |  iteration: 6439 teacher: 0 stage: sketch lr: 0.000551\n",
      "batch 224 loss: 1.28850 acc: 0.70996 | v_loss: 1.22955 v_acc: 0.72103 |  iteration: 6440 teacher: 0 stage: sketch lr: 0.000551\n",
      "batch 225 loss: 1.24173 acc: 0.70215 | v_loss: 1.43004 v_acc: 0.68848 |  iteration: 6441 teacher: 1 stage: sketch lr: 0.000551\n",
      "batch 226 loss: 1.34794 acc: 0.70247 | v_loss: 1.31062 v_acc: 0.71159 |  iteration: 6442 teacher: 0 stage: sketch lr: 0.000551\n",
      "batch 227 loss: 1.24542 acc: 0.71224 | v_loss: 1.19056 v_acc: 0.70931 |  iteration: 6443 teacher: 0 stage: sketch lr: 0.000551\n",
      "batch 228 loss: 1.20799 acc: 0.71973 | v_loss: 1.26760 v_acc: 0.71354 |  iteration: 6444 teacher: 0 stage: sketch lr: 0.000551\n",
      "batch 229 loss: 1.27929 acc: 0.70573 | v_loss: 1.16665 v_acc: 0.70605 |  iteration: 6445 teacher: 0 stage: sketch lr: 0.000550\n",
      "batch 230 loss: 1.40413 acc: 0.68848 | v_loss: 1.26692 v_acc: 0.69694 |  iteration: 6446 teacher: 0 stage: sketch lr: 0.000550\n",
      "batch 231 loss: 1.30103 acc: 0.70247 | v_loss: 1.22625 v_acc: 0.71549 |  iteration: 6447 teacher: 1 stage: sketch lr: 0.000550\n",
      "batch 232 loss: 1.22588 acc: 0.70638 | v_loss: 1.16904 v_acc: 0.72038 |  iteration: 6448 teacher: 1 stage: sketch lr: 0.000550\n",
      "batch 233 loss: 1.33191 acc: 0.70378 | v_loss: 1.13495 v_acc: 0.72819 |  iteration: 6449 teacher: 1 stage: sketch lr: 0.000550\n",
      "batch 234 loss: 1.32284 acc: 0.70671 | v_loss: 1.26507 v_acc: 0.71940 |  iteration: 6450 teacher: 1 stage: sketch lr: 0.000550\n",
      "batch 235 loss: 1.21790 acc: 0.70703 | v_loss: 1.25244 v_acc: 0.70605 |  iteration: 6451 teacher: 0 stage: sketch lr: 0.000550\n",
      "batch 236 loss: 1.29512 acc: 0.71094 | v_loss: 1.26653 v_acc: 0.70931 |  iteration: 6452 teacher: 1 stage: sketch lr: 0.000550\n",
      "batch 237 loss: 1.33678 acc: 0.69987 | v_loss: 1.11390 v_acc: 0.72201 |  iteration: 6453 teacher: 1 stage: sketch lr: 0.000550\n",
      "batch 238 loss: 1.27342 acc: 0.70215 | v_loss: 1.25587 v_acc: 0.73307 |  iteration: 6454 teacher: 0 stage: sketch lr: 0.000550\n",
      "batch 239 loss: 1.27725 acc: 0.70996 | v_loss: 1.31888 v_acc: 0.70052 |  iteration: 6455 teacher: 0 stage: sketch lr: 0.000550\n",
      "batch 240 loss: 1.40809 acc: 0.69564 | v_loss: 1.31624 v_acc: 0.72363 |  iteration: 6456 teacher: 0 stage: sketch lr: 0.000550\n",
      "batch 241 loss: 1.22019 acc: 0.70964 | v_loss: 1.16797 v_acc: 0.72201 |  iteration: 6457 teacher: 1 stage: sketch lr: 0.000550\n",
      "batch 242 loss: 1.30589 acc: 0.70117 | v_loss: 1.11633 v_acc: 0.73503 |  iteration: 6458 teacher: 1 stage: sketch lr: 0.000550\n",
      "batch 243 loss: 1.33446 acc: 0.69336 | v_loss: 1.11661 v_acc: 0.72656 |  iteration: 6459 teacher: 1 stage: sketch lr: 0.000550\n",
      "batch 244 loss: 1.25616 acc: 0.70215 | v_loss: 1.19983 v_acc: 0.70703 |  iteration: 6460 teacher: 0 stage: sketch lr: 0.000550\n",
      "batch 245 loss: 1.30876 acc: 0.70345 | v_loss: 1.23985 v_acc: 0.70085 |  iteration: 6461 teacher: 0 stage: sketch lr: 0.000550\n",
      "batch 246 loss: 1.32387 acc: 0.70182 | v_loss: 1.18496 v_acc: 0.71582 |  iteration: 6462 teacher: 0 stage: sketch lr: 0.000550\n",
      "batch 247 loss: 1.26248 acc: 0.71647 | v_loss: 1.31282 v_acc: 0.71777 |  iteration: 6463 teacher: 1 stage: sketch lr: 0.000550\n",
      "batch 248 loss: 1.26491 acc: 0.71159 | v_loss: 1.47192 v_acc: 0.69303 |  iteration: 6464 teacher: 1 stage: sketch lr: 0.000550\n",
      "batch 249 loss: 1.26852 acc: 0.70280 | v_loss: 1.34712 v_acc: 0.69531 |  iteration: 6465 teacher: 1 stage: sketch lr: 0.000550\n",
      "batch 250 loss: 1.32610 acc: 0.69954 | v_loss: 1.19235 v_acc: 0.72168 |  iteration: 6466 teacher: 0 stage: sketch lr: 0.000550\n",
      "batch 251 loss: 1.31446 acc: 0.70898 | v_loss: 1.15621 v_acc: 0.70898 |  iteration: 6467 teacher: 1 stage: sketch lr: 0.000550\n",
      "batch 252 loss: 1.22726 acc: 0.70833 | v_loss: 1.17184 v_acc: 0.71745 |  iteration: 6468 teacher: 0 stage: sketch lr: 0.000550\n",
      "batch 253 loss: 1.30977 acc: 0.69434 | v_loss: 1.21004 v_acc: 0.70020 |  iteration: 6469 teacher: 0 stage: sketch lr: 0.000549\n",
      "batch 254 loss: 1.38958 acc: 0.69889 | v_loss: 1.29176 v_acc: 0.71159 |  iteration: 6470 teacher: 1 stage: sketch lr: 0.000549\n",
      "batch 255 loss: 1.44914 acc: 0.68620 | v_loss: 1.22097 v_acc: 0.72526 |  iteration: 6471 teacher: 0 stage: sketch lr: 0.000549\n",
      "batch 256 loss: 1.29866 acc: 0.71191 | v_loss: 1.25160 v_acc: 0.72559 |  iteration: 6472 teacher: 1 stage: sketch lr: 0.000549\n",
      "batch 257 loss: 1.31937 acc: 0.70573 | v_loss: 1.25839 v_acc: 0.71322 |  iteration: 6473 teacher: 1 stage: sketch lr: 0.000549\n",
      "batch 258 loss: 1.26565 acc: 0.70508 | v_loss: 1.16743 v_acc: 0.72070 |  iteration: 6474 teacher: 0 stage: sketch lr: 0.000549\n",
      "batch 259 loss: 1.30878 acc: 0.70736 | v_loss: 1.13790 v_acc: 0.72005 |  iteration: 6475 teacher: 0 stage: sketch lr: 0.000549\n",
      "batch 260 loss: 1.26307 acc: 0.71257 | v_loss: 1.45448 v_acc: 0.69303 |  iteration: 6476 teacher: 1 stage: sketch lr: 0.000549\n",
      "batch 261 loss: 1.26215 acc: 0.70964 | v_loss: 1.20276 v_acc: 0.71257 |  iteration: 6477 teacher: 0 stage: sketch lr: 0.000549\n",
      "batch 262 loss: 1.21047 acc: 0.71615 | v_loss: 1.23148 v_acc: 0.71680 |  iteration: 6478 teacher: 1 stage: sketch lr: 0.000549\n",
      "batch 263 loss: 1.29223 acc: 0.69987 | v_loss: 1.21041 v_acc: 0.71484 |  iteration: 6479 teacher: 0 stage: sketch lr: 0.000549\n",
      "batch 264 loss: 1.17220 acc: 0.72526 | v_loss: 1.28916 v_acc: 0.70540 |  iteration: 6480 teacher: 1 stage: sketch lr: 0.000549\n",
      "batch 265 loss: 1.29390 acc: 0.71191 | v_loss: 1.14540 v_acc: 0.73210 |  iteration: 6481 teacher: 0 stage: sketch lr: 0.000549\n",
      "batch 266 loss: 1.27190 acc: 0.70736 | v_loss: 1.40994 v_acc: 0.71647 |  iteration: 6482 teacher: 1 stage: sketch lr: 0.000549\n",
      "batch 267 loss: 1.32854 acc: 0.69727 | v_loss: 1.19400 v_acc: 0.69987 |  iteration: 6483 teacher: 1 stage: sketch lr: 0.000549\n",
      "batch 268 loss: 1.29298 acc: 0.71257 | v_loss: 1.20489 v_acc: 0.70345 |  iteration: 6484 teacher: 0 stage: sketch lr: 0.000549\n",
      "batch 269 loss: 1.28149 acc: 0.70671 | v_loss: 1.26988 v_acc: 0.70312 |  iteration: 6485 teacher: 1 stage: sketch lr: 0.000549\n",
      "batch 270 loss: 1.49106 acc: 0.68717 | v_loss: 1.28453 v_acc: 0.70182 |  iteration: 6486 teacher: 1 stage: sketch lr: 0.000549\n",
      "batch 271 loss: 1.37684 acc: 0.70052 | v_loss: 1.33862 v_acc: 0.69759 |  iteration: 6487 teacher: 1 stage: sketch lr: 0.000549\n",
      "batch 272 loss: 1.34234 acc: 0.70312 | v_loss: 1.36779 v_acc: 0.70736 |  iteration: 6488 teacher: 1 stage: sketch lr: 0.000549\n",
      "batch 273 loss: 1.21952 acc: 0.71582 | v_loss: 1.31595 v_acc: 0.70215 |  iteration: 6489 teacher: 0 stage: sketch lr: 0.000549\n",
      "batch 274 loss: 1.31957 acc: 0.70475 | v_loss: 1.22477 v_acc: 0.71484 |  iteration: 6490 teacher: 1 stage: sketch lr: 0.000549\n",
      "batch 275 loss: 1.31640 acc: 0.71094 | v_loss: 1.31947 v_acc: 0.70215 |  iteration: 6491 teacher: 0 stage: sketch lr: 0.000549\n",
      "batch 276 loss: 1.35150 acc: 0.70671 | v_loss: 1.25168 v_acc: 0.71126 |  iteration: 6492 teacher: 1 stage: sketch lr: 0.000548\n",
      "batch 277 loss: 1.35875 acc: 0.69954 | v_loss: 1.15274 v_acc: 0.72721 |  iteration: 6493 teacher: 0 stage: sketch lr: 0.000548\n",
      "batch 278 loss: 1.32988 acc: 0.71094 | v_loss: 1.17054 v_acc: 0.70605 |  iteration: 6494 teacher: 1 stage: sketch lr: 0.000548\n",
      "batch 279 loss: 1.34801 acc: 0.70378 | v_loss: 1.27150 v_acc: 0.70150 |  iteration: 6495 teacher: 1 stage: sketch lr: 0.000548\n",
      "batch 280 loss: 1.36818 acc: 0.69922 | v_loss: 1.33110 v_acc: 0.70312 |  iteration: 6496 teacher: 1 stage: sketch lr: 0.000548\n",
      "batch 281 loss: 1.35890 acc: 0.69824 | v_loss: 1.19291 v_acc: 0.70443 |  iteration: 6497 teacher: 0 stage: sketch lr: 0.000548\n",
      "batch 282 loss: 1.39440 acc: 0.69434 | v_loss: 1.20708 v_acc: 0.69368 |  iteration: 6498 teacher: 0 stage: sketch lr: 0.000548\n",
      "batch 283 loss: 1.31169 acc: 0.70117 | v_loss: 1.19559 v_acc: 0.70573 |  iteration: 6499 teacher: 0 stage: sketch lr: 0.000548\n",
      "batch 284 loss: 1.36006 acc: 0.69987 | v_loss: 1.19981 v_acc: 0.70540 |  iteration: 6500 teacher: 1 stage: sketch lr: 0.000548\n",
      "batch 285 loss: 1.31823 acc: 0.70182 | v_loss: 1.08059 v_acc: 0.73372 |  iteration: 6501 teacher: 0 stage: sketch lr: 0.000548\n",
      "batch 286 loss: 1.27336 acc: 0.70345 | v_loss: 1.17033 v_acc: 0.72135 |  iteration: 6502 teacher: 0 stage: sketch lr: 0.000548\n",
      "batch 287 loss: 1.31853 acc: 0.69531 | v_loss: 1.15725 v_acc: 0.70768 |  iteration: 6503 teacher: 1 stage: sketch lr: 0.000548\n",
      "batch 288 loss: 1.39078 acc: 0.69499 | v_loss: 1.12195 v_acc: 0.73210 |  iteration: 6504 teacher: 0 stage: sketch lr: 0.000548\n",
      "batch 289 loss: 1.30671 acc: 0.70573 | v_loss: 1.21236 v_acc: 0.71582 |  iteration: 6505 teacher: 1 stage: sketch lr: 0.000548\n",
      "batch 290 loss: 1.25221 acc: 0.71126 | v_loss: 1.22670 v_acc: 0.71745 |  iteration: 6506 teacher: 0 stage: sketch lr: 0.000548\n",
      "batch 291 loss: 1.35464 acc: 0.69531 | v_loss: 1.21004 v_acc: 0.72721 |  iteration: 6507 teacher: 0 stage: sketch lr: 0.000548\n",
      "batch 292 loss: 1.41733 acc: 0.68652 | v_loss: 1.40882 v_acc: 0.69466 |  iteration: 6508 teacher: 0 stage: sketch lr: 0.000548\n",
      "batch 293 loss: 1.25971 acc: 0.71257 | v_loss: 1.26676 v_acc: 0.72233 |  iteration: 6509 teacher: 1 stage: sketch lr: 0.000548\n",
      "batch 294 loss: 1.26784 acc: 0.70768 | v_loss: 1.07031 v_acc: 0.74186 |  iteration: 6510 teacher: 0 stage: sketch lr: 0.000548\n",
      "batch 295 loss: 1.20863 acc: 0.71777 | v_loss: 1.24361 v_acc: 0.70085 |  iteration: 6511 teacher: 1 stage: sketch lr: 0.000548\n",
      "batch 296 loss: 1.29186 acc: 0.70280 | v_loss: 1.27998 v_acc: 0.69987 |  iteration: 6512 teacher: 0 stage: sketch lr: 0.000548\n",
      "batch 297 loss: 1.32774 acc: 0.69499 | v_loss: 1.20089 v_acc: 0.70605 |  iteration: 6513 teacher: 0 stage: sketch lr: 0.000548\n",
      "batch 298 loss: 1.25760 acc: 0.71029 | v_loss: 1.25420 v_acc: 0.71257 |  iteration: 6514 teacher: 1 stage: sketch lr: 0.000548\n",
      "batch 299 loss: 1.29531 acc: 0.70378 | v_loss: 1.25197 v_acc: 0.69108 |  iteration: 6515 teacher: 0 stage: sketch lr: 0.000548\n",
      "batch 300 loss: 1.26036 acc: 0.70020 | v_loss: 1.21890 v_acc: 0.71549 |  iteration: 6516 teacher: 0 stage: sketch lr: 0.000547\n",
      "batch 301 loss: 1.35783 acc: 0.70378 | v_loss: 1.24873 v_acc: 0.69792 |  iteration: 6517 teacher: 1 stage: sketch lr: 0.000547\n",
      "batch 302 loss: 1.38079 acc: 0.68717 | v_loss: 1.19495 v_acc: 0.71777 |  iteration: 6518 teacher: 0 stage: sketch lr: 0.000547\n",
      "batch 303 loss: 1.28596 acc: 0.70117 | v_loss: 1.18884 v_acc: 0.72624 |  iteration: 6519 teacher: 1 stage: sketch lr: 0.000547\n",
      "batch 304 loss: 1.32692 acc: 0.70215 | v_loss: 1.25018 v_acc: 0.70410 |  iteration: 6520 teacher: 0 stage: sketch lr: 0.000547\n",
      "batch 305 loss: 1.21376 acc: 0.70573 | v_loss: 1.34311 v_acc: 0.69889 |  iteration: 6521 teacher: 0 stage: sketch lr: 0.000547\n",
      "batch 306 loss: 1.27490 acc: 0.70410 | v_loss: 1.15911 v_acc: 0.71029 |  iteration: 6522 teacher: 1 stage: sketch lr: 0.000547\n",
      "batch 307 loss: 1.24858 acc: 0.71029 | v_loss: 1.42697 v_acc: 0.68424 |  iteration: 6523 teacher: 0 stage: sketch lr: 0.000547\n",
      "batch 308 loss: 1.37282 acc: 0.69564 | v_loss: 1.17443 v_acc: 0.72363 |  iteration: 6524 teacher: 1 stage: sketch lr: 0.000547\n",
      "batch 309 loss: 1.28214 acc: 0.70280 | v_loss: 1.50312 v_acc: 0.67969 |  iteration: 6525 teacher: 0 stage: sketch lr: 0.000547\n",
      "batch 310 loss: 1.41380 acc: 0.68945 | v_loss: 1.39733 v_acc: 0.69596 |  iteration: 6526 teacher: 1 stage: sketch lr: 0.000547\n",
      "batch 311 loss: 1.40657 acc: 0.70020 | v_loss: 1.33074 v_acc: 0.69271 |  iteration: 6527 teacher: 1 stage: sketch lr: 0.000547\n",
      "batch 312 loss: 1.30311 acc: 0.69824 | v_loss: 1.34022 v_acc: 0.69694 |  iteration: 6528 teacher: 0 stage: sketch lr: 0.000547\n",
      "batch 313 loss: 1.34530 acc: 0.69759 | v_loss: 1.24103 v_acc: 0.70703 |  iteration: 6529 teacher: 0 stage: sketch lr: 0.000547\n",
      "batch 314 loss: 1.29368 acc: 0.70605 | v_loss: 1.28339 v_acc: 0.70378 |  iteration: 6530 teacher: 1 stage: sketch lr: 0.000547\n",
      "batch 315 loss: 1.29735 acc: 0.70052 | v_loss: 1.22843 v_acc: 0.71549 |  iteration: 6531 teacher: 0 stage: sketch lr: 0.000547\n",
      "batch 316 loss: 1.26695 acc: 0.70378 | v_loss: 1.40532 v_acc: 0.68848 |  iteration: 6532 teacher: 0 stage: sketch lr: 0.000547\n",
      "batch 317 loss: 1.26076 acc: 0.70638 | v_loss: 1.29566 v_acc: 0.70247 |  iteration: 6533 teacher: 0 stage: sketch lr: 0.000547\n",
      "batch 318 loss: 1.26567 acc: 0.71224 | v_loss: 1.21437 v_acc: 0.71126 |  iteration: 6534 teacher: 1 stage: sketch lr: 0.000547\n",
      "batch 319 loss: 1.31552 acc: 0.71549 | v_loss: 1.26809 v_acc: 0.71810 |  iteration: 6535 teacher: 0 stage: sketch lr: 0.000547\n",
      "batch 320 loss: 1.29589 acc: 0.70085 | v_loss: 1.17248 v_acc: 0.70378 |  iteration: 6536 teacher: 0 stage: sketch lr: 0.000547\n",
      "batch 321 loss: 1.35268 acc: 0.70280 | v_loss: 1.27482 v_acc: 0.69499 |  iteration: 6537 teacher: 0 stage: sketch lr: 0.000547\n",
      "batch 322 loss: 1.23067 acc: 0.71322 | v_loss: 1.23977 v_acc: 0.71191 |  iteration: 6538 teacher: 1 stage: sketch lr: 0.000547\n",
      "batch 323 loss: 1.32595 acc: 0.69792 | v_loss: 1.17307 v_acc: 0.72201 |  iteration: 6539 teacher: 0 stage: sketch lr: 0.000547\n",
      "batch 324 loss: 1.27585 acc: 0.70866 | v_loss: 1.13840 v_acc: 0.72298 |  iteration: 6540 teacher: 0 stage: sketch lr: 0.000546\n",
      "batch 325 loss: 1.25552 acc: 0.71289 | v_loss: 1.25669 v_acc: 0.71940 |  iteration: 6541 teacher: 0 stage: sketch lr: 0.000546\n",
      "batch 326 loss: 1.19875 acc: 0.71908 | v_loss: 1.25318 v_acc: 0.70475 |  iteration: 6542 teacher: 0 stage: sketch lr: 0.000546\n",
      "batch 327 loss: 1.31208 acc: 0.70052 | v_loss: 1.25352 v_acc: 0.71159 |  iteration: 6543 teacher: 0 stage: sketch lr: 0.000546\n",
      "batch 328 loss: 1.28515 acc: 0.71387 | v_loss: 1.11291 v_acc: 0.72331 |  iteration: 6544 teacher: 0 stage: sketch lr: 0.000546\n",
      "batch 329 loss: 1.29582 acc: 0.69987 | v_loss: 1.24978 v_acc: 0.73307 |  iteration: 6545 teacher: 0 stage: sketch lr: 0.000546\n",
      "batch 330 loss: 1.31526 acc: 0.70996 | v_loss: 1.31078 v_acc: 0.69499 |  iteration: 6546 teacher: 0 stage: sketch lr: 0.000546\n",
      "batch 331 loss: 1.26764 acc: 0.70671 | v_loss: 1.31533 v_acc: 0.72005 |  iteration: 6547 teacher: 0 stage: sketch lr: 0.000546\n",
      "batch 332 loss: 1.25741 acc: 0.70312 | v_loss: 1.17249 v_acc: 0.71615 |  iteration: 6548 teacher: 0 stage: sketch lr: 0.000546\n",
      "batch 333 loss: 1.27051 acc: 0.70833 | v_loss: 1.11966 v_acc: 0.73242 |  iteration: 6549 teacher: 1 stage: sketch lr: 0.000546\n",
      "batch 334 loss: 1.28104 acc: 0.70280 | v_loss: 1.10756 v_acc: 0.71908 |  iteration: 6550 teacher: 0 stage: sketch lr: 0.000546\n",
      "batch 335 loss: 1.27557 acc: 0.70508 | v_loss: 1.19358 v_acc: 0.70833 |  iteration: 6551 teacher: 0 stage: sketch lr: 0.000546\n",
      "batch 336 loss: 1.32664 acc: 0.70703 | v_loss: 1.23049 v_acc: 0.70345 |  iteration: 6552 teacher: 0 stage: sketch lr: 0.000546\n",
      "batch 337 loss: 1.37743 acc: 0.69434 | v_loss: 1.21773 v_acc: 0.71322 |  iteration: 6553 teacher: 1 stage: sketch lr: 0.000546\n",
      "batch 338 loss: 1.32144 acc: 0.69922 | v_loss: 1.36299 v_acc: 0.70475 |  iteration: 6554 teacher: 1 stage: sketch lr: 0.000546\n",
      "batch 339 loss: 1.30350 acc: 0.70182 | v_loss: 1.48486 v_acc: 0.69010 |  iteration: 6555 teacher: 1 stage: sketch lr: 0.000546\n",
      "batch 340 loss: 1.30538 acc: 0.70247 | v_loss: 1.35308 v_acc: 0.69466 |  iteration: 6556 teacher: 1 stage: sketch lr: 0.000546\n",
      "batch 341 loss: 1.31450 acc: 0.69857 | v_loss: 1.19906 v_acc: 0.72168 |  iteration: 6557 teacher: 0 stage: sketch lr: 0.000546\n",
      "batch 342 loss: 1.23094 acc: 0.70866 | v_loss: 1.15335 v_acc: 0.70573 |  iteration: 6558 teacher: 0 stage: sketch lr: 0.000546\n",
      "batch 343 loss: 1.21933 acc: 0.71517 | v_loss: 1.16624 v_acc: 0.71615 |  iteration: 6559 teacher: 0 stage: sketch lr: 0.000546\n",
      "batch 344 loss: 1.26351 acc: 0.71094 | v_loss: 1.21319 v_acc: 0.70247 |  iteration: 6560 teacher: 0 stage: sketch lr: 0.000546\n",
      "batch 345 loss: 1.27435 acc: 0.70378 | v_loss: 1.25614 v_acc: 0.71875 |  iteration: 6561 teacher: 0 stage: sketch lr: 0.000546\n",
      "batch 346 loss: 1.27113 acc: 0.70964 | v_loss: 1.21078 v_acc: 0.73145 |  iteration: 6562 teacher: 1 stage: sketch lr: 0.000546\n",
      "batch 347 loss: 1.21386 acc: 0.71582 | v_loss: 1.24360 v_acc: 0.71842 |  iteration: 6563 teacher: 0 stage: sketch lr: 0.000546\n",
      "batch 348 loss: 1.22215 acc: 0.71517 | v_loss: 1.24146 v_acc: 0.70768 |  iteration: 6564 teacher: 1 stage: sketch lr: 0.000545\n",
      "batch 349 loss: 1.33907 acc: 0.69531 | v_loss: 1.16564 v_acc: 0.72461 |  iteration: 6565 teacher: 0 stage: sketch lr: 0.000545\n",
      "batch 350 loss: 1.29956 acc: 0.70801 | v_loss: 1.13264 v_acc: 0.72070 |  iteration: 6566 teacher: 0 stage: sketch lr: 0.000545\n",
      "batch 351 loss: 1.30640 acc: 0.70410 | v_loss: 1.44996 v_acc: 0.69108 |  iteration: 6567 teacher: 1 stage: sketch lr: 0.000545\n",
      "batch 352 loss: 1.22398 acc: 0.71094 | v_loss: 1.21224 v_acc: 0.71289 |  iteration: 6568 teacher: 1 stage: sketch lr: 0.000545\n",
      "batch 353 loss: 1.29029 acc: 0.70736 | v_loss: 1.21985 v_acc: 0.71875 |  iteration: 6569 teacher: 1 stage: sketch lr: 0.000545\n",
      "batch 354 loss: 1.29303 acc: 0.70443 | v_loss: 1.23214 v_acc: 0.70312 |  iteration: 6570 teacher: 1 stage: sketch lr: 0.000545\n",
      "batch 355 loss: 1.34973 acc: 0.69564 | v_loss: 1.29453 v_acc: 0.69922 |  iteration: 6571 teacher: 1 stage: sketch lr: 0.000545\n",
      "batch 356 loss: 1.22531 acc: 0.71159 | v_loss: 1.13648 v_acc: 0.73079 |  iteration: 6572 teacher: 0 stage: sketch lr: 0.000545\n",
      "batch 357 loss: 1.32684 acc: 0.69401 | v_loss: 1.37064 v_acc: 0.71289 |  iteration: 6573 teacher: 1 stage: sketch lr: 0.000545\n",
      "batch 358 loss: 1.26175 acc: 0.69857 | v_loss: 1.22053 v_acc: 0.69727 |  iteration: 6574 teacher: 0 stage: sketch lr: 0.000545\n",
      "batch 359 loss: 1.26699 acc: 0.70020 | v_loss: 1.22182 v_acc: 0.69922 |  iteration: 6575 teacher: 0 stage: sketch lr: 0.000545\n",
      "batch 360 loss: 1.29468 acc: 0.70085 | v_loss: 1.26020 v_acc: 0.70378 |  iteration: 6576 teacher: 0 stage: sketch lr: 0.000545\n",
      "batch 361 loss: 1.25958 acc: 0.70020 | v_loss: 1.26894 v_acc: 0.70085 |  iteration: 6577 teacher: 0 stage: sketch lr: 0.000545\n",
      "batch 362 loss: 1.28083 acc: 0.70573 | v_loss: 1.33132 v_acc: 0.69271 |  iteration: 6578 teacher: 1 stage: sketch lr: 0.000545\n",
      "batch 363 loss: 1.29882 acc: 0.69564 | v_loss: 1.36692 v_acc: 0.70736 |  iteration: 6579 teacher: 0 stage: sketch lr: 0.000545\n",
      "batch 364 loss: 1.33193 acc: 0.69922 | v_loss: 1.28784 v_acc: 0.70540 |  iteration: 6580 teacher: 1 stage: sketch lr: 0.000545\n",
      "batch 365 loss: 1.32160 acc: 0.69434 | v_loss: 1.21973 v_acc: 0.70475 |  iteration: 6581 teacher: 1 stage: sketch lr: 0.000545\n",
      "batch 366 loss: 1.33184 acc: 0.69922 | v_loss: 1.31367 v_acc: 0.70312 |  iteration: 6582 teacher: 1 stage: sketch lr: 0.000545\n",
      "batch 367 loss: 1.27192 acc: 0.71549 | v_loss: 1.20962 v_acc: 0.71257 |  iteration: 6583 teacher: 1 stage: sketch lr: 0.000545\n",
      "batch 368 loss: 1.32455 acc: 0.69238 | v_loss: 1.16042 v_acc: 0.72363 |  iteration: 6584 teacher: 0 stage: sketch lr: 0.000545\n",
      "batch 369 loss: 1.31693 acc: 0.70638 | v_loss: 1.12491 v_acc: 0.70638 |  iteration: 6585 teacher: 1 stage: sketch lr: 0.000545\n",
      "batch 370 loss: 1.27913 acc: 0.70573 | v_loss: 1.25823 v_acc: 0.70378 |  iteration: 6586 teacher: 0 stage: sketch lr: 0.000545\n",
      "batch 371 loss: 1.27461 acc: 0.70638 | v_loss: 1.32990 v_acc: 0.69824 |  iteration: 6587 teacher: 0 stage: sketch lr: 0.000545\n",
      "batch 372 loss: 1.37069 acc: 0.69889 | v_loss: 1.14760 v_acc: 0.71484 |  iteration: 6588 teacher: 1 stage: sketch lr: 0.000544\n",
      "batch 373 loss: 1.25732 acc: 0.70475 | v_loss: 1.20298 v_acc: 0.70280 |  iteration: 6589 teacher: 0 stage: sketch lr: 0.000544\n",
      "batch 374 loss: 1.25808 acc: 0.71224 | v_loss: 1.18532 v_acc: 0.71419 |  iteration: 6590 teacher: 0 stage: sketch lr: 0.000544\n",
      "batch 375 loss: 1.31885 acc: 0.70150 | v_loss: 1.21023 v_acc: 0.70508 |  iteration: 6591 teacher: 1 stage: sketch lr: 0.000544\n",
      "batch 376 loss: 1.20264 acc: 0.71452 | v_loss: 1.06900 v_acc: 0.73926 |  iteration: 6592 teacher: 1 stage: sketch lr: 0.000544\n",
      "batch 377 loss: 1.23632 acc: 0.70605 | v_loss: 1.17857 v_acc: 0.71582 |  iteration: 6593 teacher: 1 stage: sketch lr: 0.000544\n",
      "batch 378 loss: 1.31364 acc: 0.69564 | v_loss: 1.17097 v_acc: 0.70703 |  iteration: 6594 teacher: 0 stage: sketch lr: 0.000544\n",
      "batch 379 loss: 1.21073 acc: 0.71452 | v_loss: 1.11696 v_acc: 0.73242 |  iteration: 6595 teacher: 0 stage: sketch lr: 0.000544\n",
      "batch 380 loss: 1.28513 acc: 0.70801 | v_loss: 1.21027 v_acc: 0.71452 |  iteration: 6596 teacher: 0 stage: sketch lr: 0.000544\n",
      "batch 381 loss: 1.32285 acc: 0.71159 | v_loss: 1.23519 v_acc: 0.71191 |  iteration: 6597 teacher: 1 stage: sketch lr: 0.000544\n",
      "batch 382 loss: 1.31201 acc: 0.70378 | v_loss: 1.21402 v_acc: 0.72298 |  iteration: 6598 teacher: 1 stage: sketch lr: 0.000544\n",
      "batch 383 loss: 1.28531 acc: 0.69792 | v_loss: 1.38293 v_acc: 0.70052 |  iteration: 6599 teacher: 0 stage: sketch lr: 0.000544\n",
      "batch 384 loss: 1.26234 acc: 0.70866 | v_loss: 1.26283 v_acc: 0.71810 |  iteration: 6600 teacher: 0 stage: sketch lr: 0.000544\n",
      "batch 385 loss: 1.28345 acc: 0.70573 | v_loss: 1.05131 v_acc: 0.74577 |  iteration: 6601 teacher: 1 stage: sketch lr: 0.000544\n",
      "batch 386 loss: 1.36659 acc: 0.69368 | v_loss: 1.22838 v_acc: 0.70833 |  iteration: 6602 teacher: 0 stage: sketch lr: 0.000544\n",
      "batch 387 loss: 1.31334 acc: 0.70671 | v_loss: 1.26527 v_acc: 0.69922 |  iteration: 6603 teacher: 1 stage: sketch lr: 0.000544\n",
      "batch 388 loss: 1.29545 acc: 0.70996 | v_loss: 1.23065 v_acc: 0.70508 |  iteration: 6604 teacher: 1 stage: sketch lr: 0.000544\n",
      "batch 389 loss: 1.32275 acc: 0.70117 | v_loss: 1.26236 v_acc: 0.71094 |  iteration: 6605 teacher: 1 stage: sketch lr: 0.000544\n",
      "batch 390 loss: 1.26909 acc: 0.71257 | v_loss: 1.25956 v_acc: 0.69303 |  iteration: 6606 teacher: 1 stage: sketch lr: 0.000544\n",
      "batch 391 loss: 1.23528 acc: 0.70671 | v_loss: 1.24409 v_acc: 0.70801 |  iteration: 6607 teacher: 1 stage: sketch lr: 0.000544\n",
      "batch 392 loss: 1.29381 acc: 0.70182 | v_loss: 1.26075 v_acc: 0.69206 |  iteration: 6608 teacher: 0 stage: sketch lr: 0.000544\n",
      "batch 393 loss: 1.25803 acc: 0.71615 | v_loss: 1.18600 v_acc: 0.70768 |  iteration: 6609 teacher: 1 stage: sketch lr: 0.000544\n",
      "batch 394 loss: 1.26868 acc: 0.71647 | v_loss: 1.17685 v_acc: 0.72201 |  iteration: 6610 teacher: 0 stage: sketch lr: 0.000544\n",
      "batch 395 loss: 1.30963 acc: 0.71224 | v_loss: 1.26776 v_acc: 0.70312 |  iteration: 6611 teacher: 1 stage: sketch lr: 0.000544\n",
      "batch 396 loss: 1.35826 acc: 0.69499 | v_loss: 1.33593 v_acc: 0.70085 |  iteration: 6612 teacher: 1 stage: sketch lr: 0.000543\n",
      "batch 397 loss: 1.25495 acc: 0.71159 | v_loss: 1.17416 v_acc: 0.70703 |  iteration: 6613 teacher: 1 stage: sketch lr: 0.000543\n",
      "batch 398 loss: 1.26656 acc: 0.70085 | v_loss: 1.41073 v_acc: 0.68880 |  iteration: 6614 teacher: 1 stage: sketch lr: 0.000543\n",
      "batch 399 loss: 1.28402 acc: 0.71842 | v_loss: 1.17517 v_acc: 0.72266 |  iteration: 6615 teacher: 0 stage: sketch lr: 0.000543\n",
      "batch 400 loss: 1.27710 acc: 0.70964 | v_loss: 1.49901 v_acc: 0.67839 |  iteration: 6616 teacher: 1 stage: sketch lr: 0.000543\n",
      "batch 401 loss: 1.18576 acc: 0.70931 | v_loss: 1.37679 v_acc: 0.69629 |  iteration: 6617 teacher: 1 stage: sketch lr: 0.000543\n",
      "batch 402 loss: 1.34909 acc: 0.69564 | v_loss: 1.32593 v_acc: 0.69206 |  iteration: 6618 teacher: 1 stage: sketch lr: 0.000543\n",
      "batch 403 loss: 1.17250 acc: 0.71582 | v_loss: 1.31851 v_acc: 0.69792 |  iteration: 6619 teacher: 1 stage: sketch lr: 0.000543\n",
      "batch 404 loss: 1.22811 acc: 0.71159 | v_loss: 1.21338 v_acc: 0.70605 |  iteration: 6620 teacher: 1 stage: sketch lr: 0.000543\n",
      "batch 405 loss: 1.33432 acc: 0.70247 | v_loss: 1.26542 v_acc: 0.70443 |  iteration: 6621 teacher: 0 stage: sketch lr: 0.000543\n",
      "batch 406 loss: 1.28591 acc: 0.70345 | v_loss: 1.22636 v_acc: 0.71810 |  iteration: 6622 teacher: 0 stage: sketch lr: 0.000543\n",
      "batch 407 loss: 1.23297 acc: 0.70312 | v_loss: 1.43322 v_acc: 0.69010 |  iteration: 6623 teacher: 0 stage: sketch lr: 0.000543\n",
      "batch 408 loss: 1.35436 acc: 0.69108 | v_loss: 1.31654 v_acc: 0.71061 |  iteration: 6624 teacher: 0 stage: sketch lr: 0.000543\n",
      "batch 409 loss: 1.35239 acc: 0.69792 | v_loss: 1.18002 v_acc: 0.71094 |  iteration: 6625 teacher: 0 stage: sketch lr: 0.000543\n",
      "batch 410 loss: 1.22678 acc: 0.70638 | v_loss: 1.26058 v_acc: 0.71582 |  iteration: 6626 teacher: 1 stage: sketch lr: 0.000543\n",
      "batch 411 loss: 1.32589 acc: 0.69954 | v_loss: 1.17229 v_acc: 0.70605 |  iteration: 6627 teacher: 0 stage: sketch lr: 0.000543\n",
      "batch 412 loss: 1.27415 acc: 0.70573 | v_loss: 1.28906 v_acc: 0.69759 |  iteration: 6628 teacher: 1 stage: sketch lr: 0.000543\n",
      "batch 413 loss: 1.30902 acc: 0.69727 | v_loss: 1.25048 v_acc: 0.71191 |  iteration: 6629 teacher: 1 stage: sketch lr: 0.000543\n",
      "batch 414 loss: 1.28870 acc: 0.69954 | v_loss: 1.16702 v_acc: 0.72005 |  iteration: 6630 teacher: 1 stage: sketch lr: 0.000543\n",
      "batch 415 loss: 1.27998 acc: 0.70378 | v_loss: 1.14602 v_acc: 0.72786 |  iteration: 6631 teacher: 1 stage: sketch lr: 0.000543\n",
      "batch 416 loss: 1.18473 acc: 0.71908 | v_loss: 1.27383 v_acc: 0.71810 |  iteration: 6632 teacher: 1 stage: sketch lr: 0.000543\n",
      "batch 417 loss: 1.34538 acc: 0.70085 | v_loss: 1.25397 v_acc: 0.70280 |  iteration: 6633 teacher: 1 stage: sketch lr: 0.000543\n",
      "batch 418 loss: 1.24715 acc: 0.71582 | v_loss: 1.26401 v_acc: 0.71257 |  iteration: 6634 teacher: 1 stage: sketch lr: 0.000543\n",
      "batch 419 loss: 1.31551 acc: 0.69889 | v_loss: 1.10263 v_acc: 0.72493 |  iteration: 6635 teacher: 1 stage: sketch lr: 0.000543\n",
      "batch 420 loss: 1.33936 acc: 0.69336 | v_loss: 1.23957 v_acc: 0.73372 |  iteration: 6636 teacher: 0 stage: sketch lr: 0.000543\n",
      "batch 421 loss: 1.31754 acc: 0.70736 | v_loss: 1.30621 v_acc: 0.69596 |  iteration: 6637 teacher: 0 stage: sketch lr: 0.000542\n",
      "batch 422 loss: 1.35352 acc: 0.69531 | v_loss: 1.33199 v_acc: 0.72168 |  iteration: 6638 teacher: 1 stage: sketch lr: 0.000542\n",
      "batch 423 loss: 1.22206 acc: 0.70573 | v_loss: 1.17621 v_acc: 0.71257 |  iteration: 6639 teacher: 0 stage: sketch lr: 0.000542\n",
      "batch 424 loss: 1.24616 acc: 0.70736 | v_loss: 1.13629 v_acc: 0.72591 |  iteration: 6640 teacher: 0 stage: sketch lr: 0.000542\n",
      "batch 425 loss: 1.34172 acc: 0.69596 | v_loss: 1.10799 v_acc: 0.71875 |  iteration: 6641 teacher: 1 stage: sketch lr: 0.000542\n",
      "batch 426 loss: 1.22767 acc: 0.70833 | v_loss: 1.20612 v_acc: 0.70605 |  iteration: 6642 teacher: 0 stage: sketch lr: 0.000542\n",
      "batch 427 loss: 1.28842 acc: 0.70605 | v_loss: 1.23951 v_acc: 0.70247 |  iteration: 6643 teacher: 1 stage: sketch lr: 0.000542\n",
      "batch 428 loss: 1.28386 acc: 0.70996 | v_loss: 1.20364 v_acc: 0.71224 |  iteration: 6644 teacher: 1 stage: sketch lr: 0.000542\n",
      "batch 429 loss: 1.23596 acc: 0.71387 | v_loss: 1.30383 v_acc: 0.71842 |  iteration: 6645 teacher: 1 stage: sketch lr: 0.000542\n",
      "batch 430 loss: 1.44338 acc: 0.69596 | v_loss: 1.47001 v_acc: 0.69206 |  iteration: 6646 teacher: 0 stage: sketch lr: 0.000542\n",
      "batch 431 loss: 1.33632 acc: 0.69499 | v_loss: 1.34697 v_acc: 0.69922 |  iteration: 6647 teacher: 0 stage: sketch lr: 0.000542\n",
      "batch 432 loss: 1.34360 acc: 0.70312 | v_loss: 1.19527 v_acc: 0.72266 |  iteration: 6648 teacher: 1 stage: sketch lr: 0.000542\n",
      "batch 433 loss: 1.30554 acc: 0.69466 | v_loss: 1.16418 v_acc: 0.70703 |  iteration: 6649 teacher: 1 stage: sketch lr: 0.000542\n",
      "batch 434 loss: 1.25495 acc: 0.71549 | v_loss: 1.15930 v_acc: 0.72168 |  iteration: 6650 teacher: 1 stage: sketch lr: 0.000542\n",
      "batch 435 loss: 1.36516 acc: 0.69303 | v_loss: 1.23742 v_acc: 0.70150 |  iteration: 6651 teacher: 0 stage: sketch lr: 0.000542\n",
      "batch 436 loss: 1.24122 acc: 0.71159 | v_loss: 1.24684 v_acc: 0.71647 |  iteration: 6652 teacher: 0 stage: sketch lr: 0.000542\n",
      "batch 437 loss: 1.28477 acc: 0.70964 | v_loss: 1.21213 v_acc: 0.72624 |  iteration: 6653 teacher: 0 stage: sketch lr: 0.000542\n",
      "batch 438 loss: 1.32115 acc: 0.71159 | v_loss: 1.24008 v_acc: 0.71615 |  iteration: 6654 teacher: 0 stage: sketch lr: 0.000542\n",
      "batch 439 loss: 1.35372 acc: 0.69434 | v_loss: 1.23456 v_acc: 0.71908 |  iteration: 6655 teacher: 0 stage: sketch lr: 0.000542\n",
      "batch 440 loss: 1.32376 acc: 0.70540 | v_loss: 1.15454 v_acc: 0.72461 |  iteration: 6656 teacher: 1 stage: sketch lr: 0.000542\n",
      "batch 441 loss: 1.41070 acc: 0.68978 | v_loss: 1.14335 v_acc: 0.71940 |  iteration: 6657 teacher: 1 stage: sketch lr: 0.000542\n",
      "batch 442 loss: 1.27640 acc: 0.70801 | v_loss: 1.41071 v_acc: 0.68294 |  iteration: 6658 teacher: 1 stage: sketch lr: 0.000542\n",
      "batch 443 loss: 1.43784 acc: 0.69076 | v_loss: 1.23209 v_acc: 0.70931 |  iteration: 6659 teacher: 1 stage: sketch lr: 0.000542\n",
      "batch 444 loss: 1.32690 acc: 0.70020 | v_loss: 1.24369 v_acc: 0.70996 |  iteration: 6660 teacher: 1 stage: sketch lr: 0.000542\n",
      "batch 445 loss: 1.28957 acc: 0.70931 | v_loss: 1.23526 v_acc: 0.71582 |  iteration: 6661 teacher: 1 stage: sketch lr: 0.000541\n",
      "batch 446 loss: 1.30375 acc: 0.70605 | v_loss: 1.28550 v_acc: 0.70410 |  iteration: 6662 teacher: 0 stage: sketch lr: 0.000541\n",
      "batch 447 loss: 1.32336 acc: 0.70931 | v_loss: 1.15149 v_acc: 0.72884 |  iteration: 6663 teacher: 0 stage: sketch lr: 0.000541\n",
      "batch 448 loss: 1.29781 acc: 0.71029 | v_loss: 1.36112 v_acc: 0.71224 |  iteration: 6664 teacher: 1 stage: sketch lr: 0.000541\n",
      "batch 449 loss: 1.33681 acc: 0.70378 | v_loss: 1.21349 v_acc: 0.69531 |  iteration: 6665 teacher: 1 stage: sketch lr: 0.000541\n",
      "batch 450 loss: 1.28136 acc: 0.69271 | v_loss: 1.21814 v_acc: 0.70117 |  iteration: 6666 teacher: 1 stage: sketch lr: 0.000541\n",
      "batch 451 loss: 1.28202 acc: 0.71875 | v_loss: 1.26833 v_acc: 0.70573 |  iteration: 6667 teacher: 0 stage: sketch lr: 0.000541\n",
      "batch 452 loss: 1.24791 acc: 0.72559 | v_loss: 1.27709 v_acc: 0.70150 |  iteration: 6668 teacher: 0 stage: sketch lr: 0.000541\n",
      "batch 453 loss: 1.31279 acc: 0.70280 | v_loss: 1.33413 v_acc: 0.69368 |  iteration: 6669 teacher: 0 stage: sketch lr: 0.000541\n",
      "batch 454 loss: 1.30779 acc: 0.71159 | v_loss: 1.36511 v_acc: 0.70833 |  iteration: 6670 teacher: 0 stage: sketch lr: 0.000541\n",
      "batch 455 loss: 1.37545 acc: 0.69661 | v_loss: 1.28982 v_acc: 0.70117 |  iteration: 6671 teacher: 0 stage: sketch lr: 0.000541\n",
      "batch 456 loss: 1.24835 acc: 0.71615 | v_loss: 1.18453 v_acc: 0.70996 |  iteration: 6672 teacher: 0 stage: sketch lr: 0.000541\n",
      "batch 457 loss: 1.25951 acc: 0.71777 | v_loss: 1.33613 v_acc: 0.70312 |  iteration: 6673 teacher: 0 stage: sketch lr: 0.000541\n",
      "batch 458 loss: 1.29464 acc: 0.69889 | v_loss: 1.23388 v_acc: 0.71126 |  iteration: 6674 teacher: 0 stage: sketch lr: 0.000541\n",
      "batch 459 loss: 1.26808 acc: 0.70638 | v_loss: 1.14980 v_acc: 0.72624 |  iteration: 6675 teacher: 0 stage: sketch lr: 0.000541\n",
      "batch 460 loss: 1.23262 acc: 0.71029 | v_loss: 1.14404 v_acc: 0.70345 |  iteration: 6676 teacher: 1 stage: sketch lr: 0.000541\n",
      "batch 461 loss: 1.31020 acc: 0.70247 | v_loss: 1.26980 v_acc: 0.70573 |  iteration: 6677 teacher: 0 stage: sketch lr: 0.000541\n",
      "batch 462 loss: 1.21503 acc: 0.70866 | v_loss: 1.33935 v_acc: 0.69466 |  iteration: 6678 teacher: 1 stage: sketch lr: 0.000541\n",
      "batch 463 loss: 1.20080 acc: 0.70378 | v_loss: 1.16557 v_acc: 0.70833 |  iteration: 6679 teacher: 1 stage: sketch lr: 0.000541\n",
      "batch 464 loss: 1.33315 acc: 0.69466 | v_loss: 1.20014 v_acc: 0.70182 |  iteration: 6680 teacher: 0 stage: sketch lr: 0.000541\n",
      "batch 465 loss: 1.27136 acc: 0.71126 | v_loss: 1.17957 v_acc: 0.71191 |  iteration: 6681 teacher: 0 stage: sketch lr: 0.000541\n",
      "batch 466 loss: 1.25753 acc: 0.70605 | v_loss: 1.19492 v_acc: 0.70736 |  iteration: 6682 teacher: 1 stage: sketch lr: 0.000541\n",
      "batch 467 loss: 1.32987 acc: 0.70085 | v_loss: 1.06906 v_acc: 0.73991 |  iteration: 6683 teacher: 0 stage: sketch lr: 0.000541\n",
      "batch 468 loss: 1.38435 acc: 0.69108 | v_loss: 1.17352 v_acc: 0.71940 |  iteration: 6684 teacher: 1 stage: sketch lr: 0.000541\n",
      "batch 469 loss: 1.41868 acc: 0.69010 | v_loss: 1.13219 v_acc: 0.73633 |  iteration: 6685 teacher: 0 stage: sketch lr: 0.000541\n",
      "batch 470 loss: 1.21027 acc: 0.71842 | v_loss: 1.11468 v_acc: 0.72396 |  iteration: 6686 teacher: 1 stage: sketch lr: 0.000540\n",
      "batch 471 loss: 1.27579 acc: 0.70280 | v_loss: 1.19777 v_acc: 0.71745 |  iteration: 6687 teacher: 0 stage: sketch lr: 0.000540\n",
      "batch 472 loss: 1.39219 acc: 0.70378 | v_loss: 1.23356 v_acc: 0.71419 |  iteration: 6688 teacher: 1 stage: sketch lr: 0.000540\n",
      "batch 473 loss: 1.24796 acc: 0.70801 | v_loss: 1.20867 v_acc: 0.72526 |  iteration: 6689 teacher: 1 stage: sketch lr: 0.000540\n",
      "batch 474 loss: 1.33359 acc: 0.70378 | v_loss: 1.37604 v_acc: 0.69922 |  iteration: 6690 teacher: 0 stage: sketch lr: 0.000540\n",
      "batch 475 loss: 1.24799 acc: 0.70475 | v_loss: 1.26981 v_acc: 0.71680 |  iteration: 6691 teacher: 0 stage: sketch lr: 0.000540\n",
      "batch 476 loss: 1.33112 acc: 0.69466 | v_loss: 1.06968 v_acc: 0.74154 |  iteration: 6692 teacher: 0 stage: sketch lr: 0.000540\n",
      "batch 477 loss: 1.27183 acc: 0.69922 | v_loss: 1.23020 v_acc: 0.70280 |  iteration: 6693 teacher: 0 stage: sketch lr: 0.000540\n",
      "batch 478 loss: 1.22420 acc: 0.71354 | v_loss: 1.27084 v_acc: 0.69922 |  iteration: 6694 teacher: 0 stage: sketch lr: 0.000540\n",
      "batch 479 loss: 1.26264 acc: 0.70801 | v_loss: 1.21259 v_acc: 0.70573 |  iteration: 6695 teacher: 0 stage: sketch lr: 0.000540\n",
      "batch 480 loss: 1.22625 acc: 0.70931 | v_loss: 1.26095 v_acc: 0.71126 |  iteration: 6696 teacher: 0 stage: sketch lr: 0.000540\n",
      "batch 481 loss: 1.16806 acc: 0.72656 | v_loss: 1.25252 v_acc: 0.69303 |  iteration: 6697 teacher: 1 stage: sketch lr: 0.000540\n",
      "batch 482 loss: 1.29639 acc: 0.70312 | v_loss: 1.23783 v_acc: 0.71810 |  iteration: 6698 teacher: 0 stage: sketch lr: 0.000540\n",
      "batch 483 loss: 1.36577 acc: 0.69694 | v_loss: 1.26643 v_acc: 0.69954 |  iteration: 6699 teacher: 1 stage: sketch lr: 0.000540\n",
      "batch 484 loss: 1.27313 acc: 0.71257 | v_loss: 1.17183 v_acc: 0.72559 |  iteration: 6700 teacher: 1 stage: sketch lr: 0.000540\n",
      "batch 485 loss: 1.28982 acc: 0.70638 | v_loss: 1.18589 v_acc: 0.72266 |  iteration: 6701 teacher: 1 stage: sketch lr: 0.000540\n",
      "batch 486 loss: 1.28978 acc: 0.70280 | v_loss: 1.23676 v_acc: 0.70345 |  iteration: 6702 teacher: 0 stage: sketch lr: 0.000540\n",
      "batch 487 loss: 1.25311 acc: 0.70996 | v_loss: 1.36553 v_acc: 0.70020 |  iteration: 6703 teacher: 1 stage: sketch lr: 0.000540\n",
      "batch 488 loss: 1.26217 acc: 0.71517 | v_loss: 1.16265 v_acc: 0.70736 |  iteration: 6704 teacher: 1 stage: sketch lr: 0.000540\n",
      "batch 489 loss: 1.26582 acc: 0.71191 | v_loss: 1.42638 v_acc: 0.68750 |  iteration: 6705 teacher: 0 stage: sketch lr: 0.000540\n",
      "batch 490 loss: 1.34391 acc: 0.70508 | v_loss: 1.16861 v_acc: 0.72135 |  iteration: 6706 teacher: 1 stage: sketch lr: 0.000540\n",
      "batch 491 loss: 1.25066 acc: 0.71419 | v_loss: 1.48295 v_acc: 0.68717 |  iteration: 6707 teacher: 1 stage: sketch lr: 0.000540\n",
      "batch 492 loss: 1.23755 acc: 0.71224 | v_loss: 1.37747 v_acc: 0.69922 |  iteration: 6708 teacher: 0 stage: sketch lr: 0.000540\n",
      "batch 493 loss: 1.37738 acc: 0.69564 | v_loss: 1.33643 v_acc: 0.68978 |  iteration: 6709 teacher: 0 stage: sketch lr: 0.000540\n",
      "batch 494 loss: 1.31850 acc: 0.69954 | v_loss: 1.31661 v_acc: 0.69727 |  iteration: 6710 teacher: 1 stage: sketch lr: 0.000540\n",
      "batch 495 loss: 1.26230 acc: 0.71712 | v_loss: 1.24097 v_acc: 0.70378 |  iteration: 6711 teacher: 1 stage: sketch lr: 0.000539\n",
      "batch 496 loss: 1.30949 acc: 0.69857 | v_loss: 1.26346 v_acc: 0.70508 |  iteration: 6712 teacher: 0 stage: sketch lr: 0.000539\n",
      "batch 497 loss: 1.27884 acc: 0.70052 | v_loss: 1.21730 v_acc: 0.72038 |  iteration: 6713 teacher: 1 stage: sketch lr: 0.000539\n",
      "batch 498 loss: 1.30732 acc: 0.69954 | v_loss: 1.42422 v_acc: 0.68880 |  iteration: 6714 teacher: 0 stage: sketch lr: 0.000539\n",
      "batch 499 loss: 1.30598 acc: 0.70345 | v_loss: 1.29764 v_acc: 0.71224 |  iteration: 6715 teacher: 1 stage: sketch lr: 0.000539\n",
      "batch 500 loss: 1.25439 acc: 0.70768 | v_loss: 1.18861 v_acc: 0.70801 |  iteration: 6716 teacher: 0 stage: sketch lr: 0.000539\n",
      "batch 501 loss: 1.38146 acc: 0.69271 | v_loss: 1.27026 v_acc: 0.70866 |  iteration: 6717 teacher: 1 stage: sketch lr: 0.000539\n",
      "batch 502 loss: 1.33289 acc: 0.69727 | v_loss: 1.16683 v_acc: 0.71159 |  iteration: 6718 teacher: 1 stage: sketch lr: 0.000539\n",
      "batch 503 loss: 1.22357 acc: 0.71159 | v_loss: 1.26522 v_acc: 0.70117 |  iteration: 6719 teacher: 0 stage: sketch lr: 0.000539\n",
      "batch 504 loss: 1.31870 acc: 0.69759 | v_loss: 1.23506 v_acc: 0.71549 |  iteration: 6720 teacher: 0 stage: sketch lr: 0.000539\n",
      "batch 505 loss: 1.25070 acc: 0.70508 | v_loss: 1.17316 v_acc: 0.72038 |  iteration: 6721 teacher: 0 stage: sketch lr: 0.000539\n",
      "batch 506 loss: 1.26012 acc: 0.70312 | v_loss: 1.14390 v_acc: 0.72819 |  iteration: 6722 teacher: 0 stage: sketch lr: 0.000539\n",
      "batch 507 loss: 1.23953 acc: 0.71289 | v_loss: 1.25923 v_acc: 0.71940 |  iteration: 6723 teacher: 0 stage: sketch lr: 0.000539\n",
      "batch 508 loss: 1.26093 acc: 0.71159 | v_loss: 1.25784 v_acc: 0.70605 |  iteration: 6724 teacher: 0 stage: sketch lr: 0.000539\n",
      "batch 509 loss: 1.30381 acc: 0.70736 | v_loss: 1.27601 v_acc: 0.70931 |  iteration: 6725 teacher: 0 stage: sketch lr: 0.000539\n",
      "batch 510 loss: 1.36003 acc: 0.69889 | v_loss: 1.11383 v_acc: 0.72331 |  iteration: 6726 teacher: 1 stage: sketch lr: 0.000539\n",
      "batch 511 loss: 1.33820 acc: 0.70345 | v_loss: 1.24495 v_acc: 0.73145 |  iteration: 6727 teacher: 1 stage: sketch lr: 0.000539\n",
      "batch 512 loss: 1.23560 acc: 0.71549 | v_loss: 1.30316 v_acc: 0.69727 |  iteration: 6728 teacher: 1 stage: sketch lr: 0.000539\n",
      "batch 513 loss: 1.25534 acc: 0.70638 | v_loss: 1.29917 v_acc: 0.72298 |  iteration: 6729 teacher: 0 stage: sketch lr: 0.000539\n",
      "batch 514 loss: 1.38887 acc: 0.70020 | v_loss: 1.16989 v_acc: 0.71745 |  iteration: 6730 teacher: 1 stage: sketch lr: 0.000539\n",
      "batch 515 loss: 1.32443 acc: 0.70312 | v_loss: 1.12775 v_acc: 0.73079 |  iteration: 6731 teacher: 1 stage: sketch lr: 0.000539\n",
      "batch 516 loss: 1.30972 acc: 0.71061 | v_loss: 1.11495 v_acc: 0.72135 |  iteration: 6732 teacher: 1 stage: sketch lr: 0.000539\n",
      "batch 517 loss: 1.25706 acc: 0.71777 | v_loss: 1.21097 v_acc: 0.70605 |  iteration: 6733 teacher: 1 stage: sketch lr: 0.000539\n",
      "batch 518 loss: 1.29805 acc: 0.71126 | v_loss: 1.23376 v_acc: 0.69694 |  iteration: 6734 teacher: 1 stage: sketch lr: 0.000539\n",
      "batch 519 loss: 1.37780 acc: 0.69987 | v_loss: 1.21120 v_acc: 0.71224 |  iteration: 6735 teacher: 0 stage: sketch lr: 0.000539\n",
      "batch 520 loss: 1.31688 acc: 0.71419 | v_loss: 1.32209 v_acc: 0.71842 |  iteration: 6736 teacher: 0 stage: sketch lr: 0.000538\n",
      "batch 521 loss: 1.25685 acc: 0.71224 | v_loss: 1.45710 v_acc: 0.69043 |  iteration: 6737 teacher: 0 stage: sketch lr: 0.000538\n",
      "batch 522 loss: 1.29307 acc: 0.70703 | v_loss: 1.33675 v_acc: 0.69661 |  iteration: 6738 teacher: 1 stage: sketch lr: 0.000538\n",
      "batch 523 loss: 1.30114 acc: 0.69531 | v_loss: 1.19433 v_acc: 0.72624 |  iteration: 6739 teacher: 0 stage: sketch lr: 0.000538\n",
      "batch 524 loss: 1.30805 acc: 0.69661 | v_loss: 1.16531 v_acc: 0.70898 |  iteration: 6740 teacher: 1 stage: sketch lr: 0.000538\n",
      "batch 525 loss: 1.24471 acc: 0.71387 | v_loss: 1.16830 v_acc: 0.71973 |  iteration: 6741 teacher: 0 stage: sketch lr: 0.000538\n",
      "batch 526 loss: 1.33390 acc: 0.69954 | v_loss: 1.21595 v_acc: 0.70443 |  iteration: 6742 teacher: 1 stage: sketch lr: 0.000538\n",
      "batch 527 loss: 1.30427 acc: 0.69434 | v_loss: 1.25976 v_acc: 0.71875 |  iteration: 6743 teacher: 1 stage: sketch lr: 0.000538\n",
      "batch 528 loss: 1.27764 acc: 0.70215 | v_loss: 1.21112 v_acc: 0.73145 |  iteration: 6744 teacher: 0 stage: sketch lr: 0.000538\n",
      "batch 529 loss: 1.29917 acc: 0.70085 | v_loss: 1.23190 v_acc: 0.72005 |  iteration: 6745 teacher: 0 stage: sketch lr: 0.000538\n",
      "batch 530 loss: 1.19070 acc: 0.70410 | v_loss: 1.23478 v_acc: 0.71419 |  iteration: 6746 teacher: 1 stage: sketch lr: 0.000538\n",
      "batch 531 loss: 1.30403 acc: 0.70052 | v_loss: 1.16329 v_acc: 0.72428 |  iteration: 6747 teacher: 0 stage: sketch lr: 0.000538\n",
      "batch 532 loss: 1.34625 acc: 0.69824 | v_loss: 1.13301 v_acc: 0.72070 |  iteration: 6748 teacher: 0 stage: sketch lr: 0.000538\n",
      "batch 533 loss: 1.37702 acc: 0.69141 | v_loss: 1.46456 v_acc: 0.69206 |  iteration: 6749 teacher: 0 stage: sketch lr: 0.000538\n",
      "batch 534 loss: 1.21257 acc: 0.71842 | v_loss: 1.21009 v_acc: 0.71159 |  iteration: 6750 teacher: 1 stage: sketch lr: 0.000538\n",
      "batch 535 loss: 1.29445 acc: 0.69922 | v_loss: 1.22455 v_acc: 0.71680 |  iteration: 6751 teacher: 0 stage: sketch lr: 0.000538\n",
      "batch 536 loss: 1.33373 acc: 0.69043 | v_loss: 1.23234 v_acc: 0.69824 |  iteration: 6752 teacher: 1 stage: sketch lr: 0.000538\n",
      "batch 537 loss: 1.38636 acc: 0.69173 | v_loss: 1.28810 v_acc: 0.70475 |  iteration: 6753 teacher: 0 stage: sketch lr: 0.000538\n",
      "batch 538 loss: 1.25955 acc: 0.70768 | v_loss: 1.14049 v_acc: 0.72982 |  iteration: 6754 teacher: 1 stage: sketch lr: 0.000538\n",
      "batch 539 loss: 1.36256 acc: 0.70150 | v_loss: 1.38245 v_acc: 0.71647 |  iteration: 6755 teacher: 0 stage: sketch lr: 0.000538\n",
      "batch 540 loss: 1.29155 acc: 0.70443 | v_loss: 1.19917 v_acc: 0.70020 |  iteration: 6756 teacher: 0 stage: sketch lr: 0.000538\n",
      "batch 541 loss: 1.39691 acc: 0.69531 | v_loss: 1.20915 v_acc: 0.70605 |  iteration: 6757 teacher: 1 stage: sketch lr: 0.000538\n",
      "batch 542 loss: 1.31568 acc: 0.69727 | v_loss: 1.25680 v_acc: 0.70475 |  iteration: 6758 teacher: 0 stage: sketch lr: 0.000538\n",
      "batch 543 loss: 1.24993 acc: 0.71094 | v_loss: 1.27706 v_acc: 0.70215 |  iteration: 6759 teacher: 1 stage: sketch lr: 0.000538\n",
      "batch 544 loss: 1.28794 acc: 0.70020 | v_loss: 1.33802 v_acc: 0.69661 |  iteration: 6760 teacher: 0 stage: sketch lr: 0.000538\n",
      "batch 545 loss: 1.28902 acc: 0.69987 | v_loss: 1.36712 v_acc: 0.70638 |  iteration: 6761 teacher: 0 stage: sketch lr: 0.000537\n",
      "batch 546 loss: 1.24611 acc: 0.70182 | v_loss: 1.29773 v_acc: 0.70020 |  iteration: 6762 teacher: 1 stage: sketch lr: 0.000537\n",
      "batch 547 loss: 1.23994 acc: 0.71712 | v_loss: 1.19748 v_acc: 0.70768 |  iteration: 6763 teacher: 1 stage: sketch lr: 0.000537\n",
      "batch 548 loss: 1.26833 acc: 0.70443 | v_loss: 1.33172 v_acc: 0.70605 |  iteration: 6764 teacher: 0 stage: sketch lr: 0.000537\n",
      "batch 549 loss: 1.26928 acc: 0.70378 | v_loss: 1.22377 v_acc: 0.71191 |  iteration: 6765 teacher: 0 stage: sketch lr: 0.000537\n",
      "batch 550 loss: 1.24817 acc: 0.71029 | v_loss: 1.13931 v_acc: 0.72493 |  iteration: 6766 teacher: 0 stage: sketch lr: 0.000537\n",
      "batch 551 loss: 1.27175 acc: 0.70573 | v_loss: 1.13136 v_acc: 0.70833 |  iteration: 6767 teacher: 0 stage: sketch lr: 0.000537\n",
      "batch 552 loss: 1.26231 acc: 0.70247 | v_loss: 1.24484 v_acc: 0.70671 |  iteration: 6768 teacher: 1 stage: sketch lr: 0.000537\n",
      "batch 553 loss: 1.34363 acc: 0.69759 | v_loss: 1.32544 v_acc: 0.69954 |  iteration: 6769 teacher: 1 stage: sketch lr: 0.000537\n",
      "batch 554 loss: 1.31473 acc: 0.69238 | v_loss: 1.15024 v_acc: 0.71289 |  iteration: 6770 teacher: 0 stage: sketch lr: 0.000537\n",
      "batch 555 loss: 1.24893 acc: 0.70768 | v_loss: 1.19071 v_acc: 0.70247 |  iteration: 6771 teacher: 1 stage: sketch lr: 0.000537\n",
      "batch 556 loss: 1.22933 acc: 0.70736 | v_loss: 1.19412 v_acc: 0.71126 |  iteration: 6772 teacher: 1 stage: sketch lr: 0.000537\n",
      "batch 557 loss: 1.26268 acc: 0.71191 | v_loss: 1.20723 v_acc: 0.70801 |  iteration: 6773 teacher: 1 stage: sketch lr: 0.000537\n",
      "batch 558 loss: 1.21690 acc: 0.71289 | v_loss: 1.07189 v_acc: 0.73503 |  iteration: 6774 teacher: 1 stage: sketch lr: 0.000537\n",
      "batch 559 loss: 1.35694 acc: 0.69629 | v_loss: 1.18137 v_acc: 0.71842 |  iteration: 6775 teacher: 0 stage: sketch lr: 0.000537\n",
      "batch 560 loss: 1.29945 acc: 0.71094 | v_loss: 1.13964 v_acc: 0.71615 |  iteration: 6776 teacher: 0 stage: sketch lr: 0.000537\n",
      "batch 561 loss: 1.26424 acc: 0.70898 | v_loss: 1.13378 v_acc: 0.72005 |  iteration: 6777 teacher: 1 stage: sketch lr: 0.000537\n",
      "batch 562 loss: 1.32071 acc: 0.70605 | v_loss: 1.21124 v_acc: 0.71582 |  iteration: 6778 teacher: 1 stage: sketch lr: 0.000537\n",
      "batch 563 loss: 1.30053 acc: 0.70573 | v_loss: 1.22769 v_acc: 0.72168 |  iteration: 6779 teacher: 1 stage: sketch lr: 0.000537\n",
      "batch 564 loss: 1.33532 acc: 0.70280 | v_loss: 1.20967 v_acc: 0.72721 |  iteration: 6780 teacher: 0 stage: sketch lr: 0.000537\n",
      "batch 565 loss: 1.24039 acc: 0.71810 | v_loss: 1.40614 v_acc: 0.69466 |  iteration: 6781 teacher: 1 stage: sketch lr: 0.000537\n",
      "batch 566 loss: 1.33057 acc: 0.69499 | v_loss: 1.26157 v_acc: 0.72233 |  iteration: 6782 teacher: 0 stage: sketch lr: 0.000537\n",
      "batch 567 loss: 1.35719 acc: 0.70052 | v_loss: 1.05762 v_acc: 0.73893 |  iteration: 6783 teacher: 0 stage: sketch lr: 0.000537\n",
      "batch 568 loss: 1.38460 acc: 0.69531 | v_loss: 1.22065 v_acc: 0.70671 |  iteration: 6784 teacher: 0 stage: sketch lr: 0.000537\n",
      "batch 569 loss: 1.22471 acc: 0.70898 | v_loss: 1.27627 v_acc: 0.69987 |  iteration: 6785 teacher: 0 stage: sketch lr: 0.000537\n",
      "batch 570 loss: 1.33330 acc: 0.70215 | v_loss: 1.18920 v_acc: 0.70638 |  iteration: 6786 teacher: 0 stage: sketch lr: 0.000536\n",
      "batch 571 loss: 1.38571 acc: 0.69824 | v_loss: 1.25508 v_acc: 0.71257 |  iteration: 6787 teacher: 1 stage: sketch lr: 0.000536\n",
      "batch 572 loss: 1.30281 acc: 0.70443 | v_loss: 1.25904 v_acc: 0.69043 |  iteration: 6788 teacher: 1 stage: sketch lr: 0.000536\n",
      "batch 573 loss: 1.30274 acc: 0.70443 | v_loss: 1.21392 v_acc: 0.71842 |  iteration: 6789 teacher: 0 stage: sketch lr: 0.000536\n",
      "batch 574 loss: 1.23810 acc: 0.71191 | v_loss: 1.25113 v_acc: 0.70215 |  iteration: 6790 teacher: 1 stage: sketch lr: 0.000536\n",
      "batch 575 loss: 1.26032 acc: 0.70378 | v_loss: 1.18380 v_acc: 0.72038 |  iteration: 6791 teacher: 0 stage: sketch lr: 0.000536\n",
      "batch 576 loss: 1.27764 acc: 0.70475 | v_loss: 1.17375 v_acc: 0.72786 |  iteration: 6792 teacher: 1 stage: sketch lr: 0.000536\n",
      "batch 577 loss: 1.30860 acc: 0.70573 | v_loss: 1.23985 v_acc: 0.70085 |  iteration: 6793 teacher: 0 stage: sketch lr: 0.000536\n",
      "batch 578 loss: 1.32997 acc: 0.70736 | v_loss: 1.37080 v_acc: 0.69173 |  iteration: 6794 teacher: 0 stage: sketch lr: 0.000536\n",
      "batch 579 loss: 1.30605 acc: 0.71387 | v_loss: 1.16150 v_acc: 0.70964 |  iteration: 6795 teacher: 1 stage: sketch lr: 0.000536\n",
      "batch 580 loss: 1.24109 acc: 0.71908 | v_loss: 1.43355 v_acc: 0.67969 |  iteration: 6796 teacher: 0 stage: sketch lr: 0.000536\n",
      "batch 581 loss: 1.25931 acc: 0.70052 | v_loss: 1.16732 v_acc: 0.72363 |  iteration: 6797 teacher: 0 stage: sketch lr: 0.000536\n",
      "batch 582 loss: 1.29252 acc: 0.70540 | v_loss: 1.49631 v_acc: 0.67969 |  iteration: 6798 teacher: 0 stage: sketch lr: 0.000536\n",
      "batch 583 loss: 1.29315 acc: 0.69954 | v_loss: 1.37599 v_acc: 0.69694 |  iteration: 6799 teacher: 1 stage: sketch lr: 0.000536\n",
      "batch 584 loss: 1.27206 acc: 0.70410 | v_loss: 1.32527 v_acc: 0.69173 |  iteration: 6800 teacher: 1 stage: sketch lr: 0.000536\n",
      "batch 585 loss: 1.31169 acc: 0.70150 | v_loss: 1.32135 v_acc: 0.69857 |  iteration: 6801 teacher: 1 stage: sketch lr: 0.000536\n",
      "batch 586 loss: 1.26071 acc: 0.70443 | v_loss: 1.23945 v_acc: 0.70703 |  iteration: 6802 teacher: 1 stage: sketch lr: 0.000536\n",
      "batch 587 loss: 1.22662 acc: 0.71126 | v_loss: 1.26289 v_acc: 0.70605 |  iteration: 6803 teacher: 1 stage: sketch lr: 0.000536\n",
      "batch 588 loss: 1.34624 acc: 0.70931 | v_loss: 1.22436 v_acc: 0.71973 |  iteration: 6804 teacher: 1 stage: sketch lr: 0.000536\n",
      "batch 589 loss: 1.34796 acc: 0.70345 | v_loss: 1.41531 v_acc: 0.69076 |  iteration: 6805 teacher: 1 stage: sketch lr: 0.000536\n",
      "batch 590 loss: 1.35493 acc: 0.69434 | v_loss: 1.28665 v_acc: 0.71452 |  iteration: 6806 teacher: 0 stage: sketch lr: 0.000536\n",
      "batch 591 loss: 1.29957 acc: 0.71419 | v_loss: 1.18960 v_acc: 0.70638 |  iteration: 6807 teacher: 1 stage: sketch lr: 0.000536\n",
      "batch 592 loss: 1.26888 acc: 0.70247 | v_loss: 1.27261 v_acc: 0.71484 |  iteration: 6808 teacher: 1 stage: sketch lr: 0.000536\n",
      "batch 593 loss: 1.38936 acc: 0.69987 | v_loss: 1.17524 v_acc: 0.70703 |  iteration: 6809 teacher: 0 stage: sketch lr: 0.000536\n",
      "batch 594 loss: 1.25787 acc: 0.70768 | v_loss: 1.27096 v_acc: 0.69987 |  iteration: 6810 teacher: 1 stage: sketch lr: 0.000536\n",
      "batch 595 loss: 1.32794 acc: 0.70833 | v_loss: 1.23113 v_acc: 0.71419 |  iteration: 6811 teacher: 1 stage: sketch lr: 0.000536\n",
      "batch 596 loss: 1.31421 acc: 0.70638 | v_loss: 1.17457 v_acc: 0.72135 |  iteration: 6812 teacher: 1 stage: sketch lr: 0.000535\n",
      "batch 597 loss: 1.26214 acc: 0.70638 | v_loss: 1.13766 v_acc: 0.72526 |  iteration: 6813 teacher: 0 stage: sketch lr: 0.000535\n",
      "batch 598 loss: 1.27364 acc: 0.71224 | v_loss: 1.25659 v_acc: 0.71810 |  iteration: 6814 teacher: 0 stage: sketch lr: 0.000535\n",
      "batch 599 loss: 1.35281 acc: 0.70150 | v_loss: 1.24379 v_acc: 0.70280 |  iteration: 6815 teacher: 0 stage: sketch lr: 0.000535\n",
      "batch 600 loss: 1.32961 acc: 0.69434 | v_loss: 1.24719 v_acc: 0.70931 |  iteration: 6816 teacher: 0 stage: sketch lr: 0.000535\n",
      "batch 601 loss: 1.33695 acc: 0.70085 | v_loss: 1.11311 v_acc: 0.72331 |  iteration: 6817 teacher: 0 stage: sketch lr: 0.000535\n",
      "batch 602 loss: 1.42715 acc: 0.69661 | v_loss: 1.24352 v_acc: 0.72754 |  iteration: 6818 teacher: 0 stage: sketch lr: 0.000535\n",
      "batch 603 loss: 1.37259 acc: 0.69271 | v_loss: 1.29362 v_acc: 0.70150 |  iteration: 6819 teacher: 1 stage: sketch lr: 0.000535\n",
      "batch 604 loss: 1.30297 acc: 0.70215 | v_loss: 1.27919 v_acc: 0.72591 |  iteration: 6820 teacher: 1 stage: sketch lr: 0.000535\n",
      "batch 605 loss: 1.29996 acc: 0.70801 | v_loss: 1.18342 v_acc: 0.71647 |  iteration: 6821 teacher: 1 stage: sketch lr: 0.000535\n",
      "batch 606 loss: 1.23529 acc: 0.70312 | v_loss: 1.14174 v_acc: 0.72819 |  iteration: 6822 teacher: 1 stage: sketch lr: 0.000535\n",
      "batch 607 loss: 1.29459 acc: 0.70052 | v_loss: 1.11232 v_acc: 0.72396 |  iteration: 6823 teacher: 0 stage: sketch lr: 0.000535\n",
      "batch 608 loss: 1.35767 acc: 0.69629 | v_loss: 1.21407 v_acc: 0.70833 |  iteration: 6824 teacher: 1 stage: sketch lr: 0.000535\n",
      "batch 609 loss: 1.22775 acc: 0.72559 | v_loss: 1.23105 v_acc: 0.70247 |  iteration: 6825 teacher: 1 stage: sketch lr: 0.000535\n",
      "batch 610 loss: 1.26464 acc: 0.70475 | v_loss: 1.19573 v_acc: 0.71419 |  iteration: 6826 teacher: 1 stage: sketch lr: 0.000535\n",
      "batch 611 loss: 1.26897 acc: 0.72266 | v_loss: 1.33008 v_acc: 0.70638 |  iteration: 6827 teacher: 0 stage: sketch lr: 0.000535\n",
      "batch 612 loss: 1.20598 acc: 0.72493 | v_loss: 1.48311 v_acc: 0.69141 |  iteration: 6828 teacher: 1 stage: sketch lr: 0.000535\n",
      "batch 613 loss: 1.26236 acc: 0.71029 | v_loss: 1.36266 v_acc: 0.69727 |  iteration: 6829 teacher: 1 stage: sketch lr: 0.000535\n",
      "batch 614 loss: 1.29740 acc: 0.70638 | v_loss: 1.18588 v_acc: 0.72396 |  iteration: 6830 teacher: 1 stage: sketch lr: 0.000535\n",
      "batch 615 loss: 1.29495 acc: 0.70312 | v_loss: 1.15981 v_acc: 0.71029 |  iteration: 6831 teacher: 0 stage: sketch lr: 0.000535\n",
      "batch 616 loss: 1.27698 acc: 0.71484 | v_loss: 1.15150 v_acc: 0.72331 |  iteration: 6832 teacher: 1 stage: sketch lr: 0.000535\n",
      "batch 617 loss: 1.29480 acc: 0.70247 | v_loss: 1.24358 v_acc: 0.70247 |  iteration: 6833 teacher: 0 stage: sketch lr: 0.000535\n",
      "batch 618 loss: 1.31245 acc: 0.70573 | v_loss: 1.24375 v_acc: 0.72135 |  iteration: 6834 teacher: 0 stage: sketch lr: 0.000535\n",
      "batch 619 loss: 1.32037 acc: 0.69922 | v_loss: 1.21963 v_acc: 0.72754 |  iteration: 6835 teacher: 0 stage: sketch lr: 0.000535\n",
      "batch 620 loss: 1.28514 acc: 0.69954 | v_loss: 1.23074 v_acc: 0.72038 |  iteration: 6836 teacher: 1 stage: sketch lr: 0.000535\n",
      "batch 621 loss: 1.26793 acc: 0.71257 | v_loss: 1.23039 v_acc: 0.71419 |  iteration: 6837 teacher: 1 stage: sketch lr: 0.000534\n",
      "batch 622 loss: 1.35182 acc: 0.69759 | v_loss: 1.16625 v_acc: 0.72070 |  iteration: 6838 teacher: 1 stage: sketch lr: 0.000534\n",
      "batch 623 loss: 1.37806 acc: 0.69043 | v_loss: 1.14974 v_acc: 0.71940 |  iteration: 6839 teacher: 1 stage: sketch lr: 0.000534\n",
      "batch 624 loss: 1.34500 acc: 0.69987 | v_loss: 1.46173 v_acc: 0.68294 |  iteration: 6840 teacher: 1 stage: sketch lr: 0.000534\n",
      "batch 625 loss: 1.29293 acc: 0.70736 | v_loss: 1.23317 v_acc: 0.70931 |  iteration: 6841 teacher: 0 stage: sketch lr: 0.000534\n",
      "batch 626 loss: 1.28562 acc: 0.69954 | v_loss: 1.25769 v_acc: 0.70866 |  iteration: 6842 teacher: 0 stage: sketch lr: 0.000534\n",
      "batch 627 loss: 1.32382 acc: 0.70866 | v_loss: 1.25072 v_acc: 0.70605 |  iteration: 6843 teacher: 0 stage: sketch lr: 0.000534\n",
      "batch 628 loss: 1.34520 acc: 0.69564 | v_loss: 1.28950 v_acc: 0.69596 |  iteration: 6844 teacher: 0 stage: sketch lr: 0.000534\n",
      "batch 629 loss: 1.29142 acc: 0.69987 | v_loss: 1.14306 v_acc: 0.73340 |  iteration: 6845 teacher: 0 stage: sketch lr: 0.000534\n",
      "batch 630 loss: 1.33500 acc: 0.69792 | v_loss: 1.38579 v_acc: 0.71257 |  iteration: 6846 teacher: 0 stage: sketch lr: 0.000534\n",
      "batch 631 loss: 1.28785 acc: 0.70801 | v_loss: 1.19223 v_acc: 0.69792 |  iteration: 6847 teacher: 0 stage: sketch lr: 0.000534\n",
      "batch 632 loss: 1.27787 acc: 0.71810 | v_loss: 1.20263 v_acc: 0.70215 |  iteration: 6848 teacher: 1 stage: sketch lr: 0.000534\n",
      "batch 633 loss: 1.29680 acc: 0.70150 | v_loss: 1.28653 v_acc: 0.70247 |  iteration: 6849 teacher: 0 stage: sketch lr: 0.000534\n",
      "batch 634 loss: 1.25644 acc: 0.70996 | v_loss: 1.30141 v_acc: 0.69922 |  iteration: 6850 teacher: 0 stage: sketch lr: 0.000534\n",
      "batch 635 loss: 1.28428 acc: 0.70345 | v_loss: 1.35314 v_acc: 0.69368 |  iteration: 6851 teacher: 0 stage: sketch lr: 0.000534\n",
      "batch 636 loss: 1.26857 acc: 0.71549 | v_loss: 1.36775 v_acc: 0.70833 |  iteration: 6852 teacher: 1 stage: sketch lr: 0.000534\n",
      "batch 637 loss: 1.34632 acc: 0.70280 | v_loss: 1.27786 v_acc: 0.69759 |  iteration: 6853 teacher: 1 stage: sketch lr: 0.000534\n",
      "batch 638 loss: 1.27186 acc: 0.70475 | v_loss: 1.17530 v_acc: 0.71191 |  iteration: 6854 teacher: 1 stage: sketch lr: 0.000534\n",
      "batch 639 loss: 1.22546 acc: 0.70866 | v_loss: 1.36960 v_acc: 0.70410 |  iteration: 6855 teacher: 0 stage: sketch lr: 0.000534\n",
      "batch 640 loss: 1.33749 acc: 0.69824 | v_loss: 1.26740 v_acc: 0.71712 |  iteration: 6856 teacher: 1 stage: sketch lr: 0.000534\n",
      "batch 641 loss: 1.35424 acc: 0.69792 | v_loss: 1.14632 v_acc: 0.72591 |  iteration: 6857 teacher: 0 stage: sketch lr: 0.000534\n",
      "batch 642 loss: 1.27730 acc: 0.70736 | v_loss: 1.16371 v_acc: 0.69954 |  iteration: 6858 teacher: 1 stage: sketch lr: 0.000534\n",
      "batch 643 loss: 1.27040 acc: 0.71582 | v_loss: 1.27288 v_acc: 0.70020 |  iteration: 6859 teacher: 0 stage: sketch lr: 0.000534\n",
      "batch 644 loss: 1.17336 acc: 0.71615 | v_loss: 1.34426 v_acc: 0.69303 |  iteration: 6860 teacher: 1 stage: sketch lr: 0.000534\n",
      "batch 645 loss: 1.29676 acc: 0.70768 | v_loss: 1.16746 v_acc: 0.70768 |  iteration: 6861 teacher: 0 stage: sketch lr: 0.000534\n",
      "batch 646 loss: 1.26823 acc: 0.71940 | v_loss: 1.21124 v_acc: 0.69727 |  iteration: 6862 teacher: 0 stage: sketch lr: 0.000534\n",
      "batch 647 loss: 1.38443 acc: 0.69434 | v_loss: 1.19882 v_acc: 0.70573 |  iteration: 6863 teacher: 0 stage: sketch lr: 0.000533\n",
      "batch 648 loss: 1.26102 acc: 0.70573 | v_loss: 1.21787 v_acc: 0.70280 |  iteration: 6864 teacher: 0 stage: sketch lr: 0.000533\n",
      "batch 649 loss: 1.30233 acc: 0.70931 | v_loss: 1.07470 v_acc: 0.73340 |  iteration: 6865 teacher: 0 stage: sketch lr: 0.000533\n",
      "batch 650 loss: 1.35283 acc: 0.69987 | v_loss: 1.18491 v_acc: 0.71647 |  iteration: 6866 teacher: 1 stage: sketch lr: 0.000533\n",
      "batch 651 loss: 1.17637 acc: 0.70931 | v_loss: 1.12028 v_acc: 0.74089 |  iteration: 6867 teacher: 1 stage: sketch lr: 0.000533\n",
      "batch 652 loss: 1.27061 acc: 0.70117 | v_loss: 1.11563 v_acc: 0.72005 |  iteration: 6868 teacher: 1 stage: sketch lr: 0.000533\n",
      "batch 653 loss: 1.38270 acc: 0.69401 | v_loss: 1.19963 v_acc: 0.72070 |  iteration: 6869 teacher: 0 stage: sketch lr: 0.000533\n",
      "batch 654 loss: 1.24049 acc: 0.71126 | v_loss: 1.22823 v_acc: 0.71615 |  iteration: 6870 teacher: 1 stage: sketch lr: 0.000533\n",
      "batch 655 loss: 1.29251 acc: 0.69889 | v_loss: 1.20730 v_acc: 0.72298 |  iteration: 6871 teacher: 1 stage: sketch lr: 0.000533\n",
      "batch 656 loss: 1.30781 acc: 0.70638 | v_loss: 1.40643 v_acc: 0.69922 |  iteration: 6872 teacher: 1 stage: sketch lr: 0.000533\n",
      "batch 657 loss: 1.31547 acc: 0.69694 | v_loss: 1.26949 v_acc: 0.72233 |  iteration: 6873 teacher: 1 stage: sketch lr: 0.000533\n",
      "batch 658 loss: 1.36133 acc: 0.69792 | v_loss: 1.06193 v_acc: 0.74186 |  iteration: 6874 teacher: 1 stage: sketch lr: 0.000533\n",
      "batch 659 loss: 1.32035 acc: 0.70736 | v_loss: 1.23043 v_acc: 0.70085 |  iteration: 6875 teacher: 1 stage: sketch lr: 0.000533\n",
      "batch 660 loss: 1.34026 acc: 0.70020 | v_loss: 1.29091 v_acc: 0.69824 |  iteration: 6876 teacher: 0 stage: sketch lr: 0.000533\n",
      "batch 661 loss: 1.29131 acc: 0.71126 | v_loss: 1.23069 v_acc: 0.69336 |  iteration: 6877 teacher: 1 stage: sketch lr: 0.000533\n",
      "batch 662 loss: 1.22899 acc: 0.70866 | v_loss: 1.26414 v_acc: 0.70736 |  iteration: 6878 teacher: 0 stage: sketch lr: 0.000533\n",
      "batch 663 loss: 1.28515 acc: 0.69759 | v_loss: 1.26864 v_acc: 0.69434 |  iteration: 6879 teacher: 0 stage: sketch lr: 0.000533\n",
      "batch 664 loss: 1.22987 acc: 0.71289 | v_loss: 1.22175 v_acc: 0.70898 |  iteration: 6880 teacher: 0 stage: sketch lr: 0.000533\n",
      "batch 665 loss: 1.30085 acc: 0.71582 | v_loss: 1.26030 v_acc: 0.69206 |  iteration: 6881 teacher: 0 stage: sketch lr: 0.000533\n",
      "batch 666 loss: 1.28502 acc: 0.70671 | v_loss: 1.21103 v_acc: 0.70931 |  iteration: 6882 teacher: 0 stage: sketch lr: 0.000533\n",
      "batch 667 loss: 1.27930 acc: 0.70443 | v_loss: 1.18632 v_acc: 0.72363 |  iteration: 6883 teacher: 1 stage: sketch lr: 0.000533\n",
      "batch 668 loss: 1.23403 acc: 0.72298 | v_loss: 1.26701 v_acc: 0.70117 |  iteration: 6884 teacher: 1 stage: sketch lr: 0.000533\n",
      "batch 669 loss: 1.30280 acc: 0.70703 | v_loss: 1.33613 v_acc: 0.70085 |  iteration: 6885 teacher: 1 stage: sketch lr: 0.000533\n",
      "batch 670 loss: 1.27624 acc: 0.71745 | v_loss: 1.17091 v_acc: 0.70638 |  iteration: 6886 teacher: 0 stage: sketch lr: 0.000533\n",
      "batch 671 loss: 1.36933 acc: 0.70052 | v_loss: 1.42110 v_acc: 0.68620 |  iteration: 6887 teacher: 0 stage: sketch lr: 0.000533\n",
      "batch 672 loss: 1.33377 acc: 0.70312 | v_loss: 1.17545 v_acc: 0.72298 |  iteration: 6888 teacher: 1 stage: sketch lr: 0.000532\n",
      "batch 673 loss: 1.23929 acc: 0.70996 | v_loss: 1.48997 v_acc: 0.67936 |  iteration: 6889 teacher: 0 stage: sketch lr: 0.000532\n",
      "batch 674 loss: 1.29348 acc: 0.70638 | v_loss: 1.36305 v_acc: 0.69661 |  iteration: 6890 teacher: 1 stage: sketch lr: 0.000532\n",
      "batch 675 loss: 1.31214 acc: 0.70312 | v_loss: 1.33272 v_acc: 0.69141 |  iteration: 6891 teacher: 1 stage: sketch lr: 0.000532\n",
      "batch 676 loss: 1.38540 acc: 0.69759 | v_loss: 1.30751 v_acc: 0.70020 |  iteration: 6892 teacher: 0 stage: sketch lr: 0.000532\n",
      "batch 677 loss: 1.27715 acc: 0.70703 | v_loss: 1.24794 v_acc: 0.69987 |  iteration: 6893 teacher: 1 stage: sketch lr: 0.000532\n",
      "batch 678 loss: 1.16277 acc: 0.72135 | v_loss: 1.26876 v_acc: 0.70410 |  iteration: 6894 teacher: 1 stage: sketch lr: 0.000532\n",
      "batch 679 loss: 1.20338 acc: 0.71745 | v_loss: 1.23498 v_acc: 0.71777 |  iteration: 6895 teacher: 1 stage: sketch lr: 0.000532\n",
      "batch 680 loss: 1.24478 acc: 0.71126 | v_loss: 1.42422 v_acc: 0.68522 |  iteration: 6896 teacher: 1 stage: sketch lr: 0.000532\n",
      "batch 681 loss: 1.33553 acc: 0.69108 | v_loss: 1.30493 v_acc: 0.70573 |  iteration: 6897 teacher: 0 stage: sketch lr: 0.000532\n",
      "batch 682 loss: 1.36329 acc: 0.70605 | v_loss: 1.19143 v_acc: 0.71126 |  iteration: 6898 teacher: 0 stage: sketch lr: 0.000532\n",
      "batch 683 loss: 1.24967 acc: 0.70931 | v_loss: 1.26450 v_acc: 0.71680 |  iteration: 6899 teacher: 1 stage: sketch lr: 0.000532\n",
      "batch 684 loss: 1.36150 acc: 0.70085 | v_loss: 1.17366 v_acc: 0.70443 |  iteration: 6900 teacher: 0 stage: sketch lr: 0.000532\n",
      "batch 685 loss: 1.31069 acc: 0.70703 | v_loss: 1.26658 v_acc: 0.69922 |  iteration: 6901 teacher: 1 stage: sketch lr: 0.000532\n",
      "batch 686 loss: 1.27582 acc: 0.70540 | v_loss: 1.22826 v_acc: 0.71191 |  iteration: 6902 teacher: 0 stage: sketch lr: 0.000532\n",
      "batch 687 loss: 1.41273 acc: 0.69434 | v_loss: 1.17386 v_acc: 0.71647 |  iteration: 6903 teacher: 0 stage: sketch lr: 0.000532\n",
      "batch 688 loss: 1.23051 acc: 0.70898 | v_loss: 1.14748 v_acc: 0.72526 |  iteration: 6904 teacher: 0 stage: sketch lr: 0.000532\n",
      "batch 689 loss: 1.29739 acc: 0.70931 | v_loss: 1.25554 v_acc: 0.71647 |  iteration: 6905 teacher: 1 stage: sketch lr: 0.000532\n",
      "batch 690 loss: 1.31771 acc: 0.69824 | v_loss: 1.26107 v_acc: 0.70052 |  iteration: 6906 teacher: 0 stage: sketch lr: 0.000532\n",
      "batch 691 loss: 1.33840 acc: 0.70247 | v_loss: 1.26817 v_acc: 0.70312 |  iteration: 6907 teacher: 0 stage: sketch lr: 0.000532\n",
      "batch 692 loss: 1.33898 acc: 0.70085 | v_loss: 1.12007 v_acc: 0.71419 |  iteration: 6908 teacher: 1 stage: sketch lr: 0.000532\n",
      "batch 693 loss: 1.26243 acc: 0.70573 | v_loss: 1.25350 v_acc: 0.72819 |  iteration: 6909 teacher: 1 stage: sketch lr: 0.000532\n",
      "batch 694 loss: 1.29994 acc: 0.70540 | v_loss: 1.30647 v_acc: 0.69792 |  iteration: 6910 teacher: 1 stage: sketch lr: 0.000532\n",
      "batch 695 loss: 1.34482 acc: 0.70345 | v_loss: 1.29302 v_acc: 0.71842 |  iteration: 6911 teacher: 1 stage: sketch lr: 0.000532\n",
      "batch 696 loss: 1.30148 acc: 0.70085 | v_loss: 1.15709 v_acc: 0.72201 |  iteration: 6912 teacher: 0 stage: sketch lr: 0.000532\n",
      "batch 697 loss: 1.27914 acc: 0.71094 | v_loss: 1.10588 v_acc: 0.73926 |  iteration: 6913 teacher: 1 stage: sketch lr: 0.000532\n",
      "batch 698 loss: 1.36572 acc: 0.69954 | v_loss: 1.10291 v_acc: 0.72266 |  iteration: 6914 teacher: 1 stage: sketch lr: 0.000531\n",
      "batch 699 loss: 1.35167 acc: 0.69824 | v_loss: 1.18917 v_acc: 0.71322 |  iteration: 6915 teacher: 1 stage: sketch lr: 0.000531\n",
      "batch 700 loss: 1.20879 acc: 0.71517 | v_loss: 1.23193 v_acc: 0.70247 |  iteration: 6916 teacher: 0 stage: sketch lr: 0.000531\n",
      "batch 701 loss: 1.30135 acc: 0.70898 | v_loss: 1.20976 v_acc: 0.71419 |  iteration: 6917 teacher: 1 stage: sketch lr: 0.000531\n",
      "batch 702 loss: 1.31196 acc: 0.69824 | v_loss: 1.34727 v_acc: 0.70671 |  iteration: 6918 teacher: 1 stage: sketch lr: 0.000531\n",
      "batch 703 loss: 1.25622 acc: 0.71484 | v_loss: 1.47728 v_acc: 0.68848 |  iteration: 6919 teacher: 0 stage: sketch lr: 0.000531\n",
      "batch 704 loss: 1.32733 acc: 0.69434 | v_loss: 1.36313 v_acc: 0.69564 |  iteration: 6920 teacher: 1 stage: sketch lr: 0.000531\n",
      "batch 705 loss: 1.25060 acc: 0.70280 | v_loss: 1.20569 v_acc: 0.71615 |  iteration: 6921 teacher: 0 stage: sketch lr: 0.000531\n",
      "batch 706 loss: 1.36054 acc: 0.69792 | v_loss: 1.17852 v_acc: 0.70801 |  iteration: 6922 teacher: 0 stage: sketch lr: 0.000531\n",
      "batch 707 loss: 1.27534 acc: 0.70768 | v_loss: 1.15962 v_acc: 0.71289 |  iteration: 6923 teacher: 0 stage: sketch lr: 0.000531\n",
      "batch 708 loss: 1.32963 acc: 0.70280 | v_loss: 1.22389 v_acc: 0.70085 |  iteration: 6924 teacher: 0 stage: sketch lr: 0.000531\n",
      "batch 709 loss: 1.25760 acc: 0.70801 | v_loss: 1.25804 v_acc: 0.71875 |  iteration: 6925 teacher: 0 stage: sketch lr: 0.000531\n",
      "batch 710 loss: 1.27434 acc: 0.70182 | v_loss: 1.21970 v_acc: 0.72786 |  iteration: 6926 teacher: 0 stage: sketch lr: 0.000531\n",
      "batch 711 loss: 1.37799 acc: 0.69759 | v_loss: 1.24870 v_acc: 0.71712 |  iteration: 6927 teacher: 0 stage: sketch lr: 0.000531\n",
      "batch 712 loss: 1.36296 acc: 0.69596 | v_loss: 1.24277 v_acc: 0.70931 |  iteration: 6928 teacher: 0 stage: sketch lr: 0.000531\n",
      "batch 713 loss: 1.20645 acc: 0.70671 | v_loss: 1.17167 v_acc: 0.72201 |  iteration: 6929 teacher: 1 stage: sketch lr: 0.000531\n",
      "batch 714 loss: 1.32869 acc: 0.70573 | v_loss: 1.12828 v_acc: 0.72005 |  iteration: 6930 teacher: 0 stage: sketch lr: 0.000531\n",
      "batch 715 loss: 1.28338 acc: 0.70768 | v_loss: 1.47367 v_acc: 0.69043 |  iteration: 6931 teacher: 1 stage: sketch lr: 0.000531\n",
      "batch 716 loss: 1.28924 acc: 0.69727 | v_loss: 1.19993 v_acc: 0.71224 |  iteration: 6932 teacher: 1 stage: sketch lr: 0.000531\n",
      "batch 717 loss: 1.27287 acc: 0.71615 | v_loss: 1.22666 v_acc: 0.71680 |  iteration: 6933 teacher: 1 stage: sketch lr: 0.000531\n",
      "batch 718 loss: 1.32417 acc: 0.70085 | v_loss: 1.20951 v_acc: 0.71452 |  iteration: 6934 teacher: 1 stage: sketch lr: 0.000531\n",
      "batch 719 loss: 1.34371 acc: 0.70443 | v_loss: 1.28942 v_acc: 0.70443 |  iteration: 6935 teacher: 0 stage: sketch lr: 0.000531\n",
      "batch 720 loss: 1.30258 acc: 0.70085 | v_loss: 1.14130 v_acc: 0.72917 |  iteration: 6936 teacher: 1 stage: sketch lr: 0.000531\n",
      "batch 721 loss: 1.35724 acc: 0.69401 | v_loss: 1.38162 v_acc: 0.71257 |  iteration: 6937 teacher: 0 stage: sketch lr: 0.000531\n",
      "batch 722 loss: 1.24694 acc: 0.70215 | v_loss: 1.20088 v_acc: 0.70020 |  iteration: 6938 teacher: 1 stage: sketch lr: 0.000531\n",
      "batch 723 loss: 1.27854 acc: 0.71322 | v_loss: 1.21646 v_acc: 0.70345 |  iteration: 6939 teacher: 0 stage: sketch lr: 0.000531\n",
      "batch 724 loss: 1.19040 acc: 0.71126 | v_loss: 1.27889 v_acc: 0.70410 |  iteration: 6940 teacher: 1 stage: sketch lr: 0.000530\n",
      "batch 725 loss: 1.32382 acc: 0.69564 | v_loss: 1.29129 v_acc: 0.69922 |  iteration: 6941 teacher: 1 stage: sketch lr: 0.000530\n",
      "batch 726 loss: 1.33729 acc: 0.69141 | v_loss: 1.33758 v_acc: 0.69271 |  iteration: 6942 teacher: 1 stage: sketch lr: 0.000530\n",
      "batch 727 loss: 1.33886 acc: 0.69889 | v_loss: 1.36826 v_acc: 0.70671 |  iteration: 6943 teacher: 0 stage: sketch lr: 0.000530\n",
      "batch 728 loss: 1.17342 acc: 0.71289 | v_loss: 1.29303 v_acc: 0.69759 |  iteration: 6944 teacher: 1 stage: sketch lr: 0.000530\n",
      "batch 729 loss: 1.26156 acc: 0.70378 | v_loss: 1.19828 v_acc: 0.71484 |  iteration: 6945 teacher: 0 stage: sketch lr: 0.000530\n",
      "batch 730 loss: 1.30136 acc: 0.70085 | v_loss: 1.33815 v_acc: 0.70215 |  iteration: 6946 teacher: 1 stage: sketch lr: 0.000530\n",
      "batch 731 loss: 1.38217 acc: 0.69889 | v_loss: 1.25254 v_acc: 0.71126 |  iteration: 6947 teacher: 0 stage: sketch lr: 0.000530\n",
      "batch 732 loss: 1.38652 acc: 0.69336 | v_loss: 1.13478 v_acc: 0.72591 |  iteration: 6948 teacher: 1 stage: sketch lr: 0.000530\n",
      "batch 733 loss: 1.31233 acc: 0.69922 | v_loss: 1.16830 v_acc: 0.70638 |  iteration: 6949 teacher: 1 stage: sketch lr: 0.000530\n",
      "batch 734 loss: 1.30744 acc: 0.70215 | v_loss: 1.26420 v_acc: 0.70247 |  iteration: 6950 teacher: 1 stage: sketch lr: 0.000530\n",
      "batch 735 loss: 1.35383 acc: 0.69173 | v_loss: 1.32456 v_acc: 0.69987 |  iteration: 6951 teacher: 1 stage: sketch lr: 0.000530\n",
      "batch 736 loss: 1.22902 acc: 0.71517 | v_loss: 1.18556 v_acc: 0.70540 |  iteration: 6952 teacher: 1 stage: sketch lr: 0.000530\n",
      "batch 737 loss: 1.27062 acc: 0.69889 | v_loss: 1.20169 v_acc: 0.69368 |  iteration: 6953 teacher: 0 stage: sketch lr: 0.000530\n",
      "batch 738 loss: 1.26814 acc: 0.70833 | v_loss: 1.20330 v_acc: 0.70573 |  iteration: 6954 teacher: 1 stage: sketch lr: 0.000530\n",
      "batch 739 loss: 1.25338 acc: 0.70605 | v_loss: 1.21323 v_acc: 0.70475 |  iteration: 6955 teacher: 0 stage: sketch lr: 0.000530\n",
      "batch 740 loss: 1.23263 acc: 0.70312 | v_loss: 1.07641 v_acc: 0.73568 |  iteration: 6956 teacher: 0 stage: sketch lr: 0.000530\n",
      "batch 741 loss: 1.27495 acc: 0.70801 | v_loss: 1.17581 v_acc: 0.72461 |  iteration: 6957 teacher: 1 stage: sketch lr: 0.000530\n",
      "batch 742 loss: 1.26504 acc: 0.70964 | v_loss: 1.12080 v_acc: 0.70768 |  iteration: 6958 teacher: 0 stage: sketch lr: 0.000530\n",
      "batch 743 loss: 1.28875 acc: 0.70703 | v_loss: 1.11777 v_acc: 0.73340 |  iteration: 6959 teacher: 1 stage: sketch lr: 0.000530\n",
      "batch 744 loss: 1.25098 acc: 0.71257 | v_loss: 1.20107 v_acc: 0.71419 |  iteration: 6960 teacher: 1 stage: sketch lr: 0.000530\n",
      "batch 745 loss: 1.38972 acc: 0.68783 | v_loss: 1.23110 v_acc: 0.70931 |  iteration: 6961 teacher: 1 stage: sketch lr: 0.000530\n",
      "batch 746 loss: 1.22127 acc: 0.70508 | v_loss: 1.21885 v_acc: 0.72331 |  iteration: 6962 teacher: 0 stage: sketch lr: 0.000530\n",
      "batch 747 loss: 1.22077 acc: 0.70671 | v_loss: 1.39491 v_acc: 0.69466 |  iteration: 6963 teacher: 1 stage: sketch lr: 0.000530\n",
      "batch 748 loss: 1.29110 acc: 0.69824 | v_loss: 1.26922 v_acc: 0.71452 |  iteration: 6964 teacher: 0 stage: sketch lr: 0.000530\n",
      "batch 749 loss: 1.24607 acc: 0.70215 | v_loss: 1.05557 v_acc: 0.74056 |  iteration: 6965 teacher: 1 stage: sketch lr: 0.000530\n",
      "batch 750 loss: 1.39556 acc: 0.68945 | v_loss: 1.21615 v_acc: 0.70540 |  iteration: 6966 teacher: 1 stage: sketch lr: 0.000530\n",
      "batch 751 loss: 1.26477 acc: 0.70736 | v_loss: 1.27742 v_acc: 0.69141 |  iteration: 6967 teacher: 0 stage: sketch lr: 0.000529\n",
      "batch 752 loss: 1.38202 acc: 0.69954 | v_loss: 1.22124 v_acc: 0.69108 |  iteration: 6968 teacher: 0 stage: sketch lr: 0.000529\n",
      "batch 753 loss: 1.38476 acc: 0.69173 | v_loss: 1.26154 v_acc: 0.70996 |  iteration: 6969 teacher: 1 stage: sketch lr: 0.000529\n",
      "batch 754 loss: 1.23058 acc: 0.70540 | v_loss: 1.26313 v_acc: 0.69108 |  iteration: 6970 teacher: 1 stage: sketch lr: 0.000529\n",
      "batch 755 loss: 1.28367 acc: 0.70671 | v_loss: 1.24625 v_acc: 0.70898 |  iteration: 6971 teacher: 1 stage: sketch lr: 0.000529\n",
      "batch 756 loss: 1.30820 acc: 0.70117 | v_loss: 1.27159 v_acc: 0.69434 |  iteration: 6972 teacher: 1 stage: sketch lr: 0.000529\n",
      "batch 757 loss: 1.28936 acc: 0.70703 | v_loss: 1.17113 v_acc: 0.71094 |  iteration: 6973 teacher: 1 stage: sketch lr: 0.000529\n",
      "batch 758 loss: 1.27291 acc: 0.71452 | v_loss: 1.17549 v_acc: 0.72559 |  iteration: 6974 teacher: 0 stage: sketch lr: 0.000529\n",
      "batch 759 loss: 1.28993 acc: 0.71029 | v_loss: 1.25220 v_acc: 0.70117 |  iteration: 6975 teacher: 0 stage: sketch lr: 0.000529\n",
      "batch 760 loss: 1.26921 acc: 0.71257 | v_loss: 1.36352 v_acc: 0.70085 |  iteration: 6976 teacher: 1 stage: sketch lr: 0.000529\n",
      "batch 761 loss: 1.28215 acc: 0.70052 | v_loss: 1.17785 v_acc: 0.70638 |  iteration: 6977 teacher: 0 stage: sketch lr: 0.000529\n",
      "batch 762 loss: 1.22907 acc: 0.71810 | v_loss: 1.40788 v_acc: 0.68685 |  iteration: 6978 teacher: 0 stage: sketch lr: 0.000529\n",
      "batch 763 loss: 1.33572 acc: 0.70052 | v_loss: 1.17388 v_acc: 0.71908 |  iteration: 6979 teacher: 1 stage: sketch lr: 0.000529\n",
      "batch 764 loss: 1.39202 acc: 0.69206 | v_loss: 1.48888 v_acc: 0.67936 |  iteration: 6980 teacher: 1 stage: sketch lr: 0.000529\n",
      "batch 765 loss: 1.24714 acc: 0.70866 | v_loss: 1.35709 v_acc: 0.69661 |  iteration: 6981 teacher: 1 stage: sketch lr: 0.000529\n",
      "batch 766 loss: 1.30323 acc: 0.70443 | v_loss: 1.33784 v_acc: 0.69238 |  iteration: 6982 teacher: 1 stage: sketch lr: 0.000529\n",
      "batch 767 loss: 1.29364 acc: 0.71680 | v_loss: 1.30971 v_acc: 0.69564 |  iteration: 6983 teacher: 1 stage: sketch lr: 0.000529\n",
      "batch 768 loss: 1.32285 acc: 0.70020 | v_loss: 1.24566 v_acc: 0.70117 |  iteration: 6984 teacher: 1 stage: sketch lr: 0.000529\n",
      "batch 769 loss: 1.25742 acc: 0.70508 | v_loss: 1.26613 v_acc: 0.70182 |  iteration: 6985 teacher: 0 stage: sketch lr: 0.000529\n",
      "batch 770 loss: 1.31479 acc: 0.70345 | v_loss: 1.23219 v_acc: 0.71615 |  iteration: 6986 teacher: 0 stage: sketch lr: 0.000529\n",
      "batch 771 loss: 1.25069 acc: 0.70964 | v_loss: 1.42137 v_acc: 0.69010 |  iteration: 6987 teacher: 1 stage: sketch lr: 0.000529\n",
      "batch 772 loss: 1.23877 acc: 0.71452 | v_loss: 1.29532 v_acc: 0.70964 |  iteration: 6988 teacher: 1 stage: sketch lr: 0.000529\n",
      "batch 773 loss: 1.35593 acc: 0.70182 | v_loss: 1.18391 v_acc: 0.71159 |  iteration: 6989 teacher: 1 stage: sketch lr: 0.000529\n",
      "batch 774 loss: 1.27228 acc: 0.70931 | v_loss: 1.26636 v_acc: 0.71582 |  iteration: 6990 teacher: 1 stage: sketch lr: 0.000529\n",
      "batch 775 loss: 1.27089 acc: 0.70378 | v_loss: 1.17801 v_acc: 0.70671 |  iteration: 6991 teacher: 0 stage: sketch lr: 0.000529\n",
      "batch 776 loss: 1.32427 acc: 0.70508 | v_loss: 1.27239 v_acc: 0.69987 |  iteration: 6992 teacher: 1 stage: sketch lr: 0.000529\n",
      "batch 777 loss: 1.31355 acc: 0.70638 | v_loss: 1.23477 v_acc: 0.71452 |  iteration: 6993 teacher: 0 stage: sketch lr: 0.000528\n",
      "batch 778 loss: 1.24317 acc: 0.71484 | v_loss: 1.16675 v_acc: 0.72038 |  iteration: 6994 teacher: 1 stage: sketch lr: 0.000528\n",
      "batch 779 loss: 1.27476 acc: 0.70475 | v_loss: 1.14565 v_acc: 0.72591 |  iteration: 6995 teacher: 0 stage: sketch lr: 0.000528\n",
      "batch 780 loss: 1.23358 acc: 0.71126 | v_loss: 1.25747 v_acc: 0.72233 |  iteration: 6996 teacher: 0 stage: sketch lr: 0.000528\n",
      "batch 781 loss: 1.25499 acc: 0.70215 | v_loss: 1.25213 v_acc: 0.70475 |  iteration: 6997 teacher: 1 stage: sketch lr: 0.000528\n",
      "batch 782 loss: 1.38296 acc: 0.69954 | v_loss: 1.25544 v_acc: 0.70736 |  iteration: 6998 teacher: 1 stage: sketch lr: 0.000528\n",
      "batch 783 loss: 1.24814 acc: 0.69759 | v_loss: 1.10246 v_acc: 0.72591 |  iteration: 6999 teacher: 1 stage: sketch lr: 0.000528\n",
      "batch 784 loss: 1.30308 acc: 0.70410 | v_loss: 1.25174 v_acc: 0.73177 |  iteration: 7000 teacher: 0 stage: sketch lr: 0.000528\n",
      "batch 785 loss: 1.31483 acc: 0.69987 | v_loss: 1.29861 v_acc: 0.69727 |  iteration: 7001 teacher: 0 stage: sketch lr: 0.000528\n",
      "batch 786 loss: 1.37898 acc: 0.69564 | v_loss: 1.30559 v_acc: 0.72363 |  iteration: 7002 teacher: 0 stage: sketch lr: 0.000528\n",
      "batch 787 loss: 1.34387 acc: 0.70605 | v_loss: 1.16182 v_acc: 0.71777 |  iteration: 7003 teacher: 1 stage: sketch lr: 0.000528\n",
      "batch 788 loss: 1.32453 acc: 0.70443 | v_loss: 1.11499 v_acc: 0.73600 |  iteration: 7004 teacher: 1 stage: sketch lr: 0.000528\n",
      "batch 789 loss: 1.27143 acc: 0.70898 | v_loss: 1.11079 v_acc: 0.72233 |  iteration: 7005 teacher: 1 stage: sketch lr: 0.000528\n",
      "batch 790 loss: 1.26663 acc: 0.70768 | v_loss: 1.19405 v_acc: 0.70475 |  iteration: 7006 teacher: 0 stage: sketch lr: 0.000528\n",
      "batch 791 loss: 1.31123 acc: 0.70866 | v_loss: 1.24740 v_acc: 0.69596 |  iteration: 7007 teacher: 1 stage: sketch lr: 0.000528\n",
      "batch 792 loss: 1.37671 acc: 0.69434 | v_loss: 1.19845 v_acc: 0.71582 |  iteration: 7008 teacher: 1 stage: sketch lr: 0.000528\n",
      "batch 793 loss: 1.43733 acc: 0.68913 | v_loss: 1.29707 v_acc: 0.72949 |  iteration: 7009 teacher: 1 stage: sketch lr: 0.000528\n",
      "batch 794 loss: 1.28604 acc: 0.70215 | v_loss: 1.45065 v_acc: 0.69466 |  iteration: 7010 teacher: 0 stage: sketch lr: 0.000528\n",
      "batch 795 loss: 1.30986 acc: 0.70150 | v_loss: 1.34079 v_acc: 0.69857 |  iteration: 7011 teacher: 0 stage: sketch lr: 0.000528\n",
      "batch 796 loss: 1.26111 acc: 0.69499 | v_loss: 1.18806 v_acc: 0.72428 |  iteration: 7012 teacher: 1 stage: sketch lr: 0.000528\n",
      "batch 797 loss: 1.21323 acc: 0.71842 | v_loss: 1.15332 v_acc: 0.70898 |  iteration: 7013 teacher: 0 stage: sketch lr: 0.000528\n",
      "batch 798 loss: 1.33383 acc: 0.69564 | v_loss: 1.16049 v_acc: 0.71810 |  iteration: 7014 teacher: 1 stage: sketch lr: 0.000528\n",
      "batch 799 loss: 1.34103 acc: 0.69987 | v_loss: 1.21852 v_acc: 0.70247 |  iteration: 7015 teacher: 0 stage: sketch lr: 0.000528\n",
      "batch 800 loss: 1.23717 acc: 0.70020 | v_loss: 1.25949 v_acc: 0.71875 |  iteration: 7016 teacher: 0 stage: sketch lr: 0.000528\n",
      "batch 801 loss: 1.26531 acc: 0.71061 | v_loss: 1.22030 v_acc: 0.73210 |  iteration: 7017 teacher: 0 stage: sketch lr: 0.000528\n",
      "batch 802 loss: 1.30039 acc: 0.70508 | v_loss: 1.24722 v_acc: 0.71908 |  iteration: 7018 teacher: 1 stage: sketch lr: 0.000528\n",
      "batch 803 loss: 1.19701 acc: 0.70931 | v_loss: 1.23974 v_acc: 0.71224 |  iteration: 7019 teacher: 1 stage: sketch lr: 0.000528\n",
      "batch 804 loss: 1.20414 acc: 0.72233 | v_loss: 1.15175 v_acc: 0.72493 |  iteration: 7020 teacher: 0 stage: sketch lr: 0.000527\n",
      "batch 805 loss: 1.23634 acc: 0.71191 | v_loss: 1.12429 v_acc: 0.72428 |  iteration: 7021 teacher: 0 stage: sketch lr: 0.000527\n",
      "batch 806 loss: 1.25528 acc: 0.70638 | v_loss: 1.40957 v_acc: 0.68880 |  iteration: 7022 teacher: 0 stage: sketch lr: 0.000527\n",
      "batch 807 loss: 1.20427 acc: 0.70768 | v_loss: 1.20752 v_acc: 0.71191 |  iteration: 7023 teacher: 0 stage: sketch lr: 0.000527\n",
      "batch 808 loss: 1.34699 acc: 0.69759 | v_loss: 1.22275 v_acc: 0.71973 |  iteration: 7024 teacher: 0 stage: sketch lr: 0.000527\n",
      "batch 809 loss: 1.24712 acc: 0.70866 | v_loss: 1.24093 v_acc: 0.70898 |  iteration: 7025 teacher: 0 stage: sketch lr: 0.000527\n",
      "batch 810 loss: 1.30160 acc: 0.70671 | v_loss: 1.28810 v_acc: 0.70638 |  iteration: 7026 teacher: 1 stage: sketch lr: 0.000527\n",
      "batch 811 loss: 1.21872 acc: 0.71647 | v_loss: 1.13464 v_acc: 0.73242 |  iteration: 7027 teacher: 1 stage: sketch lr: 0.000527\n",
      "batch 812 loss: 1.30831 acc: 0.69889 | v_loss: 1.38824 v_acc: 0.71387 |  iteration: 7028 teacher: 0 stage: sketch lr: 0.000527\n",
      "batch 813 loss: 1.22329 acc: 0.71615 | v_loss: 1.18366 v_acc: 0.70247 |  iteration: 7029 teacher: 0 stage: sketch lr: 0.000527\n",
      "batch 814 loss: 1.35537 acc: 0.69401 | v_loss: 1.20901 v_acc: 0.70573 |  iteration: 7030 teacher: 0 stage: sketch lr: 0.000527\n",
      "batch 815 loss: 1.27554 acc: 0.70475 | v_loss: 1.27340 v_acc: 0.70117 |  iteration: 7031 teacher: 0 stage: sketch lr: 0.000527\n",
      "batch 816 loss: 1.30571 acc: 0.71094 | v_loss: 1.28739 v_acc: 0.70508 |  iteration: 7032 teacher: 0 stage: sketch lr: 0.000527\n",
      "batch 817 loss: 1.26950 acc: 0.70605 | v_loss: 1.34870 v_acc: 0.69238 |  iteration: 7033 teacher: 1 stage: sketch lr: 0.000527\n",
      "batch 818 loss: 1.31580 acc: 0.69954 | v_loss: 1.36226 v_acc: 0.70182 |  iteration: 7034 teacher: 0 stage: sketch lr: 0.000527\n",
      "batch 819 loss: 1.35722 acc: 0.69694 | v_loss: 1.29474 v_acc: 0.70573 |  iteration: 7035 teacher: 1 stage: sketch lr: 0.000527\n",
      "batch 820 loss: 1.34341 acc: 0.70410 | v_loss: 1.20169 v_acc: 0.71257 |  iteration: 7036 teacher: 1 stage: sketch lr: 0.000527\n",
      "batch 821 loss: 1.18106 acc: 0.72266 | v_loss: 1.32237 v_acc: 0.70345 |  iteration: 7037 teacher: 0 stage: sketch lr: 0.000527\n",
      "batch 822 loss: 1.33434 acc: 0.70215 | v_loss: 1.23488 v_acc: 0.71126 |  iteration: 7038 teacher: 0 stage: sketch lr: 0.000527\n",
      "batch 823 loss: 1.32400 acc: 0.70573 | v_loss: 1.13541 v_acc: 0.72396 |  iteration: 7039 teacher: 0 stage: sketch lr: 0.000527\n",
      "batch 824 loss: 1.28245 acc: 0.70573 | v_loss: 1.13984 v_acc: 0.70736 |  iteration: 7040 teacher: 1 stage: sketch lr: 0.000527\n",
      "batch 825 loss: 1.15430 acc: 0.71484 | v_loss: 1.25253 v_acc: 0.70671 |  iteration: 7041 teacher: 0 stage: sketch lr: 0.000527\n",
      "batch 826 loss: 1.33225 acc: 0.69564 | v_loss: 1.33596 v_acc: 0.69954 |  iteration: 7042 teacher: 0 stage: sketch lr: 0.000527\n",
      "batch 827 loss: 1.32068 acc: 0.70312 | v_loss: 1.17595 v_acc: 0.71484 |  iteration: 7043 teacher: 1 stage: sketch lr: 0.000527\n",
      "batch 828 loss: 1.28066 acc: 0.70605 | v_loss: 1.20074 v_acc: 0.70312 |  iteration: 7044 teacher: 0 stage: sketch lr: 0.000527\n",
      "batch 829 loss: 1.28124 acc: 0.70020 | v_loss: 1.18123 v_acc: 0.71680 |  iteration: 7045 teacher: 0 stage: sketch lr: 0.000527\n",
      "batch 830 loss: 1.23064 acc: 0.70801 | v_loss: 1.19393 v_acc: 0.70671 |  iteration: 7046 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 831 loss: 1.29178 acc: 0.70540 | v_loss: 1.08853 v_acc: 0.73568 |  iteration: 7047 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 832 loss: 1.38119 acc: 0.69076 | v_loss: 1.17564 v_acc: 0.72461 |  iteration: 7048 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 833 loss: 1.24246 acc: 0.70931 | v_loss: 1.14776 v_acc: 0.72721 |  iteration: 7049 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 834 loss: 1.31864 acc: 0.70833 | v_loss: 1.12050 v_acc: 0.72363 |  iteration: 7050 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 835 loss: 1.43644 acc: 0.69108 | v_loss: 1.21056 v_acc: 0.71973 |  iteration: 7051 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 836 loss: 1.26385 acc: 0.70085 | v_loss: 1.23684 v_acc: 0.71484 |  iteration: 7052 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 837 loss: 1.30385 acc: 0.70182 | v_loss: 1.20460 v_acc: 0.72168 |  iteration: 7053 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 838 loss: 1.43533 acc: 0.68945 | v_loss: 1.38475 v_acc: 0.69629 |  iteration: 7054 teacher: 1 stage: sketch lr: 0.000526\n",
      "batch 839 loss: 1.24464 acc: 0.70964 | v_loss: 1.25351 v_acc: 0.72266 |  iteration: 7055 teacher: 1 stage: sketch lr: 0.000526\n",
      "batch 840 loss: 1.33533 acc: 0.69987 | v_loss: 1.06389 v_acc: 0.74316 |  iteration: 7056 teacher: 1 stage: sketch lr: 0.000526\n",
      "batch 841 loss: 1.26592 acc: 0.69727 | v_loss: 1.21942 v_acc: 0.70573 |  iteration: 7057 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 842 loss: 1.30492 acc: 0.70931 | v_loss: 1.27618 v_acc: 0.70247 |  iteration: 7058 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 843 loss: 1.28695 acc: 0.69824 | v_loss: 1.18789 v_acc: 0.70638 |  iteration: 7059 teacher: 1 stage: sketch lr: 0.000526\n",
      "batch 844 loss: 1.31648 acc: 0.70247 | v_loss: 1.25138 v_acc: 0.71322 |  iteration: 7060 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 845 loss: 1.22819 acc: 0.70443 | v_loss: 1.24778 v_acc: 0.69271 |  iteration: 7061 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 846 loss: 1.29283 acc: 0.70605 | v_loss: 1.22339 v_acc: 0.71842 |  iteration: 7062 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 847 loss: 1.22943 acc: 0.71126 | v_loss: 1.25583 v_acc: 0.70215 |  iteration: 7063 teacher: 1 stage: sketch lr: 0.000526\n",
      "batch 848 loss: 1.27002 acc: 0.70508 | v_loss: 1.18983 v_acc: 0.72005 |  iteration: 7064 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 849 loss: 1.24483 acc: 0.70703 | v_loss: 1.19178 v_acc: 0.72786 |  iteration: 7065 teacher: 1 stage: sketch lr: 0.000526\n",
      "batch 850 loss: 1.39269 acc: 0.68880 | v_loss: 1.26230 v_acc: 0.70345 |  iteration: 7066 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 851 loss: 1.22536 acc: 0.70898 | v_loss: 1.33754 v_acc: 0.69857 |  iteration: 7067 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 852 loss: 1.27287 acc: 0.70052 | v_loss: 1.15036 v_acc: 0.70931 |  iteration: 7068 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 853 loss: 1.28684 acc: 0.69727 | v_loss: 1.43192 v_acc: 0.67969 |  iteration: 7069 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 854 loss: 1.30126 acc: 0.70182 | v_loss: 1.17865 v_acc: 0.72103 |  iteration: 7070 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 855 loss: 1.19679 acc: 0.70996 | v_loss: 1.49121 v_acc: 0.67513 |  iteration: 7071 teacher: 1 stage: sketch lr: 0.000526\n",
      "batch 856 loss: 1.33440 acc: 0.69596 | v_loss: 1.39474 v_acc: 0.68815 |  iteration: 7072 teacher: 0 stage: sketch lr: 0.000526\n",
      "batch 857 loss: 1.22995 acc: 0.70052 | v_loss: 1.34736 v_acc: 0.69271 |  iteration: 7073 teacher: 0 stage: sketch lr: 0.000525\n",
      "batch 858 loss: 1.31989 acc: 0.68587 | v_loss: 1.32120 v_acc: 0.69792 |  iteration: 7074 teacher: 0 stage: sketch lr: 0.000525\n",
      "batch 859 loss: 1.28944 acc: 0.69564 | v_loss: 1.23032 v_acc: 0.70736 |  iteration: 7075 teacher: 1 stage: sketch lr: 0.000525\n",
      "batch 860 loss: 1.30657 acc: 0.69792 | v_loss: 1.25980 v_acc: 0.70605 |  iteration: 7076 teacher: 0 stage: sketch lr: 0.000525\n",
      "batch 861 loss: 1.30663 acc: 0.70182 | v_loss: 1.22093 v_acc: 0.71973 |  iteration: 7077 teacher: 1 stage: sketch lr: 0.000525\n",
      "batch 862 loss: 1.23496 acc: 0.70378 | v_loss: 1.40865 v_acc: 0.69303 |  iteration: 7078 teacher: 0 stage: sketch lr: 0.000525\n",
      "batch 863 loss: 1.39426 acc: 0.69141 | v_loss: 1.29263 v_acc: 0.70247 |  iteration: 7079 teacher: 1 stage: sketch lr: 0.000525\n",
      "batch 864 loss: 1.37882 acc: 0.70280 | v_loss: 1.19791 v_acc: 0.71159 |  iteration: 7080 teacher: 0 stage: sketch lr: 0.000525\n",
      "batch 865 loss: 1.21358 acc: 0.71940 | v_loss: 1.26259 v_acc: 0.71777 |  iteration: 7081 teacher: 1 stage: sketch lr: 0.000525\n",
      "batch 866 loss: 1.25346 acc: 0.70964 | v_loss: 1.17060 v_acc: 0.70443 |  iteration: 7082 teacher: 1 stage: sketch lr: 0.000525\n",
      "batch 867 loss: 1.32566 acc: 0.69954 | v_loss: 1.27419 v_acc: 0.69759 |  iteration: 7083 teacher: 1 stage: sketch lr: 0.000525\n",
      "batch 868 loss: 1.34760 acc: 0.70280 | v_loss: 1.23459 v_acc: 0.71517 |  iteration: 7084 teacher: 0 stage: sketch lr: 0.000525\n",
      "batch 869 loss: 1.23381 acc: 0.71289 | v_loss: 1.16998 v_acc: 0.71680 |  iteration: 7085 teacher: 0 stage: sketch lr: 0.000525\n",
      "batch 870 loss: 1.35263 acc: 0.70443 | v_loss: 1.14409 v_acc: 0.72884 |  iteration: 7086 teacher: 0 stage: sketch lr: 0.000525\n",
      "batch 871 loss: 1.24037 acc: 0.72396 | v_loss: 1.26715 v_acc: 0.71810 |  iteration: 7087 teacher: 0 stage: sketch lr: 0.000525\n",
      "batch 872 loss: 1.26376 acc: 0.70312 | v_loss: 1.25368 v_acc: 0.70443 |  iteration: 7088 teacher: 0 stage: sketch lr: 0.000525\n",
      "batch 873 loss: 1.27252 acc: 0.70312 | v_loss: 1.26054 v_acc: 0.70996 |  iteration: 7089 teacher: 1 stage: sketch lr: 0.000525\n",
      "batch 874 loss: 1.36248 acc: 0.70410 | v_loss: 1.11158 v_acc: 0.72331 |  iteration: 7090 teacher: 0 stage: sketch lr: 0.000525\n",
      "batch 875 loss: 1.26305 acc: 0.69987 | v_loss: 1.25535 v_acc: 0.73145 |  iteration: 7091 teacher: 0 stage: sketch lr: 0.000525\n",
      "batch 876 loss: 1.34682 acc: 0.69824 | v_loss: 1.30383 v_acc: 0.69629 |  iteration: 7092 teacher: 0 stage: sketch lr: 0.000525\n",
      "batch 877 loss: 1.21703 acc: 0.70736 | v_loss: 1.30237 v_acc: 0.72070 |  iteration: 7093 teacher: 1 stage: sketch lr: 0.000525\n",
      "batch 878 loss: 1.34786 acc: 0.69824 | v_loss: 1.15231 v_acc: 0.71908 |  iteration: 7094 teacher: 0 stage: sketch lr: 0.000525\n",
      "batch 879 loss: 1.28545 acc: 0.70410 | v_loss: 1.10507 v_acc: 0.73828 |  iteration: 7095 teacher: 1 stage: sketch lr: 0.000525\n",
      "batch 880 loss: 1.29535 acc: 0.71094 | v_loss: 1.10280 v_acc: 0.72396 |  iteration: 7096 teacher: 0 stage: sketch lr: 0.000525\n",
      "batch 881 loss: 1.18244 acc: 0.71484 | v_loss: 1.19071 v_acc: 0.71126 |  iteration: 7097 teacher: 1 stage: sketch lr: 0.000525\n",
      "batch 882 loss: 1.26786 acc: 0.71387 | v_loss: 1.23474 v_acc: 0.70508 |  iteration: 7098 teacher: 1 stage: sketch lr: 0.000525\n",
      "batch 883 loss: 1.22115 acc: 0.70898 | v_loss: 1.19052 v_acc: 0.71517 |  iteration: 7099 teacher: 1 stage: sketch lr: 0.000525\n",
      "batch 884 loss: 1.32885 acc: 0.70020 | v_loss: 1.29153 v_acc: 0.71680 |  iteration: 7100 teacher: 0 stage: sketch lr: 0.000524\n",
      "batch 885 loss: 1.40895 acc: 0.68457 | v_loss: 1.46371 v_acc: 0.69271 |  iteration: 7101 teacher: 1 stage: sketch lr: 0.000524\n",
      "batch 886 loss: 1.24624 acc: 0.71257 | v_loss: 1.34271 v_acc: 0.69857 |  iteration: 7102 teacher: 1 stage: sketch lr: 0.000524\n",
      "batch 887 loss: 1.33414 acc: 0.70345 | v_loss: 1.19232 v_acc: 0.72233 |  iteration: 7103 teacher: 1 stage: sketch lr: 0.000524\n",
      "batch 888 loss: 1.24134 acc: 0.71289 | v_loss: 1.16670 v_acc: 0.70866 |  iteration: 7104 teacher: 1 stage: sketch lr: 0.000524\n",
      "batch 889 loss: 1.30441 acc: 0.69759 | v_loss: 1.16091 v_acc: 0.71842 |  iteration: 7105 teacher: 0 stage: sketch lr: 0.000524\n",
      "batch 890 loss: 1.24465 acc: 0.71777 | v_loss: 1.22527 v_acc: 0.70247 |  iteration: 7106 teacher: 0 stage: sketch lr: 0.000524\n",
      "batch 891 loss: 1.25668 acc: 0.69954 | v_loss: 1.26372 v_acc: 0.72103 |  iteration: 7107 teacher: 0 stage: sketch lr: 0.000524\n",
      "batch 892 loss: 1.22778 acc: 0.70280 | v_loss: 1.21546 v_acc: 0.72721 |  iteration: 7108 teacher: 1 stage: sketch lr: 0.000524\n",
      "batch 893 loss: 1.36494 acc: 0.69727 | v_loss: 1.25271 v_acc: 0.71810 |  iteration: 7109 teacher: 1 stage: sketch lr: 0.000524\n",
      "batch 894 loss: 1.27139 acc: 0.70247 | v_loss: 1.24324 v_acc: 0.71615 |  iteration: 7110 teacher: 0 stage: sketch lr: 0.000524\n",
      "batch 895 loss: 1.30381 acc: 0.69824 | v_loss: 1.15945 v_acc: 0.72168 |  iteration: 7111 teacher: 0 stage: sketch lr: 0.000524\n",
      "batch 896 loss: 1.28080 acc: 0.69954 | v_loss: 1.12556 v_acc: 0.72201 |  iteration: 7112 teacher: 1 stage: sketch lr: 0.000524\n",
      "batch 897 loss: 1.31045 acc: 0.70768 | v_loss: 1.43519 v_acc: 0.68978 |  iteration: 7113 teacher: 1 stage: sketch lr: 0.000524\n",
      "batch 898 loss: 1.26562 acc: 0.70605 | v_loss: 1.20491 v_acc: 0.71322 |  iteration: 7114 teacher: 1 stage: sketch lr: 0.000524\n",
      "batch 899 loss: 1.22847 acc: 0.71452 | v_loss: 1.22598 v_acc: 0.71452 |  iteration: 7115 teacher: 1 stage: sketch lr: 0.000524\n",
      "batch 900 loss: 1.29039 acc: 0.70410 | v_loss: 1.23283 v_acc: 0.70378 |  iteration: 7116 teacher: 1 stage: sketch lr: 0.000524\n",
      "batch 901 loss: 1.30382 acc: 0.70540 | v_loss: 1.29879 v_acc: 0.70443 |  iteration: 7117 teacher: 0 stage: sketch lr: 0.000524\n",
      "batch 902 loss: 1.35451 acc: 0.70215 | v_loss: 1.13733 v_acc: 0.73145 |  iteration: 7118 teacher: 1 stage: sketch lr: 0.000524\n",
      "batch 903 loss: 1.31655 acc: 0.70085 | v_loss: 1.37578 v_acc: 0.71745 |  iteration: 7119 teacher: 1 stage: sketch lr: 0.000524\n",
      "batch 904 loss: 1.33960 acc: 0.70280 | v_loss: 1.20578 v_acc: 0.70085 |  iteration: 7120 teacher: 1 stage: sketch lr: 0.000524\n",
      "batch 905 loss: 1.22552 acc: 0.71973 | v_loss: 1.22446 v_acc: 0.70117 |  iteration: 7121 teacher: 0 stage: sketch lr: 0.000524\n",
      "batch 906 loss: 1.38528 acc: 0.69694 | v_loss: 1.27816 v_acc: 0.70508 |  iteration: 7122 teacher: 1 stage: sketch lr: 0.000524\n",
      "batch 907 loss: 1.34792 acc: 0.69564 | v_loss: 1.27631 v_acc: 0.70573 |  iteration: 7123 teacher: 1 stage: sketch lr: 0.000524\n",
      "batch 908 loss: 1.26798 acc: 0.70280 | v_loss: 1.33827 v_acc: 0.69010 |  iteration: 7124 teacher: 1 stage: sketch lr: 0.000524\n",
      "batch 909 loss: 1.21980 acc: 0.71029 | v_loss: 1.36272 v_acc: 0.70475 |  iteration: 7125 teacher: 1 stage: sketch lr: 0.000524\n",
      "batch 910 loss: 1.27819 acc: 0.70703 | v_loss: 1.28831 v_acc: 0.70443 |  iteration: 7126 teacher: 0 stage: sketch lr: 0.000524\n",
      "batch 911 loss: 1.27032 acc: 0.70247 | v_loss: 1.20480 v_acc: 0.70768 |  iteration: 7127 teacher: 0 stage: sketch lr: 0.000523\n",
      "batch 912 loss: 1.31959 acc: 0.69922 | v_loss: 1.31109 v_acc: 0.70410 |  iteration: 7128 teacher: 0 stage: sketch lr: 0.000523\n",
      "batch 913 loss: 1.27986 acc: 0.69987 | v_loss: 1.20598 v_acc: 0.71257 |  iteration: 7129 teacher: 0 stage: sketch lr: 0.000523\n",
      "batch 914 loss: 1.30388 acc: 0.69792 | v_loss: 1.16134 v_acc: 0.72038 |  iteration: 7130 teacher: 0 stage: sketch lr: 0.000523\n",
      "batch 915 loss: 1.26271 acc: 0.70150 | v_loss: 1.12045 v_acc: 0.70898 |  iteration: 7131 teacher: 0 stage: sketch lr: 0.000523\n",
      "batch 916 loss: 1.29875 acc: 0.69564 | v_loss: 1.25535 v_acc: 0.70931 |  iteration: 7132 teacher: 0 stage: sketch lr: 0.000523\n",
      "batch 917 loss: 1.42448 acc: 0.68815 | v_loss: 1.33876 v_acc: 0.69141 |  iteration: 7133 teacher: 1 stage: sketch lr: 0.000523\n",
      "batch 918 loss: 1.18707 acc: 0.71842 | v_loss: 1.15620 v_acc: 0.71452 |  iteration: 7134 teacher: 0 stage: sketch lr: 0.000523\n",
      "batch 919 loss: 1.25503 acc: 0.71354 | v_loss: 1.19103 v_acc: 0.70150 |  iteration: 7135 teacher: 0 stage: sketch lr: 0.000523\n",
      "batch 920 loss: 1.30358 acc: 0.69922 | v_loss: 1.20328 v_acc: 0.71061 |  iteration: 7136 teacher: 0 stage: sketch lr: 0.000523\n",
      "batch 921 loss: 1.39397 acc: 0.69368 | v_loss: 1.24144 v_acc: 0.70150 |  iteration: 7137 teacher: 1 stage: sketch lr: 0.000523\n",
      "batch 922 loss: 1.26784 acc: 0.70280 | v_loss: 1.06636 v_acc: 0.73893 |  iteration: 7138 teacher: 0 stage: sketch lr: 0.000523\n",
      "batch 923 loss: 1.25469 acc: 0.70931 | v_loss: 1.18376 v_acc: 0.71289 |  iteration: 7139 teacher: 1 stage: sketch lr: 0.000523\n",
      "batch 924 loss: 1.23750 acc: 0.71452 | v_loss: 1.12375 v_acc: 0.71517 |  iteration: 7140 teacher: 0 stage: sketch lr: 0.000523\n",
      "batch 925 loss: 1.29865 acc: 0.70117 | v_loss: 1.12278 v_acc: 0.72135 |  iteration: 7141 teacher: 0 stage: sketch lr: 0.000523\n",
      "batch 926 loss: 1.39261 acc: 0.68945 | v_loss: 1.21071 v_acc: 0.72038 |  iteration: 7142 teacher: 1 stage: sketch lr: 0.000523\n",
      "batch 927 loss: 1.28108 acc: 0.70215 | v_loss: 1.24439 v_acc: 0.71126 |  iteration: 7143 teacher: 0 stage: sketch lr: 0.000523\n",
      "batch 928 loss: 1.27109 acc: 0.69759 | v_loss: 1.22665 v_acc: 0.71615 |  iteration: 7144 teacher: 0 stage: sketch lr: 0.000523\n",
      "batch 929 loss: 1.33956 acc: 0.70378 | v_loss: 1.38361 v_acc: 0.69271 |  iteration: 7145 teacher: 0 stage: sketch lr: 0.000523\n",
      "batch 930 loss: 1.31884 acc: 0.70605 | v_loss: 1.30515 v_acc: 0.71322 |  iteration: 7146 teacher: 1 stage: sketch lr: 0.000523\n",
      "batch 931 loss: 1.25866 acc: 0.71029 | v_loss: 1.07584 v_acc: 0.73926 |  iteration: 7147 teacher: 0 stage: sketch lr: 0.000523\n",
      "batch 932 loss: 1.38228 acc: 0.69043 | v_loss: 1.19954 v_acc: 0.70671 |  iteration: 7148 teacher: 1 stage: sketch lr: 0.000523\n",
      "batch 933 loss: 1.27127 acc: 0.70964 | v_loss: 1.30672 v_acc: 0.69043 |  iteration: 7149 teacher: 1 stage: sketch lr: 0.000523\n",
      "batch 934 loss: 1.32831 acc: 0.70410 | v_loss: 1.22200 v_acc: 0.69466 |  iteration: 7150 teacher: 0 stage: sketch lr: 0.000523\n",
      "batch 935 loss: 1.26138 acc: 0.70605 | v_loss: 1.25531 v_acc: 0.70280 |  iteration: 7151 teacher: 1 stage: sketch lr: 0.000523\n",
      "batch 936 loss: 1.25671 acc: 0.70964 | v_loss: 1.25798 v_acc: 0.69336 |  iteration: 7152 teacher: 1 stage: sketch lr: 0.000523\n",
      "batch 937 loss: 1.27224 acc: 0.70475 | v_loss: 1.24039 v_acc: 0.71680 |  iteration: 7153 teacher: 0 stage: sketch lr: 0.000523\n",
      "batch 938 loss: 1.35779 acc: 0.69792 | v_loss: 1.26666 v_acc: 0.70247 |  iteration: 7154 teacher: 1 stage: sketch lr: 0.000523\n",
      "batch 939 loss: 1.27813 acc: 0.70801 | v_loss: 1.16192 v_acc: 0.72754 |  iteration: 7155 teacher: 1 stage: sketch lr: 0.000522\n",
      "batch 940 loss: 1.26958 acc: 0.70703 | v_loss: 1.17838 v_acc: 0.72624 |  iteration: 7156 teacher: 1 stage: sketch lr: 0.000522\n",
      "batch 941 loss: 1.27136 acc: 0.70378 | v_loss: 1.24706 v_acc: 0.70410 |  iteration: 7157 teacher: 1 stage: sketch lr: 0.000522\n",
      "batch 942 loss: 1.29684 acc: 0.69759 | v_loss: 1.34694 v_acc: 0.69954 |  iteration: 7158 teacher: 0 stage: sketch lr: 0.000522\n",
      "batch 943 loss: 1.28149 acc: 0.70345 | v_loss: 1.16090 v_acc: 0.70703 |  iteration: 7159 teacher: 0 stage: sketch lr: 0.000522\n",
      "batch 944 loss: 1.27124 acc: 0.70671 | v_loss: 1.41010 v_acc: 0.68392 |  iteration: 7160 teacher: 0 stage: sketch lr: 0.000522\n",
      "batch 945 loss: 1.37601 acc: 0.69466 | v_loss: 1.18417 v_acc: 0.71745 |  iteration: 7161 teacher: 0 stage: sketch lr: 0.000522\n",
      "batch 946 loss: 1.32528 acc: 0.70508 | v_loss: 1.47058 v_acc: 0.68392 |  iteration: 7162 teacher: 0 stage: sketch lr: 0.000522\n",
      "batch 947 loss: 1.29961 acc: 0.69987 | v_loss: 1.35684 v_acc: 0.69792 |  iteration: 7163 teacher: 1 stage: sketch lr: 0.000522\n",
      "batch 948 loss: 1.33899 acc: 0.69727 | v_loss: 1.33872 v_acc: 0.68945 |  iteration: 7164 teacher: 1 stage: sketch lr: 0.000522\n",
      "batch 949 loss: 1.28942 acc: 0.70508 | v_loss: 1.30963 v_acc: 0.69759 |  iteration: 7165 teacher: 0 stage: sketch lr: 0.000522\n",
      "batch 950 loss: 1.37229 acc: 0.68783 | v_loss: 1.25342 v_acc: 0.70215 |  iteration: 7166 teacher: 0 stage: sketch lr: 0.000522\n",
      "batch 951 loss: 1.29758 acc: 0.70573 | v_loss: 1.27164 v_acc: 0.69889 |  iteration: 7167 teacher: 1 stage: sketch lr: 0.000522\n",
      "batch 952 loss: 1.24779 acc: 0.71191 | v_loss: 1.21984 v_acc: 0.71419 |  iteration: 7168 teacher: 1 stage: sketch lr: 0.000522\n",
      "batch 953 loss: 1.29985 acc: 0.70280 | v_loss: 1.41458 v_acc: 0.69173 |  iteration: 7169 teacher: 0 stage: sketch lr: 0.000522\n",
      "batch 954 loss: 1.27239 acc: 0.70931 | v_loss: 1.29927 v_acc: 0.70247 |  iteration: 7170 teacher: 1 stage: sketch lr: 0.000522\n",
      "batch 955 loss: 1.27106 acc: 0.71289 | v_loss: 1.18426 v_acc: 0.71224 |  iteration: 7171 teacher: 1 stage: sketch lr: 0.000522\n",
      "batch 956 loss: 1.26829 acc: 0.69922 | v_loss: 1.26648 v_acc: 0.71549 |  iteration: 7172 teacher: 0 stage: sketch lr: 0.000522\n",
      "batch 957 loss: 1.27003 acc: 0.69987 | v_loss: 1.17326 v_acc: 0.70540 |  iteration: 7173 teacher: 1 stage: sketch lr: 0.000522\n",
      "batch 958 loss: 1.31315 acc: 0.70280 | v_loss: 1.27808 v_acc: 0.69759 |  iteration: 7174 teacher: 1 stage: sketch lr: 0.000522\n",
      "batch 959 loss: 1.27783 acc: 0.70312 | v_loss: 1.24426 v_acc: 0.71191 |  iteration: 7175 teacher: 0 stage: sketch lr: 0.000522\n",
      "batch 960 loss: 1.29758 acc: 0.70150 | v_loss: 1.16775 v_acc: 0.72005 |  iteration: 7176 teacher: 0 stage: sketch lr: 0.000522\n",
      "batch 961 loss: 1.29747 acc: 0.70345 | v_loss: 1.14433 v_acc: 0.72591 |  iteration: 7177 teacher: 0 stage: sketch lr: 0.000522\n",
      "batch 962 loss: 1.26865 acc: 0.70215 | v_loss: 1.28079 v_acc: 0.71419 |  iteration: 7178 teacher: 1 stage: sketch lr: 0.000522\n",
      "batch 963 loss: 1.33074 acc: 0.69108 | v_loss: 1.26244 v_acc: 0.70475 |  iteration: 7179 teacher: 0 stage: sketch lr: 0.000522\n",
      "batch 964 loss: 1.32341 acc: 0.69368 | v_loss: 1.26477 v_acc: 0.70833 |  iteration: 7180 teacher: 0 stage: sketch lr: 0.000522\n",
      "batch 965 loss: 1.34640 acc: 0.69857 | v_loss: 1.11844 v_acc: 0.71908 |  iteration: 7181 teacher: 0 stage: sketch lr: 0.000522\n",
      "batch 966 loss: 1.32012 acc: 0.69499 | v_loss: 1.24527 v_acc: 0.73145 |  iteration: 7182 teacher: 1 stage: sketch lr: 0.000521\n",
      "batch 967 loss: 1.27871 acc: 0.70443 | v_loss: 1.30901 v_acc: 0.69596 |  iteration: 7183 teacher: 1 stage: sketch lr: 0.000521\n",
      "batch 968 loss: 1.27203 acc: 0.70671 | v_loss: 1.31157 v_acc: 0.72266 |  iteration: 7184 teacher: 0 stage: sketch lr: 0.000521\n",
      "batch 969 loss: 1.32564 acc: 0.70150 | v_loss: 1.16558 v_acc: 0.72005 |  iteration: 7185 teacher: 0 stage: sketch lr: 0.000521\n",
      "batch 970 loss: 1.37731 acc: 0.69173 | v_loss: 1.11044 v_acc: 0.73861 |  iteration: 7186 teacher: 1 stage: sketch lr: 0.000521\n",
      "batch 971 loss: 1.29757 acc: 0.70215 | v_loss: 1.09767 v_acc: 0.72852 |  iteration: 7187 teacher: 0 stage: sketch lr: 0.000521\n",
      "batch 972 loss: 1.25198 acc: 0.71387 | v_loss: 1.20066 v_acc: 0.71387 |  iteration: 7188 teacher: 0 stage: sketch lr: 0.000521\n",
      "batch 973 loss: 1.25378 acc: 0.69792 | v_loss: 1.22242 v_acc: 0.70247 |  iteration: 7189 teacher: 0 stage: sketch lr: 0.000521\n",
      "batch 974 loss: 1.23485 acc: 0.71126 | v_loss: 1.22655 v_acc: 0.71126 |  iteration: 7190 teacher: 0 stage: sketch lr: 0.000521\n",
      "batch 975 loss: 1.32422 acc: 0.70215 | v_loss: 1.35891 v_acc: 0.70443 |  iteration: 7191 teacher: 0 stage: sketch lr: 0.000521\n",
      "batch 976 loss: 1.29697 acc: 0.70996 | v_loss: 1.47310 v_acc: 0.69564 |  iteration: 7192 teacher: 1 stage: sketch lr: 0.000521\n",
      "batch 977 loss: 1.31108 acc: 0.69173 | v_loss: 1.33957 v_acc: 0.70020 |  iteration: 7193 teacher: 1 stage: sketch lr: 0.000521\n",
      "batch 978 loss: 1.32663 acc: 0.69987 | v_loss: 1.19905 v_acc: 0.72038 |  iteration: 7194 teacher: 1 stage: sketch lr: 0.000521\n",
      "batch 979 loss: 1.23973 acc: 0.71680 | v_loss: 1.16008 v_acc: 0.69987 |  iteration: 7195 teacher: 0 stage: sketch lr: 0.000521\n",
      "batch 980 loss: 1.34563 acc: 0.69727 | v_loss: 1.16874 v_acc: 0.71615 |  iteration: 7196 teacher: 1 stage: sketch lr: 0.000521\n",
      "batch 981 loss: 1.34410 acc: 0.69792 | v_loss: 1.23998 v_acc: 0.69238 |  iteration: 7197 teacher: 1 stage: sketch lr: 0.000521\n",
      "batch 982 loss: 1.31778 acc: 0.69596 | v_loss: 1.25205 v_acc: 0.70768 |  iteration: 7198 teacher: 1 stage: sketch lr: 0.000521\n",
      "batch 983 loss: 1.29440 acc: 0.70150 | v_loss: 1.21866 v_acc: 0.72982 |  iteration: 7199 teacher: 1 stage: sketch lr: 0.000521\n",
      "batch 984 loss: 1.29939 acc: 0.70150 | v_loss: 1.23478 v_acc: 0.72005 |  iteration: 7200 teacher: 1 stage: sketch lr: 0.000521\n",
      "batch 985 loss: 1.34231 acc: 0.70020 | v_loss: 1.23662 v_acc: 0.71061 |  iteration: 7201 teacher: 0 stage: sketch lr: 0.000521\n",
      "batch 986 loss: 1.35343 acc: 0.69596 | v_loss: 1.14631 v_acc: 0.72461 |  iteration: 7202 teacher: 1 stage: sketch lr: 0.000521\n",
      "batch 987 loss: 1.34542 acc: 0.70052 | v_loss: 1.12517 v_acc: 0.71908 |  iteration: 7203 teacher: 1 stage: sketch lr: 0.000521\n",
      "batch 988 loss: 1.23206 acc: 0.70182 | v_loss: 1.44893 v_acc: 0.69271 |  iteration: 7204 teacher: 1 stage: sketch lr: 0.000521\n",
      "batch 989 loss: 1.31437 acc: 0.69987 | v_loss: 1.19906 v_acc: 0.71484 |  iteration: 7205 teacher: 0 stage: sketch lr: 0.000521\n",
      "batch 990 loss: 1.35905 acc: 0.69727 | v_loss: 1.22708 v_acc: 0.71973 |  iteration: 7206 teacher: 1 stage: sketch lr: 0.000521\n",
      "batch 991 loss: 1.33313 acc: 0.69596 | v_loss: 1.21830 v_acc: 0.71810 |  iteration: 7207 teacher: 0 stage: sketch lr: 0.000521\n",
      "batch 992 loss: 1.22821 acc: 0.70866 | v_loss: 1.27897 v_acc: 0.70410 |  iteration: 7208 teacher: 0 stage: sketch lr: 0.000521\n",
      "batch 993 loss: 1.24297 acc: 0.70508 | v_loss: 1.13341 v_acc: 0.73014 |  iteration: 7209 teacher: 0 stage: sketch lr: 0.000521\n",
      "batch 994 loss: 1.32377 acc: 0.69857 | v_loss: 1.37805 v_acc: 0.71452 |  iteration: 7210 teacher: 1 stage: sketch lr: 0.000520\n",
      "batch 995 loss: 1.26801 acc: 0.71387 | v_loss: 1.19529 v_acc: 0.69954 |  iteration: 7211 teacher: 0 stage: sketch lr: 0.000520\n",
      "batch 996 loss: 1.31811 acc: 0.69987 | v_loss: 1.21318 v_acc: 0.70378 |  iteration: 7212 teacher: 1 stage: sketch lr: 0.000520\n",
      "batch 997 loss: 1.24523 acc: 0.70931 | v_loss: 1.25446 v_acc: 0.70345 |  iteration: 7213 teacher: 0 stage: sketch lr: 0.000520\n",
      "batch 998 loss: 1.21225 acc: 0.71387 | v_loss: 1.26990 v_acc: 0.70117 |  iteration: 7214 teacher: 1 stage: sketch lr: 0.000520\n",
      "batch 999 loss: 1.29580 acc: 0.71094 | v_loss: 1.33284 v_acc: 0.68880 |  iteration: 7215 teacher: 1 stage: sketch lr: 0.000520\n",
      "batch 1000 loss: 1.25632 acc: 0.71484 | v_loss: 1.36642 v_acc: 0.70540 |  iteration: 7216 teacher: 0 stage: sketch lr: 0.000520\n",
      "batch 1001 loss: 1.24258 acc: 0.71224 | v_loss: 1.28307 v_acc: 0.70540 |  iteration: 7217 teacher: 0 stage: sketch lr: 0.000520\n",
      "batch 1002 loss: 1.35713 acc: 0.68783 | v_loss: 1.20383 v_acc: 0.70768 |  iteration: 7218 teacher: 1 stage: sketch lr: 0.000520\n",
      "batch 1003 loss: 1.23840 acc: 0.71257 | v_loss: 1.31812 v_acc: 0.70671 |  iteration: 7219 teacher: 0 stage: sketch lr: 0.000520\n",
      "batch 1004 loss: 1.29160 acc: 0.70736 | v_loss: 1.21537 v_acc: 0.71289 |  iteration: 7220 teacher: 0 stage: sketch lr: 0.000520\n",
      "batch 1005 loss: 1.29931 acc: 0.69954 | v_loss: 1.13257 v_acc: 0.72852 |  iteration: 7221 teacher: 1 stage: sketch lr: 0.000520\n",
      "batch 1006 loss: 1.30989 acc: 0.70443 | v_loss: 1.14655 v_acc: 0.70801 |  iteration: 7222 teacher: 1 stage: sketch lr: 0.000520\n",
      "batch 1007 loss: 1.32404 acc: 0.71354 | v_loss: 1.25888 v_acc: 0.70573 |  iteration: 7223 teacher: 0 stage: sketch lr: 0.000520\n",
      "batch 1008 loss: 1.33939 acc: 0.68815 | v_loss: 1.33030 v_acc: 0.69401 |  iteration: 7224 teacher: 0 stage: sketch lr: 0.000520\n",
      "batch 1009 loss: 1.32092 acc: 0.69368 | v_loss: 1.14990 v_acc: 0.71647 |  iteration: 7225 teacher: 1 stage: sketch lr: 0.000520\n",
      "batch 1010 loss: 1.28631 acc: 0.69954 | v_loss: 1.19912 v_acc: 0.70020 |  iteration: 7226 teacher: 1 stage: sketch lr: 0.000520\n",
      "batch 1011 loss: 1.29655 acc: 0.71094 | v_loss: 1.19703 v_acc: 0.71289 |  iteration: 7227 teacher: 0 stage: sketch lr: 0.000520\n",
      "batch 1012 loss: 1.24690 acc: 0.70443 | v_loss: 1.21095 v_acc: 0.70150 |  iteration: 7228 teacher: 1 stage: sketch lr: 0.000520\n",
      "batch 1013 loss: 1.32719 acc: 0.69857 | v_loss: 1.10136 v_acc: 0.73340 |  iteration: 7229 teacher: 0 stage: sketch lr: 0.000520\n",
      "batch 1014 loss: 1.31217 acc: 0.70215 | v_loss: 1.19062 v_acc: 0.71712 |  iteration: 7230 teacher: 0 stage: sketch lr: 0.000520\n",
      "batch 1015 loss: 1.23737 acc: 0.71647 | v_loss: 1.14682 v_acc: 0.73047 |  iteration: 7231 teacher: 1 stage: sketch lr: 0.000520\n",
      "batch 1016 loss: 1.27361 acc: 0.70833 | v_loss: 1.11492 v_acc: 0.72559 |  iteration: 7232 teacher: 0 stage: sketch lr: 0.000520\n",
      "batch 1017 loss: 1.21789 acc: 0.70736 | v_loss: 1.19742 v_acc: 0.72005 |  iteration: 7233 teacher: 1 stage: sketch lr: 0.000520\n",
      "batch 1018 loss: 1.30830 acc: 0.70768 | v_loss: 1.23523 v_acc: 0.71354 |  iteration: 7234 teacher: 0 stage: sketch lr: 0.000520\n",
      "batch 1019 loss: 1.39904 acc: 0.68783 | v_loss: 1.20517 v_acc: 0.72461 |  iteration: 7235 teacher: 1 stage: sketch lr: 0.000520\n",
      "batch 1020 loss: 1.27329 acc: 0.71126 | v_loss: 1.38288 v_acc: 0.70182 |  iteration: 7236 teacher: 1 stage: sketch lr: 0.000520\n",
      "batch 1021 loss: 1.40345 acc: 0.68457 | v_loss: 1.26254 v_acc: 0.72135 |  iteration: 7237 teacher: 0 stage: sketch lr: 0.000520\n",
      "batch 1022 loss: 1.33662 acc: 0.70150 | v_loss: 1.04902 v_acc: 0.74447 |  iteration: 7238 teacher: 1 stage: sketch lr: 0.000519\n",
      "batch 1023 loss: 1.36769 acc: 0.69499 | v_loss: 1.20789 v_acc: 0.70964 |  iteration: 7239 teacher: 1 stage: sketch lr: 0.000519\n",
      "batch 1024 loss: 1.32704 acc: 0.70475 | v_loss: 1.28094 v_acc: 0.69987 |  iteration: 7240 teacher: 1 stage: sketch lr: 0.000519\n",
      "batch 1025 loss: 1.36182 acc: 0.69824 | v_loss: 1.20139 v_acc: 0.70573 |  iteration: 7241 teacher: 1 stage: sketch lr: 0.000519\n",
      "batch 1026 loss: 1.38699 acc: 0.69727 | v_loss: 1.26415 v_acc: 0.70768 |  iteration: 7242 teacher: 1 stage: sketch lr: 0.000519\n",
      "batch 1027 loss: 1.26542 acc: 0.70410 | v_loss: 1.25776 v_acc: 0.69401 |  iteration: 7243 teacher: 0 stage: sketch lr: 0.000519\n",
      "batch 1028 loss: 1.30069 acc: 0.70020 | v_loss: 1.22001 v_acc: 0.71647 |  iteration: 7244 teacher: 0 stage: sketch lr: 0.000519\n",
      "batch 1029 loss: 1.30708 acc: 0.69857 | v_loss: 1.26493 v_acc: 0.69824 |  iteration: 7245 teacher: 0 stage: sketch lr: 0.000519\n",
      "batch 1030 loss: 1.26425 acc: 0.71289 | v_loss: 1.18284 v_acc: 0.71647 |  iteration: 7246 teacher: 1 stage: sketch lr: 0.000519\n",
      "batch 1031 loss: 1.24578 acc: 0.70736 | v_loss: 1.18048 v_acc: 0.72461 |  iteration: 7247 teacher: 0 stage: sketch lr: 0.000519\n",
      "batch 1032 loss: 1.20514 acc: 0.71680 | v_loss: 1.24482 v_acc: 0.70540 |  iteration: 7248 teacher: 0 stage: sketch lr: 0.000519\n",
      "batch 1033 loss: 1.34886 acc: 0.70443 | v_loss: 1.35753 v_acc: 0.69857 |  iteration: 7249 teacher: 0 stage: sketch lr: 0.000519\n",
      "batch 1034 loss: 1.16950 acc: 0.71289 | v_loss: 1.15826 v_acc: 0.70833 |  iteration: 7250 teacher: 1 stage: sketch lr: 0.000519\n",
      "batch 1035 loss: 1.33301 acc: 0.70964 | v_loss: 1.41979 v_acc: 0.68522 |  iteration: 7251 teacher: 1 stage: sketch lr: 0.000519\n",
      "batch 1036 loss: 1.33832 acc: 0.69954 | v_loss: 1.17426 v_acc: 0.72168 |  iteration: 7252 teacher: 0 stage: sketch lr: 0.000519\n",
      "batch 1037 loss: 1.28939 acc: 0.71777 | v_loss: 1.47990 v_acc: 0.67969 |  iteration: 7253 teacher: 0 stage: sketch lr: 0.000519\n",
      "batch 1038 loss: 1.24615 acc: 0.71094 | v_loss: 1.37387 v_acc: 0.69727 |  iteration: 7254 teacher: 0 stage: sketch lr: 0.000519\n",
      "batch 1039 loss: 1.28995 acc: 0.71029 | v_loss: 1.33125 v_acc: 0.69173 |  iteration: 7255 teacher: 0 stage: sketch lr: 0.000519\n",
      "batch 1040 loss: 1.28118 acc: 0.70443 | v_loss: 1.31472 v_acc: 0.69889 |  iteration: 7256 teacher: 0 stage: sketch lr: 0.000519\n",
      "batch 1041 loss: 1.25464 acc: 0.71224 | v_loss: 1.23577 v_acc: 0.70768 |  iteration: 7257 teacher: 0 stage: sketch lr: 0.000519\n",
      "batch 1042 loss: 1.29010 acc: 0.70410 | v_loss: 1.26739 v_acc: 0.70312 |  iteration: 7258 teacher: 1 stage: sketch lr: 0.000519\n",
      "batch 1043 loss: 1.26078 acc: 0.70605 | v_loss: 1.22614 v_acc: 0.71419 |  iteration: 7259 teacher: 1 stage: sketch lr: 0.000519\n",
      "batch 1044 loss: 1.30275 acc: 0.70345 | v_loss: 1.43420 v_acc: 0.67871 |  iteration: 7260 teacher: 0 stage: sketch lr: 0.000519\n",
      "batch 1045 loss: 1.25186 acc: 0.70378 | v_loss: 1.29316 v_acc: 0.70898 |  iteration: 7261 teacher: 1 stage: sketch lr: 0.000519\n",
      "batch 1046 loss: 1.33015 acc: 0.69141 | v_loss: 1.20462 v_acc: 0.70866 |  iteration: 7262 teacher: 0 stage: sketch lr: 0.000519\n",
      "batch 1047 loss: 1.32719 acc: 0.69629 | v_loss: 1.25879 v_acc: 0.71517 |  iteration: 7263 teacher: 1 stage: sketch lr: 0.000519\n",
      "batch 1048 loss: 1.21845 acc: 0.70736 | v_loss: 1.15904 v_acc: 0.70671 |  iteration: 7264 teacher: 1 stage: sketch lr: 0.000519\n",
      "batch 1049 loss: 1.23541 acc: 0.71029 | v_loss: 1.26007 v_acc: 0.69922 |  iteration: 7265 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 1050 loss: 1.32149 acc: 0.70215 | v_loss: 1.22266 v_acc: 0.71517 |  iteration: 7266 teacher: 0 stage: sketch lr: 0.000518\n",
      "batch 1051 loss: 1.31567 acc: 0.69857 | v_loss: 1.16982 v_acc: 0.72038 |  iteration: 7267 teacher: 0 stage: sketch lr: 0.000518\n",
      "batch 1052 loss: 1.24737 acc: 0.70605 | v_loss: 1.12606 v_acc: 0.72819 |  iteration: 7268 teacher: 0 stage: sketch lr: 0.000518\n",
      "batch 1053 loss: 1.30018 acc: 0.70443 | v_loss: 1.25502 v_acc: 0.71940 |  iteration: 7269 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 1054 loss: 1.26996 acc: 0.71289 | v_loss: 1.24745 v_acc: 0.70540 |  iteration: 7270 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 1055 loss: 1.33884 acc: 0.70117 | v_loss: 1.25898 v_acc: 0.70540 |  iteration: 7271 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 1056 loss: 1.30016 acc: 0.70215 | v_loss: 1.11533 v_acc: 0.71647 |  iteration: 7272 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 1057 loss: 1.31713 acc: 0.70833 | v_loss: 1.23840 v_acc: 0.73014 |  iteration: 7273 teacher: 0 stage: sketch lr: 0.000518\n",
      "batch 1058 loss: 1.26194 acc: 0.69857 | v_loss: 1.30653 v_acc: 0.69694 |  iteration: 7274 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 1059 loss: 1.28457 acc: 0.69824 | v_loss: 1.30138 v_acc: 0.72331 |  iteration: 7275 teacher: 0 stage: sketch lr: 0.000518\n",
      "batch 1060 loss: 1.28792 acc: 0.69824 | v_loss: 1.16029 v_acc: 0.71712 |  iteration: 7276 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 1061 loss: 1.22542 acc: 0.70898 | v_loss: 1.10452 v_acc: 0.73177 |  iteration: 7277 teacher: 0 stage: sketch lr: 0.000518\n",
      "batch 1062 loss: 1.33729 acc: 0.69987 | v_loss: 1.11178 v_acc: 0.72689 |  iteration: 7278 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 1063 loss: 1.25826 acc: 0.71484 | v_loss: 1.19426 v_acc: 0.70638 |  iteration: 7279 teacher: 0 stage: sketch lr: 0.000518\n",
      "batch 1064 loss: 1.23654 acc: 0.71549 | v_loss: 1.22990 v_acc: 0.69629 |  iteration: 7280 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 1065 loss: 1.33058 acc: 0.70085 | v_loss: 1.18977 v_acc: 0.71484 |  iteration: 7281 teacher: 0 stage: sketch lr: 0.000518\n",
      "batch 1066 loss: 1.32813 acc: 0.69661 | v_loss: 1.31100 v_acc: 0.72949 |  iteration: 7282 teacher: 0 stage: sketch lr: 0.000518\n",
      "batch 1067 loss: 1.28111 acc: 0.70508 | v_loss: 1.49882 v_acc: 0.69238 |  iteration: 7283 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 1068 loss: 1.25240 acc: 0.71257 | v_loss: 1.35851 v_acc: 0.69531 |  iteration: 7284 teacher: 0 stage: sketch lr: 0.000518\n",
      "batch 1069 loss: 1.23159 acc: 0.70931 | v_loss: 1.18738 v_acc: 0.72168 |  iteration: 7285 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 1070 loss: 1.39500 acc: 0.68945 | v_loss: 1.15502 v_acc: 0.70573 |  iteration: 7286 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 1071 loss: 1.30346 acc: 0.69499 | v_loss: 1.16121 v_acc: 0.71908 |  iteration: 7287 teacher: 0 stage: sketch lr: 0.000518\n",
      "batch 1072 loss: 1.26201 acc: 0.69889 | v_loss: 1.21043 v_acc: 0.70605 |  iteration: 7288 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 1073 loss: 1.30926 acc: 0.71224 | v_loss: 1.27074 v_acc: 0.71517 |  iteration: 7289 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 1074 loss: 1.32200 acc: 0.69564 | v_loss: 1.21634 v_acc: 0.72982 |  iteration: 7290 teacher: 0 stage: sketch lr: 0.000518\n",
      "batch 1075 loss: 1.27427 acc: 0.70540 | v_loss: 1.23113 v_acc: 0.72233 |  iteration: 7291 teacher: 0 stage: sketch lr: 0.000518\n",
      "batch 1076 loss: 1.30277 acc: 0.70540 | v_loss: 1.22985 v_acc: 0.71354 |  iteration: 7292 teacher: 1 stage: sketch lr: 0.000518\n",
      "batch 1077 loss: 1.24273 acc: 0.70540 | v_loss: 1.16602 v_acc: 0.72461 |  iteration: 7293 teacher: 0 stage: sketch lr: 0.000518\n",
      "batch 1078 loss: 1.22776 acc: 0.70443 | v_loss: 1.13598 v_acc: 0.71777 |  iteration: 7294 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 1079 loss: 1.34585 acc: 0.69401 | v_loss: 1.47152 v_acc: 0.69043 |  iteration: 7295 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 1080 loss: 1.32068 acc: 0.69564 | v_loss: 1.20149 v_acc: 0.70866 |  iteration: 7296 teacher: 1 stage: sketch lr: 0.000517\n",
      "batch 1081 loss: 1.31459 acc: 0.70117 | v_loss: 1.21821 v_acc: 0.71712 |  iteration: 7297 teacher: 1 stage: sketch lr: 0.000517\n",
      "batch 1082 loss: 1.23888 acc: 0.70312 | v_loss: 1.21175 v_acc: 0.71387 |  iteration: 7298 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 1083 loss: 1.29490 acc: 0.71191 | v_loss: 1.27837 v_acc: 0.70378 |  iteration: 7299 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 1084 loss: 1.37509 acc: 0.69303 | v_loss: 1.13403 v_acc: 0.72982 |  iteration: 7300 teacher: 1 stage: sketch lr: 0.000517\n",
      "batch 1085 loss: 1.37377 acc: 0.70020 | v_loss: 1.37037 v_acc: 0.71224 |  iteration: 7301 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 1086 loss: 1.36370 acc: 0.69434 | v_loss: 1.23519 v_acc: 0.69564 |  iteration: 7302 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 1087 loss: 1.28414 acc: 0.70768 | v_loss: 1.22452 v_acc: 0.69661 |  iteration: 7303 teacher: 1 stage: sketch lr: 0.000517\n",
      "batch 1088 loss: 1.28028 acc: 0.70736 | v_loss: 1.25921 v_acc: 0.70410 |  iteration: 7304 teacher: 1 stage: sketch lr: 0.000517\n",
      "batch 1089 loss: 1.29237 acc: 0.70736 | v_loss: 1.27149 v_acc: 0.70508 |  iteration: 7305 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 1090 loss: 1.40970 acc: 0.69466 | v_loss: 1.34108 v_acc: 0.69076 |  iteration: 7306 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 1091 loss: 1.23003 acc: 0.71647 | v_loss: 1.36585 v_acc: 0.70508 |  iteration: 7307 teacher: 1 stage: sketch lr: 0.000517\n",
      "batch 1092 loss: 1.27642 acc: 0.70638 | v_loss: 1.29688 v_acc: 0.70540 |  iteration: 7308 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 1093 loss: 1.25245 acc: 0.70866 | v_loss: 1.23038 v_acc: 0.70540 |  iteration: 7309 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 1094 loss: 1.31892 acc: 0.70052 | v_loss: 1.31137 v_acc: 0.70540 |  iteration: 7310 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 1095 loss: 1.33415 acc: 0.70703 | v_loss: 1.20542 v_acc: 0.72005 |  iteration: 7311 teacher: 1 stage: sketch lr: 0.000517\n",
      "batch 1096 loss: 1.40847 acc: 0.69727 | v_loss: 1.14709 v_acc: 0.72331 |  iteration: 7312 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 1097 loss: 1.33545 acc: 0.69954 | v_loss: 1.13555 v_acc: 0.71224 |  iteration: 7313 teacher: 1 stage: sketch lr: 0.000517\n",
      "batch 1098 loss: 1.31711 acc: 0.69434 | v_loss: 1.26179 v_acc: 0.70605 |  iteration: 7314 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 1099 loss: 1.30490 acc: 0.70085 | v_loss: 1.31748 v_acc: 0.69922 |  iteration: 7315 teacher: 1 stage: sketch lr: 0.000517\n",
      "batch 1100 loss: 1.30124 acc: 0.69922 | v_loss: 1.14560 v_acc: 0.71484 |  iteration: 7316 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 1101 loss: 1.32097 acc: 0.69499 | v_loss: 1.19577 v_acc: 0.70117 |  iteration: 7317 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 1102 loss: 1.33186 acc: 0.69661 | v_loss: 1.19850 v_acc: 0.71615 |  iteration: 7318 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 1103 loss: 1.29428 acc: 0.70605 | v_loss: 1.21467 v_acc: 0.70508 |  iteration: 7319 teacher: 1 stage: sketch lr: 0.000517\n",
      "batch 1104 loss: 1.27253 acc: 0.70703 | v_loss: 1.08128 v_acc: 0.73340 |  iteration: 7320 teacher: 0 stage: sketch lr: 0.000517\n",
      "batch 1105 loss: 1.22073 acc: 0.70703 | v_loss: 1.18925 v_acc: 0.71712 |  iteration: 7321 teacher: 1 stage: sketch lr: 0.000517\n",
      "batch 1106 loss: 1.32779 acc: 0.69792 | v_loss: 1.18000 v_acc: 0.73047 |  iteration: 7322 teacher: 0 stage: sketch lr: 0.000516\n",
      "batch 1107 loss: 1.27446 acc: 0.70768 | v_loss: 1.13537 v_acc: 0.72135 |  iteration: 7323 teacher: 1 stage: sketch lr: 0.000516\n",
      "batch 1108 loss: 1.36868 acc: 0.69694 | v_loss: 1.20760 v_acc: 0.71582 |  iteration: 7324 teacher: 1 stage: sketch lr: 0.000516\n",
      "batch 1109 loss: 1.26670 acc: 0.70898 | v_loss: 1.24357 v_acc: 0.71224 |  iteration: 7325 teacher: 1 stage: sketch lr: 0.000516\n",
      "batch 1110 loss: 1.32301 acc: 0.69922 | v_loss: 1.19766 v_acc: 0.72070 |  iteration: 7326 teacher: 0 stage: sketch lr: 0.000516\n",
      "batch 1111 loss: 1.25373 acc: 0.70443 | v_loss: 1.38914 v_acc: 0.69727 |  iteration: 7327 teacher: 0 stage: sketch lr: 0.000516\n",
      "batch 1112 loss: 1.34905 acc: 0.69694 | v_loss: 1.25418 v_acc: 0.72168 |  iteration: 7328 teacher: 1 stage: sketch lr: 0.000516\n",
      "batch 1113 loss: 1.28737 acc: 0.71224 | v_loss: 1.04863 v_acc: 0.74674 |  iteration: 7329 teacher: 1 stage: sketch lr: 0.000516\n",
      "batch 1114 loss: 1.35200 acc: 0.69629 | v_loss: 1.22294 v_acc: 0.70801 |  iteration: 7330 teacher: 1 stage: sketch lr: 0.000516\n",
      "batch 1115 loss: 1.35752 acc: 0.70443 | v_loss: 1.26742 v_acc: 0.69987 |  iteration: 7331 teacher: 0 stage: sketch lr: 0.000516\n",
      "batch 1116 loss: 1.28637 acc: 0.70573 | v_loss: 1.21031 v_acc: 0.70638 |  iteration: 7332 teacher: 0 stage: sketch lr: 0.000516\n",
      "batch 1117 loss: 1.30542 acc: 0.70833 | v_loss: 1.25664 v_acc: 0.71257 |  iteration: 7333 teacher: 0 stage: sketch lr: 0.000516\n",
      "batch 1118 loss: 1.32321 acc: 0.69759 | v_loss: 1.25047 v_acc: 0.68913 |  iteration: 7334 teacher: 0 stage: sketch lr: 0.000516\n",
      "batch 1119 loss: 1.29030 acc: 0.70605 | v_loss: 1.21505 v_acc: 0.71191 |  iteration: 7335 teacher: 1 stage: sketch lr: 0.000516\n",
      "batch 1120 loss: 1.25510 acc: 0.70931 | v_loss: 1.25995 v_acc: 0.69922 |  iteration: 7336 teacher: 1 stage: sketch lr: 0.000516\n",
      "batch 1121 loss: 1.27826 acc: 0.69499 | v_loss: 1.19115 v_acc: 0.72233 |  iteration: 7337 teacher: 0 stage: sketch lr: 0.000516\n",
      "batch 1122 loss: 1.28270 acc: 0.70345 | v_loss: 1.18279 v_acc: 0.72656 |  iteration: 7338 teacher: 1 stage: sketch lr: 0.000516\n",
      "batch 1123 loss: 1.28184 acc: 0.69727 | v_loss: 1.24749 v_acc: 0.70345 |  iteration: 7339 teacher: 0 stage: sketch lr: 0.000516\n",
      "batch 1124 loss: 1.25613 acc: 0.70410 | v_loss: 1.34765 v_acc: 0.69889 |  iteration: 7340 teacher: 1 stage: sketch lr: 0.000516\n",
      "batch 1125 loss: 1.25617 acc: 0.70703 | v_loss: 1.15631 v_acc: 0.70931 |  iteration: 7341 teacher: 1 stage: sketch lr: 0.000516\n",
      "batch 1126 loss: 1.33089 acc: 0.69954 | v_loss: 1.41746 v_acc: 0.68522 |  iteration: 7342 teacher: 1 stage: sketch lr: 0.000516\n",
      "batch 1127 loss: 1.34553 acc: 0.69759 | v_loss: 1.17514 v_acc: 0.72168 |  iteration: 7343 teacher: 1 stage: sketch lr: 0.000516\n",
      "batch 1128 loss: 1.40735 acc: 0.69303 | v_loss: 1.48443 v_acc: 0.67969 |  iteration: 7344 teacher: 0 stage: sketch lr: 0.000516\n",
      "batch 1129 loss: 1.27595 acc: 0.69596 | v_loss: 1.35957 v_acc: 0.69661 |  iteration: 7345 teacher: 1 stage: sketch lr: 0.000516\n",
      "batch 1130 loss: 1.25735 acc: 0.70801 | v_loss: 1.33655 v_acc: 0.69238 |  iteration: 7346 teacher: 0 stage: sketch lr: 0.000516\n",
      "batch 1131 loss: 1.31820 acc: 0.70085 | v_loss: 1.30706 v_acc: 0.70182 |  iteration: 7347 teacher: 1 stage: sketch lr: 0.000516\n",
      "batch 1132 loss: 1.31439 acc: 0.69857 | v_loss: 1.23143 v_acc: 0.70801 |  iteration: 7348 teacher: 0 stage: sketch lr: 0.000516\n",
      "batch 1133 loss: 1.32453 acc: 0.69694 | v_loss: 1.26967 v_acc: 0.70573 |  iteration: 7349 teacher: 0 stage: sketch lr: 0.000516\n",
      "batch 1134 loss: 1.32886 acc: 0.69954 | v_loss: 1.23560 v_acc: 0.71647 |  iteration: 7350 teacher: 1 stage: sketch lr: 0.000515\n",
      "batch 1135 loss: 1.29145 acc: 0.70345 | v_loss: 1.42510 v_acc: 0.68359 |  iteration: 7351 teacher: 1 stage: sketch lr: 0.000515\n",
      "batch 1136 loss: 1.26344 acc: 0.70638 | v_loss: 1.31274 v_acc: 0.70020 |  iteration: 7352 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 1137 loss: 1.29821 acc: 0.70475 | v_loss: 1.18023 v_acc: 0.71029 |  iteration: 7353 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 1138 loss: 1.29107 acc: 0.71289 | v_loss: 1.27182 v_acc: 0.71549 |  iteration: 7354 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 1139 loss: 1.29452 acc: 0.70508 | v_loss: 1.18460 v_acc: 0.70052 |  iteration: 7355 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 1140 loss: 1.34055 acc: 0.69824 | v_loss: 1.25833 v_acc: 0.69466 |  iteration: 7356 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 1141 loss: 1.34734 acc: 0.70247 | v_loss: 1.22364 v_acc: 0.71387 |  iteration: 7357 teacher: 1 stage: sketch lr: 0.000515\n",
      "batch 1142 loss: 1.28310 acc: 0.69889 | v_loss: 1.18355 v_acc: 0.71647 |  iteration: 7358 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 1143 loss: 1.16848 acc: 0.71777 | v_loss: 1.12991 v_acc: 0.72982 |  iteration: 7359 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 1144 loss: 1.34259 acc: 0.69922 | v_loss: 1.25385 v_acc: 0.71940 |  iteration: 7360 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 1145 loss: 1.29250 acc: 0.70182 | v_loss: 1.25387 v_acc: 0.70605 |  iteration: 7361 teacher: 1 stage: sketch lr: 0.000515\n",
      "batch 1146 loss: 1.36722 acc: 0.69336 | v_loss: 1.27180 v_acc: 0.70898 |  iteration: 7362 teacher: 1 stage: sketch lr: 0.000515\n",
      "batch 1147 loss: 1.23650 acc: 0.70833 | v_loss: 1.11633 v_acc: 0.72266 |  iteration: 7363 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 1148 loss: 1.22531 acc: 0.71419 | v_loss: 1.24438 v_acc: 0.72884 |  iteration: 7364 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 1149 loss: 1.19077 acc: 0.71549 | v_loss: 1.30836 v_acc: 0.69564 |  iteration: 7365 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 1150 loss: 1.32921 acc: 0.69792 | v_loss: 1.30697 v_acc: 0.72038 |  iteration: 7366 teacher: 1 stage: sketch lr: 0.000515\n",
      "batch 1151 loss: 1.32059 acc: 0.71322 | v_loss: 1.16292 v_acc: 0.72103 |  iteration: 7367 teacher: 1 stage: sketch lr: 0.000515\n",
      "batch 1152 loss: 1.33977 acc: 0.69954 | v_loss: 1.10727 v_acc: 0.73958 |  iteration: 7368 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 1153 loss: 1.39435 acc: 0.69564 | v_loss: 1.10982 v_acc: 0.72396 |  iteration: 7369 teacher: 1 stage: sketch lr: 0.000515\n",
      "batch 1154 loss: 1.24583 acc: 0.70508 | v_loss: 1.19033 v_acc: 0.71224 |  iteration: 7370 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 1155 loss: 1.26316 acc: 0.70833 | v_loss: 1.23132 v_acc: 0.70410 |  iteration: 7371 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 1156 loss: 1.24322 acc: 0.70247 | v_loss: 1.20439 v_acc: 0.71159 |  iteration: 7372 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 1157 loss: 1.30859 acc: 0.71061 | v_loss: 1.33913 v_acc: 0.70443 |  iteration: 7373 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 1158 loss: 1.24629 acc: 0.71257 | v_loss: 1.46671 v_acc: 0.69336 |  iteration: 7374 teacher: 1 stage: sketch lr: 0.000515\n",
      "batch 1159 loss: 1.22629 acc: 0.70605 | v_loss: 1.34473 v_acc: 0.69629 |  iteration: 7375 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 1160 loss: 1.21181 acc: 0.70931 | v_loss: 1.19535 v_acc: 0.72298 |  iteration: 7376 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 1161 loss: 1.24883 acc: 0.70638 | v_loss: 1.15154 v_acc: 0.70247 |  iteration: 7377 teacher: 1 stage: sketch lr: 0.000515\n",
      "batch 1162 loss: 1.35575 acc: 0.69206 | v_loss: 1.16542 v_acc: 0.71615 |  iteration: 7378 teacher: 0 stage: sketch lr: 0.000515\n",
      "batch 1163 loss: 1.24296 acc: 0.71029 | v_loss: 1.22811 v_acc: 0.69727 |  iteration: 7379 teacher: 1 stage: sketch lr: 0.000514\n",
      "batch 1164 loss: 1.33368 acc: 0.70638 | v_loss: 1.25244 v_acc: 0.71029 |  iteration: 7380 teacher: 1 stage: sketch lr: 0.000514\n",
      "batch 1165 loss: 1.27853 acc: 0.70996 | v_loss: 1.21660 v_acc: 0.72852 |  iteration: 7381 teacher: 0 stage: sketch lr: 0.000514\n",
      "batch 1166 loss: 1.23126 acc: 0.71029 | v_loss: 1.23351 v_acc: 0.71582 |  iteration: 7382 teacher: 1 stage: sketch lr: 0.000514\n",
      "batch 1167 loss: 1.37212 acc: 0.69499 | v_loss: 1.24405 v_acc: 0.70020 |  iteration: 7383 teacher: 1 stage: sketch lr: 0.000514\n",
      "batch 1168 loss: 1.33327 acc: 0.69206 | v_loss: 1.17287 v_acc: 0.72103 |  iteration: 7384 teacher: 1 stage: sketch lr: 0.000514\n",
      "batch 1169 loss: 1.34128 acc: 0.69824 | v_loss: 1.12840 v_acc: 0.71745 |  iteration: 7385 teacher: 0 stage: sketch lr: 0.000514\n",
      "batch 1170 loss: 1.38340 acc: 0.69303 | v_loss: 1.43891 v_acc: 0.68490 |  iteration: 7386 teacher: 1 stage: sketch lr: 0.000514\n",
      "batch 1171 loss: 1.35303 acc: 0.69336 | v_loss: 1.20279 v_acc: 0.70931 |  iteration: 7387 teacher: 0 stage: sketch lr: 0.000514\n",
      "batch 1172 loss: 1.29222 acc: 0.70052 | v_loss: 1.23710 v_acc: 0.70866 |  iteration: 7388 teacher: 0 stage: sketch lr: 0.000514\n",
      "batch 1173 loss: 1.28742 acc: 0.69857 | v_loss: 1.26635 v_acc: 0.69564 |  iteration: 7389 teacher: 0 stage: sketch lr: 0.000514\n",
      "batch 1174 loss: 1.29455 acc: 0.70117 | v_loss: 1.29841 v_acc: 0.69792 |  iteration: 7390 teacher: 1 stage: sketch lr: 0.000514\n",
      "batch 1175 loss: 1.31800 acc: 0.71224 | v_loss: 1.14719 v_acc: 0.72917 |  iteration: 7391 teacher: 0 stage: sketch lr: 0.000514\n",
      "batch 1176 loss: 1.28915 acc: 0.69987 | v_loss: 1.38798 v_acc: 0.71061 |  iteration: 7392 teacher: 1 stage: sketch lr: 0.000514\n",
      "batch 1177 loss: 1.32846 acc: 0.69271 | v_loss: 1.19988 v_acc: 0.70247 |  iteration: 7393 teacher: 1 stage: sketch lr: 0.000514\n",
      "batch 1178 loss: 1.25524 acc: 0.70117 | v_loss: 1.21229 v_acc: 0.70345 |  iteration: 7394 teacher: 1 stage: sketch lr: 0.000514\n",
      "batch 1179 loss: 1.26304 acc: 0.70866 | v_loss: 1.25905 v_acc: 0.70280 |  iteration: 7395 teacher: 0 stage: sketch lr: 0.000514\n",
      "batch 1180 loss: 1.34017 acc: 0.69108 | v_loss: 1.26849 v_acc: 0.70312 |  iteration: 7396 teacher: 1 stage: sketch lr: 0.000514\n",
      "batch 1181 loss: 1.32172 acc: 0.71029 | v_loss: 1.32677 v_acc: 0.69564 |  iteration: 7397 teacher: 1 stage: sketch lr: 0.000514\n",
      "batch 1182 loss: 1.35994 acc: 0.68978 | v_loss: 1.37419 v_acc: 0.70638 |  iteration: 7398 teacher: 0 stage: sketch lr: 0.000514\n",
      "batch 1183 loss: 1.41762 acc: 0.69141 | v_loss: 1.28898 v_acc: 0.70085 |  iteration: 7399 teacher: 0 stage: sketch lr: 0.000514\n",
      "batch 1184 loss: 1.24184 acc: 0.71159 | v_loss: 1.18975 v_acc: 0.70605 |  iteration: 7400 teacher: 0 stage: sketch lr: 0.000514\n",
      "batch 1185 loss: 1.20032 acc: 0.70996 | v_loss: 1.33461 v_acc: 0.70312 |  iteration: 7401 teacher: 0 stage: sketch lr: 0.000514\n",
      "batch 1186 loss: 1.28062 acc: 0.70052 | v_loss: 1.24507 v_acc: 0.71061 |  iteration: 7402 teacher: 1 stage: sketch lr: 0.000514\n",
      "batch 1187 loss: 1.29409 acc: 0.69759 | v_loss: 1.14163 v_acc: 0.72721 |  iteration: 7403 teacher: 0 stage: sketch lr: 0.000514\n",
      "batch 1188 loss: 1.29944 acc: 0.70410 | v_loss: 1.14566 v_acc: 0.70508 |  iteration: 7404 teacher: 1 stage: sketch lr: 0.000514\n",
      "batch 1189 loss: 1.35224 acc: 0.69824 | v_loss: 1.26298 v_acc: 0.70182 |  iteration: 7405 teacher: 0 stage: sketch lr: 0.000514\n",
      "batch 1190 loss: 1.15282 acc: 0.72266 | v_loss: 1.32422 v_acc: 0.69824 |  iteration: 7406 teacher: 0 stage: sketch lr: 0.000514\n",
      "batch 1191 loss: 1.31616 acc: 0.69694 | v_loss: 1.16569 v_acc: 0.70638 |  iteration: 7407 teacher: 1 stage: sketch lr: 0.000514\n",
      "batch 1192 loss: 1.36164 acc: 0.69661 | v_loss: 1.19120 v_acc: 0.69987 |  iteration: 7408 teacher: 0 stage: sketch lr: 0.000513\n",
      "batch 1193 loss: 1.31142 acc: 0.69303 | v_loss: 1.19595 v_acc: 0.70768 |  iteration: 7409 teacher: 1 stage: sketch lr: 0.000513\n",
      "batch 1194 loss: 1.29005 acc: 0.70508 | v_loss: 1.20344 v_acc: 0.70410 |  iteration: 7410 teacher: 0 stage: sketch lr: 0.000513\n",
      "batch 1195 loss: 1.34825 acc: 0.70117 | v_loss: 1.06239 v_acc: 0.74056 |  iteration: 7411 teacher: 0 stage: sketch lr: 0.000513\n",
      "batch 1196 loss: 1.26386 acc: 0.71354 | v_loss: 1.17709 v_acc: 0.71354 |  iteration: 7412 teacher: 1 stage: sketch lr: 0.000513\n",
      "batch 1197 loss: 1.19592 acc: 0.72135 | v_loss: 1.14616 v_acc: 0.70508 |  iteration: 7413 teacher: 1 stage: sketch lr: 0.000513\n",
      "batch 1198 loss: 1.24447 acc: 0.70768 | v_loss: 1.12642 v_acc: 0.72526 |  iteration: 7414 teacher: 0 stage: sketch lr: 0.000513\n",
      "batch 1199 loss: 1.31857 acc: 0.71224 | v_loss: 1.19478 v_acc: 0.72070 |  iteration: 7415 teacher: 1 stage: sketch lr: 0.000513\n",
      "batch 1200 loss: 1.32609 acc: 0.70540 | v_loss: 1.22541 v_acc: 0.71257 |  iteration: 7416 teacher: 0 stage: sketch lr: 0.000513\n",
      "batch 1201 loss: 1.29718 acc: 0.70150 | v_loss: 1.19929 v_acc: 0.72201 |  iteration: 7417 teacher: 0 stage: sketch lr: 0.000513\n",
      "batch 1202 loss: 1.33070 acc: 0.69857 | v_loss: 1.38007 v_acc: 0.70150 |  iteration: 7418 teacher: 0 stage: sketch lr: 0.000513\n",
      "batch 1203 loss: 1.24089 acc: 0.70996 | v_loss: 1.27044 v_acc: 0.72103 |  iteration: 7419 teacher: 0 stage: sketch lr: 0.000513\n",
      "batch 1204 loss: 1.32819 acc: 0.70117 | v_loss: 1.05623 v_acc: 0.74447 |  iteration: 7420 teacher: 1 stage: sketch lr: 0.000513\n",
      "batch 1205 loss: 1.20256 acc: 0.70703 | v_loss: 1.20882 v_acc: 0.70671 |  iteration: 7421 teacher: 1 stage: sketch lr: 0.000513\n",
      "batch 1206 loss: 1.26211 acc: 0.70931 | v_loss: 1.26928 v_acc: 0.70020 |  iteration: 7422 teacher: 0 stage: sketch lr: 0.000513\n",
      "batch 1207 loss: 1.28480 acc: 0.70020 | v_loss: 1.18414 v_acc: 0.71322 |  iteration: 7423 teacher: 0 stage: sketch lr: 0.000513\n",
      "batch 1208 loss: 1.29882 acc: 0.69661 | v_loss: 1.25046 v_acc: 0.71159 |  iteration: 7424 teacher: 1 stage: sketch lr: 0.000513\n",
      "batch 1209 loss: 1.39431 acc: 0.69076 | v_loss: 1.24464 v_acc: 0.69303 |  iteration: 7425 teacher: 1 stage: sketch lr: 0.000513\n",
      "batch 1210 loss: 1.34450 acc: 0.69401 | v_loss: 1.20621 v_acc: 0.71159 |  iteration: 7426 teacher: 0 stage: sketch lr: 0.000513\n",
      "batch 1211 loss: 1.34316 acc: 0.69466 | v_loss: 1.25174 v_acc: 0.69303 |  iteration: 7427 teacher: 0 stage: sketch lr: 0.000513\n",
      "batch 1212 loss: 1.31892 acc: 0.69629 | v_loss: 1.19005 v_acc: 0.71712 |  iteration: 7428 teacher: 1 stage: sketch lr: 0.000513\n",
      "batch 1213 loss: 1.33076 acc: 0.69661 | v_loss: 1.17951 v_acc: 0.72559 |  iteration: 7429 teacher: 0 stage: sketch lr: 0.000513\n",
      "batch 1214 loss: 1.32489 acc: 0.70475 | v_loss: 1.23912 v_acc: 0.70312 |  iteration: 7430 teacher: 0 stage: sketch lr: 0.000513\n",
      "batch 1215 loss: 1.33890 acc: 0.70150 | v_loss: 1.35494 v_acc: 0.70020 |  iteration: 7431 teacher: 1 stage: sketch lr: 0.000513\n",
      "batch 1216 loss: 1.32795 acc: 0.68848 | v_loss: 1.15799 v_acc: 0.70801 |  iteration: 7432 teacher: 1 stage: sketch lr: 0.000513\n",
      "batch 1217 loss: 1.32322 acc: 0.69466 | v_loss: 1.41979 v_acc: 0.68620 |  iteration: 7433 teacher: 1 stage: sketch lr: 0.000513\n",
      "batch 1218 loss: 1.24108 acc: 0.71126 | v_loss: 1.16856 v_acc: 0.72298 |  iteration: 7434 teacher: 0 stage: sketch lr: 0.000513\n",
      "batch 1219 loss: 1.21049 acc: 0.71387 | v_loss: 1.48229 v_acc: 0.67936 |  iteration: 7435 teacher: 1 stage: sketch lr: 0.000513\n",
      "batch 1220 loss: 1.36090 acc: 0.69173 | v_loss: 1.36709 v_acc: 0.69661 |  iteration: 7436 teacher: 1 stage: sketch lr: 0.000513\n",
      "batch 1221 loss: 1.29570 acc: 0.70573 | v_loss: 1.33616 v_acc: 0.69238 |  iteration: 7437 teacher: 1 stage: sketch lr: 0.000512\n",
      "batch 1222 loss: 1.29375 acc: 0.70540 | v_loss: 1.31033 v_acc: 0.70182 |  iteration: 7438 teacher: 1 stage: sketch lr: 0.000512\n",
      "batch 1223 loss: 1.29658 acc: 0.70410 | v_loss: 1.22625 v_acc: 0.70638 |  iteration: 7439 teacher: 1 stage: sketch lr: 0.000512\n",
      "batch 1224 loss: 1.28242 acc: 0.70475 | v_loss: 1.26274 v_acc: 0.70573 |  iteration: 7440 teacher: 0 stage: sketch lr: 0.000512\n",
      "batch 1225 loss: 1.32410 acc: 0.69596 | v_loss: 1.21708 v_acc: 0.71908 |  iteration: 7441 teacher: 1 stage: sketch lr: 0.000512\n",
      "batch 1226 loss: 1.34564 acc: 0.69954 | v_loss: 1.41909 v_acc: 0.68978 |  iteration: 7442 teacher: 1 stage: sketch lr: 0.000512\n",
      "batch 1227 loss: 1.27643 acc: 0.71354 | v_loss: 1.29534 v_acc: 0.71061 |  iteration: 7443 teacher: 1 stage: sketch lr: 0.000512\n",
      "batch 1228 loss: 1.23124 acc: 0.71257 | v_loss: 1.18458 v_acc: 0.71159 |  iteration: 7444 teacher: 1 stage: sketch lr: 0.000512\n",
      "batch 1229 loss: 1.25862 acc: 0.70117 | v_loss: 1.26170 v_acc: 0.71484 |  iteration: 7445 teacher: 1 stage: sketch lr: 0.000512\n",
      "batch 1230 loss: 1.28926 acc: 0.70280 | v_loss: 1.16293 v_acc: 0.70931 |  iteration: 7446 teacher: 0 stage: sketch lr: 0.000512\n",
      "batch 1231 loss: 1.28715 acc: 0.70736 | v_loss: 1.26626 v_acc: 0.69824 |  iteration: 7447 teacher: 1 stage: sketch lr: 0.000512\n",
      "batch 1232 loss: 1.28059 acc: 0.70443 | v_loss: 1.23455 v_acc: 0.71419 |  iteration: 7448 teacher: 0 stage: sketch lr: 0.000512\n",
      "batch 1233 loss: 1.24996 acc: 0.71061 | v_loss: 1.17265 v_acc: 0.71810 |  iteration: 7449 teacher: 0 stage: sketch lr: 0.000512\n",
      "batch 1234 loss: 1.28798 acc: 0.70671 | v_loss: 1.13557 v_acc: 0.72689 |  iteration: 7450 teacher: 1 stage: sketch lr: 0.000512\n",
      "batch 1235 loss: 1.33408 acc: 0.70573 | v_loss: 1.25613 v_acc: 0.71484 |  iteration: 7451 teacher: 1 stage: sketch lr: 0.000512\n",
      "batch 1236 loss: 1.21099 acc: 0.71615 | v_loss: 1.24912 v_acc: 0.70150 |  iteration: 7452 teacher: 0 stage: sketch lr: 0.000512\n",
      "batch 1237 loss: 1.23396 acc: 0.71419 | v_loss: 1.24851 v_acc: 0.70996 |  iteration: 7453 teacher: 0 stage: sketch lr: 0.000512\n",
      "batch 1238 loss: 1.31729 acc: 0.69987 | v_loss: 1.10232 v_acc: 0.72363 |  iteration: 7454 teacher: 1 stage: sketch lr: 0.000512\n",
      "batch 1239 loss: 1.22590 acc: 0.70931 | v_loss: 1.23435 v_acc: 0.73210 |  iteration: 7455 teacher: 1 stage: sketch lr: 0.000512\n",
      "batch 1240 loss: 1.25086 acc: 0.70671 | v_loss: 1.29767 v_acc: 0.69629 |  iteration: 7456 teacher: 1 stage: sketch lr: 0.000512\n",
      "batch 1241 loss: 1.27888 acc: 0.71257 | v_loss: 1.32342 v_acc: 0.71875 |  iteration: 7457 teacher: 0 stage: sketch lr: 0.000512\n",
      "batch 1242 loss: 1.29587 acc: 0.69792 | v_loss: 1.16107 v_acc: 0.71517 |  iteration: 7458 teacher: 0 stage: sketch lr: 0.000512\n",
      "epoch 5 loss: 1.29587 acc: 0.70413 | v_loss: 1.24151 v_acc: 0.71007 \n",
      "epoch: 6\n",
      "__________________________________________\n",
      "batch 0 loss: 1.29909 acc: 0.70508 | v_loss: 1.27840 v_acc: 0.69694 |  iteration: 7459 teacher: 0 stage: sketch lr: 0.000512\n",
      "batch 1 loss: 1.23299 acc: 0.70312 | v_loss: 1.18848 v_acc: 0.70801 |  iteration: 7460 teacher: 0 stage: sketch lr: 0.000512\n",
      "batch 2 loss: 1.20480 acc: 0.71680 | v_loss: 1.32466 v_acc: 0.70605 |  iteration: 7461 teacher: 1 stage: sketch lr: 0.000512\n",
      "batch 3 loss: 1.24287 acc: 0.71159 | v_loss: 1.20677 v_acc: 0.71940 |  iteration: 7462 teacher: 1 stage: sketch lr: 0.000512\n",
      "batch 4 loss: 1.28685 acc: 0.69954 | v_loss: 1.15411 v_acc: 0.72266 |  iteration: 7463 teacher: 1 stage: sketch lr: 0.000512\n",
      "batch 5 loss: 1.30144 acc: 0.70605 | v_loss: 1.12322 v_acc: 0.70801 |  iteration: 7464 teacher: 0 stage: sketch lr: 0.000512\n",
      "batch 6 loss: 1.28732 acc: 0.70605 | v_loss: 1.26610 v_acc: 0.70182 |  iteration: 7465 teacher: 1 stage: sketch lr: 0.000512\n",
      "batch 7 loss: 1.34131 acc: 0.69987 | v_loss: 1.35034 v_acc: 0.69661 |  iteration: 7466 teacher: 0 stage: sketch lr: 0.000511\n",
      "batch 8 loss: 1.33752 acc: 0.69954 | v_loss: 1.18237 v_acc: 0.70508 |  iteration: 7467 teacher: 0 stage: sketch lr: 0.000511\n",
      "batch 9 loss: 1.34469 acc: 0.69206 | v_loss: 1.20988 v_acc: 0.69596 |  iteration: 7468 teacher: 1 stage: sketch lr: 0.000511\n",
      "batch 10 loss: 1.27823 acc: 0.71029 | v_loss: 1.18715 v_acc: 0.70638 |  iteration: 7469 teacher: 1 stage: sketch lr: 0.000511\n",
      "batch 11 loss: 1.27494 acc: 0.70215 | v_loss: 1.20899 v_acc: 0.70410 |  iteration: 7470 teacher: 0 stage: sketch lr: 0.000511\n",
      "batch 12 loss: 1.16343 acc: 0.71452 | v_loss: 1.05639 v_acc: 0.73926 |  iteration: 7471 teacher: 1 stage: sketch lr: 0.000511\n",
      "batch 13 loss: 1.33430 acc: 0.69954 | v_loss: 1.17565 v_acc: 0.72168 |  iteration: 7472 teacher: 0 stage: sketch lr: 0.000511\n",
      "batch 14 loss: 1.34999 acc: 0.69499 | v_loss: 1.12277 v_acc: 0.72656 |  iteration: 7473 teacher: 1 stage: sketch lr: 0.000511\n",
      "batch 15 loss: 1.26218 acc: 0.71777 | v_loss: 1.12420 v_acc: 0.72331 |  iteration: 7474 teacher: 0 stage: sketch lr: 0.000511\n",
      "batch 16 loss: 1.22978 acc: 0.70475 | v_loss: 1.19716 v_acc: 0.71940 |  iteration: 7475 teacher: 1 stage: sketch lr: 0.000511\n",
      "batch 17 loss: 1.27566 acc: 0.71647 | v_loss: 1.23301 v_acc: 0.71224 |  iteration: 7476 teacher: 1 stage: sketch lr: 0.000511\n",
      "batch 18 loss: 1.29628 acc: 0.70085 | v_loss: 1.20573 v_acc: 0.72461 |  iteration: 7477 teacher: 1 stage: sketch lr: 0.000511\n",
      "batch 19 loss: 1.26493 acc: 0.70540 | v_loss: 1.38365 v_acc: 0.70182 |  iteration: 7478 teacher: 1 stage: sketch lr: 0.000511\n",
      "batch 20 loss: 1.34664 acc: 0.70085 | v_loss: 1.27653 v_acc: 0.71582 |  iteration: 7479 teacher: 0 stage: sketch lr: 0.000511\n",
      "batch 21 loss: 1.26127 acc: 0.71549 | v_loss: 1.05398 v_acc: 0.74447 |  iteration: 7480 teacher: 0 stage: sketch lr: 0.000511\n",
      "batch 22 loss: 1.33976 acc: 0.70312 | v_loss: 1.20452 v_acc: 0.71322 |  iteration: 7481 teacher: 1 stage: sketch lr: 0.000511\n",
      "batch 23 loss: 1.29595 acc: 0.69596 | v_loss: 1.26908 v_acc: 0.69987 |  iteration: 7482 teacher: 0 stage: sketch lr: 0.000511\n",
      "batch 24 loss: 1.29332 acc: 0.70898 | v_loss: 1.19657 v_acc: 0.70671 |  iteration: 7483 teacher: 0 stage: sketch lr: 0.000511\n",
      "batch 25 loss: 1.26817 acc: 0.70410 | v_loss: 1.25721 v_acc: 0.71159 |  iteration: 7484 teacher: 0 stage: sketch lr: 0.000511\n",
      "batch 26 loss: 1.28838 acc: 0.70443 | v_loss: 1.24832 v_acc: 0.69336 |  iteration: 7485 teacher: 0 stage: sketch lr: 0.000511\n",
      "batch 27 loss: 1.22005 acc: 0.70996 | v_loss: 1.22068 v_acc: 0.71484 |  iteration: 7486 teacher: 1 stage: sketch lr: 0.000511\n",
      "batch 28 loss: 1.27422 acc: 0.70150 | v_loss: 1.26263 v_acc: 0.69889 |  iteration: 7487 teacher: 1 stage: sketch lr: 0.000511\n",
      "batch 29 loss: 1.21186 acc: 0.71387 | v_loss: 1.17468 v_acc: 0.71159 |  iteration: 7488 teacher: 1 stage: sketch lr: 0.000511\n",
      "batch 30 loss: 1.34705 acc: 0.69076 | v_loss: 1.17867 v_acc: 0.72363 |  iteration: 7489 teacher: 1 stage: sketch lr: 0.000511\n",
      "batch 31 loss: 1.39748 acc: 0.69173 | v_loss: 1.24027 v_acc: 0.70117 |  iteration: 7490 teacher: 0 stage: sketch lr: 0.000511\n",
      "batch 32 loss: 1.24896 acc: 0.70508 | v_loss: 1.35466 v_acc: 0.69954 |  iteration: 7491 teacher: 0 stage: sketch lr: 0.000511\n",
      "batch 33 loss: 1.30191 acc: 0.70378 | v_loss: 1.15349 v_acc: 0.70833 |  iteration: 7492 teacher: 1 stage: sketch lr: 0.000511\n",
      "batch 34 loss: 1.35330 acc: 0.70833 | v_loss: 1.40541 v_acc: 0.68717 |  iteration: 7493 teacher: 0 stage: sketch lr: 0.000511\n",
      "batch 35 loss: 1.33484 acc: 0.70605 | v_loss: 1.16549 v_acc: 0.72201 |  iteration: 7494 teacher: 0 stage: sketch lr: 0.000511\n",
      "batch 36 loss: 1.30723 acc: 0.69889 | v_loss: 1.47212 v_acc: 0.67969 |  iteration: 7495 teacher: 1 stage: sketch lr: 0.000510\n",
      "batch 37 loss: 1.35741 acc: 0.69564 | v_loss: 1.36591 v_acc: 0.69596 |  iteration: 7496 teacher: 0 stage: sketch lr: 0.000510\n",
      "batch 38 loss: 1.26668 acc: 0.70443 | v_loss: 1.33540 v_acc: 0.69206 |  iteration: 7497 teacher: 0 stage: sketch lr: 0.000510\n",
      "batch 39 loss: 1.29369 acc: 0.70671 | v_loss: 1.31315 v_acc: 0.69694 |  iteration: 7498 teacher: 1 stage: sketch lr: 0.000510\n",
      "batch 40 loss: 1.33821 acc: 0.69661 | v_loss: 1.22764 v_acc: 0.70378 |  iteration: 7499 teacher: 1 stage: sketch lr: 0.000510\n",
      "batch 41 loss: 1.22456 acc: 0.71159 | v_loss: 1.26683 v_acc: 0.70573 |  iteration: 7500 teacher: 0 stage: sketch lr: 0.000510\n",
      "batch 42 loss: 1.33257 acc: 0.70768 | v_loss: 1.22150 v_acc: 0.71908 |  iteration: 7501 teacher: 1 stage: sketch lr: 0.000510\n",
      "batch 43 loss: 1.29623 acc: 0.70931 | v_loss: 1.41837 v_acc: 0.68978 |  iteration: 7502 teacher: 0 stage: sketch lr: 0.000510\n",
      "batch 44 loss: 1.32863 acc: 0.70410 | v_loss: 1.30383 v_acc: 0.71061 |  iteration: 7503 teacher: 0 stage: sketch lr: 0.000510\n",
      "batch 45 loss: 1.30082 acc: 0.70768 | v_loss: 1.19213 v_acc: 0.70931 |  iteration: 7504 teacher: 0 stage: sketch lr: 0.000510\n",
      "batch 46 loss: 1.24671 acc: 0.70052 | v_loss: 1.26539 v_acc: 0.71354 |  iteration: 7505 teacher: 0 stage: sketch lr: 0.000510\n",
      "batch 47 loss: 1.23814 acc: 0.70410 | v_loss: 1.17214 v_acc: 0.70605 |  iteration: 7506 teacher: 0 stage: sketch lr: 0.000510\n",
      "batch 48 loss: 1.23702 acc: 0.70638 | v_loss: 1.26165 v_acc: 0.70150 |  iteration: 7507 teacher: 1 stage: sketch lr: 0.000510\n",
      "batch 49 loss: 1.29931 acc: 0.70736 | v_loss: 1.22808 v_acc: 0.71549 |  iteration: 7508 teacher: 0 stage: sketch lr: 0.000510\n",
      "batch 50 loss: 1.36145 acc: 0.69792 | v_loss: 1.17302 v_acc: 0.72038 |  iteration: 7509 teacher: 1 stage: sketch lr: 0.000510\n",
      "batch 51 loss: 1.33318 acc: 0.69759 | v_loss: 1.13220 v_acc: 0.72819 |  iteration: 7510 teacher: 1 stage: sketch lr: 0.000510\n",
      "batch 52 loss: 1.27374 acc: 0.72233 | v_loss: 1.25955 v_acc: 0.71940 |  iteration: 7511 teacher: 0 stage: sketch lr: 0.000510\n",
      "batch 53 loss: 1.35693 acc: 0.70345 | v_loss: 1.25264 v_acc: 0.70508 |  iteration: 7512 teacher: 1 stage: sketch lr: 0.000510\n",
      "batch 54 loss: 1.26301 acc: 0.70247 | v_loss: 1.25849 v_acc: 0.70833 |  iteration: 7513 teacher: 0 stage: sketch lr: 0.000510\n",
      "batch 55 loss: 1.35220 acc: 0.70378 | v_loss: 1.11798 v_acc: 0.71940 |  iteration: 7514 teacher: 0 stage: sketch lr: 0.000510\n",
      "batch 56 loss: 1.23947 acc: 0.71191 | v_loss: 1.24366 v_acc: 0.73210 |  iteration: 7515 teacher: 0 stage: sketch lr: 0.000510\n",
      "batch 57 loss: 1.26991 acc: 0.70605 | v_loss: 1.30520 v_acc: 0.69954 |  iteration: 7516 teacher: 1 stage: sketch lr: 0.000510\n",
      "batch 58 loss: 1.34021 acc: 0.70508 | v_loss: 1.29860 v_acc: 0.72168 |  iteration: 7517 teacher: 1 stage: sketch lr: 0.000510\n",
      "batch 59 loss: 1.31563 acc: 0.70671 | v_loss: 1.16008 v_acc: 0.71712 |  iteration: 7518 teacher: 1 stage: sketch lr: 0.000510\n",
      "batch 60 loss: 1.32463 acc: 0.69499 | v_loss: 1.11543 v_acc: 0.72819 |  iteration: 7519 teacher: 0 stage: sketch lr: 0.000510\n",
      "batch 61 loss: 1.21713 acc: 0.72005 | v_loss: 1.10216 v_acc: 0.72363 |  iteration: 7520 teacher: 1 stage: sketch lr: 0.000510\n",
      "batch 62 loss: 1.29799 acc: 0.70898 | v_loss: 1.19538 v_acc: 0.70801 |  iteration: 7521 teacher: 0 stage: sketch lr: 0.000510\n",
      "batch 63 loss: 1.34824 acc: 0.69954 | v_loss: 1.23055 v_acc: 0.70345 |  iteration: 7522 teacher: 0 stage: sketch lr: 0.000510\n",
      "batch 64 loss: 1.26610 acc: 0.71484 | v_loss: 1.20478 v_acc: 0.71224 |  iteration: 7523 teacher: 1 stage: sketch lr: 0.000510\n",
      "batch 65 loss: 1.33105 acc: 0.69922 | v_loss: 1.33703 v_acc: 0.70475 |  iteration: 7524 teacher: 0 stage: sketch lr: 0.000509\n",
      "batch 66 loss: 1.22860 acc: 0.71810 | v_loss: 1.48157 v_acc: 0.69141 |  iteration: 7525 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 67 loss: 1.26323 acc: 0.71452 | v_loss: 1.36547 v_acc: 0.69727 |  iteration: 7526 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 68 loss: 1.22712 acc: 0.71354 | v_loss: 1.19569 v_acc: 0.72396 |  iteration: 7527 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 69 loss: 1.38387 acc: 0.69043 | v_loss: 1.17547 v_acc: 0.70801 |  iteration: 7528 teacher: 0 stage: sketch lr: 0.000509\n",
      "batch 70 loss: 1.29966 acc: 0.70312 | v_loss: 1.16374 v_acc: 0.71940 |  iteration: 7529 teacher: 0 stage: sketch lr: 0.000509\n",
      "batch 71 loss: 1.36371 acc: 0.69303 | v_loss: 1.24635 v_acc: 0.70150 |  iteration: 7530 teacher: 0 stage: sketch lr: 0.000509\n",
      "batch 72 loss: 1.28489 acc: 0.70312 | v_loss: 1.24514 v_acc: 0.71615 |  iteration: 7531 teacher: 0 stage: sketch lr: 0.000509\n",
      "batch 73 loss: 1.31209 acc: 0.70182 | v_loss: 1.21833 v_acc: 0.73047 |  iteration: 7532 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 74 loss: 1.30369 acc: 0.70182 | v_loss: 1.22824 v_acc: 0.72005 |  iteration: 7533 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 75 loss: 1.30643 acc: 0.70475 | v_loss: 1.23458 v_acc: 0.70931 |  iteration: 7534 teacher: 0 stage: sketch lr: 0.000509\n",
      "batch 76 loss: 1.23503 acc: 0.70247 | v_loss: 1.16801 v_acc: 0.72298 |  iteration: 7535 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 77 loss: 1.23256 acc: 0.71126 | v_loss: 1.14903 v_acc: 0.71908 |  iteration: 7536 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 78 loss: 1.44670 acc: 0.69336 | v_loss: 1.47134 v_acc: 0.69043 |  iteration: 7537 teacher: 0 stage: sketch lr: 0.000509\n",
      "batch 79 loss: 1.30421 acc: 0.70150 | v_loss: 1.20752 v_acc: 0.70801 |  iteration: 7538 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 80 loss: 1.26647 acc: 0.70280 | v_loss: 1.24601 v_acc: 0.71257 |  iteration: 7539 teacher: 0 stage: sketch lr: 0.000509\n",
      "batch 81 loss: 1.30313 acc: 0.70247 | v_loss: 1.21746 v_acc: 0.72624 |  iteration: 7540 teacher: 0 stage: sketch lr: 0.000509\n",
      "batch 82 loss: 1.29896 acc: 0.71191 | v_loss: 1.28636 v_acc: 0.70508 |  iteration: 7541 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 83 loss: 1.20172 acc: 0.71289 | v_loss: 1.13204 v_acc: 0.73210 |  iteration: 7542 teacher: 0 stage: sketch lr: 0.000509\n",
      "batch 84 loss: 1.26885 acc: 0.70345 | v_loss: 1.38232 v_acc: 0.71322 |  iteration: 7543 teacher: 0 stage: sketch lr: 0.000509\n",
      "batch 85 loss: 1.25746 acc: 0.70150 | v_loss: 1.17788 v_acc: 0.70150 |  iteration: 7544 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 86 loss: 1.35079 acc: 0.70410 | v_loss: 1.20213 v_acc: 0.70573 |  iteration: 7545 teacher: 0 stage: sketch lr: 0.000509\n",
      "batch 87 loss: 1.31089 acc: 0.69922 | v_loss: 1.25908 v_acc: 0.70378 |  iteration: 7546 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 88 loss: 1.37176 acc: 0.70052 | v_loss: 1.28378 v_acc: 0.70150 |  iteration: 7547 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 89 loss: 1.47303 acc: 0.68880 | v_loss: 1.33591 v_acc: 0.69238 |  iteration: 7548 teacher: 0 stage: sketch lr: 0.000509\n",
      "batch 90 loss: 1.31245 acc: 0.70150 | v_loss: 1.36567 v_acc: 0.70573 |  iteration: 7549 teacher: 0 stage: sketch lr: 0.000509\n",
      "batch 91 loss: 1.32642 acc: 0.70117 | v_loss: 1.29101 v_acc: 0.69759 |  iteration: 7550 teacher: 0 stage: sketch lr: 0.000509\n",
      "batch 92 loss: 1.25403 acc: 0.71745 | v_loss: 1.21099 v_acc: 0.70671 |  iteration: 7551 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 93 loss: 1.38517 acc: 0.69596 | v_loss: 1.30328 v_acc: 0.70638 |  iteration: 7552 teacher: 1 stage: sketch lr: 0.000509\n",
      "batch 94 loss: 1.26392 acc: 0.70605 | v_loss: 1.21869 v_acc: 0.71224 |  iteration: 7553 teacher: 0 stage: sketch lr: 0.000509\n",
      "batch 95 loss: 1.33007 acc: 0.69857 | v_loss: 1.15261 v_acc: 0.72201 |  iteration: 7554 teacher: 1 stage: sketch lr: 0.000508\n",
      "batch 96 loss: 1.26408 acc: 0.71029 | v_loss: 1.14714 v_acc: 0.70736 |  iteration: 7555 teacher: 0 stage: sketch lr: 0.000508\n",
      "batch 97 loss: 1.29292 acc: 0.69889 | v_loss: 1.25808 v_acc: 0.70801 |  iteration: 7556 teacher: 1 stage: sketch lr: 0.000508\n",
      "batch 98 loss: 1.30664 acc: 0.70605 | v_loss: 1.31826 v_acc: 0.69824 |  iteration: 7557 teacher: 0 stage: sketch lr: 0.000508\n",
      "batch 99 loss: 1.31193 acc: 0.70280 | v_loss: 1.15471 v_acc: 0.71452 |  iteration: 7558 teacher: 0 stage: sketch lr: 0.000508\n",
      "batch 100 loss: 1.27028 acc: 0.70833 | v_loss: 1.17780 v_acc: 0.70312 |  iteration: 7559 teacher: 1 stage: sketch lr: 0.000508\n",
      "batch 101 loss: 1.36788 acc: 0.69629 | v_loss: 1.19189 v_acc: 0.71191 |  iteration: 7560 teacher: 1 stage: sketch lr: 0.000508\n",
      "batch 102 loss: 1.33344 acc: 0.70150 | v_loss: 1.18964 v_acc: 0.70736 |  iteration: 7561 teacher: 0 stage: sketch lr: 0.000508\n",
      "batch 103 loss: 1.30742 acc: 0.70378 | v_loss: 1.06053 v_acc: 0.73535 |  iteration: 7562 teacher: 0 stage: sketch lr: 0.000508\n",
      "batch 104 loss: 1.32635 acc: 0.70150 | v_loss: 1.17681 v_acc: 0.72005 |  iteration: 7563 teacher: 1 stage: sketch lr: 0.000508\n",
      "batch 105 loss: 1.33058 acc: 0.70508 | v_loss: 1.15001 v_acc: 0.73275 |  iteration: 7564 teacher: 1 stage: sketch lr: 0.000508\n",
      "batch 106 loss: 1.36258 acc: 0.69694 | v_loss: 1.12481 v_acc: 0.72005 |  iteration: 7565 teacher: 0 stage: sketch lr: 0.000508\n",
      "batch 107 loss: 1.34540 acc: 0.69434 | v_loss: 1.20382 v_acc: 0.71582 |  iteration: 7566 teacher: 0 stage: sketch lr: 0.000508\n",
      "batch 108 loss: 1.25199 acc: 0.70801 | v_loss: 1.24231 v_acc: 0.71224 |  iteration: 7567 teacher: 1 stage: sketch lr: 0.000508\n",
      "batch 109 loss: 1.32901 acc: 0.70150 | v_loss: 1.20636 v_acc: 0.72005 |  iteration: 7568 teacher: 1 stage: sketch lr: 0.000508\n",
      "batch 110 loss: 1.18063 acc: 0.72168 | v_loss: 1.37743 v_acc: 0.69987 |  iteration: 7569 teacher: 1 stage: sketch lr: 0.000508\n",
      "batch 111 loss: 1.27962 acc: 0.70703 | v_loss: 1.27042 v_acc: 0.72201 |  iteration: 7570 teacher: 1 stage: sketch lr: 0.000508\n",
      "batch 112 loss: 1.29202 acc: 0.70215 | v_loss: 1.05613 v_acc: 0.74740 |  iteration: 7571 teacher: 1 stage: sketch lr: 0.000508\n",
      "batch 113 loss: 1.33205 acc: 0.70052 | v_loss: 1.21199 v_acc: 0.70280 |  iteration: 7572 teacher: 0 stage: sketch lr: 0.000508\n",
      "batch 114 loss: 1.29538 acc: 0.70150 | v_loss: 1.28881 v_acc: 0.69824 |  iteration: 7573 teacher: 1 stage: sketch lr: 0.000508\n",
      "batch 115 loss: 1.23830 acc: 0.70996 | v_loss: 1.22616 v_acc: 0.68685 |  iteration: 7574 teacher: 0 stage: sketch lr: 0.000508\n",
      "batch 116 loss: 1.36992 acc: 0.70312 | v_loss: 1.27502 v_acc: 0.70215 |  iteration: 7575 teacher: 1 stage: sketch lr: 0.000508\n",
      "batch 117 loss: 1.32920 acc: 0.69629 | v_loss: 1.25562 v_acc: 0.69271 |  iteration: 7576 teacher: 1 stage: sketch lr: 0.000508\n",
      "batch 118 loss: 1.27806 acc: 0.70898 | v_loss: 1.22601 v_acc: 0.70801 |  iteration: 7577 teacher: 1 stage: sketch lr: 0.000508\n",
      "batch 119 loss: 1.28010 acc: 0.70898 | v_loss: 1.27367 v_acc: 0.69499 |  iteration: 7578 teacher: 0 stage: sketch lr: 0.000508\n",
      "batch 120 loss: 1.17049 acc: 0.70703 | v_loss: 1.18267 v_acc: 0.72233 |  iteration: 7579 teacher: 0 stage: sketch lr: 0.000508\n",
      "batch 121 loss: 1.34885 acc: 0.69531 | v_loss: 1.18457 v_acc: 0.72656 |  iteration: 7580 teacher: 1 stage: sketch lr: 0.000508\n",
      "batch 122 loss: 1.23628 acc: 0.71224 | v_loss: 1.24263 v_acc: 0.70475 |  iteration: 7581 teacher: 1 stage: sketch lr: 0.000508\n",
      "batch 123 loss: 1.32970 acc: 0.69596 | v_loss: 1.33047 v_acc: 0.69954 |  iteration: 7582 teacher: 0 stage: sketch lr: 0.000508\n",
      "batch 124 loss: 1.33571 acc: 0.70540 | v_loss: 1.15649 v_acc: 0.70671 |  iteration: 7583 teacher: 0 stage: sketch lr: 0.000508\n",
      "batch 125 loss: 1.26898 acc: 0.70117 | v_loss: 1.41965 v_acc: 0.68685 |  iteration: 7584 teacher: 1 stage: sketch lr: 0.000507\n",
      "batch 126 loss: 1.29573 acc: 0.70378 | v_loss: 1.17430 v_acc: 0.72461 |  iteration: 7585 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 127 loss: 1.30781 acc: 0.70052 | v_loss: 1.47490 v_acc: 0.68555 |  iteration: 7586 teacher: 1 stage: sketch lr: 0.000507\n",
      "batch 128 loss: 1.28252 acc: 0.71224 | v_loss: 1.36641 v_acc: 0.69727 |  iteration: 7587 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 129 loss: 1.24449 acc: 0.71029 | v_loss: 1.33213 v_acc: 0.68913 |  iteration: 7588 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 130 loss: 1.27365 acc: 0.70801 | v_loss: 1.31166 v_acc: 0.69759 |  iteration: 7589 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 131 loss: 1.29540 acc: 0.70052 | v_loss: 1.23604 v_acc: 0.70215 |  iteration: 7590 teacher: 1 stage: sketch lr: 0.000507\n",
      "batch 132 loss: 1.24908 acc: 0.71061 | v_loss: 1.26979 v_acc: 0.69889 |  iteration: 7591 teacher: 1 stage: sketch lr: 0.000507\n",
      "batch 133 loss: 1.37625 acc: 0.69401 | v_loss: 1.21403 v_acc: 0.71419 |  iteration: 7592 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 134 loss: 1.26085 acc: 0.70638 | v_loss: 1.41442 v_acc: 0.69108 |  iteration: 7593 teacher: 1 stage: sketch lr: 0.000507\n",
      "batch 135 loss: 1.36175 acc: 0.70931 | v_loss: 1.28984 v_acc: 0.71126 |  iteration: 7594 teacher: 1 stage: sketch lr: 0.000507\n",
      "batch 136 loss: 1.25385 acc: 0.70345 | v_loss: 1.20853 v_acc: 0.70866 |  iteration: 7595 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 137 loss: 1.22844 acc: 0.70898 | v_loss: 1.26801 v_acc: 0.71354 |  iteration: 7596 teacher: 1 stage: sketch lr: 0.000507\n",
      "batch 138 loss: 1.28461 acc: 0.71126 | v_loss: 1.16127 v_acc: 0.70605 |  iteration: 7597 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 139 loss: 1.34517 acc: 0.69759 | v_loss: 1.26411 v_acc: 0.69922 |  iteration: 7598 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 140 loss: 1.37695 acc: 0.68783 | v_loss: 1.23572 v_acc: 0.71191 |  iteration: 7599 teacher: 1 stage: sketch lr: 0.000507\n",
      "batch 141 loss: 1.34126 acc: 0.69466 | v_loss: 1.17342 v_acc: 0.71484 |  iteration: 7600 teacher: 1 stage: sketch lr: 0.000507\n",
      "batch 142 loss: 1.22915 acc: 0.71322 | v_loss: 1.13779 v_acc: 0.72624 |  iteration: 7601 teacher: 1 stage: sketch lr: 0.000507\n",
      "batch 143 loss: 1.27859 acc: 0.69922 | v_loss: 1.25615 v_acc: 0.71387 |  iteration: 7602 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 144 loss: 1.28251 acc: 0.70703 | v_loss: 1.24943 v_acc: 0.70215 |  iteration: 7603 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 145 loss: 1.25582 acc: 0.69889 | v_loss: 1.25950 v_acc: 0.70540 |  iteration: 7604 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 146 loss: 1.28326 acc: 0.70378 | v_loss: 1.11277 v_acc: 0.71582 |  iteration: 7605 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 147 loss: 1.26721 acc: 0.70801 | v_loss: 1.24203 v_acc: 0.72982 |  iteration: 7606 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 148 loss: 1.28309 acc: 0.71224 | v_loss: 1.30214 v_acc: 0.69792 |  iteration: 7607 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 149 loss: 1.33682 acc: 0.69922 | v_loss: 1.31408 v_acc: 0.72168 |  iteration: 7608 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 150 loss: 1.31307 acc: 0.70247 | v_loss: 1.16135 v_acc: 0.71842 |  iteration: 7609 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 151 loss: 1.35090 acc: 0.69661 | v_loss: 1.11141 v_acc: 0.73828 |  iteration: 7610 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 152 loss: 1.31112 acc: 0.69141 | v_loss: 1.09939 v_acc: 0.72266 |  iteration: 7611 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 153 loss: 1.37137 acc: 0.70085 | v_loss: 1.18348 v_acc: 0.71094 |  iteration: 7612 teacher: 1 stage: sketch lr: 0.000507\n",
      "batch 154 loss: 1.29625 acc: 0.69987 | v_loss: 1.23970 v_acc: 0.70345 |  iteration: 7613 teacher: 0 stage: sketch lr: 0.000507\n",
      "batch 155 loss: 1.34848 acc: 0.69108 | v_loss: 1.20182 v_acc: 0.71224 |  iteration: 7614 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 156 loss: 1.26353 acc: 0.70280 | v_loss: 1.33045 v_acc: 0.70475 |  iteration: 7615 teacher: 1 stage: sketch lr: 0.000506\n",
      "batch 157 loss: 1.28312 acc: 0.70508 | v_loss: 1.48221 v_acc: 0.69108 |  iteration: 7616 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 158 loss: 1.31775 acc: 0.70085 | v_loss: 1.35219 v_acc: 0.69434 |  iteration: 7617 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 159 loss: 1.24559 acc: 0.70898 | v_loss: 1.19940 v_acc: 0.72168 |  iteration: 7618 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 160 loss: 1.28580 acc: 0.70801 | v_loss: 1.15668 v_acc: 0.70215 |  iteration: 7619 teacher: 1 stage: sketch lr: 0.000506\n",
      "batch 161 loss: 1.27803 acc: 0.70378 | v_loss: 1.15796 v_acc: 0.72201 |  iteration: 7620 teacher: 1 stage: sketch lr: 0.000506\n",
      "batch 162 loss: 1.32347 acc: 0.70410 | v_loss: 1.22955 v_acc: 0.70378 |  iteration: 7621 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 163 loss: 1.29882 acc: 0.70573 | v_loss: 1.24927 v_acc: 0.71647 |  iteration: 7622 teacher: 1 stage: sketch lr: 0.000506\n",
      "batch 164 loss: 1.27428 acc: 0.70280 | v_loss: 1.20948 v_acc: 0.73079 |  iteration: 7623 teacher: 1 stage: sketch lr: 0.000506\n",
      "batch 165 loss: 1.17763 acc: 0.71582 | v_loss: 1.23613 v_acc: 0.72005 |  iteration: 7624 teacher: 1 stage: sketch lr: 0.000506\n",
      "batch 166 loss: 1.24982 acc: 0.71061 | v_loss: 1.23966 v_acc: 0.71061 |  iteration: 7625 teacher: 1 stage: sketch lr: 0.000506\n",
      "batch 167 loss: 1.22179 acc: 0.70898 | v_loss: 1.15640 v_acc: 0.72624 |  iteration: 7626 teacher: 1 stage: sketch lr: 0.000506\n",
      "batch 168 loss: 1.32953 acc: 0.69336 | v_loss: 1.12354 v_acc: 0.71842 |  iteration: 7627 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 169 loss: 1.25222 acc: 0.70182 | v_loss: 1.47688 v_acc: 0.69108 |  iteration: 7628 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 170 loss: 1.35463 acc: 0.68457 | v_loss: 1.19777 v_acc: 0.71126 |  iteration: 7629 teacher: 1 stage: sketch lr: 0.000506\n",
      "batch 171 loss: 1.31032 acc: 0.70573 | v_loss: 1.23300 v_acc: 0.72038 |  iteration: 7630 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 172 loss: 1.23864 acc: 0.71029 | v_loss: 1.22263 v_acc: 0.70931 |  iteration: 7631 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 173 loss: 1.30643 acc: 0.69987 | v_loss: 1.28442 v_acc: 0.70508 |  iteration: 7632 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 174 loss: 1.26858 acc: 0.70443 | v_loss: 1.15145 v_acc: 0.73275 |  iteration: 7633 teacher: 1 stage: sketch lr: 0.000506\n",
      "batch 175 loss: 1.27343 acc: 0.70182 | v_loss: 1.40523 v_acc: 0.70833 |  iteration: 7634 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 176 loss: 1.39646 acc: 0.70020 | v_loss: 1.18926 v_acc: 0.69824 |  iteration: 7635 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 177 loss: 1.31087 acc: 0.70182 | v_loss: 1.20999 v_acc: 0.69596 |  iteration: 7636 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 178 loss: 1.27204 acc: 0.70410 | v_loss: 1.27066 v_acc: 0.70182 |  iteration: 7637 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 179 loss: 1.32719 acc: 0.69922 | v_loss: 1.28125 v_acc: 0.70312 |  iteration: 7638 teacher: 1 stage: sketch lr: 0.000506\n",
      "batch 180 loss: 1.27753 acc: 0.70052 | v_loss: 1.33542 v_acc: 0.69922 |  iteration: 7639 teacher: 1 stage: sketch lr: 0.000506\n",
      "batch 181 loss: 1.27864 acc: 0.70638 | v_loss: 1.36877 v_acc: 0.71029 |  iteration: 7640 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 182 loss: 1.27969 acc: 0.71289 | v_loss: 1.28459 v_acc: 0.70052 |  iteration: 7641 teacher: 1 stage: sketch lr: 0.000506\n",
      "batch 183 loss: 1.24791 acc: 0.71159 | v_loss: 1.18304 v_acc: 0.71159 |  iteration: 7642 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 184 loss: 1.30445 acc: 0.70475 | v_loss: 1.34459 v_acc: 0.70703 |  iteration: 7643 teacher: 0 stage: sketch lr: 0.000506\n",
      "batch 185 loss: 1.24221 acc: 0.70964 | v_loss: 1.23049 v_acc: 0.71875 |  iteration: 7644 teacher: 0 stage: sketch lr: 0.000505\n",
      "batch 186 loss: 1.31457 acc: 0.70671 | v_loss: 1.13095 v_acc: 0.72331 |  iteration: 7645 teacher: 0 stage: sketch lr: 0.000505\n",
      "batch 187 loss: 1.22225 acc: 0.71452 | v_loss: 1.13841 v_acc: 0.71615 |  iteration: 7646 teacher: 0 stage: sketch lr: 0.000505\n",
      "batch 188 loss: 1.36937 acc: 0.70085 | v_loss: 1.24583 v_acc: 0.71126 |  iteration: 7647 teacher: 1 stage: sketch lr: 0.000505\n",
      "batch 189 loss: 1.25865 acc: 0.71712 | v_loss: 1.32476 v_acc: 0.69857 |  iteration: 7648 teacher: 0 stage: sketch lr: 0.000505\n",
      "batch 190 loss: 1.27436 acc: 0.71322 | v_loss: 1.17069 v_acc: 0.70475 |  iteration: 7649 teacher: 1 stage: sketch lr: 0.000505\n",
      "batch 191 loss: 1.28986 acc: 0.71484 | v_loss: 1.20516 v_acc: 0.69596 |  iteration: 7650 teacher: 0 stage: sketch lr: 0.000505\n",
      "batch 192 loss: 1.31743 acc: 0.70150 | v_loss: 1.19362 v_acc: 0.70833 |  iteration: 7651 teacher: 1 stage: sketch lr: 0.000505\n",
      "batch 193 loss: 1.22664 acc: 0.70703 | v_loss: 1.20707 v_acc: 0.70215 |  iteration: 7652 teacher: 1 stage: sketch lr: 0.000505\n",
      "batch 194 loss: 1.38144 acc: 0.69629 | v_loss: 1.07806 v_acc: 0.73926 |  iteration: 7653 teacher: 1 stage: sketch lr: 0.000505\n",
      "batch 195 loss: 1.28980 acc: 0.70443 | v_loss: 1.17914 v_acc: 0.71745 |  iteration: 7654 teacher: 0 stage: sketch lr: 0.000505\n",
      "batch 196 loss: 1.33426 acc: 0.70280 | v_loss: 1.15616 v_acc: 0.73014 |  iteration: 7655 teacher: 1 stage: sketch lr: 0.000505\n",
      "batch 197 loss: 1.25687 acc: 0.70638 | v_loss: 1.12721 v_acc: 0.72005 |  iteration: 7656 teacher: 1 stage: sketch lr: 0.000505\n",
      "batch 198 loss: 1.32267 acc: 0.70475 | v_loss: 1.20783 v_acc: 0.71973 |  iteration: 7657 teacher: 1 stage: sketch lr: 0.000505\n",
      "batch 199 loss: 1.24243 acc: 0.71094 | v_loss: 1.22517 v_acc: 0.71484 |  iteration: 7658 teacher: 0 stage: sketch lr: 0.000505\n",
      "batch 200 loss: 1.31596 acc: 0.70378 | v_loss: 1.20014 v_acc: 0.72266 |  iteration: 7659 teacher: 0 stage: sketch lr: 0.000505\n",
      "batch 201 loss: 1.37319 acc: 0.69531 | v_loss: 1.39036 v_acc: 0.69694 |  iteration: 7660 teacher: 0 stage: sketch lr: 0.000505\n",
      "batch 202 loss: 1.27069 acc: 0.70833 | v_loss: 1.26109 v_acc: 0.72005 |  iteration: 7661 teacher: 0 stage: sketch lr: 0.000505\n",
      "batch 203 loss: 1.29340 acc: 0.71126 | v_loss: 1.05517 v_acc: 0.74837 |  iteration: 7662 teacher: 0 stage: sketch lr: 0.000505\n",
      "batch 204 loss: 1.22210 acc: 0.70833 | v_loss: 1.21799 v_acc: 0.70833 |  iteration: 7663 teacher: 0 stage: sketch lr: 0.000505\n",
      "batch 205 loss: 1.35242 acc: 0.70215 | v_loss: 1.27804 v_acc: 0.69987 |  iteration: 7664 teacher: 1 stage: sketch lr: 0.000505\n",
      "batch 206 loss: 1.24980 acc: 0.71419 | v_loss: 1.22411 v_acc: 0.70638 |  iteration: 7665 teacher: 0 stage: sketch lr: 0.000505\n",
      "batch 207 loss: 1.27725 acc: 0.70736 | v_loss: 1.25671 v_acc: 0.71354 |  iteration: 7666 teacher: 1 stage: sketch lr: 0.000505\n",
      "batch 208 loss: 1.28768 acc: 0.71094 | v_loss: 1.25034 v_acc: 0.69531 |  iteration: 7667 teacher: 1 stage: sketch lr: 0.000505\n",
      "batch 209 loss: 1.31904 acc: 0.70280 | v_loss: 1.22796 v_acc: 0.71875 |  iteration: 7668 teacher: 1 stage: sketch lr: 0.000505\n",
      "batch 210 loss: 1.31214 acc: 0.71029 | v_loss: 1.26047 v_acc: 0.70215 |  iteration: 7669 teacher: 0 stage: sketch lr: 0.000505\n",
      "batch 211 loss: 1.34611 acc: 0.70345 | v_loss: 1.20439 v_acc: 0.71094 |  iteration: 7670 teacher: 1 stage: sketch lr: 0.000505\n",
      "batch 212 loss: 1.33409 acc: 0.69694 | v_loss: 1.19021 v_acc: 0.72201 |  iteration: 7671 teacher: 0 stage: sketch lr: 0.000505\n",
      "batch 213 loss: 1.34447 acc: 0.69922 | v_loss: 1.26387 v_acc: 0.70280 |  iteration: 7672 teacher: 0 stage: sketch lr: 0.000505\n",
      "batch 214 loss: 1.31610 acc: 0.70638 | v_loss: 1.33068 v_acc: 0.69857 |  iteration: 7673 teacher: 1 stage: sketch lr: 0.000505\n",
      "batch 215 loss: 1.26413 acc: 0.70052 | v_loss: 1.16231 v_acc: 0.70605 |  iteration: 7674 teacher: 0 stage: sketch lr: 0.000504\n",
      "batch 216 loss: 1.18815 acc: 0.71126 | v_loss: 1.41502 v_acc: 0.68066 |  iteration: 7675 teacher: 1 stage: sketch lr: 0.000504\n",
      "batch 217 loss: 1.23691 acc: 0.70996 | v_loss: 1.18046 v_acc: 0.71842 |  iteration: 7676 teacher: 1 stage: sketch lr: 0.000504\n",
      "batch 218 loss: 1.28676 acc: 0.70736 | v_loss: 1.47887 v_acc: 0.67513 |  iteration: 7677 teacher: 1 stage: sketch lr: 0.000504\n",
      "batch 219 loss: 1.24944 acc: 0.69792 | v_loss: 1.36709 v_acc: 0.69336 |  iteration: 7678 teacher: 1 stage: sketch lr: 0.000504\n",
      "batch 220 loss: 1.30366 acc: 0.70638 | v_loss: 1.34739 v_acc: 0.69727 |  iteration: 7679 teacher: 0 stage: sketch lr: 0.000504\n",
      "batch 221 loss: 1.28765 acc: 0.71354 | v_loss: 1.30192 v_acc: 0.70020 |  iteration: 7680 teacher: 0 stage: sketch lr: 0.000504\n",
      "batch 222 loss: 1.26312 acc: 0.70996 | v_loss: 1.22850 v_acc: 0.70638 |  iteration: 7681 teacher: 1 stage: sketch lr: 0.000504\n",
      "batch 223 loss: 1.41439 acc: 0.69238 | v_loss: 1.25977 v_acc: 0.70410 |  iteration: 7682 teacher: 1 stage: sketch lr: 0.000504\n",
      "batch 224 loss: 1.32981 acc: 0.69303 | v_loss: 1.21441 v_acc: 0.71842 |  iteration: 7683 teacher: 1 stage: sketch lr: 0.000504\n",
      "batch 225 loss: 1.34016 acc: 0.70898 | v_loss: 1.42169 v_acc: 0.68880 |  iteration: 7684 teacher: 0 stage: sketch lr: 0.000504\n",
      "batch 226 loss: 1.19477 acc: 0.71387 | v_loss: 1.29082 v_acc: 0.71159 |  iteration: 7685 teacher: 0 stage: sketch lr: 0.000504\n",
      "batch 227 loss: 1.29553 acc: 0.70931 | v_loss: 1.19670 v_acc: 0.70768 |  iteration: 7686 teacher: 0 stage: sketch lr: 0.000504\n",
      "batch 228 loss: 1.33530 acc: 0.70378 | v_loss: 1.27202 v_acc: 0.71224 |  iteration: 7687 teacher: 0 stage: sketch lr: 0.000504\n",
      "batch 229 loss: 1.34696 acc: 0.69108 | v_loss: 1.19043 v_acc: 0.69922 |  iteration: 7688 teacher: 1 stage: sketch lr: 0.000504\n",
      "batch 230 loss: 1.36051 acc: 0.70020 | v_loss: 1.26192 v_acc: 0.69857 |  iteration: 7689 teacher: 0 stage: sketch lr: 0.000504\n",
      "batch 231 loss: 1.30263 acc: 0.69759 | v_loss: 1.23460 v_acc: 0.71842 |  iteration: 7690 teacher: 1 stage: sketch lr: 0.000504\n",
      "batch 232 loss: 1.28184 acc: 0.70085 | v_loss: 1.18160 v_acc: 0.71647 |  iteration: 7691 teacher: 1 stage: sketch lr: 0.000504\n",
      "batch 233 loss: 1.33133 acc: 0.70475 | v_loss: 1.14550 v_acc: 0.72559 |  iteration: 7692 teacher: 0 stage: sketch lr: 0.000504\n",
      "batch 234 loss: 1.25024 acc: 0.70703 | v_loss: 1.26160 v_acc: 0.71940 |  iteration: 7693 teacher: 1 stage: sketch lr: 0.000504\n",
      "batch 235 loss: 1.25437 acc: 0.70671 | v_loss: 1.24685 v_acc: 0.70605 |  iteration: 7694 teacher: 1 stage: sketch lr: 0.000504\n",
      "batch 236 loss: 1.31365 acc: 0.69010 | v_loss: 1.24573 v_acc: 0.70931 |  iteration: 7695 teacher: 0 stage: sketch lr: 0.000504\n",
      "batch 237 loss: 1.32422 acc: 0.70020 | v_loss: 1.10859 v_acc: 0.72331 |  iteration: 7696 teacher: 1 stage: sketch lr: 0.000504\n",
      "batch 238 loss: 1.29457 acc: 0.70638 | v_loss: 1.24290 v_acc: 0.73210 |  iteration: 7697 teacher: 0 stage: sketch lr: 0.000504\n",
      "batch 239 loss: 1.32706 acc: 0.70768 | v_loss: 1.29293 v_acc: 0.69759 |  iteration: 7698 teacher: 1 stage: sketch lr: 0.000504\n",
      "batch 240 loss: 1.29619 acc: 0.69564 | v_loss: 1.28252 v_acc: 0.72103 |  iteration: 7699 teacher: 0 stage: sketch lr: 0.000504\n",
      "batch 241 loss: 1.30495 acc: 0.69531 | v_loss: 1.15733 v_acc: 0.71908 |  iteration: 7700 teacher: 1 stage: sketch lr: 0.000504\n",
      "batch 242 loss: 1.37539 acc: 0.69401 | v_loss: 1.10644 v_acc: 0.73503 |  iteration: 7701 teacher: 0 stage: sketch lr: 0.000504\n",
      "batch 243 loss: 1.29399 acc: 0.70671 | v_loss: 1.11707 v_acc: 0.72396 |  iteration: 7702 teacher: 1 stage: sketch lr: 0.000504\n",
      "batch 244 loss: 1.28467 acc: 0.70312 | v_loss: 1.18994 v_acc: 0.71126 |  iteration: 7703 teacher: 1 stage: sketch lr: 0.000504\n",
      "batch 245 loss: 1.35712 acc: 0.69824 | v_loss: 1.26318 v_acc: 0.70247 |  iteration: 7704 teacher: 1 stage: sketch lr: 0.000504\n",
      "batch 246 loss: 1.25131 acc: 0.71094 | v_loss: 1.18982 v_acc: 0.71322 |  iteration: 7705 teacher: 1 stage: sketch lr: 0.000503\n",
      "batch 247 loss: 1.31055 acc: 0.70052 | v_loss: 1.32758 v_acc: 0.70410 |  iteration: 7706 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 248 loss: 1.29339 acc: 0.70020 | v_loss: 1.48312 v_acc: 0.69238 |  iteration: 7707 teacher: 1 stage: sketch lr: 0.000503\n",
      "batch 249 loss: 1.27604 acc: 0.70703 | v_loss: 1.35355 v_acc: 0.69531 |  iteration: 7708 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 250 loss: 1.25493 acc: 0.70280 | v_loss: 1.18849 v_acc: 0.72396 |  iteration: 7709 teacher: 1 stage: sketch lr: 0.000503\n",
      "batch 251 loss: 1.25069 acc: 0.71094 | v_loss: 1.15368 v_acc: 0.70996 |  iteration: 7710 teacher: 1 stage: sketch lr: 0.000503\n",
      "batch 252 loss: 1.30607 acc: 0.69857 | v_loss: 1.15609 v_acc: 0.72201 |  iteration: 7711 teacher: 1 stage: sketch lr: 0.000503\n",
      "batch 253 loss: 1.29324 acc: 0.70703 | v_loss: 1.23159 v_acc: 0.70378 |  iteration: 7712 teacher: 1 stage: sketch lr: 0.000503\n",
      "batch 254 loss: 1.38101 acc: 0.69857 | v_loss: 1.25023 v_acc: 0.71940 |  iteration: 7713 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 255 loss: 1.31902 acc: 0.70052 | v_loss: 1.21555 v_acc: 0.73079 |  iteration: 7714 teacher: 1 stage: sketch lr: 0.000503\n",
      "batch 256 loss: 1.34368 acc: 0.69368 | v_loss: 1.23184 v_acc: 0.71745 |  iteration: 7715 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 257 loss: 1.23721 acc: 0.70573 | v_loss: 1.23410 v_acc: 0.71126 |  iteration: 7716 teacher: 1 stage: sketch lr: 0.000503\n",
      "batch 258 loss: 1.19879 acc: 0.71126 | v_loss: 1.15377 v_acc: 0.72428 |  iteration: 7717 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 259 loss: 1.31402 acc: 0.69727 | v_loss: 1.12767 v_acc: 0.72103 |  iteration: 7718 teacher: 1 stage: sketch lr: 0.000503\n",
      "batch 260 loss: 1.22354 acc: 0.71061 | v_loss: 1.44328 v_acc: 0.69271 |  iteration: 7719 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 261 loss: 1.27420 acc: 0.71159 | v_loss: 1.19354 v_acc: 0.71452 |  iteration: 7720 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 262 loss: 1.21726 acc: 0.71452 | v_loss: 1.23580 v_acc: 0.71777 |  iteration: 7721 teacher: 1 stage: sketch lr: 0.000503\n",
      "batch 263 loss: 1.25396 acc: 0.70898 | v_loss: 1.23860 v_acc: 0.71484 |  iteration: 7722 teacher: 1 stage: sketch lr: 0.000503\n",
      "batch 264 loss: 1.26769 acc: 0.69759 | v_loss: 1.28664 v_acc: 0.70540 |  iteration: 7723 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 265 loss: 1.35723 acc: 0.69922 | v_loss: 1.13171 v_acc: 0.73047 |  iteration: 7724 teacher: 1 stage: sketch lr: 0.000503\n",
      "batch 266 loss: 1.31270 acc: 0.70378 | v_loss: 1.38669 v_acc: 0.71257 |  iteration: 7725 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 267 loss: 1.33946 acc: 0.69792 | v_loss: 1.18888 v_acc: 0.69759 |  iteration: 7726 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 268 loss: 1.21558 acc: 0.71777 | v_loss: 1.20666 v_acc: 0.70215 |  iteration: 7727 teacher: 1 stage: sketch lr: 0.000503\n",
      "batch 269 loss: 1.26226 acc: 0.70964 | v_loss: 1.27368 v_acc: 0.70247 |  iteration: 7728 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 270 loss: 1.25037 acc: 0.70475 | v_loss: 1.27989 v_acc: 0.70312 |  iteration: 7729 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 271 loss: 1.28745 acc: 0.70215 | v_loss: 1.33153 v_acc: 0.68783 |  iteration: 7730 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 272 loss: 1.38120 acc: 0.69238 | v_loss: 1.36737 v_acc: 0.70638 |  iteration: 7731 teacher: 1 stage: sketch lr: 0.000503\n",
      "batch 273 loss: 1.32763 acc: 0.70312 | v_loss: 1.28199 v_acc: 0.70020 |  iteration: 7732 teacher: 1 stage: sketch lr: 0.000503\n",
      "batch 274 loss: 1.32976 acc: 0.70703 | v_loss: 1.18756 v_acc: 0.70768 |  iteration: 7733 teacher: 0 stage: sketch lr: 0.000503\n",
      "batch 275 loss: 1.32117 acc: 0.70182 | v_loss: 1.32632 v_acc: 0.70605 |  iteration: 7734 teacher: 1 stage: sketch lr: 0.000503\n",
      "batch 276 loss: 1.25528 acc: 0.70345 | v_loss: 1.22565 v_acc: 0.71680 |  iteration: 7735 teacher: 1 stage: sketch lr: 0.000502\n",
      "batch 277 loss: 1.35018 acc: 0.69010 | v_loss: 1.14006 v_acc: 0.72526 |  iteration: 7736 teacher: 0 stage: sketch lr: 0.000502\n",
      "batch 278 loss: 1.29867 acc: 0.70475 | v_loss: 1.14083 v_acc: 0.71029 |  iteration: 7737 teacher: 1 stage: sketch lr: 0.000502\n",
      "batch 279 loss: 1.29697 acc: 0.70898 | v_loss: 1.26855 v_acc: 0.70410 |  iteration: 7738 teacher: 1 stage: sketch lr: 0.000502\n",
      "batch 280 loss: 1.29887 acc: 0.71126 | v_loss: 1.33801 v_acc: 0.68457 |  iteration: 7739 teacher: 1 stage: sketch lr: 0.000502\n",
      "batch 281 loss: 1.27322 acc: 0.70150 | v_loss: 1.15915 v_acc: 0.70215 |  iteration: 7740 teacher: 0 stage: sketch lr: 0.000502\n",
      "batch 282 loss: 1.27842 acc: 0.70508 | v_loss: 1.20139 v_acc: 0.69792 |  iteration: 7741 teacher: 0 stage: sketch lr: 0.000502\n",
      "batch 283 loss: 1.30918 acc: 0.70312 | v_loss: 1.19500 v_acc: 0.70931 |  iteration: 7742 teacher: 0 stage: sketch lr: 0.000502\n",
      "batch 284 loss: 1.26293 acc: 0.70215 | v_loss: 1.20554 v_acc: 0.70410 |  iteration: 7743 teacher: 1 stage: sketch lr: 0.000502\n",
      "batch 285 loss: 1.32724 acc: 0.69336 | v_loss: 1.05793 v_acc: 0.73991 |  iteration: 7744 teacher: 1 stage: sketch lr: 0.000502\n",
      "batch 286 loss: 1.33357 acc: 0.69368 | v_loss: 1.17713 v_acc: 0.72201 |  iteration: 7745 teacher: 0 stage: sketch lr: 0.000502\n",
      "batch 287 loss: 1.27838 acc: 0.70280 | v_loss: 1.14247 v_acc: 0.72656 |  iteration: 7746 teacher: 0 stage: sketch lr: 0.000502\n",
      "batch 288 loss: 1.28300 acc: 0.70443 | v_loss: 1.12214 v_acc: 0.72331 |  iteration: 7747 teacher: 0 stage: sketch lr: 0.000502\n",
      "batch 289 loss: 1.22715 acc: 0.70410 | v_loss: 1.19545 v_acc: 0.72363 |  iteration: 7748 teacher: 0 stage: sketch lr: 0.000502\n",
      "batch 290 loss: 1.28953 acc: 0.70573 | v_loss: 1.25194 v_acc: 0.71419 |  iteration: 7749 teacher: 1 stage: sketch lr: 0.000502\n",
      "batch 291 loss: 1.18729 acc: 0.71517 | v_loss: 1.21111 v_acc: 0.72428 |  iteration: 7750 teacher: 0 stage: sketch lr: 0.000502\n",
      "batch 292 loss: 1.31796 acc: 0.70378 | v_loss: 1.38054 v_acc: 0.70182 |  iteration: 7751 teacher: 0 stage: sketch lr: 0.000502\n",
      "batch 293 loss: 1.31082 acc: 0.70443 | v_loss: 1.28398 v_acc: 0.71712 |  iteration: 7752 teacher: 0 stage: sketch lr: 0.000502\n",
      "batch 294 loss: 1.39762 acc: 0.68555 | v_loss: 1.06868 v_acc: 0.74544 |  iteration: 7753 teacher: 1 stage: sketch lr: 0.000502\n",
      "batch 295 loss: 1.35346 acc: 0.69987 | v_loss: 1.21202 v_acc: 0.70540 |  iteration: 7754 teacher: 1 stage: sketch lr: 0.000502\n",
      "batch 296 loss: 1.33106 acc: 0.69531 | v_loss: 1.29799 v_acc: 0.68945 |  iteration: 7755 teacher: 0 stage: sketch lr: 0.000502\n",
      "batch 297 loss: 1.37001 acc: 0.69499 | v_loss: 1.20070 v_acc: 0.70280 |  iteration: 7756 teacher: 0 stage: sketch lr: 0.000502\n",
      "batch 298 loss: 1.30678 acc: 0.70378 | v_loss: 1.26148 v_acc: 0.71191 |  iteration: 7757 teacher: 0 stage: sketch lr: 0.000502\n",
      "batch 299 loss: 1.29773 acc: 0.70443 | v_loss: 1.25638 v_acc: 0.69076 |  iteration: 7758 teacher: 0 stage: sketch lr: 0.000502\n",
      "batch 300 loss: 1.42157 acc: 0.69466 | v_loss: 1.21107 v_acc: 0.71029 |  iteration: 7759 teacher: 0 stage: sketch lr: 0.000502\n",
      "batch 301 loss: 1.28577 acc: 0.69922 | v_loss: 1.26978 v_acc: 0.69303 |  iteration: 7760 teacher: 0 stage: sketch lr: 0.000502\n",
      "batch 302 loss: 1.28529 acc: 0.70736 | v_loss: 1.20010 v_acc: 0.71159 |  iteration: 7761 teacher: 1 stage: sketch lr: 0.000502\n",
      "batch 303 loss: 1.25986 acc: 0.70280 | v_loss: 1.19517 v_acc: 0.72461 |  iteration: 7762 teacher: 1 stage: sketch lr: 0.000502\n",
      "batch 304 loss: 1.24224 acc: 0.70801 | v_loss: 1.23606 v_acc: 0.70215 |  iteration: 7763 teacher: 0 stage: sketch lr: 0.000502\n",
      "batch 305 loss: 1.22795 acc: 0.71842 | v_loss: 1.36956 v_acc: 0.69889 |  iteration: 7764 teacher: 1 stage: sketch lr: 0.000502\n",
      "batch 306 loss: 1.31429 acc: 0.69303 | v_loss: 1.15170 v_acc: 0.70833 |  iteration: 7765 teacher: 1 stage: sketch lr: 0.000502\n",
      "batch 307 loss: 1.34810 acc: 0.70182 | v_loss: 1.43090 v_acc: 0.68522 |  iteration: 7766 teacher: 1 stage: sketch lr: 0.000501\n",
      "batch 308 loss: 1.24219 acc: 0.70964 | v_loss: 1.17392 v_acc: 0.72168 |  iteration: 7767 teacher: 1 stage: sketch lr: 0.000501\n",
      "batch 309 loss: 1.31160 acc: 0.69499 | v_loss: 1.48083 v_acc: 0.67969 |  iteration: 7768 teacher: 1 stage: sketch lr: 0.000501\n",
      "batch 310 loss: 1.23796 acc: 0.71354 | v_loss: 1.36596 v_acc: 0.69694 |  iteration: 7769 teacher: 1 stage: sketch lr: 0.000501\n",
      "batch 311 loss: 1.33544 acc: 0.68880 | v_loss: 1.35246 v_acc: 0.69141 |  iteration: 7770 teacher: 0 stage: sketch lr: 0.000501\n",
      "batch 312 loss: 1.27694 acc: 0.69922 | v_loss: 1.30072 v_acc: 0.70020 |  iteration: 7771 teacher: 0 stage: sketch lr: 0.000501\n",
      "batch 313 loss: 1.32485 acc: 0.69857 | v_loss: 1.21970 v_acc: 0.70703 |  iteration: 7772 teacher: 1 stage: sketch lr: 0.000501\n",
      "batch 314 loss: 1.35474 acc: 0.69499 | v_loss: 1.26139 v_acc: 0.70573 |  iteration: 7773 teacher: 1 stage: sketch lr: 0.000501\n",
      "batch 315 loss: 1.30321 acc: 0.69792 | v_loss: 1.22342 v_acc: 0.71777 |  iteration: 7774 teacher: 1 stage: sketch lr: 0.000501\n",
      "batch 316 loss: 1.29625 acc: 0.69759 | v_loss: 1.42671 v_acc: 0.68587 |  iteration: 7775 teacher: 0 stage: sketch lr: 0.000501\n",
      "batch 317 loss: 1.33872 acc: 0.69824 | v_loss: 1.30989 v_acc: 0.70117 |  iteration: 7776 teacher: 1 stage: sketch lr: 0.000501\n",
      "batch 318 loss: 1.24560 acc: 0.70150 | v_loss: 1.18729 v_acc: 0.70866 |  iteration: 7777 teacher: 0 stage: sketch lr: 0.000501\n",
      "batch 319 loss: 1.29042 acc: 0.70736 | v_loss: 1.27941 v_acc: 0.70638 |  iteration: 7778 teacher: 0 stage: sketch lr: 0.000501\n",
      "batch 320 loss: 1.31184 acc: 0.70410 | v_loss: 1.19002 v_acc: 0.69922 |  iteration: 7779 teacher: 0 stage: sketch lr: 0.000501\n",
      "batch 321 loss: 1.23176 acc: 0.70768 | v_loss: 1.26320 v_acc: 0.70247 |  iteration: 7780 teacher: 0 stage: sketch lr: 0.000501\n",
      "batch 322 loss: 1.31124 acc: 0.70150 | v_loss: 1.23407 v_acc: 0.71289 |  iteration: 7781 teacher: 1 stage: sketch lr: 0.000501\n",
      "batch 323 loss: 1.30872 acc: 0.70638 | v_loss: 1.17729 v_acc: 0.72038 |  iteration: 7782 teacher: 0 stage: sketch lr: 0.000501\n",
      "batch 324 loss: 1.25878 acc: 0.70410 | v_loss: 1.12630 v_acc: 0.72819 |  iteration: 7783 teacher: 0 stage: sketch lr: 0.000501\n",
      "batch 325 loss: 1.35510 acc: 0.69694 | v_loss: 1.25621 v_acc: 0.71940 |  iteration: 7784 teacher: 1 stage: sketch lr: 0.000501\n",
      "batch 326 loss: 1.26450 acc: 0.70964 | v_loss: 1.24342 v_acc: 0.70605 |  iteration: 7785 teacher: 1 stage: sketch lr: 0.000501\n",
      "batch 327 loss: 1.27720 acc: 0.70638 | v_loss: 1.24875 v_acc: 0.70801 |  iteration: 7786 teacher: 0 stage: sketch lr: 0.000501\n",
      "batch 328 loss: 1.26140 acc: 0.69954 | v_loss: 1.11897 v_acc: 0.71452 |  iteration: 7787 teacher: 1 stage: sketch lr: 0.000501\n",
      "batch 329 loss: 1.30628 acc: 0.69596 | v_loss: 1.23614 v_acc: 0.72754 |  iteration: 7788 teacher: 1 stage: sketch lr: 0.000501\n",
      "batch 330 loss: 1.25816 acc: 0.70540 | v_loss: 1.29277 v_acc: 0.69759 |  iteration: 7789 teacher: 1 stage: sketch lr: 0.000501\n",
      "batch 331 loss: 1.20317 acc: 0.71224 | v_loss: 1.29315 v_acc: 0.72103 |  iteration: 7790 teacher: 1 stage: sketch lr: 0.000501\n",
      "batch 332 loss: 1.22749 acc: 0.70931 | v_loss: 1.15766 v_acc: 0.71908 |  iteration: 7791 teacher: 1 stage: sketch lr: 0.000501\n",
      "batch 333 loss: 1.29140 acc: 0.71419 | v_loss: 1.10197 v_acc: 0.73503 |  iteration: 7792 teacher: 1 stage: sketch lr: 0.000501\n",
      "batch 334 loss: 1.30541 acc: 0.70801 | v_loss: 1.10532 v_acc: 0.72396 |  iteration: 7793 teacher: 1 stage: sketch lr: 0.000501\n",
      "batch 335 loss: 1.26625 acc: 0.70964 | v_loss: 1.19237 v_acc: 0.70638 |  iteration: 7794 teacher: 0 stage: sketch lr: 0.000501\n",
      "batch 336 loss: 1.31077 acc: 0.70117 | v_loss: 1.25319 v_acc: 0.69629 |  iteration: 7795 teacher: 1 stage: sketch lr: 0.000501\n",
      "batch 337 loss: 1.25303 acc: 0.70833 | v_loss: 1.19734 v_acc: 0.71322 |  iteration: 7796 teacher: 0 stage: sketch lr: 0.000501\n",
      "batch 338 loss: 1.23129 acc: 0.71419 | v_loss: 1.31661 v_acc: 0.71582 |  iteration: 7797 teacher: 0 stage: sketch lr: 0.000500\n",
      "batch 339 loss: 1.34053 acc: 0.69661 | v_loss: 1.48260 v_acc: 0.69238 |  iteration: 7798 teacher: 0 stage: sketch lr: 0.000500\n",
      "batch 340 loss: 1.24271 acc: 0.70443 | v_loss: 1.35683 v_acc: 0.69531 |  iteration: 7799 teacher: 0 stage: sketch lr: 0.000500\n",
      "batch 341 loss: 1.29996 acc: 0.70117 | v_loss: 1.18990 v_acc: 0.72168 |  iteration: 7800 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 342 loss: 1.34477 acc: 0.69434 | v_loss: 1.16758 v_acc: 0.70215 |  iteration: 7801 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 343 loss: 1.24996 acc: 0.71191 | v_loss: 1.16040 v_acc: 0.71940 |  iteration: 7802 teacher: 0 stage: sketch lr: 0.000500\n",
      "batch 344 loss: 1.26460 acc: 0.70378 | v_loss: 1.22670 v_acc: 0.70215 |  iteration: 7803 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 345 loss: 1.26196 acc: 0.70247 | v_loss: 1.25294 v_acc: 0.71224 |  iteration: 7804 teacher: 0 stage: sketch lr: 0.000500\n",
      "batch 346 loss: 1.26937 acc: 0.70247 | v_loss: 1.21655 v_acc: 0.72786 |  iteration: 7805 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 347 loss: 1.27929 acc: 0.70801 | v_loss: 1.24639 v_acc: 0.71842 |  iteration: 7806 teacher: 0 stage: sketch lr: 0.000500\n",
      "batch 348 loss: 1.31919 acc: 0.70182 | v_loss: 1.24706 v_acc: 0.70768 |  iteration: 7807 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 349 loss: 1.31839 acc: 0.69824 | v_loss: 1.16354 v_acc: 0.72396 |  iteration: 7808 teacher: 0 stage: sketch lr: 0.000500\n",
      "batch 350 loss: 1.34731 acc: 0.69727 | v_loss: 1.13682 v_acc: 0.71940 |  iteration: 7809 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 351 loss: 1.24309 acc: 0.70964 | v_loss: 1.47040 v_acc: 0.69141 |  iteration: 7810 teacher: 0 stage: sketch lr: 0.000500\n",
      "batch 352 loss: 1.23363 acc: 0.70215 | v_loss: 1.20645 v_acc: 0.70801 |  iteration: 7811 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 353 loss: 1.24539 acc: 0.69759 | v_loss: 1.24424 v_acc: 0.71354 |  iteration: 7812 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 354 loss: 1.24748 acc: 0.70671 | v_loss: 1.21985 v_acc: 0.71973 |  iteration: 7813 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 355 loss: 1.25179 acc: 0.71224 | v_loss: 1.28659 v_acc: 0.70475 |  iteration: 7814 teacher: 0 stage: sketch lr: 0.000500\n",
      "batch 356 loss: 1.27098 acc: 0.70573 | v_loss: 1.12932 v_acc: 0.73210 |  iteration: 7815 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 357 loss: 1.30136 acc: 0.70117 | v_loss: 1.38710 v_acc: 0.71615 |  iteration: 7816 teacher: 0 stage: sketch lr: 0.000500\n",
      "batch 358 loss: 1.27938 acc: 0.70736 | v_loss: 1.17388 v_acc: 0.70150 |  iteration: 7817 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 359 loss: 1.34845 acc: 0.69889 | v_loss: 1.19768 v_acc: 0.70833 |  iteration: 7818 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 360 loss: 1.28444 acc: 0.69596 | v_loss: 1.26476 v_acc: 0.70345 |  iteration: 7819 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 361 loss: 1.28030 acc: 0.70443 | v_loss: 1.28711 v_acc: 0.69564 |  iteration: 7820 teacher: 0 stage: sketch lr: 0.000500\n",
      "batch 362 loss: 1.20599 acc: 0.71322 | v_loss: 1.32976 v_acc: 0.69173 |  iteration: 7821 teacher: 0 stage: sketch lr: 0.000500\n",
      "batch 363 loss: 1.31040 acc: 0.70736 | v_loss: 1.37526 v_acc: 0.70182 |  iteration: 7822 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 364 loss: 1.31918 acc: 0.70182 | v_loss: 1.28609 v_acc: 0.70085 |  iteration: 7823 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 365 loss: 1.37096 acc: 0.69336 | v_loss: 1.19815 v_acc: 0.70638 |  iteration: 7824 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 366 loss: 1.35702 acc: 0.70410 | v_loss: 1.31180 v_acc: 0.70801 |  iteration: 7825 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 367 loss: 1.30836 acc: 0.69792 | v_loss: 1.21217 v_acc: 0.71191 |  iteration: 7826 teacher: 0 stage: sketch lr: 0.000500\n",
      "batch 368 loss: 1.25412 acc: 0.70443 | v_loss: 1.14738 v_acc: 0.72038 |  iteration: 7827 teacher: 0 stage: sketch lr: 0.000500\n",
      "batch 369 loss: 1.30458 acc: 0.70540 | v_loss: 1.13436 v_acc: 0.70736 |  iteration: 7828 teacher: 1 stage: sketch lr: 0.000500\n",
      "batch 370 loss: 1.23784 acc: 0.70996 | v_loss: 1.25075 v_acc: 0.70605 |  iteration: 7829 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 371 loss: 1.31505 acc: 0.69954 | v_loss: 1.32869 v_acc: 0.69629 |  iteration: 7830 teacher: 0 stage: sketch lr: 0.000499\n",
      "batch 372 loss: 1.28750 acc: 0.70703 | v_loss: 1.15346 v_acc: 0.71387 |  iteration: 7831 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 373 loss: 1.27384 acc: 0.71842 | v_loss: 1.20248 v_acc: 0.70312 |  iteration: 7832 teacher: 0 stage: sketch lr: 0.000499\n",
      "batch 374 loss: 1.33322 acc: 0.69857 | v_loss: 1.17938 v_acc: 0.71680 |  iteration: 7833 teacher: 0 stage: sketch lr: 0.000499\n",
      "batch 375 loss: 1.25137 acc: 0.70964 | v_loss: 1.20593 v_acc: 0.70215 |  iteration: 7834 teacher: 0 stage: sketch lr: 0.000499\n",
      "batch 376 loss: 1.28999 acc: 0.70605 | v_loss: 1.09144 v_acc: 0.73340 |  iteration: 7835 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 377 loss: 1.21993 acc: 0.72201 | v_loss: 1.18246 v_acc: 0.71647 |  iteration: 7836 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 378 loss: 1.26426 acc: 0.70964 | v_loss: 1.16265 v_acc: 0.73307 |  iteration: 7837 teacher: 0 stage: sketch lr: 0.000499\n",
      "batch 379 loss: 1.29803 acc: 0.71549 | v_loss: 1.13461 v_acc: 0.71973 |  iteration: 7838 teacher: 0 stage: sketch lr: 0.000499\n",
      "batch 380 loss: 1.28592 acc: 0.70801 | v_loss: 1.21150 v_acc: 0.71582 |  iteration: 7839 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 381 loss: 1.25321 acc: 0.70768 | v_loss: 1.24235 v_acc: 0.71224 |  iteration: 7840 teacher: 0 stage: sketch lr: 0.000499\n",
      "batch 382 loss: 1.40051 acc: 0.69401 | v_loss: 1.21713 v_acc: 0.72428 |  iteration: 7841 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 383 loss: 1.34008 acc: 0.69824 | v_loss: 1.37258 v_acc: 0.70182 |  iteration: 7842 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 384 loss: 1.46546 acc: 0.69434 | v_loss: 1.27103 v_acc: 0.71777 |  iteration: 7843 teacher: 0 stage: sketch lr: 0.000499\n",
      "batch 385 loss: 1.22212 acc: 0.70671 | v_loss: 1.06081 v_acc: 0.74447 |  iteration: 7844 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 386 loss: 1.29894 acc: 0.70573 | v_loss: 1.21154 v_acc: 0.70898 |  iteration: 7845 teacher: 0 stage: sketch lr: 0.000499\n",
      "batch 387 loss: 1.26520 acc: 0.69759 | v_loss: 1.28667 v_acc: 0.69271 |  iteration: 7846 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 388 loss: 1.35536 acc: 0.68945 | v_loss: 1.20811 v_acc: 0.69043 |  iteration: 7847 teacher: 0 stage: sketch lr: 0.000499\n",
      "batch 389 loss: 1.34423 acc: 0.69564 | v_loss: 1.26001 v_acc: 0.70215 |  iteration: 7848 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 390 loss: 1.31959 acc: 0.70443 | v_loss: 1.25725 v_acc: 0.69336 |  iteration: 7849 teacher: 0 stage: sketch lr: 0.000499\n",
      "batch 391 loss: 1.34275 acc: 0.69922 | v_loss: 1.22625 v_acc: 0.71061 |  iteration: 7850 teacher: 0 stage: sketch lr: 0.000499\n",
      "batch 392 loss: 1.23803 acc: 0.70736 | v_loss: 1.27065 v_acc: 0.69499 |  iteration: 7851 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 393 loss: 1.28586 acc: 0.70117 | v_loss: 1.18587 v_acc: 0.71745 |  iteration: 7852 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 394 loss: 1.32657 acc: 0.69727 | v_loss: 1.17989 v_acc: 0.72298 |  iteration: 7853 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 395 loss: 1.26110 acc: 0.70150 | v_loss: 1.24100 v_acc: 0.70117 |  iteration: 7854 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 396 loss: 1.30837 acc: 0.70247 | v_loss: 1.33228 v_acc: 0.70085 |  iteration: 7855 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 397 loss: 1.27350 acc: 0.70508 | v_loss: 1.16209 v_acc: 0.70703 |  iteration: 7856 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 398 loss: 1.24692 acc: 0.71419 | v_loss: 1.40507 v_acc: 0.68880 |  iteration: 7857 teacher: 0 stage: sketch lr: 0.000499\n",
      "batch 399 loss: 1.27387 acc: 0.71452 | v_loss: 1.17078 v_acc: 0.72005 |  iteration: 7858 teacher: 0 stage: sketch lr: 0.000499\n",
      "batch 400 loss: 1.29290 acc: 0.69759 | v_loss: 1.48753 v_acc: 0.67969 |  iteration: 7859 teacher: 1 stage: sketch lr: 0.000499\n",
      "batch 401 loss: 1.15491 acc: 0.71712 | v_loss: 1.37044 v_acc: 0.69661 |  iteration: 7860 teacher: 0 stage: sketch lr: 0.000498\n",
      "batch 402 loss: 1.28308 acc: 0.70768 | v_loss: 1.33146 v_acc: 0.69238 |  iteration: 7861 teacher: 0 stage: sketch lr: 0.000498\n",
      "batch 403 loss: 1.32184 acc: 0.69889 | v_loss: 1.32084 v_acc: 0.69987 |  iteration: 7862 teacher: 0 stage: sketch lr: 0.000498\n",
      "batch 404 loss: 1.35058 acc: 0.69466 | v_loss: 1.21479 v_acc: 0.70638 |  iteration: 7863 teacher: 0 stage: sketch lr: 0.000498\n",
      "batch 405 loss: 1.28131 acc: 0.71094 | v_loss: 1.26769 v_acc: 0.70312 |  iteration: 7864 teacher: 0 stage: sketch lr: 0.000498\n",
      "batch 406 loss: 1.27885 acc: 0.70443 | v_loss: 1.22474 v_acc: 0.71745 |  iteration: 7865 teacher: 0 stage: sketch lr: 0.000498\n",
      "batch 407 loss: 1.29420 acc: 0.70052 | v_loss: 1.44341 v_acc: 0.68066 |  iteration: 7866 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 408 loss: 1.25196 acc: 0.70540 | v_loss: 1.29551 v_acc: 0.71289 |  iteration: 7867 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 409 loss: 1.28236 acc: 0.70215 | v_loss: 1.21227 v_acc: 0.70182 |  iteration: 7868 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 410 loss: 1.30626 acc: 0.70540 | v_loss: 1.28813 v_acc: 0.70085 |  iteration: 7869 teacher: 0 stage: sketch lr: 0.000498\n",
      "batch 411 loss: 1.48401 acc: 0.68229 | v_loss: 1.17881 v_acc: 0.70508 |  iteration: 7870 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 412 loss: 1.25927 acc: 0.70312 | v_loss: 1.25734 v_acc: 0.69629 |  iteration: 7871 teacher: 0 stage: sketch lr: 0.000498\n",
      "batch 413 loss: 1.27285 acc: 0.70345 | v_loss: 1.22423 v_acc: 0.71322 |  iteration: 7872 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 414 loss: 1.23316 acc: 0.70801 | v_loss: 1.18230 v_acc: 0.71647 |  iteration: 7873 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 415 loss: 1.31632 acc: 0.70247 | v_loss: 1.13761 v_acc: 0.72689 |  iteration: 7874 teacher: 0 stage: sketch lr: 0.000498\n",
      "batch 416 loss: 1.28359 acc: 0.69759 | v_loss: 1.24890 v_acc: 0.71712 |  iteration: 7875 teacher: 0 stage: sketch lr: 0.000498\n",
      "batch 417 loss: 1.26559 acc: 0.69954 | v_loss: 1.24588 v_acc: 0.70410 |  iteration: 7876 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 418 loss: 1.20005 acc: 0.71126 | v_loss: 1.25179 v_acc: 0.70833 |  iteration: 7877 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 419 loss: 1.26082 acc: 0.71094 | v_loss: 1.09564 v_acc: 0.72591 |  iteration: 7878 teacher: 0 stage: sketch lr: 0.000498\n",
      "batch 420 loss: 1.28512 acc: 0.70475 | v_loss: 1.24140 v_acc: 0.73112 |  iteration: 7879 teacher: 0 stage: sketch lr: 0.000498\n",
      "batch 421 loss: 1.23710 acc: 0.71908 | v_loss: 1.30354 v_acc: 0.69694 |  iteration: 7880 teacher: 0 stage: sketch lr: 0.000498\n",
      "batch 422 loss: 1.24252 acc: 0.71387 | v_loss: 1.32289 v_acc: 0.72168 |  iteration: 7881 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 423 loss: 1.29635 acc: 0.70410 | v_loss: 1.15911 v_acc: 0.71842 |  iteration: 7882 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 424 loss: 1.41108 acc: 0.70215 | v_loss: 1.10590 v_acc: 0.73828 |  iteration: 7883 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 425 loss: 1.41962 acc: 0.69368 | v_loss: 1.10908 v_acc: 0.71973 |  iteration: 7884 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 426 loss: 1.38297 acc: 0.68685 | v_loss: 1.18004 v_acc: 0.70540 |  iteration: 7885 teacher: 0 stage: sketch lr: 0.000498\n",
      "batch 427 loss: 1.22880 acc: 0.71029 | v_loss: 1.24582 v_acc: 0.69531 |  iteration: 7886 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 428 loss: 1.21573 acc: 0.70736 | v_loss: 1.20931 v_acc: 0.71452 |  iteration: 7887 teacher: 0 stage: sketch lr: 0.000498\n",
      "batch 429 loss: 1.27202 acc: 0.70801 | v_loss: 1.34233 v_acc: 0.70345 |  iteration: 7888 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 430 loss: 1.31322 acc: 0.69531 | v_loss: 1.48349 v_acc: 0.69076 |  iteration: 7889 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 431 loss: 1.40284 acc: 0.69727 | v_loss: 1.35367 v_acc: 0.69792 |  iteration: 7890 teacher: 1 stage: sketch lr: 0.000498\n",
      "batch 432 loss: 1.17482 acc: 0.71387 | v_loss: 1.19685 v_acc: 0.72624 |  iteration: 7891 teacher: 0 stage: sketch lr: 0.000498\n",
      "batch 433 loss: 1.30329 acc: 0.70573 | v_loss: 1.15086 v_acc: 0.70996 |  iteration: 7892 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 434 loss: 1.18181 acc: 0.71549 | v_loss: 1.15997 v_acc: 0.72201 |  iteration: 7893 teacher: 1 stage: sketch lr: 0.000497\n",
      "batch 435 loss: 1.27946 acc: 0.69792 | v_loss: 1.21093 v_acc: 0.70378 |  iteration: 7894 teacher: 1 stage: sketch lr: 0.000497\n",
      "batch 436 loss: 1.24569 acc: 0.71126 | v_loss: 1.25912 v_acc: 0.71810 |  iteration: 7895 teacher: 1 stage: sketch lr: 0.000497\n",
      "batch 437 loss: 1.28294 acc: 0.69954 | v_loss: 1.20824 v_acc: 0.73014 |  iteration: 7896 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 438 loss: 1.31448 acc: 0.71647 | v_loss: 1.23637 v_acc: 0.71973 |  iteration: 7897 teacher: 1 stage: sketch lr: 0.000497\n",
      "batch 439 loss: 1.32222 acc: 0.70052 | v_loss: 1.24518 v_acc: 0.70898 |  iteration: 7898 teacher: 1 stage: sketch lr: 0.000497\n",
      "batch 440 loss: 1.45150 acc: 0.68587 | v_loss: 1.16531 v_acc: 0.72363 |  iteration: 7899 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 441 loss: 1.34557 acc: 0.68880 | v_loss: 1.12934 v_acc: 0.72005 |  iteration: 7900 teacher: 1 stage: sketch lr: 0.000497\n",
      "batch 442 loss: 1.28789 acc: 0.71029 | v_loss: 1.44074 v_acc: 0.69206 |  iteration: 7901 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 443 loss: 1.29882 acc: 0.69564 | v_loss: 1.20519 v_acc: 0.70931 |  iteration: 7902 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 444 loss: 1.26405 acc: 0.70475 | v_loss: 1.23761 v_acc: 0.71094 |  iteration: 7903 teacher: 1 stage: sketch lr: 0.000497\n",
      "batch 445 loss: 1.36804 acc: 0.69303 | v_loss: 1.23869 v_acc: 0.70410 |  iteration: 7904 teacher: 1 stage: sketch lr: 0.000497\n",
      "batch 446 loss: 1.31198 acc: 0.69759 | v_loss: 1.29821 v_acc: 0.69238 |  iteration: 7905 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 447 loss: 1.30488 acc: 0.69694 | v_loss: 1.15669 v_acc: 0.72363 |  iteration: 7906 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 448 loss: 1.25451 acc: 0.70280 | v_loss: 1.38069 v_acc: 0.70736 |  iteration: 7907 teacher: 1 stage: sketch lr: 0.000497\n",
      "batch 449 loss: 1.36254 acc: 0.69922 | v_loss: 1.20494 v_acc: 0.69564 |  iteration: 7908 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 450 loss: 1.32857 acc: 0.69954 | v_loss: 1.21764 v_acc: 0.69922 |  iteration: 7909 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 451 loss: 1.31221 acc: 0.70247 | v_loss: 1.25874 v_acc: 0.70215 |  iteration: 7910 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 452 loss: 1.34099 acc: 0.69271 | v_loss: 1.27084 v_acc: 0.70280 |  iteration: 7911 teacher: 1 stage: sketch lr: 0.000497\n",
      "batch 453 loss: 1.33304 acc: 0.70410 | v_loss: 1.33025 v_acc: 0.69954 |  iteration: 7912 teacher: 1 stage: sketch lr: 0.000497\n",
      "batch 454 loss: 1.28485 acc: 0.70085 | v_loss: 1.36741 v_acc: 0.70768 |  iteration: 7913 teacher: 1 stage: sketch lr: 0.000497\n",
      "batch 455 loss: 1.34920 acc: 0.70508 | v_loss: 1.28809 v_acc: 0.70182 |  iteration: 7914 teacher: 1 stage: sketch lr: 0.000497\n",
      "batch 456 loss: 1.26619 acc: 0.70052 | v_loss: 1.20453 v_acc: 0.70996 |  iteration: 7915 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 457 loss: 1.25997 acc: 0.71387 | v_loss: 1.30525 v_acc: 0.70703 |  iteration: 7916 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 458 loss: 1.30676 acc: 0.70540 | v_loss: 1.20418 v_acc: 0.71517 |  iteration: 7917 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 459 loss: 1.26638 acc: 0.71745 | v_loss: 1.15873 v_acc: 0.72493 |  iteration: 7918 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 460 loss: 1.25701 acc: 0.69987 | v_loss: 1.13158 v_acc: 0.70671 |  iteration: 7919 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 461 loss: 1.34893 acc: 0.70150 | v_loss: 1.27101 v_acc: 0.70150 |  iteration: 7920 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 462 loss: 1.23751 acc: 0.71159 | v_loss: 1.34708 v_acc: 0.69987 |  iteration: 7921 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 463 loss: 1.34602 acc: 0.70605 | v_loss: 1.19839 v_acc: 0.70540 |  iteration: 7922 teacher: 0 stage: sketch lr: 0.000497\n",
      "batch 464 loss: 1.21159 acc: 0.71712 | v_loss: 1.20166 v_acc: 0.69727 |  iteration: 7923 teacher: 1 stage: sketch lr: 0.000497\n",
      "batch 465 loss: 1.27500 acc: 0.69922 | v_loss: 1.17918 v_acc: 0.71191 |  iteration: 7924 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 466 loss: 1.26278 acc: 0.70573 | v_loss: 1.18990 v_acc: 0.70736 |  iteration: 7925 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 467 loss: 1.26237 acc: 0.69922 | v_loss: 1.08529 v_acc: 0.73991 |  iteration: 7926 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 468 loss: 1.28130 acc: 0.69987 | v_loss: 1.17102 v_acc: 0.72201 |  iteration: 7927 teacher: 0 stage: sketch lr: 0.000496\n",
      "batch 469 loss: 1.28664 acc: 0.71354 | v_loss: 1.16992 v_acc: 0.72559 |  iteration: 7928 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 470 loss: 1.34730 acc: 0.69629 | v_loss: 1.13616 v_acc: 0.72331 |  iteration: 7929 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 471 loss: 1.34041 acc: 0.69368 | v_loss: 1.21006 v_acc: 0.71159 |  iteration: 7930 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 472 loss: 1.24677 acc: 0.70052 | v_loss: 1.23617 v_acc: 0.70671 |  iteration: 7931 teacher: 0 stage: sketch lr: 0.000496\n",
      "batch 473 loss: 1.35725 acc: 0.69531 | v_loss: 1.21926 v_acc: 0.71777 |  iteration: 7932 teacher: 0 stage: sketch lr: 0.000496\n",
      "batch 474 loss: 1.31002 acc: 0.70247 | v_loss: 1.38543 v_acc: 0.69727 |  iteration: 7933 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 475 loss: 1.30647 acc: 0.69271 | v_loss: 1.27424 v_acc: 0.71517 |  iteration: 7934 teacher: 0 stage: sketch lr: 0.000496\n",
      "batch 476 loss: 1.31896 acc: 0.70117 | v_loss: 1.06190 v_acc: 0.74382 |  iteration: 7935 teacher: 0 stage: sketch lr: 0.000496\n",
      "batch 477 loss: 1.40886 acc: 0.69010 | v_loss: 1.20175 v_acc: 0.70964 |  iteration: 7936 teacher: 0 stage: sketch lr: 0.000496\n",
      "batch 478 loss: 1.37438 acc: 0.70085 | v_loss: 1.29430 v_acc: 0.69987 |  iteration: 7937 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 479 loss: 1.31405 acc: 0.69596 | v_loss: 1.20412 v_acc: 0.70638 |  iteration: 7938 teacher: 0 stage: sketch lr: 0.000496\n",
      "batch 480 loss: 1.30167 acc: 0.70443 | v_loss: 1.25756 v_acc: 0.71354 |  iteration: 7939 teacher: 0 stage: sketch lr: 0.000496\n",
      "batch 481 loss: 1.35120 acc: 0.69727 | v_loss: 1.25316 v_acc: 0.69531 |  iteration: 7940 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 482 loss: 1.28648 acc: 0.70410 | v_loss: 1.21098 v_acc: 0.71647 |  iteration: 7941 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 483 loss: 1.49796 acc: 0.68132 | v_loss: 1.25645 v_acc: 0.70020 |  iteration: 7942 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 484 loss: 1.31463 acc: 0.70768 | v_loss: 1.20100 v_acc: 0.71712 |  iteration: 7943 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 485 loss: 1.23838 acc: 0.71159 | v_loss: 1.18278 v_acc: 0.72461 |  iteration: 7944 teacher: 0 stage: sketch lr: 0.000496\n",
      "batch 486 loss: 1.29391 acc: 0.70866 | v_loss: 1.25122 v_acc: 0.70150 |  iteration: 7945 teacher: 0 stage: sketch lr: 0.000496\n",
      "batch 487 loss: 1.26094 acc: 0.70801 | v_loss: 1.34323 v_acc: 0.69922 |  iteration: 7946 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 488 loss: 1.26645 acc: 0.70768 | v_loss: 1.16976 v_acc: 0.70703 |  iteration: 7947 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 489 loss: 1.35179 acc: 0.69792 | v_loss: 1.40526 v_acc: 0.68880 |  iteration: 7948 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 490 loss: 1.30181 acc: 0.70768 | v_loss: 1.17069 v_acc: 0.72103 |  iteration: 7949 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 491 loss: 1.25593 acc: 0.71159 | v_loss: 1.48911 v_acc: 0.68620 |  iteration: 7950 teacher: 0 stage: sketch lr: 0.000496\n",
      "batch 492 loss: 1.28924 acc: 0.70247 | v_loss: 1.35392 v_acc: 0.69987 |  iteration: 7951 teacher: 0 stage: sketch lr: 0.000496\n",
      "batch 493 loss: 1.31093 acc: 0.70215 | v_loss: 1.32913 v_acc: 0.68913 |  iteration: 7952 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 494 loss: 1.35268 acc: 0.70215 | v_loss: 1.30201 v_acc: 0.69857 |  iteration: 7953 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 495 loss: 1.42813 acc: 0.70117 | v_loss: 1.22346 v_acc: 0.70378 |  iteration: 7954 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 496 loss: 1.25777 acc: 0.70964 | v_loss: 1.25524 v_acc: 0.70378 |  iteration: 7955 teacher: 1 stage: sketch lr: 0.000496\n",
      "batch 497 loss: 1.28784 acc: 0.71159 | v_loss: 1.21603 v_acc: 0.71973 |  iteration: 7956 teacher: 1 stage: sketch lr: 0.000495\n",
      "batch 498 loss: 1.30393 acc: 0.69824 | v_loss: 1.42478 v_acc: 0.68555 |  iteration: 7957 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 499 loss: 1.32648 acc: 0.69889 | v_loss: 1.28701 v_acc: 0.71191 |  iteration: 7958 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 500 loss: 1.30291 acc: 0.70182 | v_loss: 1.19375 v_acc: 0.70182 |  iteration: 7959 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 501 loss: 1.26791 acc: 0.70866 | v_loss: 1.27754 v_acc: 0.70410 |  iteration: 7960 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 502 loss: 1.37892 acc: 0.70443 | v_loss: 1.17518 v_acc: 0.70378 |  iteration: 7961 teacher: 1 stage: sketch lr: 0.000495\n",
      "batch 503 loss: 1.20502 acc: 0.71484 | v_loss: 1.25982 v_acc: 0.69466 |  iteration: 7962 teacher: 1 stage: sketch lr: 0.000495\n",
      "batch 504 loss: 1.28672 acc: 0.70215 | v_loss: 1.22821 v_acc: 0.71354 |  iteration: 7963 teacher: 1 stage: sketch lr: 0.000495\n",
      "batch 505 loss: 1.29203 acc: 0.69922 | v_loss: 1.18090 v_acc: 0.71973 |  iteration: 7964 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 506 loss: 1.41789 acc: 0.69206 | v_loss: 1.13832 v_acc: 0.72331 |  iteration: 7965 teacher: 1 stage: sketch lr: 0.000495\n",
      "batch 507 loss: 1.26670 acc: 0.70638 | v_loss: 1.24860 v_acc: 0.71647 |  iteration: 7966 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 508 loss: 1.29340 acc: 0.70964 | v_loss: 1.25018 v_acc: 0.70150 |  iteration: 7967 teacher: 1 stage: sketch lr: 0.000495\n",
      "batch 509 loss: 1.25397 acc: 0.70996 | v_loss: 1.25198 v_acc: 0.70964 |  iteration: 7968 teacher: 1 stage: sketch lr: 0.000495\n",
      "batch 510 loss: 1.28263 acc: 0.70378 | v_loss: 1.11030 v_acc: 0.72266 |  iteration: 7969 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 511 loss: 1.33952 acc: 0.69824 | v_loss: 1.24937 v_acc: 0.72819 |  iteration: 7970 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 512 loss: 1.27538 acc: 0.70312 | v_loss: 1.28957 v_acc: 0.69792 |  iteration: 7971 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 513 loss: 1.25832 acc: 0.69954 | v_loss: 1.28378 v_acc: 0.71842 |  iteration: 7972 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 514 loss: 1.28839 acc: 0.69987 | v_loss: 1.16447 v_acc: 0.71810 |  iteration: 7973 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 515 loss: 1.36155 acc: 0.70215 | v_loss: 1.11587 v_acc: 0.73535 |  iteration: 7974 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 516 loss: 1.26691 acc: 0.70605 | v_loss: 1.10820 v_acc: 0.72559 |  iteration: 7975 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 517 loss: 1.37551 acc: 0.69271 | v_loss: 1.19508 v_acc: 0.70703 |  iteration: 7976 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 518 loss: 1.27233 acc: 0.70020 | v_loss: 1.24599 v_acc: 0.69466 |  iteration: 7977 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 519 loss: 1.32514 acc: 0.69759 | v_loss: 1.19777 v_acc: 0.71484 |  iteration: 7978 teacher: 1 stage: sketch lr: 0.000495\n",
      "batch 520 loss: 1.24495 acc: 0.71159 | v_loss: 1.29936 v_acc: 0.72949 |  iteration: 7979 teacher: 1 stage: sketch lr: 0.000495\n",
      "batch 521 loss: 1.33916 acc: 0.70052 | v_loss: 1.45939 v_acc: 0.69466 |  iteration: 7980 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 522 loss: 1.36811 acc: 0.70182 | v_loss: 1.34928 v_acc: 0.70117 |  iteration: 7981 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 523 loss: 1.24507 acc: 0.70150 | v_loss: 1.20089 v_acc: 0.71745 |  iteration: 7982 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 524 loss: 1.28855 acc: 0.70508 | v_loss: 1.15788 v_acc: 0.70638 |  iteration: 7983 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 525 loss: 1.28455 acc: 0.70182 | v_loss: 1.15345 v_acc: 0.72070 |  iteration: 7984 teacher: 1 stage: sketch lr: 0.000495\n",
      "batch 526 loss: 1.27930 acc: 0.69661 | v_loss: 1.22041 v_acc: 0.70410 |  iteration: 7985 teacher: 1 stage: sketch lr: 0.000495\n",
      "batch 527 loss: 1.22743 acc: 0.71647 | v_loss: 1.25276 v_acc: 0.72103 |  iteration: 7986 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 528 loss: 1.20438 acc: 0.71322 | v_loss: 1.20759 v_acc: 0.72949 |  iteration: 7987 teacher: 0 stage: sketch lr: 0.000495\n",
      "batch 529 loss: 1.28296 acc: 0.70768 | v_loss: 1.23840 v_acc: 0.72396 |  iteration: 7988 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 530 loss: 1.32604 acc: 0.70150 | v_loss: 1.24165 v_acc: 0.71159 |  iteration: 7989 teacher: 1 stage: sketch lr: 0.000494\n",
      "batch 531 loss: 1.21745 acc: 0.71484 | v_loss: 1.15623 v_acc: 0.72624 |  iteration: 7990 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 532 loss: 1.27322 acc: 0.70801 | v_loss: 1.13120 v_acc: 0.71842 |  iteration: 7991 teacher: 1 stage: sketch lr: 0.000494\n",
      "batch 533 loss: 1.34930 acc: 0.69922 | v_loss: 1.42254 v_acc: 0.69271 |  iteration: 7992 teacher: 1 stage: sketch lr: 0.000494\n",
      "batch 534 loss: 1.33451 acc: 0.69434 | v_loss: 1.20277 v_acc: 0.70736 |  iteration: 7993 teacher: 1 stage: sketch lr: 0.000494\n",
      "batch 535 loss: 1.32012 acc: 0.70117 | v_loss: 1.24049 v_acc: 0.71354 |  iteration: 7994 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 536 loss: 1.25923 acc: 0.72135 | v_loss: 1.22569 v_acc: 0.72201 |  iteration: 7995 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 537 loss: 1.35390 acc: 0.69434 | v_loss: 1.28235 v_acc: 0.70475 |  iteration: 7996 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 538 loss: 1.25653 acc: 0.69954 | v_loss: 1.14533 v_acc: 0.73210 |  iteration: 7997 teacher: 1 stage: sketch lr: 0.000494\n",
      "batch 539 loss: 1.32880 acc: 0.70182 | v_loss: 1.37756 v_acc: 0.71322 |  iteration: 7998 teacher: 1 stage: sketch lr: 0.000494\n",
      "batch 540 loss: 1.38858 acc: 0.69531 | v_loss: 1.18978 v_acc: 0.69531 |  iteration: 7999 teacher: 1 stage: sketch lr: 0.000494\n",
      "batch 541 loss: 1.40575 acc: 0.69043 | v_loss: 1.20296 v_acc: 0.70443 |  iteration: 8000 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 542 loss: 1.27642 acc: 0.70052 | v_loss: 1.26406 v_acc: 0.70117 |  iteration: 8001 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 543 loss: 1.24937 acc: 0.71582 | v_loss: 1.27815 v_acc: 0.69954 |  iteration: 8002 teacher: 1 stage: sketch lr: 0.000494\n",
      "batch 544 loss: 1.27597 acc: 0.70345 | v_loss: 1.33115 v_acc: 0.69661 |  iteration: 8003 teacher: 1 stage: sketch lr: 0.000494\n",
      "batch 545 loss: 1.25095 acc: 0.71419 | v_loss: 1.36815 v_acc: 0.70768 |  iteration: 8004 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 546 loss: 1.30526 acc: 0.70312 | v_loss: 1.27717 v_acc: 0.69759 |  iteration: 8005 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 547 loss: 1.28096 acc: 0.70410 | v_loss: 1.19185 v_acc: 0.71094 |  iteration: 8006 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 548 loss: 1.32732 acc: 0.70150 | v_loss: 1.32556 v_acc: 0.70671 |  iteration: 8007 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 549 loss: 1.30157 acc: 0.70410 | v_loss: 1.22352 v_acc: 0.71777 |  iteration: 8008 teacher: 1 stage: sketch lr: 0.000494\n",
      "batch 550 loss: 1.28317 acc: 0.70117 | v_loss: 1.13934 v_acc: 0.72331 |  iteration: 8009 teacher: 1 stage: sketch lr: 0.000494\n",
      "batch 551 loss: 1.32790 acc: 0.69922 | v_loss: 1.13041 v_acc: 0.71484 |  iteration: 8010 teacher: 1 stage: sketch lr: 0.000494\n",
      "batch 552 loss: 1.28909 acc: 0.71647 | v_loss: 1.26106 v_acc: 0.70182 |  iteration: 8011 teacher: 1 stage: sketch lr: 0.000494\n",
      "batch 553 loss: 1.25475 acc: 0.70866 | v_loss: 1.34014 v_acc: 0.69661 |  iteration: 8012 teacher: 1 stage: sketch lr: 0.000494\n",
      "batch 554 loss: 1.25979 acc: 0.70573 | v_loss: 1.17857 v_acc: 0.70508 |  iteration: 8013 teacher: 1 stage: sketch lr: 0.000494\n",
      "batch 555 loss: 1.34640 acc: 0.70182 | v_loss: 1.20627 v_acc: 0.69596 |  iteration: 8014 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 556 loss: 1.22565 acc: 0.71354 | v_loss: 1.18977 v_acc: 0.70801 |  iteration: 8015 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 557 loss: 1.32022 acc: 0.70833 | v_loss: 1.20604 v_acc: 0.70345 |  iteration: 8016 teacher: 1 stage: sketch lr: 0.000494\n",
      "batch 558 loss: 1.23805 acc: 0.70605 | v_loss: 1.06296 v_acc: 0.73600 |  iteration: 8017 teacher: 1 stage: sketch lr: 0.000494\n",
      "batch 559 loss: 1.28496 acc: 0.70378 | v_loss: 1.17965 v_acc: 0.71647 |  iteration: 8018 teacher: 0 stage: sketch lr: 0.000494\n",
      "batch 560 loss: 1.31636 acc: 0.69987 | v_loss: 1.12052 v_acc: 0.73405 |  iteration: 8019 teacher: 1 stage: sketch lr: 0.000494\n",
      "batch 561 loss: 1.32326 acc: 0.69857 | v_loss: 1.12061 v_acc: 0.72038 |  iteration: 8020 teacher: 0 stage: sketch lr: 0.000493\n",
      "batch 562 loss: 1.32844 acc: 0.69596 | v_loss: 1.19724 v_acc: 0.71842 |  iteration: 8021 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 563 loss: 1.28772 acc: 0.70378 | v_loss: 1.21992 v_acc: 0.71908 |  iteration: 8022 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 564 loss: 1.29562 acc: 0.70671 | v_loss: 1.19169 v_acc: 0.72233 |  iteration: 8023 teacher: 0 stage: sketch lr: 0.000493\n",
      "batch 565 loss: 1.34767 acc: 0.69857 | v_loss: 1.38565 v_acc: 0.69629 |  iteration: 8024 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 566 loss: 1.30095 acc: 0.69987 | v_loss: 1.25845 v_acc: 0.72005 |  iteration: 8025 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 567 loss: 1.32579 acc: 0.70345 | v_loss: 1.06550 v_acc: 0.74544 |  iteration: 8026 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 568 loss: 1.30218 acc: 0.69857 | v_loss: 1.20988 v_acc: 0.70540 |  iteration: 8027 teacher: 0 stage: sketch lr: 0.000493\n",
      "batch 569 loss: 1.32164 acc: 0.70410 | v_loss: 1.30645 v_acc: 0.69368 |  iteration: 8028 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 570 loss: 1.27515 acc: 0.70638 | v_loss: 1.18476 v_acc: 0.70312 |  iteration: 8029 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 571 loss: 1.35732 acc: 0.69564 | v_loss: 1.26242 v_acc: 0.71257 |  iteration: 8030 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 572 loss: 1.35831 acc: 0.69238 | v_loss: 1.26952 v_acc: 0.69368 |  iteration: 8031 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 573 loss: 1.27976 acc: 0.70671 | v_loss: 1.21043 v_acc: 0.71842 |  iteration: 8032 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 574 loss: 1.27945 acc: 0.70703 | v_loss: 1.25917 v_acc: 0.70247 |  iteration: 8033 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 575 loss: 1.36868 acc: 0.69954 | v_loss: 1.18228 v_acc: 0.72005 |  iteration: 8034 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 576 loss: 1.20634 acc: 0.71973 | v_loss: 1.17635 v_acc: 0.72786 |  iteration: 8035 teacher: 0 stage: sketch lr: 0.000493\n",
      "batch 577 loss: 1.29405 acc: 0.71289 | v_loss: 1.23722 v_acc: 0.70215 |  iteration: 8036 teacher: 0 stage: sketch lr: 0.000493\n",
      "batch 578 loss: 1.35053 acc: 0.69922 | v_loss: 1.36885 v_acc: 0.69987 |  iteration: 8037 teacher: 0 stage: sketch lr: 0.000493\n",
      "batch 579 loss: 1.34306 acc: 0.70085 | v_loss: 1.17571 v_acc: 0.70703 |  iteration: 8038 teacher: 0 stage: sketch lr: 0.000493\n",
      "batch 580 loss: 1.27196 acc: 0.70052 | v_loss: 1.41256 v_acc: 0.68750 |  iteration: 8039 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 581 loss: 1.20592 acc: 0.72201 | v_loss: 1.16173 v_acc: 0.72656 |  iteration: 8040 teacher: 0 stage: sketch lr: 0.000493\n",
      "batch 582 loss: 1.35668 acc: 0.69889 | v_loss: 1.47989 v_acc: 0.68620 |  iteration: 8041 teacher: 0 stage: sketch lr: 0.000493\n",
      "batch 583 loss: 1.25196 acc: 0.70605 | v_loss: 1.35462 v_acc: 0.69889 |  iteration: 8042 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 584 loss: 1.29021 acc: 0.70671 | v_loss: 1.33374 v_acc: 0.68978 |  iteration: 8043 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 585 loss: 1.25256 acc: 0.71354 | v_loss: 1.30211 v_acc: 0.69792 |  iteration: 8044 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 586 loss: 1.37132 acc: 0.70280 | v_loss: 1.23484 v_acc: 0.70378 |  iteration: 8045 teacher: 0 stage: sketch lr: 0.000493\n",
      "batch 587 loss: 1.27933 acc: 0.71842 | v_loss: 1.25400 v_acc: 0.70215 |  iteration: 8046 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 588 loss: 1.22747 acc: 0.71191 | v_loss: 1.20692 v_acc: 0.71615 |  iteration: 8047 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 589 loss: 1.32186 acc: 0.70703 | v_loss: 1.41302 v_acc: 0.68750 |  iteration: 8048 teacher: 0 stage: sketch lr: 0.000493\n",
      "batch 590 loss: 1.36234 acc: 0.69401 | v_loss: 1.28355 v_acc: 0.70443 |  iteration: 8049 teacher: 0 stage: sketch lr: 0.000493\n",
      "batch 591 loss: 1.41861 acc: 0.69173 | v_loss: 1.23161 v_acc: 0.70898 |  iteration: 8050 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 592 loss: 1.23739 acc: 0.71452 | v_loss: 1.26473 v_acc: 0.71582 |  iteration: 8051 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 593 loss: 1.33497 acc: 0.70540 | v_loss: 1.16483 v_acc: 0.70443 |  iteration: 8052 teacher: 1 stage: sketch lr: 0.000493\n",
      "batch 594 loss: 1.30164 acc: 0.69531 | v_loss: 1.25296 v_acc: 0.69727 |  iteration: 8053 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 595 loss: 1.27137 acc: 0.70150 | v_loss: 1.22453 v_acc: 0.71322 |  iteration: 8054 teacher: 1 stage: sketch lr: 0.000492\n",
      "batch 596 loss: 1.27488 acc: 0.71094 | v_loss: 1.17681 v_acc: 0.72070 |  iteration: 8055 teacher: 1 stage: sketch lr: 0.000492\n",
      "batch 597 loss: 1.22856 acc: 0.71061 | v_loss: 1.13104 v_acc: 0.72819 |  iteration: 8056 teacher: 1 stage: sketch lr: 0.000492\n",
      "batch 598 loss: 1.24950 acc: 0.72005 | v_loss: 1.25072 v_acc: 0.71940 |  iteration: 8057 teacher: 1 stage: sketch lr: 0.000492\n",
      "batch 599 loss: 1.26295 acc: 0.70638 | v_loss: 1.24511 v_acc: 0.70573 |  iteration: 8058 teacher: 1 stage: sketch lr: 0.000492\n",
      "batch 600 loss: 1.18593 acc: 0.71875 | v_loss: 1.24645 v_acc: 0.70996 |  iteration: 8059 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 601 loss: 1.34966 acc: 0.69661 | v_loss: 1.11284 v_acc: 0.71484 |  iteration: 8060 teacher: 1 stage: sketch lr: 0.000492\n",
      "batch 602 loss: 1.29664 acc: 0.70312 | v_loss: 1.23623 v_acc: 0.72884 |  iteration: 8061 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 603 loss: 1.14199 acc: 0.72070 | v_loss: 1.29431 v_acc: 0.69922 |  iteration: 8062 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 604 loss: 1.27901 acc: 0.70671 | v_loss: 1.29532 v_acc: 0.72103 |  iteration: 8063 teacher: 1 stage: sketch lr: 0.000492\n",
      "batch 605 loss: 1.27277 acc: 0.70703 | v_loss: 1.15338 v_acc: 0.72135 |  iteration: 8064 teacher: 1 stage: sketch lr: 0.000492\n",
      "batch 606 loss: 1.28580 acc: 0.70736 | v_loss: 1.09697 v_acc: 0.73926 |  iteration: 8065 teacher: 1 stage: sketch lr: 0.000492\n",
      "batch 607 loss: 1.27278 acc: 0.70866 | v_loss: 1.10380 v_acc: 0.72689 |  iteration: 8066 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 608 loss: 1.28961 acc: 0.71094 | v_loss: 1.18200 v_acc: 0.70638 |  iteration: 8067 teacher: 1 stage: sketch lr: 0.000492\n",
      "batch 609 loss: 1.23363 acc: 0.70964 | v_loss: 1.24632 v_acc: 0.69759 |  iteration: 8068 teacher: 1 stage: sketch lr: 0.000492\n",
      "batch 610 loss: 1.28612 acc: 0.71126 | v_loss: 1.18986 v_acc: 0.71452 |  iteration: 8069 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 611 loss: 1.23054 acc: 0.71224 | v_loss: 1.32640 v_acc: 0.70378 |  iteration: 8070 teacher: 1 stage: sketch lr: 0.000492\n",
      "batch 612 loss: 1.31587 acc: 0.70443 | v_loss: 1.47937 v_acc: 0.69043 |  iteration: 8071 teacher: 1 stage: sketch lr: 0.000492\n",
      "batch 613 loss: 1.31834 acc: 0.70573 | v_loss: 1.35467 v_acc: 0.69596 |  iteration: 8072 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 614 loss: 1.30540 acc: 0.70247 | v_loss: 1.19260 v_acc: 0.72103 |  iteration: 8073 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 615 loss: 1.28220 acc: 0.70931 | v_loss: 1.16058 v_acc: 0.70508 |  iteration: 8074 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 616 loss: 1.21908 acc: 0.71354 | v_loss: 1.16288 v_acc: 0.72266 |  iteration: 8075 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 617 loss: 1.36778 acc: 0.69629 | v_loss: 1.23487 v_acc: 0.69889 |  iteration: 8076 teacher: 1 stage: sketch lr: 0.000492\n",
      "batch 618 loss: 1.22854 acc: 0.71094 | v_loss: 1.25262 v_acc: 0.71224 |  iteration: 8077 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 619 loss: 1.36794 acc: 0.69857 | v_loss: 1.21183 v_acc: 0.72754 |  iteration: 8078 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 620 loss: 1.26344 acc: 0.71257 | v_loss: 1.23809 v_acc: 0.71647 |  iteration: 8079 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 621 loss: 1.27320 acc: 0.70378 | v_loss: 1.24121 v_acc: 0.70508 |  iteration: 8080 teacher: 1 stage: sketch lr: 0.000492\n",
      "batch 622 loss: 1.23736 acc: 0.71387 | v_loss: 1.15999 v_acc: 0.72298 |  iteration: 8081 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 623 loss: 1.30059 acc: 0.71257 | v_loss: 1.12518 v_acc: 0.72135 |  iteration: 8082 teacher: 1 stage: sketch lr: 0.000492\n",
      "batch 624 loss: 1.32719 acc: 0.69108 | v_loss: 1.46057 v_acc: 0.69368 |  iteration: 8083 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 625 loss: 1.27602 acc: 0.69694 | v_loss: 1.19594 v_acc: 0.71452 |  iteration: 8084 teacher: 1 stage: sketch lr: 0.000492\n",
      "batch 626 loss: 1.27059 acc: 0.70866 | v_loss: 1.22544 v_acc: 0.71777 |  iteration: 8085 teacher: 0 stage: sketch lr: 0.000492\n",
      "batch 627 loss: 1.35097 acc: 0.69922 | v_loss: 1.22088 v_acc: 0.71484 |  iteration: 8086 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 628 loss: 1.29917 acc: 0.71094 | v_loss: 1.28511 v_acc: 0.70540 |  iteration: 8087 teacher: 1 stage: sketch lr: 0.000491\n",
      "batch 629 loss: 1.30225 acc: 0.69238 | v_loss: 1.13636 v_acc: 0.73047 |  iteration: 8088 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 630 loss: 1.27364 acc: 0.70117 | v_loss: 1.37204 v_acc: 0.71484 |  iteration: 8089 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 631 loss: 1.27072 acc: 0.70182 | v_loss: 1.19169 v_acc: 0.70312 |  iteration: 8090 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 632 loss: 1.33032 acc: 0.69629 | v_loss: 1.20832 v_acc: 0.70345 |  iteration: 8091 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 633 loss: 1.32836 acc: 0.69727 | v_loss: 1.25999 v_acc: 0.70508 |  iteration: 8092 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 634 loss: 1.35660 acc: 0.69043 | v_loss: 1.28276 v_acc: 0.70247 |  iteration: 8093 teacher: 1 stage: sketch lr: 0.000491\n",
      "batch 635 loss: 1.27803 acc: 0.70605 | v_loss: 1.33784 v_acc: 0.68717 |  iteration: 8094 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 636 loss: 1.32527 acc: 0.69889 | v_loss: 1.37047 v_acc: 0.70150 |  iteration: 8095 teacher: 1 stage: sketch lr: 0.000491\n",
      "batch 637 loss: 1.29969 acc: 0.70736 | v_loss: 1.28749 v_acc: 0.70443 |  iteration: 8096 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 638 loss: 1.22717 acc: 0.70898 | v_loss: 1.20863 v_acc: 0.70768 |  iteration: 8097 teacher: 1 stage: sketch lr: 0.000491\n",
      "batch 639 loss: 1.29121 acc: 0.70247 | v_loss: 1.30519 v_acc: 0.70898 |  iteration: 8098 teacher: 1 stage: sketch lr: 0.000491\n",
      "batch 640 loss: 1.22640 acc: 0.70345 | v_loss: 1.21156 v_acc: 0.71257 |  iteration: 8099 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 641 loss: 1.30561 acc: 0.70443 | v_loss: 1.13812 v_acc: 0.72266 |  iteration: 8100 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 642 loss: 1.24450 acc: 0.71224 | v_loss: 1.12440 v_acc: 0.71615 |  iteration: 8101 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 643 loss: 1.25007 acc: 0.71615 | v_loss: 1.25118 v_acc: 0.71126 |  iteration: 8102 teacher: 1 stage: sketch lr: 0.000491\n",
      "batch 644 loss: 1.22547 acc: 0.71582 | v_loss: 1.34797 v_acc: 0.69954 |  iteration: 8103 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 645 loss: 1.23196 acc: 0.70996 | v_loss: 1.17721 v_acc: 0.71484 |  iteration: 8104 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 646 loss: 1.28632 acc: 0.70117 | v_loss: 1.19758 v_acc: 0.70312 |  iteration: 8105 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 647 loss: 1.25273 acc: 0.70898 | v_loss: 1.17476 v_acc: 0.71680 |  iteration: 8106 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 648 loss: 1.28894 acc: 0.69596 | v_loss: 1.18114 v_acc: 0.70671 |  iteration: 8107 teacher: 1 stage: sketch lr: 0.000491\n",
      "batch 649 loss: 1.27779 acc: 0.70931 | v_loss: 1.08972 v_acc: 0.73568 |  iteration: 8108 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 650 loss: 1.21550 acc: 0.70931 | v_loss: 1.16524 v_acc: 0.72461 |  iteration: 8109 teacher: 1 stage: sketch lr: 0.000491\n",
      "batch 651 loss: 1.21086 acc: 0.71224 | v_loss: 1.16841 v_acc: 0.72689 |  iteration: 8110 teacher: 1 stage: sketch lr: 0.000491\n",
      "batch 652 loss: 1.22862 acc: 0.69596 | v_loss: 1.12211 v_acc: 0.72852 |  iteration: 8111 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 653 loss: 1.21591 acc: 0.71680 | v_loss: 1.20128 v_acc: 0.72103 |  iteration: 8112 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 654 loss: 1.25951 acc: 0.70931 | v_loss: 1.24468 v_acc: 0.71224 |  iteration: 8113 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 655 loss: 1.26799 acc: 0.70573 | v_loss: 1.20780 v_acc: 0.72038 |  iteration: 8114 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 656 loss: 1.30176 acc: 0.70312 | v_loss: 1.38277 v_acc: 0.69661 |  iteration: 8115 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 657 loss: 1.32266 acc: 0.70280 | v_loss: 1.26908 v_acc: 0.71745 |  iteration: 8116 teacher: 1 stage: sketch lr: 0.000491\n",
      "batch 658 loss: 1.24726 acc: 0.70280 | v_loss: 1.06804 v_acc: 0.74382 |  iteration: 8117 teacher: 1 stage: sketch lr: 0.000491\n",
      "batch 659 loss: 1.34520 acc: 0.71484 | v_loss: 1.23344 v_acc: 0.70182 |  iteration: 8118 teacher: 0 stage: sketch lr: 0.000491\n",
      "batch 660 loss: 1.27693 acc: 0.71159 | v_loss: 1.28140 v_acc: 0.70898 |  iteration: 8119 teacher: 0 stage: sketch lr: 0.000490\n",
      "batch 661 loss: 1.25506 acc: 0.70020 | v_loss: 1.20912 v_acc: 0.73177 |  iteration: 8120 teacher: 1 stage: sketch lr: 0.000490\n",
      "batch 662 loss: 1.28225 acc: 0.71484 | v_loss: 1.24859 v_acc: 0.72103 |  iteration: 8121 teacher: 0 stage: sketch lr: 0.000490\n",
      "batch 663 loss: 1.23687 acc: 0.71354 | v_loss: 1.25399 v_acc: 0.69108 |  iteration: 8122 teacher: 1 stage: sketch lr: 0.000490\n",
      "batch 664 loss: 1.31080 acc: 0.70345 | v_loss: 1.22084 v_acc: 0.70898 |  iteration: 8123 teacher: 0 stage: sketch lr: 0.000490\n",
      "batch 665 loss: 1.33133 acc: 0.70410 | v_loss: 1.25399 v_acc: 0.70085 |  iteration: 8124 teacher: 1 stage: sketch lr: 0.000490\n",
      "batch 666 loss: 1.22667 acc: 0.71419 | v_loss: 1.19695 v_acc: 0.71712 |  iteration: 8125 teacher: 1 stage: sketch lr: 0.000490\n",
      "batch 667 loss: 1.17292 acc: 0.72005 | v_loss: 1.17822 v_acc: 0.72917 |  iteration: 8126 teacher: 0 stage: sketch lr: 0.000490\n",
      "batch 668 loss: 1.26470 acc: 0.70182 | v_loss: 1.25064 v_acc: 0.70410 |  iteration: 8127 teacher: 0 stage: sketch lr: 0.000490\n",
      "batch 669 loss: 1.29475 acc: 0.70345 | v_loss: 1.32688 v_acc: 0.69108 |  iteration: 8128 teacher: 1 stage: sketch lr: 0.000490\n",
      "batch 670 loss: 1.26749 acc: 0.70443 | v_loss: 1.15542 v_acc: 0.71094 |  iteration: 8129 teacher: 0 stage: sketch lr: 0.000490\n",
      "batch 671 loss: 1.29569 acc: 0.70215 | v_loss: 1.42094 v_acc: 0.68327 |  iteration: 8130 teacher: 1 stage: sketch lr: 0.000490\n",
      "batch 672 loss: 1.31342 acc: 0.70215 | v_loss: 1.17458 v_acc: 0.71582 |  iteration: 8131 teacher: 0 stage: sketch lr: 0.000490\n",
      "batch 673 loss: 1.25569 acc: 0.71289 | v_loss: 1.49002 v_acc: 0.67220 |  iteration: 8132 teacher: 1 stage: sketch lr: 0.000490\n",
      "batch 674 loss: 1.29058 acc: 0.70638 | v_loss: 1.37201 v_acc: 0.68652 |  iteration: 8133 teacher: 1 stage: sketch lr: 0.000490\n",
      "batch 675 loss: 1.28576 acc: 0.70020 | v_loss: 1.33843 v_acc: 0.68945 |  iteration: 8134 teacher: 0 stage: sketch lr: 0.000490\n",
      "batch 676 loss: 1.38978 acc: 0.69499 | v_loss: 1.30719 v_acc: 0.70475 |  iteration: 8135 teacher: 0 stage: sketch lr: 0.000490\n",
      "batch 677 loss: 1.30575 acc: 0.70573 | v_loss: 1.23479 v_acc: 0.70736 |  iteration: 8136 teacher: 1 stage: sketch lr: 0.000490\n",
      "batch 678 loss: 1.28564 acc: 0.70117 | v_loss: 1.25975 v_acc: 0.70345 |  iteration: 8137 teacher: 1 stage: sketch lr: 0.000490\n",
      "batch 679 loss: 1.32608 acc: 0.70215 | v_loss: 1.21500 v_acc: 0.71940 |  iteration: 8138 teacher: 1 stage: sketch lr: 0.000490\n",
      "batch 680 loss: 1.40350 acc: 0.69043 | v_loss: 1.41214 v_acc: 0.68815 |  iteration: 8139 teacher: 0 stage: sketch lr: 0.000490\n",
      "batch 681 loss: 1.31825 acc: 0.70443 | v_loss: 1.29680 v_acc: 0.70215 |  iteration: 8140 teacher: 0 stage: sketch lr: 0.000490\n",
      "batch 682 loss: 1.27603 acc: 0.70768 | v_loss: 1.21048 v_acc: 0.70898 |  iteration: 8141 teacher: 1 stage: sketch lr: 0.000490\n",
      "batch 683 loss: 1.40050 acc: 0.69336 | v_loss: 1.26389 v_acc: 0.71582 |  iteration: 8142 teacher: 0 stage: sketch lr: 0.000490\n",
      "batch 684 loss: 1.33557 acc: 0.70182 | v_loss: 1.17283 v_acc: 0.70443 |  iteration: 8143 teacher: 0 stage: sketch lr: 0.000490\n",
      "batch 685 loss: 1.32447 acc: 0.69759 | v_loss: 1.27046 v_acc: 0.70150 |  iteration: 8144 teacher: 1 stage: sketch lr: 0.000490\n",
      "batch 686 loss: 1.19167 acc: 0.72396 | v_loss: 1.22905 v_acc: 0.71549 |  iteration: 8145 teacher: 1 stage: sketch lr: 0.000490\n",
      "batch 687 loss: 1.25261 acc: 0.70247 | v_loss: 1.16950 v_acc: 0.72103 |  iteration: 8146 teacher: 0 stage: sketch lr: 0.000490\n",
      "batch 688 loss: 1.24373 acc: 0.71712 | v_loss: 1.12495 v_acc: 0.72298 |  iteration: 8147 teacher: 0 stage: sketch lr: 0.000490\n",
      "batch 689 loss: 1.35956 acc: 0.70378 | v_loss: 1.25455 v_acc: 0.71940 |  iteration: 8148 teacher: 0 stage: sketch lr: 0.000490\n",
      "batch 690 loss: 1.21270 acc: 0.70866 | v_loss: 1.25135 v_acc: 0.70475 |  iteration: 8149 teacher: 0 stage: sketch lr: 0.000490\n",
      "batch 691 loss: 1.21605 acc: 0.72038 | v_loss: 1.25490 v_acc: 0.70833 |  iteration: 8150 teacher: 0 stage: sketch lr: 0.000490\n",
      "batch 692 loss: 1.29161 acc: 0.70117 | v_loss: 1.10615 v_acc: 0.72591 |  iteration: 8151 teacher: 1 stage: sketch lr: 0.000490\n",
      "batch 693 loss: 1.36436 acc: 0.69889 | v_loss: 1.23776 v_acc: 0.73145 |  iteration: 8152 teacher: 0 stage: sketch lr: 0.000489\n",
      "batch 694 loss: 1.24698 acc: 0.71647 | v_loss: 1.30096 v_acc: 0.69759 |  iteration: 8153 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 695 loss: 1.23639 acc: 0.71224 | v_loss: 1.30467 v_acc: 0.72233 |  iteration: 8154 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 696 loss: 1.28850 acc: 0.70573 | v_loss: 1.16302 v_acc: 0.72201 |  iteration: 8155 teacher: 0 stage: sketch lr: 0.000489\n",
      "batch 697 loss: 1.25643 acc: 0.70280 | v_loss: 1.11663 v_acc: 0.73503 |  iteration: 8156 teacher: 0 stage: sketch lr: 0.000489\n",
      "batch 698 loss: 1.42008 acc: 0.69564 | v_loss: 1.10317 v_acc: 0.72493 |  iteration: 8157 teacher: 0 stage: sketch lr: 0.000489\n",
      "batch 699 loss: 1.27770 acc: 0.71452 | v_loss: 1.19046 v_acc: 0.70703 |  iteration: 8158 teacher: 0 stage: sketch lr: 0.000489\n",
      "batch 700 loss: 1.27951 acc: 0.70736 | v_loss: 1.24596 v_acc: 0.69694 |  iteration: 8159 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 701 loss: 1.27048 acc: 0.70866 | v_loss: 1.19918 v_acc: 0.71322 |  iteration: 8160 teacher: 0 stage: sketch lr: 0.000489\n",
      "batch 702 loss: 1.25940 acc: 0.71712 | v_loss: 1.27298 v_acc: 0.74479 |  iteration: 8161 teacher: 0 stage: sketch lr: 0.000489\n",
      "batch 703 loss: 1.30250 acc: 0.70052 | v_loss: 1.47428 v_acc: 0.69596 |  iteration: 8162 teacher: 0 stage: sketch lr: 0.000489\n",
      "batch 704 loss: 1.29809 acc: 0.70703 | v_loss: 1.34741 v_acc: 0.70508 |  iteration: 8163 teacher: 0 stage: sketch lr: 0.000489\n",
      "batch 705 loss: 1.32518 acc: 0.70768 | v_loss: 1.19766 v_acc: 0.72005 |  iteration: 8164 teacher: 0 stage: sketch lr: 0.000489\n",
      "batch 706 loss: 1.31315 acc: 0.71126 | v_loss: 1.15849 v_acc: 0.69987 |  iteration: 8165 teacher: 0 stage: sketch lr: 0.000489\n",
      "batch 707 loss: 1.23367 acc: 0.70866 | v_loss: 1.15241 v_acc: 0.71940 |  iteration: 8166 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 708 loss: 1.27792 acc: 0.70540 | v_loss: 1.22672 v_acc: 0.70605 |  iteration: 8167 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 709 loss: 1.22045 acc: 0.70833 | v_loss: 1.25153 v_acc: 0.71615 |  iteration: 8168 teacher: 0 stage: sketch lr: 0.000489\n",
      "batch 710 loss: 1.32803 acc: 0.70605 | v_loss: 1.20788 v_acc: 0.73014 |  iteration: 8169 teacher: 0 stage: sketch lr: 0.000489\n",
      "batch 711 loss: 1.29236 acc: 0.70117 | v_loss: 1.23276 v_acc: 0.71842 |  iteration: 8170 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 712 loss: 1.32183 acc: 0.69954 | v_loss: 1.23139 v_acc: 0.71842 |  iteration: 8171 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 713 loss: 1.29381 acc: 0.70703 | v_loss: 1.14766 v_acc: 0.72428 |  iteration: 8172 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 714 loss: 1.34999 acc: 0.70182 | v_loss: 1.12052 v_acc: 0.72103 |  iteration: 8173 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 715 loss: 1.27583 acc: 0.71484 | v_loss: 1.40250 v_acc: 0.69010 |  iteration: 8174 teacher: 0 stage: sketch lr: 0.000489\n",
      "batch 716 loss: 1.29712 acc: 0.70085 | v_loss: 1.20134 v_acc: 0.70768 |  iteration: 8175 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 717 loss: 1.28767 acc: 0.70378 | v_loss: 1.23128 v_acc: 0.71517 |  iteration: 8176 teacher: 0 stage: sketch lr: 0.000489\n",
      "batch 718 loss: 1.26830 acc: 0.71452 | v_loss: 1.24586 v_acc: 0.69857 |  iteration: 8177 teacher: 0 stage: sketch lr: 0.000489\n",
      "batch 719 loss: 1.30374 acc: 0.70085 | v_loss: 1.29616 v_acc: 0.69759 |  iteration: 8178 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 720 loss: 1.31586 acc: 0.69922 | v_loss: 1.13506 v_acc: 0.73112 |  iteration: 8179 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 721 loss: 1.25172 acc: 0.70475 | v_loss: 1.37255 v_acc: 0.71582 |  iteration: 8180 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 722 loss: 1.37528 acc: 0.69466 | v_loss: 1.18822 v_acc: 0.70085 |  iteration: 8181 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 723 loss: 1.42800 acc: 0.68132 | v_loss: 1.21182 v_acc: 0.70410 |  iteration: 8182 teacher: 0 stage: sketch lr: 0.000489\n",
      "batch 724 loss: 1.26319 acc: 0.69922 | v_loss: 1.26190 v_acc: 0.70443 |  iteration: 8183 teacher: 1 stage: sketch lr: 0.000489\n",
      "batch 725 loss: 1.26688 acc: 0.71029 | v_loss: 1.27446 v_acc: 0.70410 |  iteration: 8184 teacher: 0 stage: sketch lr: 0.000489\n",
      "batch 726 loss: 1.32238 acc: 0.69987 | v_loss: 1.33252 v_acc: 0.68978 |  iteration: 8185 teacher: 0 stage: sketch lr: 0.000488\n",
      "batch 727 loss: 1.24394 acc: 0.70638 | v_loss: 1.37453 v_acc: 0.70540 |  iteration: 8186 teacher: 0 stage: sketch lr: 0.000488\n",
      "batch 728 loss: 1.21906 acc: 0.71257 | v_loss: 1.28219 v_acc: 0.70540 |  iteration: 8187 teacher: 0 stage: sketch lr: 0.000488\n",
      "batch 729 loss: 1.40640 acc: 0.70312 | v_loss: 1.18939 v_acc: 0.70475 |  iteration: 8188 teacher: 0 stage: sketch lr: 0.000488\n",
      "batch 730 loss: 1.24112 acc: 0.70833 | v_loss: 1.34004 v_acc: 0.70312 |  iteration: 8189 teacher: 1 stage: sketch lr: 0.000488\n",
      "batch 731 loss: 1.33835 acc: 0.70182 | v_loss: 1.21758 v_acc: 0.71354 |  iteration: 8190 teacher: 0 stage: sketch lr: 0.000488\n",
      "batch 732 loss: 1.26479 acc: 0.71680 | v_loss: 1.13847 v_acc: 0.72428 |  iteration: 8191 teacher: 1 stage: sketch lr: 0.000488\n",
      "batch 733 loss: 1.31506 acc: 0.70508 | v_loss: 1.13800 v_acc: 0.70768 |  iteration: 8192 teacher: 0 stage: sketch lr: 0.000488\n",
      "batch 734 loss: 1.29983 acc: 0.70150 | v_loss: 1.26038 v_acc: 0.70671 |  iteration: 8193 teacher: 0 stage: sketch lr: 0.000488\n",
      "batch 735 loss: 1.27390 acc: 0.70150 | v_loss: 1.34745 v_acc: 0.68555 |  iteration: 8194 teacher: 0 stage: sketch lr: 0.000488\n",
      "batch 736 loss: 1.33581 acc: 0.70736 | v_loss: 1.17856 v_acc: 0.70117 |  iteration: 8195 teacher: 0 stage: sketch lr: 0.000488\n",
      "batch 737 loss: 1.33215 acc: 0.70996 | v_loss: 1.18918 v_acc: 0.69564 |  iteration: 8196 teacher: 1 stage: sketch lr: 0.000488\n",
      "batch 738 loss: 1.31641 acc: 0.70020 | v_loss: 1.19685 v_acc: 0.70898 |  iteration: 8197 teacher: 0 stage: sketch lr: 0.000488\n",
      "batch 739 loss: 1.24822 acc: 0.70801 | v_loss: 1.20896 v_acc: 0.71029 |  iteration: 8198 teacher: 0 stage: sketch lr: 0.000488\n",
      "batch 740 loss: 1.20422 acc: 0.70801 | v_loss: 1.06844 v_acc: 0.73470 |  iteration: 8199 teacher: 1 stage: sketch lr: 0.000488\n",
      "batch 741 loss: 1.27436 acc: 0.70573 | v_loss: 1.17796 v_acc: 0.71647 |  iteration: 8200 teacher: 0 stage: sketch lr: 0.000488\n",
      "batch 742 loss: 1.30105 acc: 0.70052 | v_loss: 1.13629 v_acc: 0.72559 |  iteration: 8201 teacher: 0 stage: sketch lr: 0.000488\n",
      "batch 743 loss: 1.28775 acc: 0.70475 | v_loss: 1.11954 v_acc: 0.72493 |  iteration: 8202 teacher: 0 stage: sketch lr: 0.000488\n",
      "batch 744 loss: 1.32284 acc: 0.70280 | v_loss: 1.19671 v_acc: 0.72038 |  iteration: 8203 teacher: 0 stage: sketch lr: 0.000488\n",
      "batch 745 loss: 1.25153 acc: 0.70833 | v_loss: 1.22991 v_acc: 0.71419 |  iteration: 8204 teacher: 0 stage: sketch lr: 0.000488\n",
      "batch 908 loss: 1.26459 acc: 0.71126 | v_loss: 1.35187 v_acc: 0.68750 |  iteration: 8367 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 909 loss: 1.22539 acc: 0.71354 | v_loss: 1.37083 v_acc: 0.70801 |  iteration: 8368 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 910 loss: 1.35492 acc: 0.69889 | v_loss: 1.27587 v_acc: 0.70150 |  iteration: 8369 teacher: 0 stage: sketch lr: 0.000483\n",
      "batch 911 loss: 1.32999 acc: 0.69759 | v_loss: 1.19360 v_acc: 0.71094 |  iteration: 8370 teacher: 0 stage: sketch lr: 0.000483\n",
      "batch 912 loss: 1.38841 acc: 0.69271 | v_loss: 1.32847 v_acc: 0.70345 |  iteration: 8371 teacher: 0 stage: sketch lr: 0.000483\n",
      "batch 913 loss: 1.20304 acc: 0.70573 | v_loss: 1.22103 v_acc: 0.71191 |  iteration: 8372 teacher: 0 stage: sketch lr: 0.000483\n",
      "batch 914 loss: 1.27371 acc: 0.70052 | v_loss: 1.14900 v_acc: 0.72396 |  iteration: 8373 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 915 loss: 1.35392 acc: 0.69727 | v_loss: 1.14067 v_acc: 0.70020 |  iteration: 8374 teacher: 0 stage: sketch lr: 0.000483\n",
      "batch 916 loss: 1.29265 acc: 0.70508 | v_loss: 1.25913 v_acc: 0.70020 |  iteration: 8375 teacher: 0 stage: sketch lr: 0.000483\n",
      "batch 917 loss: 1.24233 acc: 0.71061 | v_loss: 1.33462 v_acc: 0.68880 |  iteration: 8376 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 918 loss: 1.28898 acc: 0.71094 | v_loss: 1.15496 v_acc: 0.71615 |  iteration: 8377 teacher: 0 stage: sketch lr: 0.000483\n",
      "batch 919 loss: 1.27524 acc: 0.70475 | v_loss: 1.20686 v_acc: 0.69727 |  iteration: 8378 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 920 loss: 1.41135 acc: 0.70052 | v_loss: 1.20625 v_acc: 0.70605 |  iteration: 8379 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 921 loss: 1.25323 acc: 0.70638 | v_loss: 1.21437 v_acc: 0.70280 |  iteration: 8380 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 922 loss: 1.22858 acc: 0.70020 | v_loss: 1.08185 v_acc: 0.73340 |  iteration: 8381 teacher: 0 stage: sketch lr: 0.000483\n",
      "batch 923 loss: 1.27417 acc: 0.71061 | v_loss: 1.17996 v_acc: 0.71680 |  iteration: 8382 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 924 loss: 1.29039 acc: 0.70703 | v_loss: 1.14847 v_acc: 0.74056 |  iteration: 8383 teacher: 0 stage: sketch lr: 0.000483\n",
      "batch 925 loss: 1.32187 acc: 0.70605 | v_loss: 1.12914 v_acc: 0.72656 |  iteration: 8384 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 926 loss: 1.36623 acc: 0.69238 | v_loss: 1.20399 v_acc: 0.72103 |  iteration: 8385 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 927 loss: 1.34870 acc: 0.69076 | v_loss: 1.23494 v_acc: 0.71354 |  iteration: 8386 teacher: 0 stage: sketch lr: 0.000483\n",
      "batch 928 loss: 1.28567 acc: 0.70020 | v_loss: 1.21420 v_acc: 0.72428 |  iteration: 8387 teacher: 0 stage: sketch lr: 0.000483\n",
      "batch 929 loss: 1.28088 acc: 0.71224 | v_loss: 1.38350 v_acc: 0.70150 |  iteration: 8388 teacher: 1 stage: sketch lr: 0.000483\n",
      "batch 930 loss: 1.35562 acc: 0.70085 | v_loss: 1.26152 v_acc: 0.72168 |  iteration: 8389 teacher: 0 stage: sketch lr: 0.000483\n",
      "batch 931 loss: 1.28500 acc: 0.69368 | v_loss: 1.05786 v_acc: 0.74740 |  iteration: 8390 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 932 loss: 1.41830 acc: 0.68783 | v_loss: 1.22429 v_acc: 0.70833 |  iteration: 8391 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 933 loss: 1.30145 acc: 0.70931 | v_loss: 1.26496 v_acc: 0.69987 |  iteration: 8392 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 934 loss: 1.32158 acc: 0.70736 | v_loss: 1.20809 v_acc: 0.70182 |  iteration: 8393 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 935 loss: 1.22148 acc: 0.70833 | v_loss: 1.25798 v_acc: 0.71094 |  iteration: 8394 teacher: 1 stage: sketch lr: 0.000482\n",
      "batch 936 loss: 1.34221 acc: 0.69303 | v_loss: 1.24796 v_acc: 0.69661 |  iteration: 8395 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 937 loss: 1.32377 acc: 0.70117 | v_loss: 1.22082 v_acc: 0.70964 |  iteration: 8396 teacher: 1 stage: sketch lr: 0.000482\n",
      "batch 938 loss: 1.22610 acc: 0.70703 | v_loss: 1.25668 v_acc: 0.69108 |  iteration: 8397 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 939 loss: 1.23846 acc: 0.71191 | v_loss: 1.20338 v_acc: 0.71549 |  iteration: 8398 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 940 loss: 1.29994 acc: 0.69889 | v_loss: 1.18512 v_acc: 0.72461 |  iteration: 8399 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 941 loss: 1.28561 acc: 0.71126 | v_loss: 1.24815 v_acc: 0.70312 |  iteration: 8400 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 942 loss: 1.16731 acc: 0.71712 | v_loss: 1.32786 v_acc: 0.69857 |  iteration: 8401 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 943 loss: 1.25478 acc: 0.70768 | v_loss: 1.14930 v_acc: 0.70898 |  iteration: 8402 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 944 loss: 1.32853 acc: 0.70182 | v_loss: 1.41865 v_acc: 0.68522 |  iteration: 8403 teacher: 1 stage: sketch lr: 0.000482\n",
      "batch 945 loss: 1.33205 acc: 0.70150 | v_loss: 1.15544 v_acc: 0.72168 |  iteration: 8404 teacher: 1 stage: sketch lr: 0.000482\n",
      "batch 946 loss: 1.35229 acc: 0.69759 | v_loss: 1.49395 v_acc: 0.67969 |  iteration: 8405 teacher: 1 stage: sketch lr: 0.000482\n",
      "batch 947 loss: 1.29027 acc: 0.71289 | v_loss: 1.38317 v_acc: 0.69596 |  iteration: 8406 teacher: 1 stage: sketch lr: 0.000482\n",
      "batch 948 loss: 1.34432 acc: 0.69043 | v_loss: 1.33564 v_acc: 0.69238 |  iteration: 8407 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 949 loss: 1.22880 acc: 0.71387 | v_loss: 1.30803 v_acc: 0.70085 |  iteration: 8408 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 950 loss: 1.28204 acc: 0.70996 | v_loss: 1.23139 v_acc: 0.70573 |  iteration: 8409 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 951 loss: 1.29704 acc: 0.70475 | v_loss: 1.25655 v_acc: 0.70703 |  iteration: 8410 teacher: 1 stage: sketch lr: 0.000482\n",
      "batch 952 loss: 1.29574 acc: 0.70247 | v_loss: 1.22445 v_acc: 0.71615 |  iteration: 8411 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 953 loss: 1.32104 acc: 0.70410 | v_loss: 1.42807 v_acc: 0.68034 |  iteration: 8412 teacher: 1 stage: sketch lr: 0.000482\n",
      "batch 954 loss: 1.32225 acc: 0.69271 | v_loss: 1.28158 v_acc: 0.71159 |  iteration: 8413 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 955 loss: 1.31529 acc: 0.69173 | v_loss: 1.20499 v_acc: 0.70638 |  iteration: 8414 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 956 loss: 1.30116 acc: 0.69824 | v_loss: 1.26058 v_acc: 0.71647 |  iteration: 8415 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 957 loss: 1.31429 acc: 0.69596 | v_loss: 1.17229 v_acc: 0.70443 |  iteration: 8416 teacher: 1 stage: sketch lr: 0.000482\n",
      "batch 958 loss: 1.27763 acc: 0.70931 | v_loss: 1.25861 v_acc: 0.69889 |  iteration: 8417 teacher: 1 stage: sketch lr: 0.000482\n",
      "batch 959 loss: 1.34981 acc: 0.69661 | v_loss: 1.23174 v_acc: 0.71257 |  iteration: 8418 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 960 loss: 1.30226 acc: 0.70020 | v_loss: 1.17534 v_acc: 0.71615 |  iteration: 8419 teacher: 1 stage: sketch lr: 0.000482\n",
      "batch 961 loss: 1.35965 acc: 0.69824 | v_loss: 1.13579 v_acc: 0.72982 |  iteration: 8420 teacher: 1 stage: sketch lr: 0.000482\n",
      "batch 962 loss: 1.32204 acc: 0.70410 | v_loss: 1.25135 v_acc: 0.71647 |  iteration: 8421 teacher: 1 stage: sketch lr: 0.000482\n",
      "batch 963 loss: 1.37320 acc: 0.69271 | v_loss: 1.25666 v_acc: 0.70052 |  iteration: 8422 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 964 loss: 1.27144 acc: 0.69857 | v_loss: 1.26476 v_acc: 0.70312 |  iteration: 8423 teacher: 1 stage: sketch lr: 0.000482\n",
      "batch 965 loss: 1.25068 acc: 0.71452 | v_loss: 1.11947 v_acc: 0.71419 |  iteration: 8424 teacher: 0 stage: sketch lr: 0.000482\n",
      "batch 966 loss: 1.27564 acc: 0.71354 | v_loss: 1.25020 v_acc: 0.72754 |  iteration: 8425 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 967 loss: 1.20730 acc: 0.71094 | v_loss: 1.30416 v_acc: 0.69792 |  iteration: 8426 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 968 loss: 1.28863 acc: 0.70964 | v_loss: 1.29973 v_acc: 0.72201 |  iteration: 8427 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 969 loss: 1.27104 acc: 0.70345 | v_loss: 1.14417 v_acc: 0.72233 |  iteration: 8428 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 970 loss: 1.35951 acc: 0.69629 | v_loss: 1.09139 v_acc: 0.74447 |  iteration: 8429 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 971 loss: 1.36030 acc: 0.70378 | v_loss: 1.10032 v_acc: 0.72493 |  iteration: 8430 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 972 loss: 1.25121 acc: 0.70833 | v_loss: 1.18058 v_acc: 0.71126 |  iteration: 8431 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 973 loss: 1.23450 acc: 0.70540 | v_loss: 1.22420 v_acc: 0.70703 |  iteration: 8432 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 974 loss: 1.24372 acc: 0.69759 | v_loss: 1.19718 v_acc: 0.71549 |  iteration: 8433 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 975 loss: 1.36044 acc: 0.69271 | v_loss: 1.34257 v_acc: 0.70475 |  iteration: 8434 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 976 loss: 1.29173 acc: 0.70475 | v_loss: 1.47284 v_acc: 0.69368 |  iteration: 8435 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 977 loss: 1.27587 acc: 0.69824 | v_loss: 1.34981 v_acc: 0.69596 |  iteration: 8436 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 978 loss: 1.37154 acc: 0.69271 | v_loss: 1.20051 v_acc: 0.72266 |  iteration: 8437 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 979 loss: 1.34166 acc: 0.70052 | v_loss: 1.15816 v_acc: 0.70247 |  iteration: 8438 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 980 loss: 1.28057 acc: 0.70215 | v_loss: 1.16747 v_acc: 0.71712 |  iteration: 8439 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 981 loss: 1.24331 acc: 0.69889 | v_loss: 1.22006 v_acc: 0.69661 |  iteration: 8440 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 982 loss: 1.33576 acc: 0.69173 | v_loss: 1.26154 v_acc: 0.71126 |  iteration: 8441 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 983 loss: 1.34299 acc: 0.69499 | v_loss: 1.21059 v_acc: 0.73145 |  iteration: 8442 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 984 loss: 1.34309 acc: 0.69368 | v_loss: 1.23892 v_acc: 0.71908 |  iteration: 8443 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 985 loss: 1.32780 acc: 0.70475 | v_loss: 1.24920 v_acc: 0.70312 |  iteration: 8444 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 986 loss: 1.31279 acc: 0.70085 | v_loss: 1.16556 v_acc: 0.72428 |  iteration: 8445 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 987 loss: 1.21377 acc: 0.71484 | v_loss: 1.12529 v_acc: 0.72070 |  iteration: 8446 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 988 loss: 1.29257 acc: 0.69596 | v_loss: 1.44695 v_acc: 0.69206 |  iteration: 8447 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 989 loss: 1.30069 acc: 0.70703 | v_loss: 1.19666 v_acc: 0.70964 |  iteration: 8448 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 990 loss: 1.29133 acc: 0.71061 | v_loss: 1.22338 v_acc: 0.71615 |  iteration: 8449 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 991 loss: 1.28724 acc: 0.70117 | v_loss: 1.22616 v_acc: 0.71452 |  iteration: 8450 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 992 loss: 1.32939 acc: 0.69368 | v_loss: 1.28684 v_acc: 0.70443 |  iteration: 8451 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 993 loss: 1.27450 acc: 0.70345 | v_loss: 1.13424 v_acc: 0.73145 |  iteration: 8452 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 994 loss: 1.27898 acc: 0.70182 | v_loss: 1.38929 v_acc: 0.71647 |  iteration: 8453 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 995 loss: 1.37168 acc: 0.70345 | v_loss: 1.18757 v_acc: 0.70117 |  iteration: 8454 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 996 loss: 1.22820 acc: 0.71387 | v_loss: 1.19775 v_acc: 0.70833 |  iteration: 8455 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 997 loss: 1.29422 acc: 0.70736 | v_loss: 1.26704 v_acc: 0.70508 |  iteration: 8456 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 998 loss: 1.30023 acc: 0.70345 | v_loss: 1.28265 v_acc: 0.70182 |  iteration: 8457 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 999 loss: 1.24476 acc: 0.71029 | v_loss: 1.34136 v_acc: 0.69531 |  iteration: 8458 teacher: 0 stage: sketch lr: 0.000481\n",
      "batch 1000 loss: 1.29449 acc: 0.70443 | v_loss: 1.36979 v_acc: 0.70443 |  iteration: 8459 teacher: 1 stage: sketch lr: 0.000481\n",
      "batch 1001 loss: 1.31644 acc: 0.69824 | v_loss: 1.29756 v_acc: 0.70540 |  iteration: 8460 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 1002 loss: 1.21395 acc: 0.71647 | v_loss: 1.20747 v_acc: 0.71452 |  iteration: 8461 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 1003 loss: 1.23003 acc: 0.70801 | v_loss: 1.30418 v_acc: 0.70280 |  iteration: 8462 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 1004 loss: 1.32238 acc: 0.69792 | v_loss: 1.22963 v_acc: 0.71126 |  iteration: 8463 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 1005 loss: 1.23832 acc: 0.70150 | v_loss: 1.14862 v_acc: 0.72591 |  iteration: 8464 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 1006 loss: 1.26612 acc: 0.70508 | v_loss: 1.14348 v_acc: 0.70671 |  iteration: 8465 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 1007 loss: 1.25898 acc: 0.70540 | v_loss: 1.26445 v_acc: 0.70378 |  iteration: 8466 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 1008 loss: 1.21337 acc: 0.70964 | v_loss: 1.31305 v_acc: 0.69824 |  iteration: 8467 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 1009 loss: 1.39445 acc: 0.69238 | v_loss: 1.15706 v_acc: 0.70540 |  iteration: 8468 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 1010 loss: 1.35204 acc: 0.70020 | v_loss: 1.20573 v_acc: 0.69368 |  iteration: 8469 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 1011 loss: 1.32068 acc: 0.70247 | v_loss: 1.20360 v_acc: 0.70573 |  iteration: 8470 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 1012 loss: 1.23721 acc: 0.71029 | v_loss: 1.20836 v_acc: 0.70215 |  iteration: 8471 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 1013 loss: 1.30895 acc: 0.70052 | v_loss: 1.08665 v_acc: 0.73503 |  iteration: 8472 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 1014 loss: 1.42963 acc: 0.69173 | v_loss: 1.17915 v_acc: 0.71582 |  iteration: 8473 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 1015 loss: 1.27325 acc: 0.70378 | v_loss: 1.16117 v_acc: 0.75163 |  iteration: 8474 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 1016 loss: 1.23052 acc: 0.70833 | v_loss: 1.14622 v_acc: 0.72005 |  iteration: 8475 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 1017 loss: 1.32231 acc: 0.70443 | v_loss: 1.22133 v_acc: 0.71582 |  iteration: 8476 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 1018 loss: 1.17411 acc: 0.71908 | v_loss: 1.26020 v_acc: 0.71126 |  iteration: 8477 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 1019 loss: 1.19206 acc: 0.71029 | v_loss: 1.24868 v_acc: 0.72038 |  iteration: 8478 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 1020 loss: 1.30761 acc: 0.70150 | v_loss: 1.38461 v_acc: 0.70020 |  iteration: 8479 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 1021 loss: 1.32652 acc: 0.70280 | v_loss: 1.29408 v_acc: 0.71484 |  iteration: 8480 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 1022 loss: 1.42977 acc: 0.68945 | v_loss: 1.06143 v_acc: 0.74316 |  iteration: 8481 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 1023 loss: 1.31831 acc: 0.70052 | v_loss: 1.20068 v_acc: 0.71126 |  iteration: 8482 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 1024 loss: 1.34458 acc: 0.70247 | v_loss: 1.28043 v_acc: 0.69694 |  iteration: 8483 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 1025 loss: 1.29525 acc: 0.70085 | v_loss: 1.21997 v_acc: 0.68913 |  iteration: 8484 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 1026 loss: 1.28229 acc: 0.70703 | v_loss: 1.27459 v_acc: 0.70247 |  iteration: 8485 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 1027 loss: 1.32348 acc: 0.70085 | v_loss: 1.25867 v_acc: 0.69792 |  iteration: 8486 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 1028 loss: 1.36700 acc: 0.68913 | v_loss: 1.24257 v_acc: 0.70801 |  iteration: 8487 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 1029 loss: 1.31046 acc: 0.70768 | v_loss: 1.27556 v_acc: 0.69727 |  iteration: 8488 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 1030 loss: 1.31394 acc: 0.70475 | v_loss: 1.17320 v_acc: 0.71094 |  iteration: 8489 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 1031 loss: 1.25649 acc: 0.70638 | v_loss: 1.18098 v_acc: 0.72233 |  iteration: 8490 teacher: 0 stage: sketch lr: 0.000480\n",
      "batch 1032 loss: 1.36204 acc: 0.70378 | v_loss: 1.23591 v_acc: 0.70378 |  iteration: 8491 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 1033 loss: 1.24488 acc: 0.71029 | v_loss: 1.34563 v_acc: 0.69889 |  iteration: 8492 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 1034 loss: 1.29576 acc: 0.70475 | v_loss: 1.16375 v_acc: 0.70833 |  iteration: 8493 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 1035 loss: 1.24420 acc: 0.70443 | v_loss: 1.40558 v_acc: 0.68783 |  iteration: 8494 teacher: 1 stage: sketch lr: 0.000480\n",
      "batch 1036 loss: 1.31884 acc: 0.70052 | v_loss: 1.17999 v_acc: 0.71875 |  iteration: 8495 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1037 loss: 1.33813 acc: 0.69987 | v_loss: 1.48265 v_acc: 0.67904 |  iteration: 8496 teacher: 1 stage: sketch lr: 0.000479\n",
      "batch 1038 loss: 1.36062 acc: 0.70736 | v_loss: 1.36632 v_acc: 0.69661 |  iteration: 8497 teacher: 1 stage: sketch lr: 0.000479\n",
      "batch 1039 loss: 1.29803 acc: 0.70573 | v_loss: 1.33578 v_acc: 0.69141 |  iteration: 8498 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1040 loss: 1.29028 acc: 0.69954 | v_loss: 1.31034 v_acc: 0.69857 |  iteration: 8499 teacher: 1 stage: sketch lr: 0.000479\n",
      "batch 1041 loss: 1.23362 acc: 0.70736 | v_loss: 1.23596 v_acc: 0.70605 |  iteration: 8500 teacher: 1 stage: sketch lr: 0.000479\n",
      "batch 1042 loss: 1.29940 acc: 0.70833 | v_loss: 1.26446 v_acc: 0.70801 |  iteration: 8501 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1043 loss: 1.27815 acc: 0.70573 | v_loss: 1.22133 v_acc: 0.72298 |  iteration: 8502 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1044 loss: 1.26913 acc: 0.71940 | v_loss: 1.42612 v_acc: 0.68132 |  iteration: 8503 teacher: 1 stage: sketch lr: 0.000479\n",
      "batch 1045 loss: 1.26751 acc: 0.71094 | v_loss: 1.28557 v_acc: 0.71224 |  iteration: 8504 teacher: 1 stage: sketch lr: 0.000479\n",
      "batch 1046 loss: 1.41765 acc: 0.69824 | v_loss: 1.20202 v_acc: 0.70768 |  iteration: 8505 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1047 loss: 1.20588 acc: 0.71582 | v_loss: 1.27235 v_acc: 0.71191 |  iteration: 8506 teacher: 1 stage: sketch lr: 0.000479\n",
      "batch 1048 loss: 1.24830 acc: 0.71126 | v_loss: 1.17638 v_acc: 0.70508 |  iteration: 8507 teacher: 1 stage: sketch lr: 0.000479\n",
      "batch 1049 loss: 1.31632 acc: 0.70182 | v_loss: 1.25917 v_acc: 0.69889 |  iteration: 8508 teacher: 1 stage: sketch lr: 0.000479\n",
      "batch 1050 loss: 1.33834 acc: 0.70085 | v_loss: 1.22578 v_acc: 0.71842 |  iteration: 8509 teacher: 1 stage: sketch lr: 0.000479\n",
      "batch 1051 loss: 1.27351 acc: 0.71191 | v_loss: 1.17492 v_acc: 0.71647 |  iteration: 8510 teacher: 1 stage: sketch lr: 0.000479\n",
      "batch 1052 loss: 1.35735 acc: 0.69727 | v_loss: 1.14553 v_acc: 0.72526 |  iteration: 8511 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1053 loss: 1.37659 acc: 0.69141 | v_loss: 1.26311 v_acc: 0.71029 |  iteration: 8512 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1054 loss: 1.36087 acc: 0.69108 | v_loss: 1.25334 v_acc: 0.70085 |  iteration: 8513 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1055 loss: 1.38952 acc: 0.70117 | v_loss: 1.25443 v_acc: 0.70410 |  iteration: 8514 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1056 loss: 1.33758 acc: 0.69987 | v_loss: 1.12131 v_acc: 0.71419 |  iteration: 8515 teacher: 1 stage: sketch lr: 0.000479\n",
      "batch 1057 loss: 1.23800 acc: 0.70605 | v_loss: 1.25068 v_acc: 0.72819 |  iteration: 8516 teacher: 1 stage: sketch lr: 0.000479\n",
      "batch 1058 loss: 1.25189 acc: 0.70703 | v_loss: 1.30463 v_acc: 0.69792 |  iteration: 8517 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1059 loss: 1.27090 acc: 0.71289 | v_loss: 1.29909 v_acc: 0.71940 |  iteration: 8518 teacher: 1 stage: sketch lr: 0.000479\n",
      "batch 1060 loss: 1.22773 acc: 0.71191 | v_loss: 1.15352 v_acc: 0.72135 |  iteration: 8519 teacher: 1 stage: sketch lr: 0.000479\n",
      "batch 1061 loss: 1.34484 acc: 0.70508 | v_loss: 1.09526 v_acc: 0.74284 |  iteration: 8520 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1062 loss: 1.33874 acc: 0.69336 | v_loss: 1.11261 v_acc: 0.72493 |  iteration: 8521 teacher: 1 stage: sketch lr: 0.000479\n",
      "batch 1063 loss: 1.33183 acc: 0.70345 | v_loss: 1.18413 v_acc: 0.71126 |  iteration: 8522 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1064 loss: 1.27378 acc: 0.70703 | v_loss: 1.22298 v_acc: 0.70345 |  iteration: 8523 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1065 loss: 1.27985 acc: 0.71126 | v_loss: 1.21398 v_acc: 0.70736 |  iteration: 8524 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1066 loss: 1.26944 acc: 0.71810 | v_loss: 1.35246 v_acc: 0.68522 |  iteration: 8525 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1067 loss: 1.26603 acc: 0.71029 | v_loss: 1.47523 v_acc: 0.69271 |  iteration: 8526 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1068 loss: 1.36364 acc: 0.69499 | v_loss: 1.35703 v_acc: 0.69564 |  iteration: 8527 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1069 loss: 1.28690 acc: 0.70605 | v_loss: 1.20578 v_acc: 0.71615 |  iteration: 8528 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1070 loss: 1.29399 acc: 0.70247 | v_loss: 1.17724 v_acc: 0.70801 |  iteration: 8529 teacher: 0 stage: sketch lr: 0.000479\n",
      "batch 1071 loss: 1.29385 acc: 0.70671 | v_loss: 1.17259 v_acc: 0.71517 |  iteration: 8530 teacher: 1 stage: sketch lr: 0.000479\n",
      "batch 1072 loss: 1.23311 acc: 0.70866 | v_loss: 1.21855 v_acc: 0.69987 |  iteration: 8531 teacher: 1 stage: sketch lr: 0.000478\n",
      "batch 1073 loss: 1.33337 acc: 0.70703 | v_loss: 1.25015 v_acc: 0.71094 |  iteration: 8532 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1074 loss: 1.21640 acc: 0.71029 | v_loss: 1.20572 v_acc: 0.72852 |  iteration: 8533 teacher: 1 stage: sketch lr: 0.000478\n",
      "batch 1075 loss: 1.33364 acc: 0.70150 | v_loss: 1.22430 v_acc: 0.71875 |  iteration: 8534 teacher: 1 stage: sketch lr: 0.000478\n",
      "batch 1076 loss: 1.28687 acc: 0.70312 | v_loss: 1.23713 v_acc: 0.70443 |  iteration: 8535 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1077 loss: 1.25977 acc: 0.71354 | v_loss: 1.15209 v_acc: 0.72493 |  iteration: 8536 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1078 loss: 1.34760 acc: 0.70247 | v_loss: 1.12244 v_acc: 0.71908 |  iteration: 8537 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1079 loss: 1.25081 acc: 0.70996 | v_loss: 1.41547 v_acc: 0.69271 |  iteration: 8538 teacher: 1 stage: sketch lr: 0.000478\n",
      "batch 1080 loss: 1.32283 acc: 0.69759 | v_loss: 1.20469 v_acc: 0.71224 |  iteration: 8539 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1081 loss: 1.24334 acc: 0.71322 | v_loss: 1.22328 v_acc: 0.71777 |  iteration: 8540 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1082 loss: 1.25506 acc: 0.70508 | v_loss: 1.22006 v_acc: 0.71908 |  iteration: 8541 teacher: 1 stage: sketch lr: 0.000478\n",
      "batch 1083 loss: 1.26216 acc: 0.70898 | v_loss: 1.26951 v_acc: 0.70703 |  iteration: 8542 teacher: 1 stage: sketch lr: 0.000478\n",
      "batch 1084 loss: 1.28115 acc: 0.70736 | v_loss: 1.13249 v_acc: 0.73145 |  iteration: 8543 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1085 loss: 1.27320 acc: 0.70475 | v_loss: 1.36791 v_acc: 0.71452 |  iteration: 8544 teacher: 1 stage: sketch lr: 0.000478\n",
      "batch 1086 loss: 1.20060 acc: 0.71745 | v_loss: 1.19944 v_acc: 0.69792 |  iteration: 8545 teacher: 1 stage: sketch lr: 0.000478\n",
      "batch 1087 loss: 1.33362 acc: 0.69531 | v_loss: 1.21465 v_acc: 0.70475 |  iteration: 8546 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1088 loss: 1.29998 acc: 0.71126 | v_loss: 1.28320 v_acc: 0.70280 |  iteration: 8547 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1089 loss: 1.26448 acc: 0.71354 | v_loss: 1.28590 v_acc: 0.70150 |  iteration: 8548 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1090 loss: 1.20461 acc: 0.71419 | v_loss: 1.34339 v_acc: 0.68880 |  iteration: 8549 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1091 loss: 1.27260 acc: 0.70866 | v_loss: 1.36657 v_acc: 0.70573 |  iteration: 8550 teacher: 1 stage: sketch lr: 0.000478\n",
      "batch 1092 loss: 1.33355 acc: 0.70150 | v_loss: 1.28828 v_acc: 0.70443 |  iteration: 8551 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1093 loss: 1.29513 acc: 0.69434 | v_loss: 1.20913 v_acc: 0.70508 |  iteration: 8552 teacher: 1 stage: sketch lr: 0.000478\n",
      "batch 1094 loss: 1.35023 acc: 0.69043 | v_loss: 1.30749 v_acc: 0.70443 |  iteration: 8553 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1095 loss: 1.27779 acc: 0.70931 | v_loss: 1.21463 v_acc: 0.71159 |  iteration: 8554 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1096 loss: 1.28027 acc: 0.70443 | v_loss: 1.13269 v_acc: 0.72396 |  iteration: 8555 teacher: 1 stage: sketch lr: 0.000478\n",
      "batch 1097 loss: 1.27910 acc: 0.71484 | v_loss: 1.14761 v_acc: 0.70703 |  iteration: 8556 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1098 loss: 1.29886 acc: 0.70671 | v_loss: 1.26582 v_acc: 0.70215 |  iteration: 8557 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1099 loss: 1.29001 acc: 0.70508 | v_loss: 1.31924 v_acc: 0.69922 |  iteration: 8558 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1100 loss: 1.24362 acc: 0.70605 | v_loss: 1.15148 v_acc: 0.71484 |  iteration: 8559 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1101 loss: 1.33959 acc: 0.70573 | v_loss: 1.20077 v_acc: 0.70182 |  iteration: 8560 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1102 loss: 1.24935 acc: 0.70996 | v_loss: 1.18665 v_acc: 0.71159 |  iteration: 8561 teacher: 1 stage: sketch lr: 0.000478\n",
      "batch 1103 loss: 1.24112 acc: 0.70898 | v_loss: 1.20069 v_acc: 0.70378 |  iteration: 8562 teacher: 0 stage: sketch lr: 0.000478\n",
      "batch 1104 loss: 1.29282 acc: 0.69987 | v_loss: 1.07675 v_acc: 0.73665 |  iteration: 8563 teacher: 1 stage: sketch lr: 0.000478\n",
      "batch 1105 loss: 1.35783 acc: 0.69271 | v_loss: 1.16791 v_acc: 0.72201 |  iteration: 8564 teacher: 1 stage: sketch lr: 0.000478\n",
      "batch 1106 loss: 1.26321 acc: 0.70085 | v_loss: 1.17866 v_acc: 0.72689 |  iteration: 8565 teacher: 1 stage: sketch lr: 0.000478\n",
      "batch 1107 loss: 1.24951 acc: 0.70312 | v_loss: 1.12936 v_acc: 0.72819 |  iteration: 8566 teacher: 1 stage: sketch lr: 0.000478\n",
      "batch 1108 loss: 1.34409 acc: 0.70378 | v_loss: 1.21143 v_acc: 0.72103 |  iteration: 8567 teacher: 1 stage: sketch lr: 0.000477\n",
      "batch 1109 loss: 1.25502 acc: 0.70475 | v_loss: 1.24838 v_acc: 0.71257 |  iteration: 8568 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 1110 loss: 1.31040 acc: 0.69922 | v_loss: 1.21690 v_acc: 0.72428 |  iteration: 8569 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 1111 loss: 1.28142 acc: 0.70540 | v_loss: 1.38025 v_acc: 0.70182 |  iteration: 8570 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 1112 loss: 1.32977 acc: 0.70312 | v_loss: 1.27449 v_acc: 0.72135 |  iteration: 8571 teacher: 1 stage: sketch lr: 0.000477\n",
      "batch 1113 loss: 1.27980 acc: 0.70833 | v_loss: 1.05624 v_acc: 0.74447 |  iteration: 8572 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 1114 loss: 1.31725 acc: 0.70020 | v_loss: 1.19889 v_acc: 0.70964 |  iteration: 8573 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 1115 loss: 1.35189 acc: 0.68620 | v_loss: 1.28271 v_acc: 0.70117 |  iteration: 8574 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 1116 loss: 1.37982 acc: 0.69336 | v_loss: 1.19869 v_acc: 0.70215 |  iteration: 8575 teacher: 1 stage: sketch lr: 0.000477\n",
      "batch 1117 loss: 1.28247 acc: 0.70605 | v_loss: 1.24684 v_acc: 0.71094 |  iteration: 8576 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 1118 loss: 1.35125 acc: 0.69759 | v_loss: 1.24861 v_acc: 0.69238 |  iteration: 8577 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 1119 loss: 1.27719 acc: 0.70085 | v_loss: 1.21065 v_acc: 0.71322 |  iteration: 8578 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 1120 loss: 1.24833 acc: 0.70833 | v_loss: 1.25711 v_acc: 0.69857 |  iteration: 8579 teacher: 1 stage: sketch lr: 0.000477\n",
      "batch 1121 loss: 1.29695 acc: 0.70150 | v_loss: 1.18170 v_acc: 0.71257 |  iteration: 8580 teacher: 1 stage: sketch lr: 0.000477\n",
      "batch 1122 loss: 1.38930 acc: 0.69466 | v_loss: 1.17939 v_acc: 0.72624 |  iteration: 8581 teacher: 1 stage: sketch lr: 0.000477\n",
      "batch 1123 loss: 1.28150 acc: 0.70182 | v_loss: 1.23130 v_acc: 0.70378 |  iteration: 8582 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 1124 loss: 1.29979 acc: 0.70898 | v_loss: 1.33931 v_acc: 0.69954 |  iteration: 8583 teacher: 1 stage: sketch lr: 0.000477\n",
      "batch 1125 loss: 1.38965 acc: 0.70020 | v_loss: 1.15725 v_acc: 0.70898 |  iteration: 8584 teacher: 1 stage: sketch lr: 0.000477\n",
      "batch 1126 loss: 1.19338 acc: 0.70378 | v_loss: 1.41417 v_acc: 0.68620 |  iteration: 8585 teacher: 1 stage: sketch lr: 0.000477\n",
      "batch 1127 loss: 1.32210 acc: 0.70508 | v_loss: 1.16339 v_acc: 0.72298 |  iteration: 8586 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 1128 loss: 1.30566 acc: 0.70638 | v_loss: 1.47907 v_acc: 0.67839 |  iteration: 8587 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 1129 loss: 1.26812 acc: 0.70898 | v_loss: 1.36617 v_acc: 0.69727 |  iteration: 8588 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 1130 loss: 1.30064 acc: 0.70801 | v_loss: 1.35248 v_acc: 0.69238 |  iteration: 8589 teacher: 1 stage: sketch lr: 0.000477\n",
      "batch 1131 loss: 1.26502 acc: 0.70020 | v_loss: 1.30640 v_acc: 0.70182 |  iteration: 8590 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 1132 loss: 1.24554 acc: 0.71582 | v_loss: 1.25067 v_acc: 0.70638 |  iteration: 8591 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 1133 loss: 1.32603 acc: 0.70964 | v_loss: 1.25731 v_acc: 0.70410 |  iteration: 8592 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 1134 loss: 1.31087 acc: 0.70312 | v_loss: 1.21751 v_acc: 0.71842 |  iteration: 8593 teacher: 1 stage: sketch lr: 0.000477\n",
      "batch 1135 loss: 1.26807 acc: 0.71191 | v_loss: 1.40885 v_acc: 0.69108 |  iteration: 8594 teacher: 1 stage: sketch lr: 0.000477\n",
      "batch 1136 loss: 1.22245 acc: 0.70866 | v_loss: 1.29412 v_acc: 0.71126 |  iteration: 8595 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 1137 loss: 1.29109 acc: 0.69792 | v_loss: 1.19045 v_acc: 0.71094 |  iteration: 8596 teacher: 1 stage: sketch lr: 0.000477\n",
      "batch 1138 loss: 1.24453 acc: 0.70475 | v_loss: 1.25350 v_acc: 0.71549 |  iteration: 8597 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 1139 loss: 1.33946 acc: 0.70020 | v_loss: 1.16927 v_acc: 0.70540 |  iteration: 8598 teacher: 1 stage: sketch lr: 0.000477\n",
      "batch 1140 loss: 1.18006 acc: 0.71582 | v_loss: 1.25858 v_acc: 0.69824 |  iteration: 8599 teacher: 1 stage: sketch lr: 0.000477\n",
      "batch 1141 loss: 1.32178 acc: 0.70508 | v_loss: 1.22645 v_acc: 0.71484 |  iteration: 8600 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 1142 loss: 1.22711 acc: 0.70996 | v_loss: 1.16790 v_acc: 0.71647 |  iteration: 8601 teacher: 1 stage: sketch lr: 0.000477\n",
      "batch 1143 loss: 1.27108 acc: 0.70150 | v_loss: 1.12994 v_acc: 0.72819 |  iteration: 8602 teacher: 0 stage: sketch lr: 0.000477\n",
      "batch 1144 loss: 1.24658 acc: 0.69987 | v_loss: 1.26236 v_acc: 0.71517 |  iteration: 8603 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 1145 loss: 1.37244 acc: 0.69271 | v_loss: 1.24453 v_acc: 0.70540 |  iteration: 8604 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 1146 loss: 1.25872 acc: 0.70736 | v_loss: 1.24921 v_acc: 0.70508 |  iteration: 8605 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 1147 loss: 1.34691 acc: 0.69987 | v_loss: 1.10505 v_acc: 0.71452 |  iteration: 8606 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 1148 loss: 1.37138 acc: 0.69629 | v_loss: 1.24510 v_acc: 0.72721 |  iteration: 8607 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 1149 loss: 1.27179 acc: 0.70931 | v_loss: 1.29675 v_acc: 0.69336 |  iteration: 8608 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 1150 loss: 1.26756 acc: 0.69694 | v_loss: 1.29885 v_acc: 0.72331 |  iteration: 8609 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 1151 loss: 1.27276 acc: 0.70540 | v_loss: 1.14900 v_acc: 0.72168 |  iteration: 8610 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 1152 loss: 1.23797 acc: 0.70312 | v_loss: 1.09987 v_acc: 0.73600 |  iteration: 8611 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 1153 loss: 1.29753 acc: 0.71257 | v_loss: 1.10435 v_acc: 0.72266 |  iteration: 8612 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 1154 loss: 1.39470 acc: 0.70117 | v_loss: 1.18789 v_acc: 0.71061 |  iteration: 8613 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 1155 loss: 1.39665 acc: 0.70573 | v_loss: 1.24003 v_acc: 0.69759 |  iteration: 8614 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 1156 loss: 1.31557 acc: 0.69499 | v_loss: 1.19699 v_acc: 0.71191 |  iteration: 8615 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 1157 loss: 1.34655 acc: 0.70768 | v_loss: 1.31510 v_acc: 0.71647 |  iteration: 8616 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 1158 loss: 1.29877 acc: 0.70866 | v_loss: 1.45602 v_acc: 0.69238 |  iteration: 8617 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 1159 loss: 1.34697 acc: 0.71257 | v_loss: 1.34502 v_acc: 0.69954 |  iteration: 8618 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 1160 loss: 1.32620 acc: 0.70085 | v_loss: 1.19730 v_acc: 0.72363 |  iteration: 8619 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 1161 loss: 1.31160 acc: 0.70964 | v_loss: 1.17678 v_acc: 0.70345 |  iteration: 8620 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 1162 loss: 1.36523 acc: 0.69401 | v_loss: 1.17384 v_acc: 0.71582 |  iteration: 8621 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 1163 loss: 1.26834 acc: 0.70475 | v_loss: 1.22614 v_acc: 0.70312 |  iteration: 8622 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 1164 loss: 1.28941 acc: 0.70508 | v_loss: 1.25786 v_acc: 0.71875 |  iteration: 8623 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 1165 loss: 1.25291 acc: 0.71029 | v_loss: 1.21209 v_acc: 0.73177 |  iteration: 8624 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 1166 loss: 1.22463 acc: 0.71159 | v_loss: 1.23254 v_acc: 0.71973 |  iteration: 8625 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 1167 loss: 1.30268 acc: 0.70345 | v_loss: 1.24532 v_acc: 0.70898 |  iteration: 8626 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 1168 loss: 1.25108 acc: 0.72201 | v_loss: 1.15197 v_acc: 0.72689 |  iteration: 8627 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 1169 loss: 1.26746 acc: 0.71452 | v_loss: 1.12196 v_acc: 0.72005 |  iteration: 8628 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 1170 loss: 1.26818 acc: 0.70605 | v_loss: 1.42209 v_acc: 0.69303 |  iteration: 8629 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 1171 loss: 1.31593 acc: 0.70801 | v_loss: 1.20883 v_acc: 0.71094 |  iteration: 8630 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 1172 loss: 1.32255 acc: 0.69954 | v_loss: 1.21347 v_acc: 0.71680 |  iteration: 8631 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 1173 loss: 1.26817 acc: 0.71484 | v_loss: 1.20681 v_acc: 0.72038 |  iteration: 8632 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 1174 loss: 1.28405 acc: 0.70378 | v_loss: 1.27728 v_acc: 0.70443 |  iteration: 8633 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 1175 loss: 1.32566 acc: 0.70475 | v_loss: 1.13765 v_acc: 0.73405 |  iteration: 8634 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 1176 loss: 1.26895 acc: 0.70085 | v_loss: 1.37077 v_acc: 0.71615 |  iteration: 8635 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 1177 loss: 1.38694 acc: 0.69531 | v_loss: 1.19173 v_acc: 0.69759 |  iteration: 8636 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 1178 loss: 1.28284 acc: 0.70866 | v_loss: 1.20432 v_acc: 0.70703 |  iteration: 8637 teacher: 1 stage: sketch lr: 0.000476\n",
      "batch 1179 loss: 1.25860 acc: 0.71029 | v_loss: 1.25408 v_acc: 0.70540 |  iteration: 8638 teacher: 0 stage: sketch lr: 0.000476\n",
      "batch 1180 loss: 1.22433 acc: 0.71061 | v_loss: 1.26792 v_acc: 0.70215 |  iteration: 8639 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 1181 loss: 1.19111 acc: 0.71029 | v_loss: 1.32845 v_acc: 0.69466 |  iteration: 8640 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 1182 loss: 1.34308 acc: 0.70182 | v_loss: 1.35930 v_acc: 0.70671 |  iteration: 8641 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 1183 loss: 1.33703 acc: 0.71094 | v_loss: 1.28585 v_acc: 0.70182 |  iteration: 8642 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 1184 loss: 1.27648 acc: 0.70312 | v_loss: 1.19634 v_acc: 0.70996 |  iteration: 8643 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 1185 loss: 1.32310 acc: 0.70508 | v_loss: 1.30331 v_acc: 0.70605 |  iteration: 8644 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 1186 loss: 1.31908 acc: 0.69629 | v_loss: 1.21738 v_acc: 0.71777 |  iteration: 8645 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 1187 loss: 1.28766 acc: 0.69499 | v_loss: 1.14149 v_acc: 0.72005 |  iteration: 8646 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 1188 loss: 1.22471 acc: 0.70410 | v_loss: 1.13231 v_acc: 0.71029 |  iteration: 8647 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 1189 loss: 1.27919 acc: 0.70410 | v_loss: 1.26340 v_acc: 0.70540 |  iteration: 8648 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 1190 loss: 1.22236 acc: 0.71842 | v_loss: 1.32582 v_acc: 0.69727 |  iteration: 8649 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 1191 loss: 1.31780 acc: 0.69629 | v_loss: 1.16816 v_acc: 0.70508 |  iteration: 8650 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 1192 loss: 1.28315 acc: 0.70508 | v_loss: 1.20432 v_acc: 0.69531 |  iteration: 8651 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 1193 loss: 1.25449 acc: 0.70508 | v_loss: 1.18805 v_acc: 0.70801 |  iteration: 8652 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 1194 loss: 1.28499 acc: 0.70312 | v_loss: 1.20767 v_acc: 0.70312 |  iteration: 8653 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 1195 loss: 1.20284 acc: 0.71289 | v_loss: 1.05065 v_acc: 0.73893 |  iteration: 8654 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 1196 loss: 1.35755 acc: 0.69694 | v_loss: 1.18218 v_acc: 0.71647 |  iteration: 8655 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 1197 loss: 1.25603 acc: 0.71094 | v_loss: 1.11581 v_acc: 0.73405 |  iteration: 8656 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 1198 loss: 1.27243 acc: 0.70964 | v_loss: 1.12268 v_acc: 0.72103 |  iteration: 8657 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 1199 loss: 1.29330 acc: 0.69368 | v_loss: 1.19560 v_acc: 0.71940 |  iteration: 8658 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 1200 loss: 1.29164 acc: 0.69954 | v_loss: 1.21222 v_acc: 0.71484 |  iteration: 8659 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 1201 loss: 1.32782 acc: 0.69857 | v_loss: 1.18830 v_acc: 0.71810 |  iteration: 8660 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 1202 loss: 1.27117 acc: 0.71126 | v_loss: 1.39204 v_acc: 0.69987 |  iteration: 8661 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 1203 loss: 1.37027 acc: 0.69564 | v_loss: 1.26432 v_acc: 0.71549 |  iteration: 8662 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 1204 loss: 1.25483 acc: 0.71908 | v_loss: 1.06087 v_acc: 0.74544 |  iteration: 8663 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 1205 loss: 1.27494 acc: 0.70052 | v_loss: 1.21012 v_acc: 0.70345 |  iteration: 8664 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 1206 loss: 1.35651 acc: 0.68978 | v_loss: 1.28730 v_acc: 0.69531 |  iteration: 8665 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 1207 loss: 1.27004 acc: 0.70475 | v_loss: 1.19384 v_acc: 0.71029 |  iteration: 8666 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 1208 loss: 1.30296 acc: 0.69434 | v_loss: 1.25881 v_acc: 0.71615 |  iteration: 8667 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 1209 loss: 1.33639 acc: 0.69434 | v_loss: 1.25472 v_acc: 0.69043 |  iteration: 8668 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 1210 loss: 1.30546 acc: 0.70475 | v_loss: 1.20296 v_acc: 0.71842 |  iteration: 8669 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 1211 loss: 1.29472 acc: 0.70280 | v_loss: 1.25026 v_acc: 0.69987 |  iteration: 8670 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 1212 loss: 1.25142 acc: 0.70378 | v_loss: 1.20367 v_acc: 0.71387 |  iteration: 8671 teacher: 0 stage: sketch lr: 0.000475\n",
      "batch 1213 loss: 1.33739 acc: 0.69824 | v_loss: 1.18157 v_acc: 0.72786 |  iteration: 8672 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 1214 loss: 1.28554 acc: 0.70280 | v_loss: 1.25036 v_acc: 0.70540 |  iteration: 8673 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 1215 loss: 1.24425 acc: 0.70833 | v_loss: 1.32954 v_acc: 0.69857 |  iteration: 8674 teacher: 1 stage: sketch lr: 0.000475\n",
      "batch 1216 loss: 1.21634 acc: 0.71549 | v_loss: 1.15352 v_acc: 0.70833 |  iteration: 8675 teacher: 0 stage: sketch lr: 0.000474\n",
      "batch 1217 loss: 1.37909 acc: 0.69206 | v_loss: 1.41320 v_acc: 0.68522 |  iteration: 8676 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 1218 loss: 1.22927 acc: 0.71777 | v_loss: 1.16188 v_acc: 0.72168 |  iteration: 8677 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 1219 loss: 1.29328 acc: 0.70833 | v_loss: 1.47975 v_acc: 0.67969 |  iteration: 8678 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 1220 loss: 1.30247 acc: 0.69564 | v_loss: 1.37139 v_acc: 0.69661 |  iteration: 8679 teacher: 0 stage: sketch lr: 0.000474\n",
      "batch 1221 loss: 1.27625 acc: 0.70410 | v_loss: 1.33092 v_acc: 0.69141 |  iteration: 8680 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 1222 loss: 1.32802 acc: 0.69954 | v_loss: 1.32676 v_acc: 0.69661 |  iteration: 8681 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 1223 loss: 1.26207 acc: 0.70443 | v_loss: 1.23331 v_acc: 0.70540 |  iteration: 8682 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 1224 loss: 1.25659 acc: 0.70638 | v_loss: 1.27375 v_acc: 0.70443 |  iteration: 8683 teacher: 0 stage: sketch lr: 0.000474\n",
      "batch 1225 loss: 1.27288 acc: 0.70378 | v_loss: 1.24092 v_acc: 0.71647 |  iteration: 8684 teacher: 0 stage: sketch lr: 0.000474\n",
      "batch 1226 loss: 1.31348 acc: 0.70247 | v_loss: 1.42983 v_acc: 0.68197 |  iteration: 8685 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 1227 loss: 1.42876 acc: 0.69499 | v_loss: 1.30705 v_acc: 0.70833 |  iteration: 8686 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 1228 loss: 1.24365 acc: 0.71745 | v_loss: 1.20008 v_acc: 0.70182 |  iteration: 8687 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 1229 loss: 1.37259 acc: 0.69108 | v_loss: 1.28732 v_acc: 0.70085 |  iteration: 8688 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 1230 loss: 1.28396 acc: 0.70312 | v_loss: 1.17185 v_acc: 0.70508 |  iteration: 8689 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 1231 loss: 1.31765 acc: 0.69173 | v_loss: 1.27257 v_acc: 0.69596 |  iteration: 8690 teacher: 0 stage: sketch lr: 0.000474\n",
      "batch 1232 loss: 1.38118 acc: 0.68555 | v_loss: 1.24308 v_acc: 0.71029 |  iteration: 8691 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 1233 loss: 1.26871 acc: 0.70801 | v_loss: 1.17273 v_acc: 0.71647 |  iteration: 8692 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 1234 loss: 1.31061 acc: 0.70182 | v_loss: 1.13132 v_acc: 0.72591 |  iteration: 8693 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 1235 loss: 1.28178 acc: 0.70573 | v_loss: 1.25048 v_acc: 0.72266 |  iteration: 8694 teacher: 0 stage: sketch lr: 0.000474\n",
      "batch 1236 loss: 1.20419 acc: 0.70801 | v_loss: 1.25011 v_acc: 0.70410 |  iteration: 8695 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 1237 loss: 1.23722 acc: 0.70964 | v_loss: 1.25433 v_acc: 0.70833 |  iteration: 8696 teacher: 0 stage: sketch lr: 0.000474\n",
      "batch 1238 loss: 1.34388 acc: 0.69466 | v_loss: 1.09666 v_acc: 0.72591 |  iteration: 8697 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 1239 loss: 1.24151 acc: 0.70378 | v_loss: 1.24635 v_acc: 0.73112 |  iteration: 8698 teacher: 0 stage: sketch lr: 0.000474\n",
      "batch 1240 loss: 1.36502 acc: 0.69531 | v_loss: 1.29629 v_acc: 0.69727 |  iteration: 8699 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 1241 loss: 1.32307 acc: 0.69368 | v_loss: 1.30375 v_acc: 0.72135 |  iteration: 8700 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 1242 loss: 1.21364 acc: 0.70833 | v_loss: 1.16652 v_acc: 0.71842 |  iteration: 8701 teacher: 1 stage: sketch lr: 0.000474\n",
      "epoch 6 loss: 1.29370 acc: 0.70411 | v_loss: 1.23842 v_acc: 0.71012 \n",
      "epoch: 7\n",
      "__________________________________________\n",
      "batch 0 loss: 1.30503 acc: 0.70964 | v_loss: 1.27980 v_acc: 0.70345 |  iteration: 8702 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 1 loss: 1.31495 acc: 0.70280 | v_loss: 1.20066 v_acc: 0.70996 |  iteration: 8703 teacher: 0 stage: sketch lr: 0.000474\n",
      "batch 2 loss: 1.27426 acc: 0.70443 | v_loss: 1.30907 v_acc: 0.70638 |  iteration: 8704 teacher: 0 stage: sketch lr: 0.000474\n",
      "batch 3 loss: 1.33879 acc: 0.69759 | v_loss: 1.21537 v_acc: 0.71159 |  iteration: 8705 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 4 loss: 1.24015 acc: 0.70605 | v_loss: 1.14789 v_acc: 0.72331 |  iteration: 8706 teacher: 1 stage: sketch lr: 0.000474\n",
      "batch 5 loss: 1.23164 acc: 0.71094 | v_loss: 1.13322 v_acc: 0.70996 |  iteration: 8707 teacher: 0 stage: sketch lr: 0.000474\n",
      "batch 6 loss: 1.37603 acc: 0.69238 | v_loss: 1.25910 v_acc: 0.70443 |  iteration: 8708 teacher: 0 stage: sketch lr: 0.000474\n",
      "batch 7 loss: 1.24032 acc: 0.71224 | v_loss: 1.32348 v_acc: 0.69727 |  iteration: 8709 teacher: 0 stage: sketch lr: 0.000474\n",
      "batch 8 loss: 1.35614 acc: 0.69206 | v_loss: 1.14947 v_acc: 0.70801 |  iteration: 8710 teacher: 0 stage: sketch lr: 0.000474\n",
      "batch 9 loss: 1.29764 acc: 0.69694 | v_loss: 1.19161 v_acc: 0.70215 |  iteration: 8711 teacher: 0 stage: sketch lr: 0.000474\n",
      "batch 10 loss: 1.25251 acc: 0.71647 | v_loss: 1.18408 v_acc: 0.71680 |  iteration: 8712 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 11 loss: 1.26831 acc: 0.70410 | v_loss: 1.20005 v_acc: 0.70671 |  iteration: 8713 teacher: 1 stage: sketch lr: 0.000473\n",
      "batch 12 loss: 1.24362 acc: 0.71354 | v_loss: 1.06317 v_acc: 0.73503 |  iteration: 8714 teacher: 1 stage: sketch lr: 0.000473\n",
      "batch 13 loss: 1.31115 acc: 0.70150 | v_loss: 1.16379 v_acc: 0.72331 |  iteration: 8715 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 14 loss: 1.38568 acc: 0.69466 | v_loss: 1.17840 v_acc: 0.72689 |  iteration: 8716 teacher: 1 stage: sketch lr: 0.000473\n",
      "batch 15 loss: 1.28457 acc: 0.70801 | v_loss: 1.13340 v_acc: 0.72331 |  iteration: 8717 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 16 loss: 1.32805 acc: 0.70573 | v_loss: 1.20706 v_acc: 0.71842 |  iteration: 8718 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 17 loss: 1.23836 acc: 0.70443 | v_loss: 1.24028 v_acc: 0.71191 |  iteration: 8719 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 18 loss: 1.36804 acc: 0.69531 | v_loss: 1.20993 v_acc: 0.71973 |  iteration: 8720 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 19 loss: 1.22045 acc: 0.70801 | v_loss: 1.38313 v_acc: 0.69987 |  iteration: 8721 teacher: 1 stage: sketch lr: 0.000473\n",
      "batch 20 loss: 1.33659 acc: 0.70378 | v_loss: 1.26512 v_acc: 0.71549 |  iteration: 8722 teacher: 1 stage: sketch lr: 0.000473\n",
      "batch 21 loss: 1.33361 acc: 0.70540 | v_loss: 1.05649 v_acc: 0.74740 |  iteration: 8723 teacher: 1 stage: sketch lr: 0.000473\n",
      "batch 22 loss: 1.24780 acc: 0.72070 | v_loss: 1.23469 v_acc: 0.70247 |  iteration: 8724 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 23 loss: 1.29995 acc: 0.70508 | v_loss: 1.25533 v_acc: 0.70280 |  iteration: 8725 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 24 loss: 1.24783 acc: 0.71354 | v_loss: 1.21763 v_acc: 0.71647 |  iteration: 8726 teacher: 1 stage: sketch lr: 0.000473\n",
      "batch 25 loss: 1.23646 acc: 0.70703 | v_loss: 1.25005 v_acc: 0.71061 |  iteration: 8727 teacher: 1 stage: sketch lr: 0.000473\n",
      "batch 26 loss: 1.23325 acc: 0.71452 | v_loss: 1.24837 v_acc: 0.69043 |  iteration: 8728 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 27 loss: 1.30932 acc: 0.70378 | v_loss: 1.23407 v_acc: 0.70996 |  iteration: 8729 teacher: 1 stage: sketch lr: 0.000473\n",
      "batch 28 loss: 1.24878 acc: 0.70638 | v_loss: 1.27187 v_acc: 0.70020 |  iteration: 8730 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 29 loss: 1.32589 acc: 0.69824 | v_loss: 1.16772 v_acc: 0.71582 |  iteration: 8731 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 30 loss: 1.29287 acc: 0.70703 | v_loss: 1.17242 v_acc: 0.72559 |  iteration: 8732 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 31 loss: 1.26532 acc: 0.69987 | v_loss: 1.24112 v_acc: 0.70540 |  iteration: 8733 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 32 loss: 1.32415 acc: 0.70085 | v_loss: 1.32840 v_acc: 0.69857 |  iteration: 8734 teacher: 1 stage: sketch lr: 0.000473\n",
      "batch 33 loss: 1.38046 acc: 0.68945 | v_loss: 1.15686 v_acc: 0.70573 |  iteration: 8735 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 34 loss: 1.28725 acc: 0.71322 | v_loss: 1.40944 v_acc: 0.68555 |  iteration: 8736 teacher: 1 stage: sketch lr: 0.000473\n",
      "batch 35 loss: 1.30953 acc: 0.68945 | v_loss: 1.18530 v_acc: 0.71842 |  iteration: 8737 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 36 loss: 1.39859 acc: 0.69368 | v_loss: 1.46340 v_acc: 0.68555 |  iteration: 8738 teacher: 1 stage: sketch lr: 0.000473\n",
      "batch 37 loss: 1.33154 acc: 0.69857 | v_loss: 1.36250 v_acc: 0.69596 |  iteration: 8739 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 38 loss: 1.27931 acc: 0.70312 | v_loss: 1.32565 v_acc: 0.69336 |  iteration: 8740 teacher: 1 stage: sketch lr: 0.000473\n",
      "batch 39 loss: 1.32085 acc: 0.70117 | v_loss: 1.32090 v_acc: 0.69466 |  iteration: 8741 teacher: 1 stage: sketch lr: 0.000473\n",
      "batch 40 loss: 1.27020 acc: 0.71289 | v_loss: 1.24088 v_acc: 0.70573 |  iteration: 8742 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 41 loss: 1.33181 acc: 0.69466 | v_loss: 1.27655 v_acc: 0.70280 |  iteration: 8743 teacher: 1 stage: sketch lr: 0.000473\n",
      "batch 42 loss: 1.22852 acc: 0.71159 | v_loss: 1.23312 v_acc: 0.71615 |  iteration: 8744 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 43 loss: 1.21774 acc: 0.71061 | v_loss: 1.40949 v_acc: 0.68945 |  iteration: 8745 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 44 loss: 1.25338 acc: 0.71257 | v_loss: 1.30995 v_acc: 0.70671 |  iteration: 8746 teacher: 1 stage: sketch lr: 0.000473\n",
      "batch 45 loss: 1.32601 acc: 0.69596 | v_loss: 1.17597 v_acc: 0.70833 |  iteration: 8747 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 46 loss: 1.22142 acc: 0.71289 | v_loss: 1.26188 v_acc: 0.71712 |  iteration: 8748 teacher: 0 stage: sketch lr: 0.000473\n",
      "batch 47 loss: 1.29054 acc: 0.70378 | v_loss: 1.16908 v_acc: 0.70605 |  iteration: 8749 teacher: 1 stage: sketch lr: 0.000472\n",
      "batch 48 loss: 1.26385 acc: 0.70996 | v_loss: 1.25790 v_acc: 0.70280 |  iteration: 8750 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 49 loss: 1.28419 acc: 0.70345 | v_loss: 1.22467 v_acc: 0.71354 |  iteration: 8751 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 50 loss: 1.28793 acc: 0.69922 | v_loss: 1.16430 v_acc: 0.72135 |  iteration: 8752 teacher: 1 stage: sketch lr: 0.000472\n",
      "batch 51 loss: 1.25435 acc: 0.70020 | v_loss: 1.13231 v_acc: 0.72526 |  iteration: 8753 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 52 loss: 1.21310 acc: 0.71452 | v_loss: 1.25676 v_acc: 0.71908 |  iteration: 8754 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 53 loss: 1.26687 acc: 0.71484 | v_loss: 1.25214 v_acc: 0.70410 |  iteration: 8755 teacher: 1 stage: sketch lr: 0.000472\n",
      "batch 54 loss: 1.26192 acc: 0.70345 | v_loss: 1.26527 v_acc: 0.70605 |  iteration: 8756 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 55 loss: 1.29199 acc: 0.69303 | v_loss: 1.10994 v_acc: 0.71745 |  iteration: 8757 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 56 loss: 1.34107 acc: 0.69889 | v_loss: 1.24474 v_acc: 0.72721 |  iteration: 8758 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 57 loss: 1.33959 acc: 0.69661 | v_loss: 1.31086 v_acc: 0.69531 |  iteration: 8759 teacher: 1 stage: sketch lr: 0.000472\n",
      "batch 58 loss: 1.26535 acc: 0.71680 | v_loss: 1.31154 v_acc: 0.72461 |  iteration: 8760 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 59 loss: 1.31995 acc: 0.69889 | v_loss: 1.15461 v_acc: 0.71777 |  iteration: 8761 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 60 loss: 1.28454 acc: 0.70964 | v_loss: 1.09487 v_acc: 0.73600 |  iteration: 8762 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 61 loss: 1.28262 acc: 0.70605 | v_loss: 1.11205 v_acc: 0.72396 |  iteration: 8763 teacher: 1 stage: sketch lr: 0.000472\n",
      "batch 62 loss: 1.32443 acc: 0.70378 | v_loss: 1.18472 v_acc: 0.70964 |  iteration: 8764 teacher: 1 stage: sketch lr: 0.000472\n",
      "batch 63 loss: 1.16532 acc: 0.71484 | v_loss: 1.23450 v_acc: 0.70215 |  iteration: 8765 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 64 loss: 1.21176 acc: 0.70964 | v_loss: 1.19022 v_acc: 0.71419 |  iteration: 8766 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 65 loss: 1.25698 acc: 0.70638 | v_loss: 1.32681 v_acc: 0.70475 |  iteration: 8767 teacher: 1 stage: sketch lr: 0.000472\n",
      "batch 66 loss: 1.31078 acc: 0.70573 | v_loss: 1.47685 v_acc: 0.69141 |  iteration: 8768 teacher: 1 stage: sketch lr: 0.000472\n",
      "batch 67 loss: 1.30094 acc: 0.70866 | v_loss: 1.34189 v_acc: 0.69727 |  iteration: 8769 teacher: 1 stage: sketch lr: 0.000472\n",
      "batch 68 loss: 1.29805 acc: 0.70117 | v_loss: 1.18786 v_acc: 0.72396 |  iteration: 8770 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 69 loss: 1.28195 acc: 0.70833 | v_loss: 1.15151 v_acc: 0.70312 |  iteration: 8771 teacher: 1 stage: sketch lr: 0.000472\n",
      "batch 70 loss: 1.32144 acc: 0.70345 | v_loss: 1.16210 v_acc: 0.71582 |  iteration: 8772 teacher: 1 stage: sketch lr: 0.000472\n",
      "batch 71 loss: 1.24511 acc: 0.71257 | v_loss: 1.22288 v_acc: 0.70020 |  iteration: 8773 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 72 loss: 1.39213 acc: 0.69792 | v_loss: 1.25875 v_acc: 0.71061 |  iteration: 8774 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 73 loss: 1.25604 acc: 0.71810 | v_loss: 1.20789 v_acc: 0.73145 |  iteration: 8775 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 74 loss: 1.37436 acc: 0.69434 | v_loss: 1.23174 v_acc: 0.71973 |  iteration: 8776 teacher: 1 stage: sketch lr: 0.000472\n",
      "batch 75 loss: 1.36169 acc: 0.70052 | v_loss: 1.24744 v_acc: 0.70605 |  iteration: 8777 teacher: 1 stage: sketch lr: 0.000472\n",
      "batch 76 loss: 1.26691 acc: 0.70182 | v_loss: 1.16195 v_acc: 0.72168 |  iteration: 8778 teacher: 1 stage: sketch lr: 0.000472\n",
      "batch 77 loss: 1.27453 acc: 0.70703 | v_loss: 1.12911 v_acc: 0.72201 |  iteration: 8779 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 78 loss: 1.31089 acc: 0.70833 | v_loss: 1.43331 v_acc: 0.69271 |  iteration: 8780 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 79 loss: 1.38868 acc: 0.68978 | v_loss: 1.20694 v_acc: 0.70768 |  iteration: 8781 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 80 loss: 1.30912 acc: 0.69661 | v_loss: 1.22408 v_acc: 0.71973 |  iteration: 8782 teacher: 1 stage: sketch lr: 0.000472\n",
      "batch 81 loss: 1.30033 acc: 0.70801 | v_loss: 1.22433 v_acc: 0.71484 |  iteration: 8783 teacher: 1 stage: sketch lr: 0.000472\n",
      "batch 82 loss: 1.43501 acc: 0.68880 | v_loss: 1.28056 v_acc: 0.70540 |  iteration: 8784 teacher: 0 stage: sketch lr: 0.000472\n",
      "batch 83 loss: 1.35559 acc: 0.70280 | v_loss: 1.14069 v_acc: 0.73112 |  iteration: 8785 teacher: 1 stage: sketch lr: 0.000472\n",
      "batch 84 loss: 1.37324 acc: 0.68685 | v_loss: 1.36809 v_acc: 0.71745 |  iteration: 8786 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 85 loss: 1.32837 acc: 0.70020 | v_loss: 1.20207 v_acc: 0.70150 |  iteration: 8787 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 86 loss: 1.25841 acc: 0.71029 | v_loss: 1.21539 v_acc: 0.70833 |  iteration: 8788 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 87 loss: 1.26386 acc: 0.70312 | v_loss: 1.26838 v_acc: 0.70443 |  iteration: 8789 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 88 loss: 1.30528 acc: 0.70475 | v_loss: 1.27984 v_acc: 0.70443 |  iteration: 8790 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 89 loss: 1.23422 acc: 0.70866 | v_loss: 1.34125 v_acc: 0.68848 |  iteration: 8791 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 90 loss: 1.25096 acc: 0.71029 | v_loss: 1.36684 v_acc: 0.70638 |  iteration: 8792 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 91 loss: 1.31970 acc: 0.69466 | v_loss: 1.29180 v_acc: 0.70540 |  iteration: 8793 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 92 loss: 1.24498 acc: 0.70866 | v_loss: 1.19888 v_acc: 0.70703 |  iteration: 8794 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 93 loss: 1.33111 acc: 0.69499 | v_loss: 1.32973 v_acc: 0.70443 |  iteration: 8795 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 94 loss: 1.24842 acc: 0.70703 | v_loss: 1.21100 v_acc: 0.71940 |  iteration: 8796 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 95 loss: 1.28727 acc: 0.70085 | v_loss: 1.13273 v_acc: 0.72461 |  iteration: 8797 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 96 loss: 1.27268 acc: 0.71159 | v_loss: 1.13370 v_acc: 0.70833 |  iteration: 8798 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 97 loss: 1.38184 acc: 0.69303 | v_loss: 1.24962 v_acc: 0.70605 |  iteration: 8799 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 98 loss: 1.28743 acc: 0.70801 | v_loss: 1.32457 v_acc: 0.69954 |  iteration: 8800 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 99 loss: 1.27085 acc: 0.70768 | v_loss: 1.16071 v_acc: 0.71484 |  iteration: 8801 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 100 loss: 1.33336 acc: 0.69922 | v_loss: 1.20497 v_acc: 0.70085 |  iteration: 8802 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 101 loss: 1.31520 acc: 0.69922 | v_loss: 1.18759 v_acc: 0.71354 |  iteration: 8803 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 102 loss: 1.26625 acc: 0.70736 | v_loss: 1.21880 v_acc: 0.70508 |  iteration: 8804 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 103 loss: 1.32426 acc: 0.69401 | v_loss: 1.09160 v_acc: 0.73372 |  iteration: 8805 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 104 loss: 1.33474 acc: 0.70475 | v_loss: 1.17936 v_acc: 0.71680 |  iteration: 8806 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 105 loss: 1.32046 acc: 0.69954 | v_loss: 1.14587 v_acc: 0.74089 |  iteration: 8807 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 106 loss: 1.25449 acc: 0.71061 | v_loss: 1.12741 v_acc: 0.72038 |  iteration: 8808 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 107 loss: 1.37120 acc: 0.69727 | v_loss: 1.20386 v_acc: 0.71582 |  iteration: 8809 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 108 loss: 1.35283 acc: 0.69857 | v_loss: 1.22373 v_acc: 0.71322 |  iteration: 8810 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 109 loss: 1.34480 acc: 0.70020 | v_loss: 1.20649 v_acc: 0.71940 |  iteration: 8811 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 110 loss: 1.26119 acc: 0.70345 | v_loss: 1.39013 v_acc: 0.69759 |  iteration: 8812 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 111 loss: 1.21518 acc: 0.70996 | v_loss: 1.25893 v_acc: 0.71875 |  iteration: 8813 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 112 loss: 1.30146 acc: 0.71094 | v_loss: 1.05563 v_acc: 0.74382 |  iteration: 8814 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 113 loss: 1.34205 acc: 0.69564 | v_loss: 1.22512 v_acc: 0.70312 |  iteration: 8815 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 114 loss: 1.25769 acc: 0.70378 | v_loss: 1.25999 v_acc: 0.70247 |  iteration: 8816 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 115 loss: 1.31636 acc: 0.69922 | v_loss: 1.20531 v_acc: 0.70833 |  iteration: 8817 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 116 loss: 1.30152 acc: 0.71094 | v_loss: 1.24617 v_acc: 0.71061 |  iteration: 8818 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 117 loss: 1.39208 acc: 0.69759 | v_loss: 1.24939 v_acc: 0.69043 |  iteration: 8819 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 118 loss: 1.25802 acc: 0.70671 | v_loss: 1.23419 v_acc: 0.70898 |  iteration: 8820 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 119 loss: 1.23534 acc: 0.70247 | v_loss: 1.26330 v_acc: 0.69434 |  iteration: 8821 teacher: 0 stage: sketch lr: 0.000471\n",
      "batch 120 loss: 1.35434 acc: 0.69010 | v_loss: 1.17422 v_acc: 0.71094 |  iteration: 8822 teacher: 1 stage: sketch lr: 0.000471\n",
      "batch 121 loss: 1.36333 acc: 0.69694 | v_loss: 1.17401 v_acc: 0.72559 |  iteration: 8823 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 122 loss: 1.20650 acc: 0.71549 | v_loss: 1.23031 v_acc: 0.70312 |  iteration: 8824 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 123 loss: 1.22658 acc: 0.71126 | v_loss: 1.33659 v_acc: 0.70020 |  iteration: 8825 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 124 loss: 1.24328 acc: 0.70996 | v_loss: 1.15238 v_acc: 0.70833 |  iteration: 8826 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 125 loss: 1.27347 acc: 0.70736 | v_loss: 1.40133 v_acc: 0.68717 |  iteration: 8827 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 126 loss: 1.31036 acc: 0.70215 | v_loss: 1.16703 v_acc: 0.72201 |  iteration: 8828 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 127 loss: 1.33068 acc: 0.70443 | v_loss: 1.46501 v_acc: 0.68294 |  iteration: 8829 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 128 loss: 1.17963 acc: 0.71517 | v_loss: 1.34809 v_acc: 0.70020 |  iteration: 8830 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 129 loss: 1.23957 acc: 0.70443 | v_loss: 1.33332 v_acc: 0.68913 |  iteration: 8831 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 130 loss: 1.27049 acc: 0.70931 | v_loss: 1.31320 v_acc: 0.69759 |  iteration: 8832 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 131 loss: 1.32197 acc: 0.70247 | v_loss: 1.23169 v_acc: 0.70215 |  iteration: 8833 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 132 loss: 1.26247 acc: 0.70508 | v_loss: 1.26160 v_acc: 0.70215 |  iteration: 8834 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 133 loss: 1.35900 acc: 0.69922 | v_loss: 1.21274 v_acc: 0.71615 |  iteration: 8835 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 134 loss: 1.34164 acc: 0.70573 | v_loss: 1.42820 v_acc: 0.69076 |  iteration: 8836 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 135 loss: 1.21719 acc: 0.71126 | v_loss: 1.30652 v_acc: 0.71387 |  iteration: 8837 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 136 loss: 1.31162 acc: 0.70312 | v_loss: 1.17276 v_acc: 0.70833 |  iteration: 8838 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 137 loss: 1.25205 acc: 0.70443 | v_loss: 1.27056 v_acc: 0.70768 |  iteration: 8839 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 138 loss: 1.33147 acc: 0.70508 | v_loss: 1.18050 v_acc: 0.70020 |  iteration: 8840 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 139 loss: 1.28446 acc: 0.70215 | v_loss: 1.25987 v_acc: 0.70150 |  iteration: 8841 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 140 loss: 1.26958 acc: 0.71061 | v_loss: 1.23217 v_acc: 0.71549 |  iteration: 8842 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 141 loss: 1.22180 acc: 0.71875 | v_loss: 1.16653 v_acc: 0.71549 |  iteration: 8843 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 142 loss: 1.29413 acc: 0.70247 | v_loss: 1.14609 v_acc: 0.72363 |  iteration: 8844 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 143 loss: 1.35962 acc: 0.69303 | v_loss: 1.27200 v_acc: 0.71322 |  iteration: 8845 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 144 loss: 1.19913 acc: 0.70638 | v_loss: 1.24849 v_acc: 0.70475 |  iteration: 8846 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 145 loss: 1.29057 acc: 0.70378 | v_loss: 1.25007 v_acc: 0.71159 |  iteration: 8847 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 146 loss: 1.29173 acc: 0.71159 | v_loss: 1.10494 v_acc: 0.72461 |  iteration: 8848 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 147 loss: 1.31713 acc: 0.70182 | v_loss: 1.23277 v_acc: 0.73047 |  iteration: 8849 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 148 loss: 1.30936 acc: 0.70671 | v_loss: 1.29778 v_acc: 0.69792 |  iteration: 8850 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 149 loss: 1.24379 acc: 0.71745 | v_loss: 1.29424 v_acc: 0.72103 |  iteration: 8851 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 150 loss: 1.19049 acc: 0.71745 | v_loss: 1.15528 v_acc: 0.72201 |  iteration: 8852 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 151 loss: 1.26980 acc: 0.69922 | v_loss: 1.10767 v_acc: 0.73503 |  iteration: 8853 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 152 loss: 1.24021 acc: 0.70215 | v_loss: 1.09999 v_acc: 0.72331 |  iteration: 8854 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 153 loss: 1.35125 acc: 0.69727 | v_loss: 1.18420 v_acc: 0.70801 |  iteration: 8855 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 154 loss: 1.35695 acc: 0.70312 | v_loss: 1.22660 v_acc: 0.69629 |  iteration: 8856 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 155 loss: 1.31534 acc: 0.70312 | v_loss: 1.20557 v_acc: 0.70996 |  iteration: 8857 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 156 loss: 1.24716 acc: 0.71029 | v_loss: 1.33871 v_acc: 0.70312 |  iteration: 8858 teacher: 0 stage: sketch lr: 0.000470\n",
      "batch 157 loss: 1.28791 acc: 0.70345 | v_loss: 1.47311 v_acc: 0.69173 |  iteration: 8859 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 158 loss: 1.33234 acc: 0.69824 | v_loss: 1.34828 v_acc: 0.70117 |  iteration: 8860 teacher: 1 stage: sketch lr: 0.000470\n",
      "batch 159 loss: 1.30153 acc: 0.69987 | v_loss: 1.19555 v_acc: 0.72070 |  iteration: 8861 teacher: 1 stage: sketch lr: 0.000469\n",
      "batch 160 loss: 1.32477 acc: 0.70378 | v_loss: 1.16508 v_acc: 0.70931 |  iteration: 8862 teacher: 1 stage: sketch lr: 0.000469\n",
      "batch 161 loss: 1.27781 acc: 0.70085 | v_loss: 1.16174 v_acc: 0.72396 |  iteration: 8863 teacher: 1 stage: sketch lr: 0.000469\n",
      "batch 162 loss: 1.28085 acc: 0.69596 | v_loss: 1.23196 v_acc: 0.70475 |  iteration: 8864 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 163 loss: 1.29408 acc: 0.70280 | v_loss: 1.24636 v_acc: 0.71875 |  iteration: 8865 teacher: 1 stage: sketch lr: 0.000469\n",
      "batch 164 loss: 1.42481 acc: 0.68587 | v_loss: 1.22100 v_acc: 0.73014 |  iteration: 8866 teacher: 1 stage: sketch lr: 0.000469\n",
      "batch 165 loss: 1.29944 acc: 0.71029 | v_loss: 1.24437 v_acc: 0.71973 |  iteration: 8867 teacher: 1 stage: sketch lr: 0.000469\n",
      "batch 166 loss: 1.25989 acc: 0.70736 | v_loss: 1.23867 v_acc: 0.70964 |  iteration: 8868 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 167 loss: 1.28774 acc: 0.70182 | v_loss: 1.15055 v_acc: 0.72493 |  iteration: 8869 teacher: 1 stage: sketch lr: 0.000469\n",
      "batch 168 loss: 1.31480 acc: 0.69792 | v_loss: 1.12671 v_acc: 0.72038 |  iteration: 8870 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 169 loss: 1.27841 acc: 0.70801 | v_loss: 1.42680 v_acc: 0.69206 |  iteration: 8871 teacher: 1 stage: sketch lr: 0.000469\n",
      "batch 170 loss: 1.22551 acc: 0.71126 | v_loss: 1.20645 v_acc: 0.70996 |  iteration: 8872 teacher: 1 stage: sketch lr: 0.000469\n",
      "batch 171 loss: 1.30550 acc: 0.69922 | v_loss: 1.24557 v_acc: 0.71647 |  iteration: 8873 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 172 loss: 1.31921 acc: 0.69759 | v_loss: 1.23088 v_acc: 0.71875 |  iteration: 8874 teacher: 1 stage: sketch lr: 0.000469\n",
      "batch 173 loss: 1.38117 acc: 0.69987 | v_loss: 1.28052 v_acc: 0.70410 |  iteration: 8875 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 174 loss: 1.32398 acc: 0.70801 | v_loss: 1.13408 v_acc: 0.73145 |  iteration: 8876 teacher: 1 stage: sketch lr: 0.000469\n",
      "batch 175 loss: 1.26477 acc: 0.70898 | v_loss: 1.35389 v_acc: 0.71452 |  iteration: 8877 teacher: 1 stage: sketch lr: 0.000469\n",
      "batch 176 loss: 1.25610 acc: 0.72103 | v_loss: 1.19774 v_acc: 0.69727 |  iteration: 8878 teacher: 1 stage: sketch lr: 0.000469\n",
      "batch 177 loss: 1.31799 acc: 0.70378 | v_loss: 1.21038 v_acc: 0.70703 |  iteration: 8879 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 178 loss: 1.30609 acc: 0.70573 | v_loss: 1.25648 v_acc: 0.70540 |  iteration: 8880 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 179 loss: 1.29280 acc: 0.69824 | v_loss: 1.27635 v_acc: 0.70443 |  iteration: 8881 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 180 loss: 1.18983 acc: 0.71322 | v_loss: 1.33290 v_acc: 0.69303 |  iteration: 8882 teacher: 1 stage: sketch lr: 0.000469\n",
      "batch 181 loss: 1.38757 acc: 0.69889 | v_loss: 1.36419 v_acc: 0.70605 |  iteration: 8883 teacher: 1 stage: sketch lr: 0.000469\n",
      "batch 182 loss: 1.28497 acc: 0.70247 | v_loss: 1.29170 v_acc: 0.70215 |  iteration: 8884 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 183 loss: 1.33815 acc: 0.69824 | v_loss: 1.20392 v_acc: 0.70931 |  iteration: 8885 teacher: 1 stage: sketch lr: 0.000469\n",
      "batch 184 loss: 1.33416 acc: 0.70280 | v_loss: 1.30847 v_acc: 0.70638 |  iteration: 8886 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 185 loss: 1.25392 acc: 0.71289 | v_loss: 1.21450 v_acc: 0.71680 |  iteration: 8887 teacher: 1 stage: sketch lr: 0.000469\n",
      "batch 186 loss: 1.27270 acc: 0.70833 | v_loss: 1.13944 v_acc: 0.72428 |  iteration: 8888 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 187 loss: 1.27460 acc: 0.70475 | v_loss: 1.13343 v_acc: 0.70703 |  iteration: 8889 teacher: 1 stage: sketch lr: 0.000469\n",
      "batch 188 loss: 1.26831 acc: 0.70085 | v_loss: 1.25577 v_acc: 0.70605 |  iteration: 8890 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 189 loss: 1.25934 acc: 0.71289 | v_loss: 1.31448 v_acc: 0.69987 |  iteration: 8891 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 190 loss: 1.36754 acc: 0.69141 | v_loss: 1.15674 v_acc: 0.70801 |  iteration: 8892 teacher: 1 stage: sketch lr: 0.000469\n",
      "batch 191 loss: 1.32310 acc: 0.70215 | v_loss: 1.19480 v_acc: 0.69661 |  iteration: 8893 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 192 loss: 1.27181 acc: 0.71582 | v_loss: 1.19400 v_acc: 0.70638 |  iteration: 8894 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 193 loss: 1.31767 acc: 0.69889 | v_loss: 1.20214 v_acc: 0.70410 |  iteration: 8895 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 194 loss: 1.28204 acc: 0.70280 | v_loss: 1.05605 v_acc: 0.73926 |  iteration: 8896 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 195 loss: 1.28394 acc: 0.70768 | v_loss: 1.18323 v_acc: 0.71908 |  iteration: 8897 teacher: 1 stage: sketch lr: 0.000469\n",
      "batch 196 loss: 1.26956 acc: 0.70638 | v_loss: 1.13923 v_acc: 0.73112 |  iteration: 8898 teacher: 0 stage: sketch lr: 0.000469\n",
      "batch 197 loss: 1.36494 acc: 0.69661 | v_loss: 1.11859 v_acc: 0.71940 |  iteration: 8899 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 198 loss: 1.27891 acc: 0.70866 | v_loss: 1.19816 v_acc: 0.71582 |  iteration: 8900 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 199 loss: 1.22648 acc: 0.70931 | v_loss: 1.22926 v_acc: 0.71159 |  iteration: 8901 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 200 loss: 1.24703 acc: 0.71517 | v_loss: 1.20294 v_acc: 0.72168 |  iteration: 8902 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 201 loss: 1.26611 acc: 0.71549 | v_loss: 1.37955 v_acc: 0.70215 |  iteration: 8903 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 202 loss: 1.23340 acc: 0.70898 | v_loss: 1.27403 v_acc: 0.71712 |  iteration: 8904 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 203 loss: 1.29304 acc: 0.70638 | v_loss: 1.05222 v_acc: 0.74382 |  iteration: 8905 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 204 loss: 1.30516 acc: 0.69271 | v_loss: 1.20551 v_acc: 0.70573 |  iteration: 8906 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 205 loss: 1.32024 acc: 0.70605 | v_loss: 1.26276 v_acc: 0.70020 |  iteration: 8907 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 206 loss: 1.29821 acc: 0.69694 | v_loss: 1.18641 v_acc: 0.70768 |  iteration: 8908 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 207 loss: 1.26643 acc: 0.71387 | v_loss: 1.25506 v_acc: 0.71061 |  iteration: 8909 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 208 loss: 1.32406 acc: 0.70117 | v_loss: 1.23769 v_acc: 0.69303 |  iteration: 8910 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 209 loss: 1.29736 acc: 0.70150 | v_loss: 1.22388 v_acc: 0.70833 |  iteration: 8911 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 210 loss: 1.27250 acc: 0.69987 | v_loss: 1.26098 v_acc: 0.69303 |  iteration: 8912 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 211 loss: 1.33670 acc: 0.69629 | v_loss: 1.17106 v_acc: 0.71191 |  iteration: 8913 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 212 loss: 1.39286 acc: 0.68978 | v_loss: 1.17760 v_acc: 0.72298 |  iteration: 8914 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 213 loss: 1.29474 acc: 0.70085 | v_loss: 1.23895 v_acc: 0.70312 |  iteration: 8915 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 214 loss: 1.28569 acc: 0.69922 | v_loss: 1.35141 v_acc: 0.69987 |  iteration: 8916 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 215 loss: 1.30001 acc: 0.69368 | v_loss: 1.16572 v_acc: 0.70736 |  iteration: 8917 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 216 loss: 1.30307 acc: 0.70150 | v_loss: 1.40608 v_acc: 0.68750 |  iteration: 8918 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 217 loss: 1.26691 acc: 0.70768 | v_loss: 1.16360 v_acc: 0.72656 |  iteration: 8919 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 218 loss: 1.34785 acc: 0.70052 | v_loss: 1.47797 v_acc: 0.68327 |  iteration: 8920 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 219 loss: 1.20724 acc: 0.70703 | v_loss: 1.35878 v_acc: 0.69694 |  iteration: 8921 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 220 loss: 1.30102 acc: 0.70150 | v_loss: 1.31763 v_acc: 0.69076 |  iteration: 8922 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 221 loss: 1.37316 acc: 0.70020 | v_loss: 1.31393 v_acc: 0.69629 |  iteration: 8923 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 222 loss: 1.25606 acc: 0.70117 | v_loss: 1.22802 v_acc: 0.70345 |  iteration: 8924 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 223 loss: 1.28963 acc: 0.70312 | v_loss: 1.27241 v_acc: 0.70052 |  iteration: 8925 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 224 loss: 1.24494 acc: 0.70508 | v_loss: 1.21666 v_acc: 0.71680 |  iteration: 8926 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 225 loss: 1.28233 acc: 0.70508 | v_loss: 1.41839 v_acc: 0.68848 |  iteration: 8927 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 226 loss: 1.25332 acc: 0.70605 | v_loss: 1.30468 v_acc: 0.70247 |  iteration: 8928 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 227 loss: 1.29717 acc: 0.69954 | v_loss: 1.19118 v_acc: 0.70898 |  iteration: 8929 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 228 loss: 1.25045 acc: 0.70996 | v_loss: 1.25609 v_acc: 0.71712 |  iteration: 8930 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 229 loss: 1.33339 acc: 0.70085 | v_loss: 1.17196 v_acc: 0.70540 |  iteration: 8931 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 230 loss: 1.28198 acc: 0.69987 | v_loss: 1.26681 v_acc: 0.69857 |  iteration: 8932 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 231 loss: 1.25370 acc: 0.70508 | v_loss: 1.22843 v_acc: 0.71842 |  iteration: 8933 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 232 loss: 1.36675 acc: 0.69759 | v_loss: 1.16629 v_acc: 0.71549 |  iteration: 8934 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 233 loss: 1.38388 acc: 0.69368 | v_loss: 1.14042 v_acc: 0.72233 |  iteration: 8935 teacher: 0 stage: sketch lr: 0.000468\n",
      "batch 234 loss: 1.22312 acc: 0.69759 | v_loss: 1.28079 v_acc: 0.71029 |  iteration: 8936 teacher: 1 stage: sketch lr: 0.000468\n",
      "batch 235 loss: 1.32007 acc: 0.69173 | v_loss: 1.24911 v_acc: 0.70573 |  iteration: 8937 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 236 loss: 1.31576 acc: 0.69857 | v_loss: 1.24705 v_acc: 0.71126 |  iteration: 8938 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 237 loss: 1.32561 acc: 0.70280 | v_loss: 1.10855 v_acc: 0.71810 |  iteration: 8939 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 238 loss: 1.34811 acc: 0.69661 | v_loss: 1.24530 v_acc: 0.73145 |  iteration: 8940 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 239 loss: 1.30161 acc: 0.69336 | v_loss: 1.30303 v_acc: 0.69531 |  iteration: 8941 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 240 loss: 1.35972 acc: 0.69238 | v_loss: 1.30626 v_acc: 0.72461 |  iteration: 8942 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 241 loss: 1.20115 acc: 0.71745 | v_loss: 1.15539 v_acc: 0.71810 |  iteration: 8943 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 242 loss: 1.28538 acc: 0.70996 | v_loss: 1.09709 v_acc: 0.73698 |  iteration: 8944 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 243 loss: 1.30160 acc: 0.70573 | v_loss: 1.10363 v_acc: 0.72559 |  iteration: 8945 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 244 loss: 1.40671 acc: 0.69206 | v_loss: 1.18089 v_acc: 0.71126 |  iteration: 8946 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 245 loss: 1.28641 acc: 0.70573 | v_loss: 1.23841 v_acc: 0.70671 |  iteration: 8947 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 246 loss: 1.44675 acc: 0.68359 | v_loss: 1.20077 v_acc: 0.71549 |  iteration: 8948 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 247 loss: 1.25859 acc: 0.70964 | v_loss: 1.32684 v_acc: 0.70410 |  iteration: 8949 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 248 loss: 1.37200 acc: 0.69759 | v_loss: 1.45068 v_acc: 0.69499 |  iteration: 8950 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 249 loss: 1.29774 acc: 0.70866 | v_loss: 1.33387 v_acc: 0.70020 |  iteration: 8951 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 250 loss: 1.25092 acc: 0.70443 | v_loss: 1.20394 v_acc: 0.72298 |  iteration: 8952 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 251 loss: 1.34017 acc: 0.69596 | v_loss: 1.16558 v_acc: 0.70508 |  iteration: 8953 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 252 loss: 1.26743 acc: 0.71452 | v_loss: 1.17172 v_acc: 0.71517 |  iteration: 8954 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 253 loss: 1.26003 acc: 0.71322 | v_loss: 1.22312 v_acc: 0.69759 |  iteration: 8955 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 254 loss: 1.28229 acc: 0.70215 | v_loss: 1.26102 v_acc: 0.71061 |  iteration: 8956 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 255 loss: 1.32159 acc: 0.69759 | v_loss: 1.21149 v_acc: 0.73145 |  iteration: 8957 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 256 loss: 1.24885 acc: 0.70931 | v_loss: 1.23070 v_acc: 0.71745 |  iteration: 8958 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 257 loss: 1.20610 acc: 0.70931 | v_loss: 1.23539 v_acc: 0.70866 |  iteration: 8959 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 258 loss: 1.28181 acc: 0.70052 | v_loss: 1.15366 v_acc: 0.72331 |  iteration: 8960 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 259 loss: 1.34941 acc: 0.69792 | v_loss: 1.11683 v_acc: 0.71940 |  iteration: 8961 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 260 loss: 1.28504 acc: 0.70931 | v_loss: 1.44427 v_acc: 0.69271 |  iteration: 8962 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 261 loss: 1.27918 acc: 0.69824 | v_loss: 1.19484 v_acc: 0.71224 |  iteration: 8963 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 262 loss: 1.25735 acc: 0.70345 | v_loss: 1.22340 v_acc: 0.71680 |  iteration: 8964 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 263 loss: 1.19802 acc: 0.71810 | v_loss: 1.21334 v_acc: 0.71549 |  iteration: 8965 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 264 loss: 1.23738 acc: 0.70443 | v_loss: 1.27760 v_acc: 0.70540 |  iteration: 8966 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 265 loss: 1.21572 acc: 0.71322 | v_loss: 1.12986 v_acc: 0.73145 |  iteration: 8967 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 266 loss: 1.34946 acc: 0.70833 | v_loss: 1.35475 v_acc: 0.71452 |  iteration: 8968 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 267 loss: 1.33263 acc: 0.69824 | v_loss: 1.20900 v_acc: 0.69857 |  iteration: 8969 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 268 loss: 1.25580 acc: 0.70475 | v_loss: 1.21611 v_acc: 0.70182 |  iteration: 8970 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 269 loss: 1.28806 acc: 0.70605 | v_loss: 1.26443 v_acc: 0.70312 |  iteration: 8971 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 270 loss: 1.27426 acc: 0.69434 | v_loss: 1.27355 v_acc: 0.70443 |  iteration: 8972 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 271 loss: 1.30129 acc: 0.70866 | v_loss: 1.33109 v_acc: 0.69531 |  iteration: 8973 teacher: 1 stage: sketch lr: 0.000467\n",
      "batch 272 loss: 1.25885 acc: 0.71061 | v_loss: 1.36953 v_acc: 0.70443 |  iteration: 8974 teacher: 0 stage: sketch lr: 0.000467\n",
      "batch 273 loss: 1.26463 acc: 0.71354 | v_loss: 1.28493 v_acc: 0.70345 |  iteration: 8975 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 274 loss: 1.31953 acc: 0.69824 | v_loss: 1.19409 v_acc: 0.70605 |  iteration: 8976 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 275 loss: 1.26690 acc: 0.70573 | v_loss: 1.31195 v_acc: 0.70378 |  iteration: 8977 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 276 loss: 1.35640 acc: 0.69661 | v_loss: 1.21633 v_acc: 0.71159 |  iteration: 8978 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 277 loss: 1.23377 acc: 0.70182 | v_loss: 1.14579 v_acc: 0.72559 |  iteration: 8979 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 278 loss: 1.27516 acc: 0.70931 | v_loss: 1.13026 v_acc: 0.70671 |  iteration: 8980 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 279 loss: 1.28005 acc: 0.70801 | v_loss: 1.25668 v_acc: 0.70150 |  iteration: 8981 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 280 loss: 1.16541 acc: 0.72005 | v_loss: 1.32226 v_acc: 0.69727 |  iteration: 8982 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 281 loss: 1.27670 acc: 0.71126 | v_loss: 1.16051 v_acc: 0.71159 |  iteration: 8983 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 282 loss: 1.27066 acc: 0.71615 | v_loss: 1.18577 v_acc: 0.70085 |  iteration: 8984 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 283 loss: 1.27338 acc: 0.70605 | v_loss: 1.19035 v_acc: 0.71419 |  iteration: 8985 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 284 loss: 1.28033 acc: 0.71549 | v_loss: 1.21424 v_acc: 0.70671 |  iteration: 8986 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 285 loss: 1.32845 acc: 0.69922 | v_loss: 1.06010 v_acc: 0.73307 |  iteration: 8987 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 286 loss: 1.28835 acc: 0.70638 | v_loss: 1.17003 v_acc: 0.71647 |  iteration: 8988 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 287 loss: 1.30537 acc: 0.70020 | v_loss: 1.18113 v_acc: 0.70605 |  iteration: 8989 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 288 loss: 1.28505 acc: 0.71582 | v_loss: 1.13884 v_acc: 0.72298 |  iteration: 8990 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 289 loss: 1.25345 acc: 0.70215 | v_loss: 1.21279 v_acc: 0.71680 |  iteration: 8991 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 290 loss: 1.27929 acc: 0.70020 | v_loss: 1.24234 v_acc: 0.70475 |  iteration: 8992 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 291 loss: 1.28444 acc: 0.69857 | v_loss: 1.24277 v_acc: 0.71452 |  iteration: 8993 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 292 loss: 1.16477 acc: 0.71908 | v_loss: 1.39491 v_acc: 0.69434 |  iteration: 8994 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 293 loss: 1.24192 acc: 0.70117 | v_loss: 1.27535 v_acc: 0.71322 |  iteration: 8995 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 294 loss: 1.27618 acc: 0.70312 | v_loss: 1.05693 v_acc: 0.74316 |  iteration: 8996 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 295 loss: 1.31480 acc: 0.69564 | v_loss: 1.19717 v_acc: 0.70866 |  iteration: 8997 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 296 loss: 1.36143 acc: 0.69661 | v_loss: 1.27286 v_acc: 0.69596 |  iteration: 8998 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 297 loss: 1.30345 acc: 0.70866 | v_loss: 1.17953 v_acc: 0.70833 |  iteration: 8999 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 298 loss: 1.24224 acc: 0.70475 | v_loss: 1.24738 v_acc: 0.71159 |  iteration: 9000 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 299 loss: 1.27195 acc: 0.70378 | v_loss: 1.24676 v_acc: 0.69368 |  iteration: 9001 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 300 loss: 1.27351 acc: 0.71257 | v_loss: 1.21558 v_acc: 0.71842 |  iteration: 9002 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 301 loss: 1.29833 acc: 0.70117 | v_loss: 1.26774 v_acc: 0.69857 |  iteration: 9003 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 302 loss: 1.25330 acc: 0.70573 | v_loss: 1.17288 v_acc: 0.71777 |  iteration: 9004 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 303 loss: 1.34139 acc: 0.69954 | v_loss: 1.17759 v_acc: 0.72624 |  iteration: 9005 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 304 loss: 1.37029 acc: 0.69206 | v_loss: 1.22659 v_acc: 0.70378 |  iteration: 9006 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 305 loss: 1.35514 acc: 0.69303 | v_loss: 1.34174 v_acc: 0.70020 |  iteration: 9007 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 306 loss: 1.24634 acc: 0.71549 | v_loss: 1.16410 v_acc: 0.70703 |  iteration: 9008 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 307 loss: 1.26721 acc: 0.70085 | v_loss: 1.42312 v_acc: 0.68555 |  iteration: 9009 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 308 loss: 1.35839 acc: 0.69499 | v_loss: 1.16183 v_acc: 0.72428 |  iteration: 9010 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 309 loss: 1.19474 acc: 0.71875 | v_loss: 1.49320 v_acc: 0.67936 |  iteration: 9011 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 310 loss: 1.30950 acc: 0.70768 | v_loss: 1.37638 v_acc: 0.70052 |  iteration: 9012 teacher: 0 stage: sketch lr: 0.000466\n",
      "batch 311 loss: 1.23283 acc: 0.70931 | v_loss: 1.33054 v_acc: 0.69303 |  iteration: 9013 teacher: 1 stage: sketch lr: 0.000466\n",
      "batch 312 loss: 1.43819 acc: 0.69303 | v_loss: 1.30504 v_acc: 0.70182 |  iteration: 9014 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 313 loss: 1.27209 acc: 0.70638 | v_loss: 1.23241 v_acc: 0.70605 |  iteration: 9015 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 314 loss: 1.37826 acc: 0.69108 | v_loss: 1.25931 v_acc: 0.70378 |  iteration: 9016 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 315 loss: 1.31504 acc: 0.70150 | v_loss: 1.23394 v_acc: 0.71191 |  iteration: 9017 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 316 loss: 1.23716 acc: 0.69922 | v_loss: 1.44582 v_acc: 0.68392 |  iteration: 9018 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 317 loss: 1.28103 acc: 0.70312 | v_loss: 1.29765 v_acc: 0.70833 |  iteration: 9019 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 318 loss: 1.32955 acc: 0.70410 | v_loss: 1.18438 v_acc: 0.70801 |  iteration: 9020 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 319 loss: 1.20475 acc: 0.70801 | v_loss: 1.26124 v_acc: 0.71712 |  iteration: 9021 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 320 loss: 1.24882 acc: 0.70312 | v_loss: 1.17017 v_acc: 0.70475 |  iteration: 9022 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 321 loss: 1.25537 acc: 0.70410 | v_loss: 1.27733 v_acc: 0.69564 |  iteration: 9023 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 322 loss: 1.28174 acc: 0.70573 | v_loss: 1.24038 v_acc: 0.71257 |  iteration: 9024 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 323 loss: 1.35142 acc: 0.69857 | v_loss: 1.16977 v_acc: 0.71647 |  iteration: 9025 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 324 loss: 1.32205 acc: 0.69368 | v_loss: 1.14071 v_acc: 0.72493 |  iteration: 9026 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 325 loss: 1.30557 acc: 0.70703 | v_loss: 1.27430 v_acc: 0.71322 |  iteration: 9027 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 326 loss: 1.21802 acc: 0.71126 | v_loss: 1.24964 v_acc: 0.70117 |  iteration: 9028 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 327 loss: 1.30454 acc: 0.69792 | v_loss: 1.25024 v_acc: 0.71257 |  iteration: 9029 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 328 loss: 1.37649 acc: 0.69499 | v_loss: 1.10399 v_acc: 0.72461 |  iteration: 9030 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 329 loss: 1.26689 acc: 0.69824 | v_loss: 1.24656 v_acc: 0.73145 |  iteration: 9031 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 330 loss: 1.21572 acc: 0.70703 | v_loss: 1.30461 v_acc: 0.69824 |  iteration: 9032 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 331 loss: 1.33444 acc: 0.68717 | v_loss: 1.32076 v_acc: 0.71745 |  iteration: 9033 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 332 loss: 1.26097 acc: 0.69531 | v_loss: 1.15827 v_acc: 0.71484 |  iteration: 9034 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 333 loss: 1.27866 acc: 0.70247 | v_loss: 1.10900 v_acc: 0.73698 |  iteration: 9035 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 334 loss: 1.30455 acc: 0.71126 | v_loss: 1.10717 v_acc: 0.71777 |  iteration: 9036 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 335 loss: 1.24611 acc: 0.70475 | v_loss: 1.19270 v_acc: 0.70736 |  iteration: 9037 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 336 loss: 1.25771 acc: 0.70833 | v_loss: 1.24336 v_acc: 0.69629 |  iteration: 9038 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 337 loss: 1.35120 acc: 0.69889 | v_loss: 1.19484 v_acc: 0.71484 |  iteration: 9039 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 338 loss: 1.35306 acc: 0.69759 | v_loss: 1.32121 v_acc: 0.70345 |  iteration: 9040 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 339 loss: 1.20235 acc: 0.70833 | v_loss: 1.48676 v_acc: 0.69076 |  iteration: 9041 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 340 loss: 1.23150 acc: 0.70247 | v_loss: 1.35141 v_acc: 0.69792 |  iteration: 9042 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 341 loss: 1.29102 acc: 0.69857 | v_loss: 1.19523 v_acc: 0.72038 |  iteration: 9043 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 342 loss: 1.25402 acc: 0.70378 | v_loss: 1.15912 v_acc: 0.70996 |  iteration: 9044 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 343 loss: 1.31087 acc: 0.70605 | v_loss: 1.14731 v_acc: 0.72201 |  iteration: 9045 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 344 loss: 1.32293 acc: 0.69889 | v_loss: 1.24425 v_acc: 0.70378 |  iteration: 9046 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 345 loss: 1.36843 acc: 0.70085 | v_loss: 1.24580 v_acc: 0.71745 |  iteration: 9047 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 346 loss: 1.35081 acc: 0.70052 | v_loss: 1.21649 v_acc: 0.72949 |  iteration: 9048 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 347 loss: 1.33182 acc: 0.69499 | v_loss: 1.23404 v_acc: 0.71549 |  iteration: 9049 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 348 loss: 1.32423 acc: 0.70020 | v_loss: 1.24092 v_acc: 0.70573 |  iteration: 9050 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 349 loss: 1.26059 acc: 0.71094 | v_loss: 1.16854 v_acc: 0.72201 |  iteration: 9051 teacher: 0 stage: sketch lr: 0.000465\n",
      "batch 350 loss: 1.26679 acc: 0.70540 | v_loss: 1.13655 v_acc: 0.72005 |  iteration: 9052 teacher: 1 stage: sketch lr: 0.000465\n",
      "batch 351 loss: 1.26101 acc: 0.70508 | v_loss: 1.46937 v_acc: 0.69043 |  iteration: 9053 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 352 loss: 1.29199 acc: 0.70312 | v_loss: 1.19965 v_acc: 0.70768 |  iteration: 9054 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 353 loss: 1.23851 acc: 0.71777 | v_loss: 1.22934 v_acc: 0.71810 |  iteration: 9055 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 354 loss: 1.28403 acc: 0.70280 | v_loss: 1.21459 v_acc: 0.71940 |  iteration: 9056 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 355 loss: 1.24513 acc: 0.71126 | v_loss: 1.27977 v_acc: 0.70573 |  iteration: 9057 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 356 loss: 1.21828 acc: 0.70736 | v_loss: 1.12913 v_acc: 0.73079 |  iteration: 9058 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 357 loss: 1.36850 acc: 0.70573 | v_loss: 1.37987 v_acc: 0.71745 |  iteration: 9059 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 358 loss: 1.26665 acc: 0.69727 | v_loss: 1.17944 v_acc: 0.70150 |  iteration: 9060 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 359 loss: 1.26388 acc: 0.70085 | v_loss: 1.19499 v_acc: 0.70833 |  iteration: 9061 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 360 loss: 1.31883 acc: 0.70540 | v_loss: 1.26103 v_acc: 0.70540 |  iteration: 9062 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 361 loss: 1.30834 acc: 0.70833 | v_loss: 1.27137 v_acc: 0.70215 |  iteration: 9063 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 362 loss: 1.28546 acc: 0.70801 | v_loss: 1.33478 v_acc: 0.69271 |  iteration: 9064 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 363 loss: 1.23332 acc: 0.71517 | v_loss: 1.36793 v_acc: 0.70508 |  iteration: 9065 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 364 loss: 1.24156 acc: 0.70540 | v_loss: 1.28359 v_acc: 0.70540 |  iteration: 9066 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 365 loss: 1.30925 acc: 0.70215 | v_loss: 1.20308 v_acc: 0.70736 |  iteration: 9067 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 366 loss: 1.28155 acc: 0.69596 | v_loss: 1.32283 v_acc: 0.70605 |  iteration: 9068 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 367 loss: 1.25981 acc: 0.71387 | v_loss: 1.23129 v_acc: 0.71159 |  iteration: 9069 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 368 loss: 1.22721 acc: 0.71224 | v_loss: 1.13115 v_acc: 0.72396 |  iteration: 9070 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 369 loss: 1.33138 acc: 0.69303 | v_loss: 1.16083 v_acc: 0.70605 |  iteration: 9071 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 370 loss: 1.40818 acc: 0.68457 | v_loss: 1.26411 v_acc: 0.70182 |  iteration: 9072 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 371 loss: 1.35886 acc: 0.69596 | v_loss: 1.30893 v_acc: 0.69954 |  iteration: 9073 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 372 loss: 1.28820 acc: 0.70736 | v_loss: 1.15674 v_acc: 0.70833 |  iteration: 9074 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 373 loss: 1.24260 acc: 0.70410 | v_loss: 1.19996 v_acc: 0.69336 |  iteration: 9075 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 374 loss: 1.27963 acc: 0.70117 | v_loss: 1.19417 v_acc: 0.70508 |  iteration: 9076 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 375 loss: 1.27572 acc: 0.70020 | v_loss: 1.20057 v_acc: 0.70736 |  iteration: 9077 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 376 loss: 1.36075 acc: 0.69336 | v_loss: 1.07970 v_acc: 0.74023 |  iteration: 9078 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 377 loss: 1.22253 acc: 0.71647 | v_loss: 1.17023 v_acc: 0.72428 |  iteration: 9079 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 378 loss: 1.29457 acc: 0.70703 | v_loss: 1.18894 v_acc: 0.72689 |  iteration: 9080 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 379 loss: 1.28331 acc: 0.69336 | v_loss: 1.13026 v_acc: 0.72917 |  iteration: 9081 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 380 loss: 1.28798 acc: 0.70247 | v_loss: 1.20739 v_acc: 0.72135 |  iteration: 9082 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 381 loss: 1.36650 acc: 0.69141 | v_loss: 1.24301 v_acc: 0.71094 |  iteration: 9083 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 382 loss: 1.28396 acc: 0.71615 | v_loss: 1.20955 v_acc: 0.72428 |  iteration: 9084 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 383 loss: 1.28568 acc: 0.71289 | v_loss: 1.38301 v_acc: 0.70182 |  iteration: 9085 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 384 loss: 1.26077 acc: 0.70638 | v_loss: 1.26533 v_acc: 0.71777 |  iteration: 9086 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 385 loss: 1.25032 acc: 0.70573 | v_loss: 1.05090 v_acc: 0.74447 |  iteration: 9087 teacher: 0 stage: sketch lr: 0.000464\n",
      "batch 386 loss: 1.27132 acc: 0.70964 | v_loss: 1.21978 v_acc: 0.71322 |  iteration: 9088 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 387 loss: 1.34083 acc: 0.69661 | v_loss: 1.26038 v_acc: 0.69987 |  iteration: 9089 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 388 loss: 1.33047 acc: 0.69889 | v_loss: 1.20765 v_acc: 0.70605 |  iteration: 9090 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 389 loss: 1.31281 acc: 0.71094 | v_loss: 1.24853 v_acc: 0.71029 |  iteration: 9091 teacher: 1 stage: sketch lr: 0.000464\n",
      "batch 390 loss: 1.24852 acc: 0.70964 | v_loss: 1.24234 v_acc: 0.69271 |  iteration: 9092 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 391 loss: 1.25866 acc: 0.70378 | v_loss: 1.21908 v_acc: 0.71159 |  iteration: 9093 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 392 loss: 1.29695 acc: 0.70703 | v_loss: 1.25974 v_acc: 0.69303 |  iteration: 9094 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 393 loss: 1.21031 acc: 0.72266 | v_loss: 1.18445 v_acc: 0.71712 |  iteration: 9095 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 394 loss: 1.29841 acc: 0.70475 | v_loss: 1.17723 v_acc: 0.72559 |  iteration: 9096 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 395 loss: 1.25510 acc: 0.70833 | v_loss: 1.24174 v_acc: 0.70215 |  iteration: 9097 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 396 loss: 1.18817 acc: 0.71842 | v_loss: 1.33503 v_acc: 0.69954 |  iteration: 9098 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 397 loss: 1.25182 acc: 0.70475 | v_loss: 1.15394 v_acc: 0.70833 |  iteration: 9099 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 398 loss: 1.28467 acc: 0.69987 | v_loss: 1.40859 v_acc: 0.68522 |  iteration: 9100 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 399 loss: 1.43673 acc: 0.70247 | v_loss: 1.16456 v_acc: 0.71810 |  iteration: 9101 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 400 loss: 1.30370 acc: 0.69694 | v_loss: 1.46566 v_acc: 0.68327 |  iteration: 9102 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 401 loss: 1.25249 acc: 0.70573 | v_loss: 1.35613 v_acc: 0.69694 |  iteration: 9103 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 402 loss: 1.25664 acc: 0.70312 | v_loss: 1.33545 v_acc: 0.69076 |  iteration: 9104 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 403 loss: 1.23285 acc: 0.70573 | v_loss: 1.30590 v_acc: 0.69987 |  iteration: 9105 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 404 loss: 1.25765 acc: 0.70931 | v_loss: 1.23017 v_acc: 0.70312 |  iteration: 9106 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 405 loss: 1.31311 acc: 0.69401 | v_loss: 1.25846 v_acc: 0.70020 |  iteration: 9107 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 406 loss: 1.30172 acc: 0.70703 | v_loss: 1.21545 v_acc: 0.71908 |  iteration: 9108 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 407 loss: 1.34852 acc: 0.69661 | v_loss: 1.40683 v_acc: 0.68783 |  iteration: 9109 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 408 loss: 1.26462 acc: 0.70833 | v_loss: 1.28773 v_acc: 0.70605 |  iteration: 9110 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 409 loss: 1.38096 acc: 0.68945 | v_loss: 1.19544 v_acc: 0.71061 |  iteration: 9111 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 410 loss: 1.27479 acc: 0.70182 | v_loss: 1.26108 v_acc: 0.71452 |  iteration: 9112 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 411 loss: 1.24867 acc: 0.70996 | v_loss: 1.16112 v_acc: 0.70931 |  iteration: 9113 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 412 loss: 1.32161 acc: 0.70052 | v_loss: 1.26307 v_acc: 0.70052 |  iteration: 9114 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 413 loss: 1.32968 acc: 0.70671 | v_loss: 1.23117 v_acc: 0.71224 |  iteration: 9115 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 414 loss: 1.28523 acc: 0.70378 | v_loss: 1.16895 v_acc: 0.72070 |  iteration: 9116 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 415 loss: 1.32238 acc: 0.70736 | v_loss: 1.13964 v_acc: 0.72754 |  iteration: 9117 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 416 loss: 1.25431 acc: 0.71257 | v_loss: 1.25410 v_acc: 0.71810 |  iteration: 9118 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 417 loss: 1.23730 acc: 0.71842 | v_loss: 1.25510 v_acc: 0.70182 |  iteration: 9119 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 418 loss: 1.25408 acc: 0.70801 | v_loss: 1.26154 v_acc: 0.70410 |  iteration: 9120 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 419 loss: 1.30108 acc: 0.70703 | v_loss: 1.11202 v_acc: 0.71452 |  iteration: 9121 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 420 loss: 1.21054 acc: 0.71777 | v_loss: 1.24424 v_acc: 0.72656 |  iteration: 9122 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 421 loss: 1.33115 acc: 0.70215 | v_loss: 1.29993 v_acc: 0.69661 |  iteration: 9123 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 422 loss: 1.23186 acc: 0.70833 | v_loss: 1.28542 v_acc: 0.72168 |  iteration: 9124 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 423 loss: 1.26287 acc: 0.70703 | v_loss: 1.15459 v_acc: 0.71810 |  iteration: 9125 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 424 loss: 1.28377 acc: 0.70508 | v_loss: 1.10206 v_acc: 0.73470 |  iteration: 9126 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 425 loss: 1.31997 acc: 0.70931 | v_loss: 1.10289 v_acc: 0.72591 |  iteration: 9127 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 426 loss: 1.30368 acc: 0.70898 | v_loss: 1.18878 v_acc: 0.71061 |  iteration: 9128 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 427 loss: 1.26851 acc: 0.70117 | v_loss: 1.24729 v_acc: 0.69727 |  iteration: 9129 teacher: 1 stage: sketch lr: 0.000463\n",
      "batch 428 loss: 1.36510 acc: 0.69922 | v_loss: 1.20754 v_acc: 0.71647 |  iteration: 9130 teacher: 0 stage: sketch lr: 0.000463\n",
      "batch 429 loss: 1.25220 acc: 0.69824 | v_loss: 1.34495 v_acc: 0.70345 |  iteration: 9131 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 430 loss: 1.40041 acc: 0.69629 | v_loss: 1.46628 v_acc: 0.69368 |  iteration: 9132 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 431 loss: 1.24325 acc: 0.71940 | v_loss: 1.34642 v_acc: 0.69987 |  iteration: 9133 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 432 loss: 1.27039 acc: 0.70280 | v_loss: 1.20331 v_acc: 0.72233 |  iteration: 9134 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 433 loss: 1.35463 acc: 0.70475 | v_loss: 1.15303 v_acc: 0.70964 |  iteration: 9135 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 434 loss: 1.26173 acc: 0.70247 | v_loss: 1.15608 v_acc: 0.72363 |  iteration: 9136 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 435 loss: 1.38070 acc: 0.69661 | v_loss: 1.22230 v_acc: 0.70378 |  iteration: 9137 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 436 loss: 1.16539 acc: 0.72526 | v_loss: 1.25034 v_acc: 0.70898 |  iteration: 9138 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 437 loss: 1.23060 acc: 0.71191 | v_loss: 1.21053 v_acc: 0.73145 |  iteration: 9139 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 438 loss: 1.33419 acc: 0.70247 | v_loss: 1.23043 v_acc: 0.71549 |  iteration: 9140 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 439 loss: 1.31346 acc: 0.70475 | v_loss: 1.23947 v_acc: 0.70573 |  iteration: 9141 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 440 loss: 1.23572 acc: 0.71387 | v_loss: 1.15781 v_acc: 0.72168 |  iteration: 9142 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 441 loss: 1.21065 acc: 0.71549 | v_loss: 1.13064 v_acc: 0.71940 |  iteration: 9143 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 442 loss: 1.41442 acc: 0.69694 | v_loss: 1.42713 v_acc: 0.69043 |  iteration: 9144 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 443 loss: 1.17577 acc: 0.71615 | v_loss: 1.21000 v_acc: 0.71159 |  iteration: 9145 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 444 loss: 1.26976 acc: 0.71029 | v_loss: 1.22421 v_acc: 0.71712 |  iteration: 9146 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 445 loss: 1.19769 acc: 0.71191 | v_loss: 1.21566 v_acc: 0.71354 |  iteration: 9147 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 446 loss: 1.24285 acc: 0.70768 | v_loss: 1.27548 v_acc: 0.70801 |  iteration: 9148 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 447 loss: 1.37768 acc: 0.69434 | v_loss: 1.13712 v_acc: 0.73340 |  iteration: 9149 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 448 loss: 1.27977 acc: 0.70117 | v_loss: 1.37102 v_acc: 0.71322 |  iteration: 9150 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 449 loss: 1.25105 acc: 0.70215 | v_loss: 1.18999 v_acc: 0.70150 |  iteration: 9151 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 450 loss: 1.25362 acc: 0.70508 | v_loss: 1.20066 v_acc: 0.70410 |  iteration: 9152 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 451 loss: 1.25770 acc: 0.70996 | v_loss: 1.26778 v_acc: 0.70312 |  iteration: 9153 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 452 loss: 1.33230 acc: 0.69824 | v_loss: 1.27453 v_acc: 0.70475 |  iteration: 9154 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 453 loss: 1.34017 acc: 0.69499 | v_loss: 1.33833 v_acc: 0.69596 |  iteration: 9155 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 454 loss: 1.30048 acc: 0.70605 | v_loss: 1.36045 v_acc: 0.70052 |  iteration: 9156 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 455 loss: 1.30227 acc: 0.70312 | v_loss: 1.28400 v_acc: 0.70671 |  iteration: 9157 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 456 loss: 1.33296 acc: 0.68750 | v_loss: 1.21727 v_acc: 0.70736 |  iteration: 9158 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 457 loss: 1.28604 acc: 0.70605 | v_loss: 1.30743 v_acc: 0.70703 |  iteration: 9159 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 458 loss: 1.29766 acc: 0.71029 | v_loss: 1.21588 v_acc: 0.71126 |  iteration: 9160 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 459 loss: 1.34505 acc: 0.70573 | v_loss: 1.15402 v_acc: 0.72493 |  iteration: 9161 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 460 loss: 1.28998 acc: 0.69922 | v_loss: 1.13782 v_acc: 0.70898 |  iteration: 9162 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 461 loss: 1.23707 acc: 0.70215 | v_loss: 1.25828 v_acc: 0.70703 |  iteration: 9163 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 462 loss: 1.32674 acc: 0.69889 | v_loss: 1.33106 v_acc: 0.70117 |  iteration: 9164 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 463 loss: 1.30137 acc: 0.69466 | v_loss: 1.17095 v_acc: 0.71484 |  iteration: 9165 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 464 loss: 1.37788 acc: 0.69889 | v_loss: 1.19447 v_acc: 0.70312 |  iteration: 9166 teacher: 1 stage: sketch lr: 0.000462\n",
      "batch 465 loss: 1.22728 acc: 0.71224 | v_loss: 1.17322 v_acc: 0.71517 |  iteration: 9167 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 466 loss: 1.24726 acc: 0.70443 | v_loss: 1.19495 v_acc: 0.70736 |  iteration: 9168 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 467 loss: 1.35627 acc: 0.69401 | v_loss: 1.07576 v_acc: 0.73991 |  iteration: 9169 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 468 loss: 1.29360 acc: 0.70117 | v_loss: 1.17842 v_acc: 0.71940 |  iteration: 9170 teacher: 0 stage: sketch lr: 0.000462\n",
      "batch 469 loss: 1.28739 acc: 0.69792 | v_loss: 1.13256 v_acc: 0.72852 |  iteration: 9171 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 470 loss: 1.29529 acc: 0.70540 | v_loss: 1.12417 v_acc: 0.72168 |  iteration: 9172 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 471 loss: 1.32301 acc: 0.70768 | v_loss: 1.20634 v_acc: 0.71842 |  iteration: 9173 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 472 loss: 1.22480 acc: 0.71257 | v_loss: 1.22525 v_acc: 0.71712 |  iteration: 9174 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 473 loss: 1.32071 acc: 0.69857 | v_loss: 1.20731 v_acc: 0.71680 |  iteration: 9175 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 474 loss: 1.33770 acc: 0.70345 | v_loss: 1.38795 v_acc: 0.69824 |  iteration: 9176 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 475 loss: 1.29760 acc: 0.70247 | v_loss: 1.26661 v_acc: 0.71615 |  iteration: 9177 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 476 loss: 1.30673 acc: 0.71029 | v_loss: 1.06115 v_acc: 0.74284 |  iteration: 9178 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 477 loss: 1.28344 acc: 0.70736 | v_loss: 1.20610 v_acc: 0.70410 |  iteration: 9179 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 478 loss: 1.43580 acc: 0.69401 | v_loss: 1.28672 v_acc: 0.69922 |  iteration: 9180 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 479 loss: 1.30515 acc: 0.70117 | v_loss: 1.18606 v_acc: 0.70638 |  iteration: 9181 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 480 loss: 1.26697 acc: 0.70768 | v_loss: 1.24955 v_acc: 0.71354 |  iteration: 9182 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 481 loss: 1.36998 acc: 0.69922 | v_loss: 1.24371 v_acc: 0.69694 |  iteration: 9183 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 482 loss: 1.30716 acc: 0.69629 | v_loss: 1.22518 v_acc: 0.71615 |  iteration: 9184 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 483 loss: 1.30780 acc: 0.70638 | v_loss: 1.26905 v_acc: 0.70150 |  iteration: 9185 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 484 loss: 1.29025 acc: 0.70671 | v_loss: 1.17302 v_acc: 0.71549 |  iteration: 9186 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 485 loss: 1.28042 acc: 0.70378 | v_loss: 1.17698 v_acc: 0.72461 |  iteration: 9187 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 486 loss: 1.32310 acc: 0.70312 | v_loss: 1.23441 v_acc: 0.70215 |  iteration: 9188 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 487 loss: 1.32523 acc: 0.69141 | v_loss: 1.35942 v_acc: 0.69889 |  iteration: 9189 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 488 loss: 1.30586 acc: 0.71419 | v_loss: 1.15862 v_acc: 0.70768 |  iteration: 9190 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 489 loss: 1.29235 acc: 0.70768 | v_loss: 1.41049 v_acc: 0.68522 |  iteration: 9191 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 490 loss: 1.27186 acc: 0.71289 | v_loss: 1.16759 v_acc: 0.72135 |  iteration: 9192 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 491 loss: 1.25938 acc: 0.70508 | v_loss: 1.46603 v_acc: 0.68294 |  iteration: 9193 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 492 loss: 1.27157 acc: 0.70312 | v_loss: 1.35697 v_acc: 0.70247 |  iteration: 9194 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 493 loss: 1.29319 acc: 0.70605 | v_loss: 1.33884 v_acc: 0.69238 |  iteration: 9195 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 494 loss: 1.39510 acc: 0.69043 | v_loss: 1.30543 v_acc: 0.69792 |  iteration: 9196 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 495 loss: 1.21880 acc: 0.71908 | v_loss: 1.22917 v_acc: 0.70378 |  iteration: 9197 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 496 loss: 1.28477 acc: 0.69987 | v_loss: 1.25653 v_acc: 0.70215 |  iteration: 9198 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 497 loss: 1.32441 acc: 0.69661 | v_loss: 1.20905 v_acc: 0.71973 |  iteration: 9199 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 498 loss: 1.25567 acc: 0.70540 | v_loss: 1.41889 v_acc: 0.69076 |  iteration: 9200 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 499 loss: 1.31540 acc: 0.69792 | v_loss: 1.28406 v_acc: 0.71387 |  iteration: 9201 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 500 loss: 1.23922 acc: 0.70964 | v_loss: 1.20687 v_acc: 0.70866 |  iteration: 9202 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 501 loss: 1.32104 acc: 0.70247 | v_loss: 1.26303 v_acc: 0.71484 |  iteration: 9203 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 502 loss: 1.31397 acc: 0.70150 | v_loss: 1.16020 v_acc: 0.70931 |  iteration: 9204 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 503 loss: 1.28538 acc: 0.70671 | v_loss: 1.24619 v_acc: 0.69564 |  iteration: 9205 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 504 loss: 1.31827 acc: 0.70378 | v_loss: 1.21891 v_acc: 0.71322 |  iteration: 9206 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 505 loss: 1.24346 acc: 0.70703 | v_loss: 1.18014 v_acc: 0.71810 |  iteration: 9207 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 506 loss: 1.22098 acc: 0.71126 | v_loss: 1.12719 v_acc: 0.72656 |  iteration: 9208 teacher: 1 stage: sketch lr: 0.000461\n",
      "batch 507 loss: 1.26555 acc: 0.71159 | v_loss: 1.24599 v_acc: 0.71387 |  iteration: 9209 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 508 loss: 1.29781 acc: 0.70443 | v_loss: 1.24696 v_acc: 0.70540 |  iteration: 9210 teacher: 0 stage: sketch lr: 0.000461\n",
      "batch 509 loss: 1.33428 acc: 0.69987 | v_loss: 1.25013 v_acc: 0.70410 |  iteration: 9211 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 510 loss: 1.27776 acc: 0.71126 | v_loss: 1.11329 v_acc: 0.71582 |  iteration: 9212 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 511 loss: 1.21371 acc: 0.70378 | v_loss: 1.23642 v_acc: 0.73112 |  iteration: 9213 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 512 loss: 1.22909 acc: 0.70345 | v_loss: 1.28885 v_acc: 0.69759 |  iteration: 9214 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 513 loss: 1.35730 acc: 0.68913 | v_loss: 1.30038 v_acc: 0.72363 |  iteration: 9215 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 514 loss: 1.26707 acc: 0.70768 | v_loss: 1.16116 v_acc: 0.71842 |  iteration: 9216 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 515 loss: 1.20504 acc: 0.72298 | v_loss: 1.10845 v_acc: 0.74023 |  iteration: 9217 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 516 loss: 1.29122 acc: 0.70801 | v_loss: 1.10149 v_acc: 0.72559 |  iteration: 9218 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 517 loss: 1.34237 acc: 0.69466 | v_loss: 1.18388 v_acc: 0.71224 |  iteration: 9219 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 518 loss: 1.28117 acc: 0.71061 | v_loss: 1.24573 v_acc: 0.70345 |  iteration: 9220 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 519 loss: 1.23809 acc: 0.71484 | v_loss: 1.18392 v_acc: 0.71680 |  iteration: 9221 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 520 loss: 1.38075 acc: 0.69954 | v_loss: 1.31225 v_acc: 0.70443 |  iteration: 9222 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 521 loss: 1.23206 acc: 0.71484 | v_loss: 1.48380 v_acc: 0.69076 |  iteration: 9223 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 522 loss: 1.35825 acc: 0.70540 | v_loss: 1.35438 v_acc: 0.69661 |  iteration: 9224 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 523 loss: 1.28793 acc: 0.70671 | v_loss: 1.18900 v_acc: 0.72168 |  iteration: 9225 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 524 loss: 1.22972 acc: 0.70703 | v_loss: 1.16022 v_acc: 0.70866 |  iteration: 9226 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 525 loss: 1.35986 acc: 0.69987 | v_loss: 1.14802 v_acc: 0.72331 |  iteration: 9227 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 526 loss: 1.32517 acc: 0.69792 | v_loss: 1.23251 v_acc: 0.70215 |  iteration: 9228 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 527 loss: 1.32354 acc: 0.70605 | v_loss: 1.24473 v_acc: 0.71549 |  iteration: 9229 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 528 loss: 1.23118 acc: 0.71257 | v_loss: 1.21293 v_acc: 0.72852 |  iteration: 9230 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 529 loss: 1.26312 acc: 0.70638 | v_loss: 1.22274 v_acc: 0.71842 |  iteration: 9231 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 530 loss: 1.28570 acc: 0.70508 | v_loss: 1.23467 v_acc: 0.70898 |  iteration: 9232 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 531 loss: 1.30664 acc: 0.70378 | v_loss: 1.15259 v_acc: 0.72363 |  iteration: 9233 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 532 loss: 1.30109 acc: 0.69727 | v_loss: 1.12159 v_acc: 0.72103 |  iteration: 9234 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 533 loss: 1.27478 acc: 0.70475 | v_loss: 1.42301 v_acc: 0.69173 |  iteration: 9235 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 534 loss: 1.27342 acc: 0.71029 | v_loss: 1.19863 v_acc: 0.71289 |  iteration: 9236 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 535 loss: 1.28936 acc: 0.70410 | v_loss: 1.23048 v_acc: 0.71810 |  iteration: 9237 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 536 loss: 1.22588 acc: 0.71452 | v_loss: 1.23229 v_acc: 0.71224 |  iteration: 9238 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 537 loss: 1.21347 acc: 0.72070 | v_loss: 1.28414 v_acc: 0.70378 |  iteration: 9239 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 538 loss: 1.25423 acc: 0.70833 | v_loss: 1.13157 v_acc: 0.73079 |  iteration: 9240 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 539 loss: 1.31156 acc: 0.70215 | v_loss: 1.36941 v_acc: 0.71582 |  iteration: 9241 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 540 loss: 1.33575 acc: 0.70085 | v_loss: 1.18504 v_acc: 0.70215 |  iteration: 9242 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 541 loss: 1.30715 acc: 0.69727 | v_loss: 1.20072 v_acc: 0.70736 |  iteration: 9243 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 542 loss: 1.29748 acc: 0.69889 | v_loss: 1.26115 v_acc: 0.70475 |  iteration: 9244 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 543 loss: 1.25630 acc: 0.71354 | v_loss: 1.27642 v_acc: 0.70443 |  iteration: 9245 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 544 loss: 1.25502 acc: 0.71354 | v_loss: 1.34029 v_acc: 0.69076 |  iteration: 9246 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 545 loss: 1.25245 acc: 0.71061 | v_loss: 1.35959 v_acc: 0.70638 |  iteration: 9247 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 546 loss: 1.32715 acc: 0.69531 | v_loss: 1.28372 v_acc: 0.70508 |  iteration: 9248 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 547 loss: 1.35230 acc: 0.68848 | v_loss: 1.20125 v_acc: 0.70833 |  iteration: 9249 teacher: 1 stage: sketch lr: 0.000460\n",
      "batch 548 loss: 1.36496 acc: 0.68945 | v_loss: 1.30542 v_acc: 0.70378 |  iteration: 9250 teacher: 0 stage: sketch lr: 0.000460\n",
      "batch 549 loss: 1.24037 acc: 0.70475 | v_loss: 1.21541 v_acc: 0.71257 |  iteration: 9251 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 550 loss: 1.26945 acc: 0.70964 | v_loss: 1.14053 v_acc: 0.72689 |  iteration: 9252 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 551 loss: 1.26726 acc: 0.70964 | v_loss: 1.13097 v_acc: 0.70736 |  iteration: 9253 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 552 loss: 1.29500 acc: 0.69661 | v_loss: 1.25579 v_acc: 0.70671 |  iteration: 9254 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 553 loss: 1.33776 acc: 0.70052 | v_loss: 1.32186 v_acc: 0.69661 |  iteration: 9255 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 554 loss: 1.32287 acc: 0.70117 | v_loss: 1.14193 v_acc: 0.71582 |  iteration: 9256 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 555 loss: 1.32668 acc: 0.69564 | v_loss: 1.19704 v_acc: 0.70020 |  iteration: 9257 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 556 loss: 1.31524 acc: 0.70410 | v_loss: 1.19508 v_acc: 0.71029 |  iteration: 9258 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 557 loss: 1.21737 acc: 0.71322 | v_loss: 1.21863 v_acc: 0.70215 |  iteration: 9259 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 558 loss: 1.29555 acc: 0.70117 | v_loss: 1.06885 v_acc: 0.72852 |  iteration: 9260 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 559 loss: 1.21632 acc: 0.71322 | v_loss: 1.16666 v_acc: 0.71419 |  iteration: 9261 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 560 loss: 1.31732 acc: 0.70215 | v_loss: 1.17669 v_acc: 0.69694 |  iteration: 9262 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 561 loss: 1.30938 acc: 0.70345 | v_loss: 1.13533 v_acc: 0.71908 |  iteration: 9263 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 562 loss: 1.30288 acc: 0.69987 | v_loss: 1.21699 v_acc: 0.71680 |  iteration: 9264 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 563 loss: 1.23988 acc: 0.70898 | v_loss: 1.24914 v_acc: 0.71126 |  iteration: 9265 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 564 loss: 1.27982 acc: 0.70833 | v_loss: 1.22159 v_acc: 0.72396 |  iteration: 9266 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 565 loss: 1.33862 acc: 0.70312 | v_loss: 1.37532 v_acc: 0.70182 |  iteration: 9267 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 566 loss: 1.26734 acc: 0.70638 | v_loss: 1.26182 v_acc: 0.71777 |  iteration: 9268 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 567 loss: 1.29361 acc: 0.69922 | v_loss: 1.04491 v_acc: 0.74447 |  iteration: 9269 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 568 loss: 1.28742 acc: 0.70605 | v_loss: 1.20037 v_acc: 0.71322 |  iteration: 9270 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 569 loss: 1.20626 acc: 0.71908 | v_loss: 1.25808 v_acc: 0.69987 |  iteration: 9271 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 570 loss: 1.30418 acc: 0.70638 | v_loss: 1.20238 v_acc: 0.70671 |  iteration: 9272 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 571 loss: 1.23629 acc: 0.71159 | v_loss: 1.24916 v_acc: 0.71257 |  iteration: 9273 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 572 loss: 1.27355 acc: 0.71029 | v_loss: 1.25135 v_acc: 0.69401 |  iteration: 9274 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 573 loss: 1.30743 acc: 0.70931 | v_loss: 1.22179 v_acc: 0.71061 |  iteration: 9275 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 574 loss: 1.26836 acc: 0.71322 | v_loss: 1.25582 v_acc: 0.69303 |  iteration: 9276 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 575 loss: 1.28709 acc: 0.70833 | v_loss: 1.19780 v_acc: 0.71875 |  iteration: 9277 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 576 loss: 1.33789 acc: 0.69857 | v_loss: 1.18970 v_acc: 0.72721 |  iteration: 9278 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 577 loss: 1.27439 acc: 0.70671 | v_loss: 1.24918 v_acc: 0.70378 |  iteration: 9279 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 578 loss: 1.25216 acc: 0.71126 | v_loss: 1.32804 v_acc: 0.69824 |  iteration: 9280 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 579 loss: 1.25097 acc: 0.71354 | v_loss: 1.16420 v_acc: 0.70996 |  iteration: 9281 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 580 loss: 1.29477 acc: 0.70931 | v_loss: 1.42561 v_acc: 0.68685 |  iteration: 9282 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 581 loss: 1.27888 acc: 0.69629 | v_loss: 1.18310 v_acc: 0.71940 |  iteration: 9283 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 582 loss: 1.20641 acc: 0.71126 | v_loss: 1.47715 v_acc: 0.67773 |  iteration: 9284 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 583 loss: 1.21946 acc: 0.71029 | v_loss: 1.36503 v_acc: 0.70085 |  iteration: 9285 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 584 loss: 1.21478 acc: 0.71354 | v_loss: 1.34495 v_acc: 0.69303 |  iteration: 9286 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 585 loss: 1.22857 acc: 0.70996 | v_loss: 1.30596 v_acc: 0.70378 |  iteration: 9287 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 586 loss: 1.29402 acc: 0.70150 | v_loss: 1.22275 v_acc: 0.70638 |  iteration: 9288 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 587 loss: 1.31486 acc: 0.70150 | v_loss: 1.25809 v_acc: 0.70475 |  iteration: 9289 teacher: 0 stage: sketch lr: 0.000459\n",
      "batch 588 loss: 1.18037 acc: 0.71354 | v_loss: 1.21174 v_acc: 0.71777 |  iteration: 9290 teacher: 1 stage: sketch lr: 0.000459\n",
      "batch 589 loss: 1.33319 acc: 0.70020 | v_loss: 1.41779 v_acc: 0.68913 |  iteration: 9291 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 590 loss: 1.30379 acc: 0.69759 | v_loss: 1.29603 v_acc: 0.70378 |  iteration: 9292 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 591 loss: 1.31077 acc: 0.70378 | v_loss: 1.18759 v_acc: 0.71094 |  iteration: 9293 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 592 loss: 1.29662 acc: 0.70768 | v_loss: 1.26463 v_acc: 0.71647 |  iteration: 9294 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 593 loss: 1.30048 acc: 0.70345 | v_loss: 1.17823 v_acc: 0.69857 |  iteration: 9295 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 594 loss: 1.31488 acc: 0.70345 | v_loss: 1.27276 v_acc: 0.69466 |  iteration: 9296 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 595 loss: 1.21653 acc: 0.71191 | v_loss: 1.22727 v_acc: 0.71354 |  iteration: 9297 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 596 loss: 1.31241 acc: 0.69206 | v_loss: 1.17575 v_acc: 0.71680 |  iteration: 9298 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 597 loss: 1.31905 acc: 0.70833 | v_loss: 1.13789 v_acc: 0.72689 |  iteration: 9299 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 598 loss: 1.32253 acc: 0.69694 | v_loss: 1.25955 v_acc: 0.71680 |  iteration: 9300 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 599 loss: 1.32902 acc: 0.70150 | v_loss: 1.24823 v_acc: 0.70085 |  iteration: 9301 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 600 loss: 1.24579 acc: 0.71419 | v_loss: 1.25376 v_acc: 0.70931 |  iteration: 9302 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 601 loss: 1.30689 acc: 0.69368 | v_loss: 1.10092 v_acc: 0.72591 |  iteration: 9303 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 602 loss: 1.27232 acc: 0.71387 | v_loss: 1.23308 v_acc: 0.73145 |  iteration: 9304 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 603 loss: 1.30295 acc: 0.70410 | v_loss: 1.29785 v_acc: 0.69727 |  iteration: 9305 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 604 loss: 1.32014 acc: 0.70605 | v_loss: 1.30943 v_acc: 0.71908 |  iteration: 9306 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 605 loss: 1.21425 acc: 0.70638 | v_loss: 1.15439 v_acc: 0.71810 |  iteration: 9307 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 606 loss: 1.32448 acc: 0.69531 | v_loss: 1.09546 v_acc: 0.73665 |  iteration: 9308 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 607 loss: 1.35015 acc: 0.70540 | v_loss: 1.11842 v_acc: 0.71680 |  iteration: 9309 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 608 loss: 1.32368 acc: 0.70312 | v_loss: 1.18816 v_acc: 0.70573 |  iteration: 9310 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 609 loss: 1.17889 acc: 0.71191 | v_loss: 1.27273 v_acc: 0.69596 |  iteration: 9311 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 610 loss: 1.24901 acc: 0.70898 | v_loss: 1.19261 v_acc: 0.71224 |  iteration: 9312 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 611 loss: 1.24268 acc: 0.70443 | v_loss: 1.29123 v_acc: 0.71647 |  iteration: 9313 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 612 loss: 1.26670 acc: 0.70736 | v_loss: 1.49262 v_acc: 0.69206 |  iteration: 9314 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 613 loss: 1.27000 acc: 0.71354 | v_loss: 1.35465 v_acc: 0.69857 |  iteration: 9315 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 614 loss: 1.30416 acc: 0.70085 | v_loss: 1.19317 v_acc: 0.72005 |  iteration: 9316 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 615 loss: 1.34400 acc: 0.70150 | v_loss: 1.15638 v_acc: 0.69987 |  iteration: 9317 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 616 loss: 1.26313 acc: 0.71061 | v_loss: 1.15595 v_acc: 0.71712 |  iteration: 9318 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 617 loss: 1.29840 acc: 0.69857 | v_loss: 1.21734 v_acc: 0.70247 |  iteration: 9319 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 618 loss: 1.30158 acc: 0.70182 | v_loss: 1.25818 v_acc: 0.70703 |  iteration: 9320 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 619 loss: 1.34568 acc: 0.70215 | v_loss: 1.20216 v_acc: 0.72852 |  iteration: 9321 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 620 loss: 1.24823 acc: 0.71582 | v_loss: 1.22438 v_acc: 0.72005 |  iteration: 9322 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 621 loss: 1.41769 acc: 0.68945 | v_loss: 1.24621 v_acc: 0.70443 |  iteration: 9323 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 622 loss: 1.27736 acc: 0.70378 | v_loss: 1.15481 v_acc: 0.72493 |  iteration: 9324 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 623 loss: 1.25983 acc: 0.70931 | v_loss: 1.12590 v_acc: 0.72038 |  iteration: 9325 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 624 loss: 1.34531 acc: 0.70020 | v_loss: 1.41423 v_acc: 0.69043 |  iteration: 9326 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 625 loss: 1.24478 acc: 0.70508 | v_loss: 1.21748 v_acc: 0.70866 |  iteration: 9327 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 626 loss: 1.31712 acc: 0.69401 | v_loss: 1.22959 v_acc: 0.71549 |  iteration: 9328 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 627 loss: 1.26380 acc: 0.70378 | v_loss: 1.21993 v_acc: 0.70443 |  iteration: 9329 teacher: 0 stage: sketch lr: 0.000458\n",
      "batch 628 loss: 1.29260 acc: 0.70312 | v_loss: 1.28062 v_acc: 0.69792 |  iteration: 9330 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 629 loss: 1.31560 acc: 0.70247 | v_loss: 1.15230 v_acc: 0.73503 |  iteration: 9331 teacher: 1 stage: sketch lr: 0.000458\n",
      "batch 630 loss: 1.46392 acc: 0.68685 | v_loss: 1.38659 v_acc: 0.71289 |  iteration: 9332 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 631 loss: 1.33221 acc: 0.69694 | v_loss: 1.18334 v_acc: 0.70182 |  iteration: 9333 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 633 loss: 1.28329 acc: 0.70345 | v_loss: 1.25185 v_acc: 0.70540 |  iteration: 9335 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 634 loss: 1.24796 acc: 0.69954 | v_loss: 1.25798 v_acc: 0.70215 |  iteration: 9336 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 635 loss: 1.27843 acc: 0.70247 | v_loss: 1.31983 v_acc: 0.69466 |  iteration: 9337 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 636 loss: 1.25919 acc: 0.70768 | v_loss: 1.36484 v_acc: 0.70833 |  iteration: 9338 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 637 loss: 1.25470 acc: 0.71159 | v_loss: 1.27670 v_acc: 0.70085 |  iteration: 9339 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 638 loss: 1.31002 acc: 0.71419 | v_loss: 1.19326 v_acc: 0.70898 |  iteration: 9340 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 639 loss: 1.26281 acc: 0.70443 | v_loss: 1.31666 v_acc: 0.70703 |  iteration: 9341 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 640 loss: 1.25084 acc: 0.71094 | v_loss: 1.21058 v_acc: 0.71322 |  iteration: 9342 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 641 loss: 1.29145 acc: 0.70378 | v_loss: 1.14498 v_acc: 0.72070 |  iteration: 9343 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 642 loss: 1.29309 acc: 0.70182 | v_loss: 1.12060 v_acc: 0.70996 |  iteration: 9344 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 643 loss: 1.23118 acc: 0.71387 | v_loss: 1.24498 v_acc: 0.70703 |  iteration: 9345 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 644 loss: 1.27667 acc: 0.70150 | v_loss: 1.33548 v_acc: 0.69824 |  iteration: 9346 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 645 loss: 1.27455 acc: 0.70508 | v_loss: 1.15800 v_acc: 0.71191 |  iteration: 9347 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 646 loss: 1.32307 acc: 0.70215 | v_loss: 1.19663 v_acc: 0.70312 |  iteration: 9348 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 647 loss: 1.26294 acc: 0.71126 | v_loss: 1.17380 v_acc: 0.71940 |  iteration: 9349 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 648 loss: 1.23736 acc: 0.71452 | v_loss: 1.19969 v_acc: 0.70898 |  iteration: 9350 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 649 loss: 1.30938 acc: 0.69564 | v_loss: 1.06177 v_acc: 0.73861 |  iteration: 9351 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 650 loss: 1.41712 acc: 0.69922 | v_loss: 1.17037 v_acc: 0.71517 |  iteration: 9352 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 651 loss: 1.31968 acc: 0.69759 | v_loss: 1.13815 v_acc: 0.70638 |  iteration: 9353 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 652 loss: 1.31498 acc: 0.70378 | v_loss: 1.12998 v_acc: 0.72005 |  iteration: 9354 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 653 loss: 1.29321 acc: 0.70150 | v_loss: 1.20243 v_acc: 0.72135 |  iteration: 9355 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 654 loss: 1.28126 acc: 0.71126 | v_loss: 1.22439 v_acc: 0.71875 |  iteration: 9356 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 655 loss: 1.29106 acc: 0.71061 | v_loss: 1.19652 v_acc: 0.72266 |  iteration: 9357 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 656 loss: 1.32226 acc: 0.70378 | v_loss: 1.39298 v_acc: 0.69629 |  iteration: 9358 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 657 loss: 1.27292 acc: 0.70703 | v_loss: 1.25272 v_acc: 0.72201 |  iteration: 9359 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 658 loss: 1.19874 acc: 0.72754 | v_loss: 1.05842 v_acc: 0.74837 |  iteration: 9360 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 659 loss: 1.17951 acc: 0.71322 | v_loss: 1.21460 v_acc: 0.70345 |  iteration: 9361 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 660 loss: 1.37303 acc: 0.69889 | v_loss: 1.26634 v_acc: 0.70020 |  iteration: 9362 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 661 loss: 1.39328 acc: 0.69792 | v_loss: 1.17793 v_acc: 0.70801 |  iteration: 9363 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 662 loss: 1.27413 acc: 0.71224 | v_loss: 1.25012 v_acc: 0.71126 |  iteration: 9364 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 663 loss: 1.30601 acc: 0.70671 | v_loss: 1.25018 v_acc: 0.68978 |  iteration: 9365 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 664 loss: 1.32714 acc: 0.70085 | v_loss: 1.20578 v_acc: 0.71126 |  iteration: 9366 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 665 loss: 1.29678 acc: 0.70508 | v_loss: 1.24555 v_acc: 0.69401 |  iteration: 9367 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 666 loss: 1.30712 acc: 0.69792 | v_loss: 1.21950 v_acc: 0.70898 |  iteration: 9368 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 667 loss: 1.39380 acc: 0.69759 | v_loss: 1.19008 v_acc: 0.72331 |  iteration: 9369 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 668 loss: 1.26185 acc: 0.70345 | v_loss: 1.26775 v_acc: 0.70150 |  iteration: 9370 teacher: 0 stage: sketch lr: 0.000457\n",
      "batch 669 loss: 1.26098 acc: 0.69792 | v_loss: 1.32704 v_acc: 0.70085 |  iteration: 9371 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 670 loss: 1.21685 acc: 0.71257 | v_loss: 1.16046 v_acc: 0.70703 |  iteration: 9372 teacher: 1 stage: sketch lr: 0.000457\n",
      "batch 671 loss: 1.21122 acc: 0.71191 | v_loss: 1.40190 v_acc: 0.68880 |  iteration: 9373 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 672 loss: 1.34200 acc: 0.69271 | v_loss: 1.15413 v_acc: 0.72038 |  iteration: 9374 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 673 loss: 1.24925 acc: 0.70345 | v_loss: 1.48552 v_acc: 0.68001 |  iteration: 9375 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 674 loss: 1.21208 acc: 0.70801 | v_loss: 1.37755 v_acc: 0.69661 |  iteration: 9376 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 675 loss: 1.24189 acc: 0.71061 | v_loss: 1.32294 v_acc: 0.69141 |  iteration: 9377 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 676 loss: 1.31740 acc: 0.70638 | v_loss: 1.32905 v_acc: 0.69824 |  iteration: 9378 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 677 loss: 1.21429 acc: 0.70703 | v_loss: 1.22576 v_acc: 0.70410 |  iteration: 9379 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 678 loss: 1.33014 acc: 0.69694 | v_loss: 1.27405 v_acc: 0.70150 |  iteration: 9380 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 679 loss: 1.22291 acc: 0.71940 | v_loss: 1.23813 v_acc: 0.71549 |  iteration: 9381 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 680 loss: 1.29571 acc: 0.69141 | v_loss: 1.42923 v_acc: 0.68359 |  iteration: 9382 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 681 loss: 1.27877 acc: 0.70215 | v_loss: 1.29999 v_acc: 0.70150 |  iteration: 9383 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 682 loss: 1.29115 acc: 0.70573 | v_loss: 1.18532 v_acc: 0.70833 |  iteration: 9384 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 683 loss: 1.19756 acc: 0.70964 | v_loss: 1.26627 v_acc: 0.70833 |  iteration: 9385 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 684 loss: 1.37737 acc: 0.69173 | v_loss: 1.16390 v_acc: 0.70573 |  iteration: 9386 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 685 loss: 1.30259 acc: 0.71029 | v_loss: 1.26275 v_acc: 0.69596 |  iteration: 9387 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 686 loss: 1.32022 acc: 0.69499 | v_loss: 1.23857 v_acc: 0.71029 |  iteration: 9388 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 687 loss: 1.33019 acc: 0.69792 | v_loss: 1.17516 v_acc: 0.71126 |  iteration: 9389 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 688 loss: 1.29585 acc: 0.69824 | v_loss: 1.14480 v_acc: 0.72168 |  iteration: 9390 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 689 loss: 1.33690 acc: 0.69368 | v_loss: 1.25359 v_acc: 0.71354 |  iteration: 9391 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 690 loss: 1.20286 acc: 0.71354 | v_loss: 1.24484 v_acc: 0.70150 |  iteration: 9392 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 691 loss: 1.37383 acc: 0.69238 | v_loss: 1.25340 v_acc: 0.70898 |  iteration: 9393 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 692 loss: 1.28468 acc: 0.70085 | v_loss: 1.10420 v_acc: 0.72461 |  iteration: 9394 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 693 loss: 1.25010 acc: 0.71191 | v_loss: 1.23824 v_acc: 0.73145 |  iteration: 9395 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 694 loss: 1.30101 acc: 0.70671 | v_loss: 1.29668 v_acc: 0.69824 |  iteration: 9396 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 695 loss: 1.25889 acc: 0.70605 | v_loss: 1.29340 v_acc: 0.72168 |  iteration: 9397 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 696 loss: 1.25631 acc: 0.70280 | v_loss: 1.15866 v_acc: 0.71940 |  iteration: 9398 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 697 loss: 1.36522 acc: 0.69173 | v_loss: 1.10485 v_acc: 0.74447 |  iteration: 9399 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 698 loss: 1.28177 acc: 0.70247 | v_loss: 1.10526 v_acc: 0.72493 |  iteration: 9400 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 699 loss: 1.20801 acc: 0.71191 | v_loss: 1.18780 v_acc: 0.71126 |  iteration: 9401 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 700 loss: 1.34548 acc: 0.69629 | v_loss: 1.23014 v_acc: 0.70671 |  iteration: 9402 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 701 loss: 1.28673 acc: 0.71387 | v_loss: 1.19031 v_acc: 0.71549 |  iteration: 9403 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 702 loss: 1.20474 acc: 0.71322 | v_loss: 1.33170 v_acc: 0.70475 |  iteration: 9404 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 703 loss: 1.19816 acc: 0.71387 | v_loss: 1.47350 v_acc: 0.69141 |  iteration: 9405 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 704 loss: 1.33325 acc: 0.70410 | v_loss: 1.35068 v_acc: 0.69727 |  iteration: 9406 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 705 loss: 1.28886 acc: 0.70443 | v_loss: 1.19019 v_acc: 0.72363 |  iteration: 9407 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 706 loss: 1.22283 acc: 0.71029 | v_loss: 1.15641 v_acc: 0.70964 |  iteration: 9408 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 707 loss: 1.26253 acc: 0.70801 | v_loss: 1.15564 v_acc: 0.72135 |  iteration: 9409 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 708 loss: 1.39146 acc: 0.69759 | v_loss: 1.22394 v_acc: 0.70215 |  iteration: 9410 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 709 loss: 1.30965 acc: 0.71061 | v_loss: 1.24835 v_acc: 0.71354 |  iteration: 9411 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 710 loss: 1.27217 acc: 0.70215 | v_loss: 1.20760 v_acc: 0.72721 |  iteration: 9412 teacher: 0 stage: sketch lr: 0.000456\n",
      "batch 711 loss: 1.33618 acc: 0.69922 | v_loss: 1.23130 v_acc: 0.71712 |  iteration: 9413 teacher: 1 stage: sketch lr: 0.000456\n",
      "batch 712 loss: 1.29848 acc: 0.70605 | v_loss: 1.24488 v_acc: 0.70443 |  iteration: 9414 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 713 loss: 1.39417 acc: 0.69889 | v_loss: 1.15717 v_acc: 0.72103 |  iteration: 9415 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 714 loss: 1.28325 acc: 0.70573 | v_loss: 1.13056 v_acc: 0.72135 |  iteration: 9416 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 715 loss: 1.23853 acc: 0.70703 | v_loss: 1.43656 v_acc: 0.69336 |  iteration: 9417 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 716 loss: 1.31053 acc: 0.70931 | v_loss: 1.20093 v_acc: 0.70996 |  iteration: 9418 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 717 loss: 1.38387 acc: 0.69141 | v_loss: 1.22837 v_acc: 0.71517 |  iteration: 9419 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 718 loss: 1.31490 acc: 0.69792 | v_loss: 1.21669 v_acc: 0.72005 |  iteration: 9420 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 719 loss: 1.29504 acc: 0.70996 | v_loss: 1.26898 v_acc: 0.70703 |  iteration: 9421 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 720 loss: 1.34443 acc: 0.69792 | v_loss: 1.13390 v_acc: 0.73079 |  iteration: 9422 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 721 loss: 1.27187 acc: 0.70605 | v_loss: 1.35910 v_acc: 0.71322 |  iteration: 9423 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 722 loss: 1.39805 acc: 0.70215 | v_loss: 1.20355 v_acc: 0.69564 |  iteration: 9424 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 723 loss: 1.23130 acc: 0.71159 | v_loss: 1.21250 v_acc: 0.70215 |  iteration: 9425 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 724 loss: 1.26249 acc: 0.72038 | v_loss: 1.27011 v_acc: 0.70345 |  iteration: 9426 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 725 loss: 1.28900 acc: 0.70898 | v_loss: 1.27726 v_acc: 0.70378 |  iteration: 9427 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 726 loss: 1.25546 acc: 0.71387 | v_loss: 1.34395 v_acc: 0.69076 |  iteration: 9428 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 727 loss: 1.32168 acc: 0.69694 | v_loss: 1.35922 v_acc: 0.70638 |  iteration: 9429 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 728 loss: 1.21382 acc: 0.71745 | v_loss: 1.28728 v_acc: 0.70540 |  iteration: 9430 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 729 loss: 1.34387 acc: 0.70931 | v_loss: 1.21844 v_acc: 0.70768 |  iteration: 9431 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 730 loss: 1.32116 acc: 0.71029 | v_loss: 1.30675 v_acc: 0.70671 |  iteration: 9432 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 731 loss: 1.27919 acc: 0.71061 | v_loss: 1.20893 v_acc: 0.71289 |  iteration: 9433 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 732 loss: 1.30959 acc: 0.69792 | v_loss: 1.13801 v_acc: 0.72428 |  iteration: 9434 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 733 loss: 1.33828 acc: 0.70052 | v_loss: 1.13838 v_acc: 0.70931 |  iteration: 9435 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 734 loss: 1.27578 acc: 0.70410 | v_loss: 1.25058 v_acc: 0.70247 |  iteration: 9436 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 735 loss: 1.32840 acc: 0.69759 | v_loss: 1.31296 v_acc: 0.70020 |  iteration: 9437 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 736 loss: 1.18649 acc: 0.72103 | v_loss: 1.15736 v_acc: 0.71387 |  iteration: 9438 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 737 loss: 1.25980 acc: 0.70736 | v_loss: 1.18997 v_acc: 0.70312 |  iteration: 9439 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 738 loss: 1.34046 acc: 0.69954 | v_loss: 1.18649 v_acc: 0.71680 |  iteration: 9440 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 739 loss: 1.15444 acc: 0.72656 | v_loss: 1.20351 v_acc: 0.70671 |  iteration: 9441 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 740 loss: 1.23978 acc: 0.70768 | v_loss: 1.05914 v_acc: 0.73568 |  iteration: 9442 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 741 loss: 1.43041 acc: 0.68652 | v_loss: 1.16769 v_acc: 0.72461 |  iteration: 9443 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 742 loss: 1.28938 acc: 0.70410 | v_loss: 1.12953 v_acc: 0.73145 |  iteration: 9444 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 743 loss: 1.31076 acc: 0.69987 | v_loss: 1.11703 v_acc: 0.72461 |  iteration: 9445 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 744 loss: 1.24447 acc: 0.70540 | v_loss: 1.19677 v_acc: 0.71842 |  iteration: 9446 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 745 loss: 1.32714 acc: 0.70312 | v_loss: 1.21968 v_acc: 0.71322 |  iteration: 9447 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 746 loss: 1.33720 acc: 0.69368 | v_loss: 1.18779 v_acc: 0.71940 |  iteration: 9448 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 747 loss: 1.26205 acc: 0.70085 | v_loss: 1.39036 v_acc: 0.69759 |  iteration: 9449 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 748 loss: 1.29469 acc: 0.69303 | v_loss: 1.25910 v_acc: 0.72005 |  iteration: 9450 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 749 loss: 1.23059 acc: 0.71680 | v_loss: 1.06647 v_acc: 0.74870 |  iteration: 9451 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 750 loss: 1.22018 acc: 0.70996 | v_loss: 1.20259 v_acc: 0.70605 |  iteration: 9452 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 751 loss: 1.31308 acc: 0.69206 | v_loss: 1.29130 v_acc: 0.69889 |  iteration: 9453 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 752 loss: 1.24218 acc: 0.70605 | v_loss: 1.18259 v_acc: 0.71029 |  iteration: 9454 teacher: 0 stage: sketch lr: 0.000455\n",
      "batch 753 loss: 1.24256 acc: 0.70410 | v_loss: 1.25746 v_acc: 0.71159 |  iteration: 9455 teacher: 1 stage: sketch lr: 0.000455\n",
      "batch 754 loss: 1.33576 acc: 0.70215 | v_loss: 1.25374 v_acc: 0.69173 |  iteration: 9456 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 755 loss: 1.33751 acc: 0.70898 | v_loss: 1.19604 v_acc: 0.71029 |  iteration: 9457 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 756 loss: 1.24330 acc: 0.70605 | v_loss: 1.25441 v_acc: 0.69401 |  iteration: 9458 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 757 loss: 1.32953 acc: 0.71029 | v_loss: 1.18545 v_acc: 0.71159 |  iteration: 9459 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 758 loss: 1.32135 acc: 0.70085 | v_loss: 1.17614 v_acc: 0.72363 |  iteration: 9460 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 759 loss: 1.37510 acc: 0.69173 | v_loss: 1.22050 v_acc: 0.70215 |  iteration: 9461 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 760 loss: 1.23608 acc: 0.71126 | v_loss: 1.34054 v_acc: 0.69857 |  iteration: 9462 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 761 loss: 1.34586 acc: 0.68880 | v_loss: 1.15069 v_acc: 0.70801 |  iteration: 9463 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 762 loss: 1.36418 acc: 0.70052 | v_loss: 1.40992 v_acc: 0.68392 |  iteration: 9464 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 763 loss: 1.37656 acc: 0.70052 | v_loss: 1.16018 v_acc: 0.72298 |  iteration: 9465 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 764 loss: 1.31585 acc: 0.69987 | v_loss: 1.47133 v_acc: 0.68294 |  iteration: 9466 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 765 loss: 1.27217 acc: 0.71061 | v_loss: 1.35007 v_acc: 0.70215 |  iteration: 9467 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 766 loss: 1.25706 acc: 0.71419 | v_loss: 1.31959 v_acc: 0.69238 |  iteration: 9468 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 767 loss: 1.33646 acc: 0.70150 | v_loss: 1.30387 v_acc: 0.70280 |  iteration: 9469 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 768 loss: 1.26207 acc: 0.70378 | v_loss: 1.22734 v_acc: 0.70508 |  iteration: 9470 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 769 loss: 1.24030 acc: 0.70605 | v_loss: 1.25998 v_acc: 0.70345 |  iteration: 9471 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 770 loss: 1.28950 acc: 0.71484 | v_loss: 1.21090 v_acc: 0.71745 |  iteration: 9472 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 771 loss: 1.23617 acc: 0.70085 | v_loss: 1.41476 v_acc: 0.68717 |  iteration: 9473 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 772 loss: 1.33278 acc: 0.69727 | v_loss: 1.29273 v_acc: 0.71094 |  iteration: 9474 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 773 loss: 1.27253 acc: 0.71159 | v_loss: 1.18451 v_acc: 0.70996 |  iteration: 9475 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 774 loss: 1.20785 acc: 0.71680 | v_loss: 1.26116 v_acc: 0.71419 |  iteration: 9476 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 775 loss: 1.31009 acc: 0.70312 | v_loss: 1.15823 v_acc: 0.70931 |  iteration: 9477 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 776 loss: 1.39476 acc: 0.69010 | v_loss: 1.26995 v_acc: 0.69824 |  iteration: 9478 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 777 loss: 1.35449 acc: 0.70247 | v_loss: 1.22843 v_acc: 0.71354 |  iteration: 9479 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 778 loss: 1.31974 acc: 0.70671 | v_loss: 1.16395 v_acc: 0.71647 |  iteration: 9480 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 779 loss: 1.37512 acc: 0.69271 | v_loss: 1.13430 v_acc: 0.72689 |  iteration: 9481 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 780 loss: 1.32231 acc: 0.69922 | v_loss: 1.25920 v_acc: 0.71582 |  iteration: 9482 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 781 loss: 1.32626 acc: 0.71126 | v_loss: 1.25272 v_acc: 0.70085 |  iteration: 9483 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 782 loss: 1.21147 acc: 0.71322 | v_loss: 1.26158 v_acc: 0.70443 |  iteration: 9484 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 783 loss: 1.24049 acc: 0.70508 | v_loss: 1.11113 v_acc: 0.71419 |  iteration: 9485 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 784 loss: 1.26521 acc: 0.70117 | v_loss: 1.24998 v_acc: 0.72786 |  iteration: 9486 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 785 loss: 1.30952 acc: 0.70605 | v_loss: 1.30465 v_acc: 0.69792 |  iteration: 9487 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 786 loss: 1.33114 acc: 0.69889 | v_loss: 1.29826 v_acc: 0.72201 |  iteration: 9488 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 787 loss: 1.35374 acc: 0.69141 | v_loss: 1.15127 v_acc: 0.72168 |  iteration: 9489 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 788 loss: 1.31740 acc: 0.70020 | v_loss: 1.10351 v_acc: 0.74154 |  iteration: 9490 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 789 loss: 1.36222 acc: 0.69434 | v_loss: 1.11207 v_acc: 0.72461 |  iteration: 9491 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 790 loss: 1.28544 acc: 0.70540 | v_loss: 1.18625 v_acc: 0.71094 |  iteration: 9492 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 791 loss: 1.29393 acc: 0.70768 | v_loss: 1.24227 v_acc: 0.70443 |  iteration: 9493 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 792 loss: 1.33407 acc: 0.70508 | v_loss: 1.19320 v_acc: 0.71680 |  iteration: 9494 teacher: 1 stage: sketch lr: 0.000454\n",
      "batch 793 loss: 1.31082 acc: 0.70150 | v_loss: 1.31083 v_acc: 0.70345 |  iteration: 9495 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 794 loss: 1.40049 acc: 0.69336 | v_loss: 1.47272 v_acc: 0.69076 |  iteration: 9496 teacher: 0 stage: sketch lr: 0.000454\n",
      "batch 795 loss: 1.26959 acc: 0.70378 | v_loss: 1.34146 v_acc: 0.69792 |  iteration: 9497 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 796 loss: 1.29150 acc: 0.70833 | v_loss: 1.19594 v_acc: 0.72363 |  iteration: 9498 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 797 loss: 1.23110 acc: 0.70475 | v_loss: 1.14826 v_acc: 0.70312 |  iteration: 9499 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 798 loss: 1.28035 acc: 0.69857 | v_loss: 1.15722 v_acc: 0.71908 |  iteration: 9500 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 799 loss: 1.36133 acc: 0.69368 | v_loss: 1.21200 v_acc: 0.70378 |  iteration: 9501 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 800 loss: 1.26225 acc: 0.71842 | v_loss: 1.25657 v_acc: 0.70833 |  iteration: 9502 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 801 loss: 1.29214 acc: 0.70378 | v_loss: 1.20261 v_acc: 0.73079 |  iteration: 9503 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 802 loss: 1.21882 acc: 0.71322 | v_loss: 1.22445 v_acc: 0.71777 |  iteration: 9504 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 803 loss: 1.36838 acc: 0.70020 | v_loss: 1.23811 v_acc: 0.70443 |  iteration: 9505 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 804 loss: 1.23161 acc: 0.71452 | v_loss: 1.15292 v_acc: 0.72233 |  iteration: 9506 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 805 loss: 1.28272 acc: 0.70768 | v_loss: 1.12184 v_acc: 0.72201 |  iteration: 9507 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 806 loss: 1.26283 acc: 0.70931 | v_loss: 1.43545 v_acc: 0.69368 |  iteration: 9508 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 807 loss: 1.28167 acc: 0.70573 | v_loss: 1.20876 v_acc: 0.70768 |  iteration: 9509 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 808 loss: 1.32818 acc: 0.69824 | v_loss: 1.21129 v_acc: 0.71908 |  iteration: 9510 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 809 loss: 1.25557 acc: 0.71029 | v_loss: 1.20646 v_acc: 0.71354 |  iteration: 9511 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 810 loss: 1.26971 acc: 0.69889 | v_loss: 1.27191 v_acc: 0.70540 |  iteration: 9512 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 811 loss: 1.23525 acc: 0.70931 | v_loss: 1.13693 v_acc: 0.73210 |  iteration: 9513 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 812 loss: 1.35051 acc: 0.70801 | v_loss: 1.36576 v_acc: 0.71387 |  iteration: 9514 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 813 loss: 1.26002 acc: 0.70150 | v_loss: 1.19300 v_acc: 0.69564 |  iteration: 9515 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 814 loss: 1.31516 acc: 0.70671 | v_loss: 1.21279 v_acc: 0.70215 |  iteration: 9516 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 815 loss: 1.29614 acc: 0.70768 | v_loss: 1.26812 v_acc: 0.70312 |  iteration: 9517 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 816 loss: 1.34464 acc: 0.69824 | v_loss: 1.27174 v_acc: 0.70150 |  iteration: 9518 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 817 loss: 1.19953 acc: 0.70931 | v_loss: 1.33554 v_acc: 0.68848 |  iteration: 9519 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 818 loss: 1.21753 acc: 0.70540 | v_loss: 1.35817 v_acc: 0.70638 |  iteration: 9520 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 819 loss: 1.36081 acc: 0.69303 | v_loss: 1.27864 v_acc: 0.70540 |  iteration: 9521 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 820 loss: 1.26109 acc: 0.71419 | v_loss: 1.19740 v_acc: 0.70703 |  iteration: 9522 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 821 loss: 1.27995 acc: 0.70117 | v_loss: 1.31443 v_acc: 0.70508 |  iteration: 9523 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 822 loss: 1.35918 acc: 0.69661 | v_loss: 1.21274 v_acc: 0.71647 |  iteration: 9524 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 823 loss: 1.29521 acc: 0.70052 | v_loss: 1.13103 v_acc: 0.72233 |  iteration: 9525 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 824 loss: 1.34823 acc: 0.69694 | v_loss: 1.12227 v_acc: 0.70736 |  iteration: 9526 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 825 loss: 1.26640 acc: 0.70573 | v_loss: 1.23866 v_acc: 0.70671 |  iteration: 9527 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 826 loss: 1.31431 acc: 0.71126 | v_loss: 1.31017 v_acc: 0.69922 |  iteration: 9528 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 827 loss: 1.22227 acc: 0.70605 | v_loss: 1.14898 v_acc: 0.71387 |  iteration: 9529 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 828 loss: 1.31504 acc: 0.70085 | v_loss: 1.19284 v_acc: 0.70280 |  iteration: 9530 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 829 loss: 1.36317 acc: 0.69987 | v_loss: 1.18671 v_acc: 0.71094 |  iteration: 9531 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 830 loss: 1.28733 acc: 0.70052 | v_loss: 1.21634 v_acc: 0.70605 |  iteration: 9532 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 831 loss: 1.26816 acc: 0.70410 | v_loss: 1.06796 v_acc: 0.74121 |  iteration: 9533 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 832 loss: 1.24447 acc: 0.71191 | v_loss: 1.17209 v_acc: 0.71875 |  iteration: 9534 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 833 loss: 1.27615 acc: 0.69922 | v_loss: 1.12277 v_acc: 0.72656 |  iteration: 9535 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 834 loss: 1.29526 acc: 0.70638 | v_loss: 1.12448 v_acc: 0.72298 |  iteration: 9536 teacher: 1 stage: sketch lr: 0.000453\n",
      "batch 835 loss: 1.27750 acc: 0.70801 | v_loss: 1.21131 v_acc: 0.72070 |  iteration: 9537 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 836 loss: 1.25028 acc: 0.70703 | v_loss: 1.22038 v_acc: 0.71647 |  iteration: 9538 teacher: 0 stage: sketch lr: 0.000453\n",
      "batch 837 loss: 1.30868 acc: 0.70215 | v_loss: 1.21517 v_acc: 0.72656 |  iteration: 9539 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 838 loss: 1.25068 acc: 0.70215 | v_loss: 1.38844 v_acc: 0.70182 |  iteration: 9540 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 839 loss: 1.26298 acc: 0.70378 | v_loss: 1.25616 v_acc: 0.71777 |  iteration: 9541 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 840 loss: 1.30035 acc: 0.69336 | v_loss: 1.04595 v_acc: 0.74447 |  iteration: 9542 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 841 loss: 1.29156 acc: 0.70964 | v_loss: 1.19741 v_acc: 0.71322 |  iteration: 9543 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 842 loss: 1.29806 acc: 0.70736 | v_loss: 1.26471 v_acc: 0.69987 |  iteration: 9544 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 843 loss: 1.34342 acc: 0.69596 | v_loss: 1.18407 v_acc: 0.70671 |  iteration: 9545 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 844 loss: 1.25196 acc: 0.70573 | v_loss: 1.24379 v_acc: 0.71354 |  iteration: 9546 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 845 loss: 1.23288 acc: 0.71094 | v_loss: 1.23674 v_acc: 0.69368 |  iteration: 9547 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 846 loss: 1.24499 acc: 0.70312 | v_loss: 1.20303 v_acc: 0.71126 |  iteration: 9548 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 847 loss: 1.26849 acc: 0.70573 | v_loss: 1.24742 v_acc: 0.69596 |  iteration: 9549 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 848 loss: 1.27430 acc: 0.70378 | v_loss: 1.18694 v_acc: 0.71680 |  iteration: 9550 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 849 loss: 1.39237 acc: 0.68848 | v_loss: 1.17845 v_acc: 0.72786 |  iteration: 9551 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 850 loss: 1.26330 acc: 0.70443 | v_loss: 1.23549 v_acc: 0.70540 |  iteration: 9552 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 851 loss: 1.26479 acc: 0.70540 | v_loss: 1.34235 v_acc: 0.69857 |  iteration: 9553 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 852 loss: 1.22813 acc: 0.70866 | v_loss: 1.14475 v_acc: 0.70931 |  iteration: 9554 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 853 loss: 1.21974 acc: 0.70703 | v_loss: 1.41818 v_acc: 0.68522 |  iteration: 9555 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 854 loss: 1.32143 acc: 0.70671 | v_loss: 1.16408 v_acc: 0.72168 |  iteration: 9556 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 855 loss: 1.23192 acc: 0.71126 | v_loss: 1.47640 v_acc: 0.67969 |  iteration: 9557 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 856 loss: 1.30443 acc: 0.70247 | v_loss: 1.36254 v_acc: 0.69857 |  iteration: 9558 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 857 loss: 1.40721 acc: 0.68587 | v_loss: 1.34114 v_acc: 0.69303 |  iteration: 9559 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 858 loss: 1.24190 acc: 0.70833 | v_loss: 1.30691 v_acc: 0.70215 |  iteration: 9560 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 859 loss: 1.42526 acc: 0.68750 | v_loss: 1.22910 v_acc: 0.70345 |  iteration: 9561 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 860 loss: 1.27789 acc: 0.70410 | v_loss: 1.26535 v_acc: 0.70052 |  iteration: 9562 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 861 loss: 1.24491 acc: 0.70801 | v_loss: 1.22126 v_acc: 0.71615 |  iteration: 9563 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 862 loss: 1.24295 acc: 0.70540 | v_loss: 1.39668 v_acc: 0.68880 |  iteration: 9564 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 863 loss: 1.33317 acc: 0.70312 | v_loss: 1.29298 v_acc: 0.70703 |  iteration: 9565 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 864 loss: 1.30164 acc: 0.70736 | v_loss: 1.18735 v_acc: 0.70931 |  iteration: 9566 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 865 loss: 1.22387 acc: 0.71615 | v_loss: 1.24526 v_acc: 0.71582 |  iteration: 9567 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 866 loss: 1.27673 acc: 0.70768 | v_loss: 1.16890 v_acc: 0.70443 |  iteration: 9568 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 867 loss: 1.21565 acc: 0.70378 | v_loss: 1.25280 v_acc: 0.69889 |  iteration: 9569 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 868 loss: 1.23574 acc: 0.71875 | v_loss: 1.21716 v_acc: 0.71615 |  iteration: 9570 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 869 loss: 1.24939 acc: 0.71745 | v_loss: 1.16141 v_acc: 0.72038 |  iteration: 9571 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 870 loss: 1.28031 acc: 0.70280 | v_loss: 1.12764 v_acc: 0.72363 |  iteration: 9572 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 871 loss: 1.34721 acc: 0.69954 | v_loss: 1.25477 v_acc: 0.71842 |  iteration: 9573 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 872 loss: 1.24477 acc: 0.70475 | v_loss: 1.24729 v_acc: 0.70345 |  iteration: 9574 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 873 loss: 1.30171 acc: 0.70768 | v_loss: 1.25313 v_acc: 0.70866 |  iteration: 9575 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 874 loss: 1.33204 acc: 0.70117 | v_loss: 1.09550 v_acc: 0.72591 |  iteration: 9576 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 875 loss: 1.25512 acc: 0.70117 | v_loss: 1.25532 v_acc: 0.73112 |  iteration: 9577 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 876 loss: 1.24234 acc: 0.72070 | v_loss: 1.31953 v_acc: 0.69564 |  iteration: 9578 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 877 loss: 1.21218 acc: 0.71387 | v_loss: 1.32971 v_acc: 0.72201 |  iteration: 9579 teacher: 0 stage: sketch lr: 0.000452\n",
      "batch 878 loss: 1.30562 acc: 0.69857 | v_loss: 1.14309 v_acc: 0.72201 |  iteration: 9580 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 879 loss: 1.28833 acc: 0.70215 | v_loss: 1.08793 v_acc: 0.73991 |  iteration: 9581 teacher: 1 stage: sketch lr: 0.000452\n",
      "batch 880 loss: 1.27908 acc: 0.70247 | v_loss: 1.11571 v_acc: 0.72559 |  iteration: 9582 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 881 loss: 1.27784 acc: 0.71191 | v_loss: 1.17611 v_acc: 0.70703 |  iteration: 9583 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 882 loss: 1.36792 acc: 0.69108 | v_loss: 1.24114 v_acc: 0.69596 |  iteration: 9584 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 883 loss: 1.27691 acc: 0.70410 | v_loss: 1.19490 v_acc: 0.71257 |  iteration: 9585 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 884 loss: 1.25536 acc: 0.71354 | v_loss: 1.30365 v_acc: 0.71549 |  iteration: 9586 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 885 loss: 1.32351 acc: 0.69857 | v_loss: 1.44891 v_acc: 0.69173 |  iteration: 9587 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 886 loss: 1.25123 acc: 0.70475 | v_loss: 1.34288 v_acc: 0.69792 |  iteration: 9588 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 887 loss: 1.29983 acc: 0.69727 | v_loss: 1.19603 v_acc: 0.72298 |  iteration: 9589 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 888 loss: 1.27505 acc: 0.71615 | v_loss: 1.16218 v_acc: 0.70443 |  iteration: 9590 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 889 loss: 1.33035 acc: 0.69596 | v_loss: 1.15355 v_acc: 0.71940 |  iteration: 9591 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 890 loss: 1.28881 acc: 0.70182 | v_loss: 1.21572 v_acc: 0.70410 |  iteration: 9592 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 891 loss: 1.33482 acc: 0.69303 | v_loss: 1.24586 v_acc: 0.71810 |  iteration: 9593 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 892 loss: 1.32935 acc: 0.70247 | v_loss: 1.20032 v_acc: 0.73014 |  iteration: 9594 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 893 loss: 1.20865 acc: 0.70703 | v_loss: 1.23418 v_acc: 0.71973 |  iteration: 9595 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 894 loss: 1.30324 acc: 0.70931 | v_loss: 1.23767 v_acc: 0.70964 |  iteration: 9596 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 895 loss: 1.21208 acc: 0.71126 | v_loss: 1.14370 v_acc: 0.72493 |  iteration: 9597 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 896 loss: 1.32458 acc: 0.70182 | v_loss: 1.11509 v_acc: 0.72038 |  iteration: 9598 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 897 loss: 1.27895 acc: 0.69889 | v_loss: 1.39822 v_acc: 0.69368 |  iteration: 9599 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 898 loss: 1.31455 acc: 0.69596 | v_loss: 1.20333 v_acc: 0.71419 |  iteration: 9600 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 899 loss: 1.23140 acc: 0.71191 | v_loss: 1.21735 v_acc: 0.71517 |  iteration: 9601 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 900 loss: 1.30304 acc: 0.69466 | v_loss: 1.20307 v_acc: 0.72201 |  iteration: 9602 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 901 loss: 1.29100 acc: 0.71354 | v_loss: 1.26899 v_acc: 0.70671 |  iteration: 9603 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 902 loss: 1.28351 acc: 0.70410 | v_loss: 1.14868 v_acc: 0.73177 |  iteration: 9604 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 903 loss: 1.30138 acc: 0.71777 | v_loss: 1.37663 v_acc: 0.71322 |  iteration: 9605 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 904 loss: 1.31767 acc: 0.69271 | v_loss: 1.19398 v_acc: 0.69759 |  iteration: 9606 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 905 loss: 1.33119 acc: 0.69531 | v_loss: 1.20851 v_acc: 0.70475 |  iteration: 9607 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 906 loss: 1.26919 acc: 0.70052 | v_loss: 1.25517 v_acc: 0.70280 |  iteration: 9608 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 907 loss: 1.31288 acc: 0.70117 | v_loss: 1.26280 v_acc: 0.70378 |  iteration: 9609 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 908 loss: 1.24306 acc: 0.70866 | v_loss: 1.31525 v_acc: 0.69466 |  iteration: 9610 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 909 loss: 1.33873 acc: 0.70117 | v_loss: 1.35990 v_acc: 0.70801 |  iteration: 9611 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 910 loss: 1.31314 acc: 0.70866 | v_loss: 1.26846 v_acc: 0.70410 |  iteration: 9612 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 911 loss: 1.31539 acc: 0.70475 | v_loss: 1.18394 v_acc: 0.70866 |  iteration: 9613 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 912 loss: 1.40693 acc: 0.68978 | v_loss: 1.31827 v_acc: 0.70736 |  iteration: 9614 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 913 loss: 1.26868 acc: 0.71094 | v_loss: 1.21161 v_acc: 0.71191 |  iteration: 9615 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 914 loss: 1.31876 acc: 0.69564 | v_loss: 1.14324 v_acc: 0.72266 |  iteration: 9616 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 915 loss: 1.24495 acc: 0.70801 | v_loss: 1.13253 v_acc: 0.71126 |  iteration: 9617 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 916 loss: 1.19808 acc: 0.71322 | v_loss: 1.26189 v_acc: 0.70671 |  iteration: 9618 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 917 loss: 1.29891 acc: 0.70736 | v_loss: 1.32219 v_acc: 0.69499 |  iteration: 9619 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 918 loss: 1.27387 acc: 0.69694 | v_loss: 1.15190 v_acc: 0.70703 |  iteration: 9620 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 919 loss: 1.18047 acc: 0.71191 | v_loss: 1.20274 v_acc: 0.69564 |  iteration: 9621 teacher: 1 stage: sketch lr: 0.000451\n",
      "batch 920 loss: 1.27190 acc: 0.70020 | v_loss: 1.20013 v_acc: 0.70768 |  iteration: 9622 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 921 loss: 1.27019 acc: 0.70508 | v_loss: 1.22200 v_acc: 0.70345 |  iteration: 9623 teacher: 0 stage: sketch lr: 0.000451\n",
      "batch 922 loss: 1.32430 acc: 0.70475 | v_loss: 1.05786 v_acc: 0.73633 |  iteration: 9624 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 923 loss: 1.36893 acc: 0.69857 | v_loss: 1.17994 v_acc: 0.71647 |  iteration: 9625 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 924 loss: 1.33414 acc: 0.69922 | v_loss: 1.10560 v_acc: 0.73405 |  iteration: 9626 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 925 loss: 1.25887 acc: 0.71159 | v_loss: 1.12220 v_acc: 0.72103 |  iteration: 9627 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 926 loss: 1.21726 acc: 0.71354 | v_loss: 1.19784 v_acc: 0.71745 |  iteration: 9628 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 927 loss: 1.38243 acc: 0.69889 | v_loss: 1.22898 v_acc: 0.71224 |  iteration: 9629 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 928 loss: 1.28564 acc: 0.71257 | v_loss: 1.22121 v_acc: 0.71973 |  iteration: 9630 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 929 loss: 1.27662 acc: 0.71061 | v_loss: 1.37823 v_acc: 0.69857 |  iteration: 9631 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 930 loss: 1.33215 acc: 0.68978 | v_loss: 1.27899 v_acc: 0.71777 |  iteration: 9632 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 931 loss: 1.25139 acc: 0.70768 | v_loss: 1.05730 v_acc: 0.74447 |  iteration: 9633 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 932 loss: 1.22125 acc: 0.70866 | v_loss: 1.18744 v_acc: 0.71322 |  iteration: 9634 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 933 loss: 1.26658 acc: 0.69694 | v_loss: 1.27255 v_acc: 0.69987 |  iteration: 9635 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 934 loss: 1.26167 acc: 0.71257 | v_loss: 1.18451 v_acc: 0.70671 |  iteration: 9636 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 935 loss: 1.27072 acc: 0.70150 | v_loss: 1.24540 v_acc: 0.71257 |  iteration: 9637 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 936 loss: 1.25687 acc: 0.71387 | v_loss: 1.23129 v_acc: 0.69401 |  iteration: 9638 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 937 loss: 1.32392 acc: 0.70508 | v_loss: 1.20829 v_acc: 0.71680 |  iteration: 9639 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 938 loss: 1.24985 acc: 0.69759 | v_loss: 1.24394 v_acc: 0.69792 |  iteration: 9640 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 939 loss: 1.31692 acc: 0.70703 | v_loss: 1.18487 v_acc: 0.71061 |  iteration: 9641 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 940 loss: 1.22426 acc: 0.69238 | v_loss: 1.17196 v_acc: 0.72363 |  iteration: 9642 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 941 loss: 1.33878 acc: 0.69076 | v_loss: 1.24752 v_acc: 0.70215 |  iteration: 9643 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 942 loss: 1.29998 acc: 0.70508 | v_loss: 1.32301 v_acc: 0.69922 |  iteration: 9644 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 943 loss: 1.34409 acc: 0.69434 | v_loss: 1.15838 v_acc: 0.70443 |  iteration: 9645 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 944 loss: 1.42921 acc: 0.69141 | v_loss: 1.40143 v_acc: 0.68555 |  iteration: 9646 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 945 loss: 1.26879 acc: 0.70508 | v_loss: 1.17681 v_acc: 0.72168 |  iteration: 9647 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 946 loss: 1.32869 acc: 0.69531 | v_loss: 1.46837 v_acc: 0.67708 |  iteration: 9648 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 947 loss: 1.25816 acc: 0.70638 | v_loss: 1.36090 v_acc: 0.69108 |  iteration: 9649 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 948 loss: 1.20209 acc: 0.70866 | v_loss: 1.32653 v_acc: 0.68783 |  iteration: 9650 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 949 loss: 1.25487 acc: 0.70964 | v_loss: 1.30065 v_acc: 0.70020 |  iteration: 9651 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 950 loss: 1.34777 acc: 0.70378 | v_loss: 1.22770 v_acc: 0.70410 |  iteration: 9652 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 951 loss: 1.28976 acc: 0.70182 | v_loss: 1.25590 v_acc: 0.70345 |  iteration: 9653 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 952 loss: 1.26828 acc: 0.70866 | v_loss: 1.21118 v_acc: 0.72070 |  iteration: 9654 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 953 loss: 1.33942 acc: 0.69629 | v_loss: 1.40287 v_acc: 0.68880 |  iteration: 9655 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 954 loss: 1.41056 acc: 0.69466 | v_loss: 1.28624 v_acc: 0.70508 |  iteration: 9656 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 955 loss: 1.34212 acc: 0.70443 | v_loss: 1.18507 v_acc: 0.71159 |  iteration: 9657 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 956 loss: 1.34626 acc: 0.69889 | v_loss: 1.25979 v_acc: 0.71517 |  iteration: 9658 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 957 loss: 1.38341 acc: 0.69922 | v_loss: 1.16430 v_acc: 0.70605 |  iteration: 9659 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 958 loss: 1.29653 acc: 0.69987 | v_loss: 1.25673 v_acc: 0.69824 |  iteration: 9660 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 959 loss: 1.28381 acc: 0.70215 | v_loss: 1.22490 v_acc: 0.71224 |  iteration: 9661 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 960 loss: 1.25239 acc: 0.70052 | v_loss: 1.15920 v_acc: 0.72005 |  iteration: 9662 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 961 loss: 1.38840 acc: 0.69694 | v_loss: 1.14048 v_acc: 0.72396 |  iteration: 9663 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 962 loss: 1.25345 acc: 0.69987 | v_loss: 1.27235 v_acc: 0.71680 |  iteration: 9664 teacher: 1 stage: sketch lr: 0.000450\n",
      "batch 963 loss: 1.22630 acc: 0.70345 | v_loss: 1.24667 v_acc: 0.70215 |  iteration: 9665 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 964 loss: 1.26597 acc: 0.70736 | v_loss: 1.23972 v_acc: 0.70996 |  iteration: 9666 teacher: 0 stage: sketch lr: 0.000450\n",
      "batch 965 loss: 1.29665 acc: 0.69824 | v_loss: 1.09805 v_acc: 0.72168 |  iteration: 9667 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 966 loss: 1.20647 acc: 0.71257 | v_loss: 1.23099 v_acc: 0.73014 |  iteration: 9668 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 967 loss: 1.31596 acc: 0.70247 | v_loss: 1.29192 v_acc: 0.69759 |  iteration: 9669 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 968 loss: 1.36852 acc: 0.69141 | v_loss: 1.30115 v_acc: 0.72005 |  iteration: 9670 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 969 loss: 1.29546 acc: 0.70182 | v_loss: 1.14882 v_acc: 0.72168 |  iteration: 9671 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 970 loss: 1.25401 acc: 0.70410 | v_loss: 1.09575 v_acc: 0.73535 |  iteration: 9672 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 971 loss: 1.27904 acc: 0.70475 | v_loss: 1.11616 v_acc: 0.72624 |  iteration: 9673 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 972 loss: 1.31377 acc: 0.70475 | v_loss: 1.17623 v_acc: 0.70703 |  iteration: 9674 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 973 loss: 1.31505 acc: 0.70117 | v_loss: 1.24621 v_acc: 0.69694 |  iteration: 9675 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 974 loss: 1.30975 acc: 0.70638 | v_loss: 1.18245 v_acc: 0.71615 |  iteration: 9676 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 975 loss: 1.34794 acc: 0.69434 | v_loss: 1.27092 v_acc: 0.71712 |  iteration: 9677 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 976 loss: 1.29154 acc: 0.70150 | v_loss: 1.44119 v_acc: 0.69792 |  iteration: 9678 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 977 loss: 1.37207 acc: 0.68945 | v_loss: 1.32614 v_acc: 0.70215 |  iteration: 9679 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 978 loss: 1.35229 acc: 0.70247 | v_loss: 1.19105 v_acc: 0.72201 |  iteration: 9680 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 979 loss: 1.35757 acc: 0.68945 | v_loss: 1.15524 v_acc: 0.70410 |  iteration: 9681 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 980 loss: 1.26416 acc: 0.70736 | v_loss: 1.16459 v_acc: 0.71908 |  iteration: 9682 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 981 loss: 1.25605 acc: 0.70280 | v_loss: 1.21211 v_acc: 0.70085 |  iteration: 9683 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 982 loss: 1.24734 acc: 0.70247 | v_loss: 1.25022 v_acc: 0.71094 |  iteration: 9684 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 983 loss: 1.30444 acc: 0.69824 | v_loss: 1.19945 v_acc: 0.73047 |  iteration: 9685 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 984 loss: 1.28743 acc: 0.70247 | v_loss: 1.22592 v_acc: 0.71940 |  iteration: 9686 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 985 loss: 1.30462 acc: 0.69401 | v_loss: 1.24026 v_acc: 0.70964 |  iteration: 9687 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 986 loss: 1.30021 acc: 0.69727 | v_loss: 1.14730 v_acc: 0.72656 |  iteration: 9688 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 987 loss: 1.25905 acc: 0.71126 | v_loss: 1.10913 v_acc: 0.72038 |  iteration: 9689 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 988 loss: 1.34445 acc: 0.69368 | v_loss: 1.43642 v_acc: 0.69271 |  iteration: 9690 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 989 loss: 1.31609 acc: 0.70150 | v_loss: 1.20021 v_acc: 0.70931 |  iteration: 9691 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 990 loss: 1.43449 acc: 0.69043 | v_loss: 1.20787 v_acc: 0.71810 |  iteration: 9692 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 991 loss: 1.24597 acc: 0.71484 | v_loss: 1.20308 v_acc: 0.71745 |  iteration: 9693 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 992 loss: 1.26369 acc: 0.69922 | v_loss: 1.25758 v_acc: 0.70410 |  iteration: 9694 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 993 loss: 1.25793 acc: 0.71224 | v_loss: 1.14553 v_acc: 0.72982 |  iteration: 9695 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 994 loss: 1.20311 acc: 0.70866 | v_loss: 1.36922 v_acc: 0.71387 |  iteration: 9696 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 995 loss: 1.30753 acc: 0.70215 | v_loss: 1.17810 v_acc: 0.69954 |  iteration: 9697 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 996 loss: 1.24647 acc: 0.69987 | v_loss: 1.20954 v_acc: 0.70931 |  iteration: 9698 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 997 loss: 1.26499 acc: 0.71191 | v_loss: 1.24760 v_acc: 0.70540 |  iteration: 9699 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 998 loss: 1.33412 acc: 0.69434 | v_loss: 1.25713 v_acc: 0.70247 |  iteration: 9700 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 999 loss: 1.28112 acc: 0.70833 | v_loss: 1.31849 v_acc: 0.69336 |  iteration: 9701 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 1000 loss: 1.25224 acc: 0.70085 | v_loss: 1.35605 v_acc: 0.70671 |  iteration: 9702 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 1001 loss: 1.27127 acc: 0.70736 | v_loss: 1.27446 v_acc: 0.70508 |  iteration: 9703 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 1002 loss: 1.27373 acc: 0.70573 | v_loss: 1.18188 v_acc: 0.71419 |  iteration: 9704 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 1003 loss: 1.35224 acc: 0.69629 | v_loss: 1.31270 v_acc: 0.70964 |  iteration: 9705 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 1004 loss: 1.31994 acc: 0.69987 | v_loss: 1.20389 v_acc: 0.71452 |  iteration: 9706 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 1005 loss: 1.31791 acc: 0.70638 | v_loss: 1.13595 v_acc: 0.72070 |  iteration: 9707 teacher: 0 stage: sketch lr: 0.000449\n",
      "batch 1006 loss: 1.38515 acc: 0.69271 | v_loss: 1.11013 v_acc: 0.71126 |  iteration: 9708 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 1007 loss: 1.32239 acc: 0.69987 | v_loss: 1.26048 v_acc: 0.70540 |  iteration: 9709 teacher: 1 stage: sketch lr: 0.000449\n",
      "batch 1008 loss: 1.25482 acc: 0.71745 | v_loss: 1.32355 v_acc: 0.69629 |  iteration: 9710 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1009 loss: 1.26247 acc: 0.70931 | v_loss: 1.12963 v_acc: 0.70996 |  iteration: 9711 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1010 loss: 1.28174 acc: 0.70703 | v_loss: 1.20271 v_acc: 0.69987 |  iteration: 9712 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1011 loss: 1.27728 acc: 0.70671 | v_loss: 1.15485 v_acc: 0.71647 |  iteration: 9713 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1012 loss: 1.24585 acc: 0.70703 | v_loss: 1.18610 v_acc: 0.70801 |  iteration: 9714 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1013 loss: 1.26620 acc: 0.71745 | v_loss: 1.07170 v_acc: 0.73600 |  iteration: 9715 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1014 loss: 1.25176 acc: 0.70052 | v_loss: 1.15814 v_acc: 0.72298 |  iteration: 9716 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1015 loss: 1.23029 acc: 0.71354 | v_loss: 1.17460 v_acc: 0.72396 |  iteration: 9717 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1016 loss: 1.32912 acc: 0.70085 | v_loss: 1.12917 v_acc: 0.73047 |  iteration: 9718 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1017 loss: 1.21394 acc: 0.72135 | v_loss: 1.22437 v_acc: 0.72070 |  iteration: 9719 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1018 loss: 1.24610 acc: 0.71126 | v_loss: 1.25139 v_acc: 0.71387 |  iteration: 9720 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1019 loss: 1.22487 acc: 0.71940 | v_loss: 1.21591 v_acc: 0.72233 |  iteration: 9721 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1020 loss: 1.21167 acc: 0.71777 | v_loss: 1.38300 v_acc: 0.70052 |  iteration: 9722 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1021 loss: 1.23635 acc: 0.70736 | v_loss: 1.25966 v_acc: 0.71615 |  iteration: 9723 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1022 loss: 1.30590 acc: 0.70638 | v_loss: 1.03573 v_acc: 0.74674 |  iteration: 9724 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1023 loss: 1.28742 acc: 0.72103 | v_loss: 1.20021 v_acc: 0.70378 |  iteration: 9725 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1024 loss: 1.29127 acc: 0.71191 | v_loss: 1.23900 v_acc: 0.70996 |  iteration: 9726 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1025 loss: 1.29769 acc: 0.70508 | v_loss: 1.18602 v_acc: 0.70703 |  iteration: 9727 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1026 loss: 1.20299 acc: 0.70996 | v_loss: 1.24653 v_acc: 0.71159 |  iteration: 9728 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1027 loss: 1.22449 acc: 0.70768 | v_loss: 1.24739 v_acc: 0.69661 |  iteration: 9729 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1028 loss: 1.39396 acc: 0.69434 | v_loss: 1.21873 v_acc: 0.70898 |  iteration: 9730 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1029 loss: 1.30795 acc: 0.70085 | v_loss: 1.24127 v_acc: 0.70085 |  iteration: 9731 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1030 loss: 1.29416 acc: 0.70768 | v_loss: 1.17323 v_acc: 0.71680 |  iteration: 9732 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1031 loss: 1.29742 acc: 0.70378 | v_loss: 1.16147 v_acc: 0.72656 |  iteration: 9733 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1032 loss: 1.33409 acc: 0.70280 | v_loss: 1.22999 v_acc: 0.70508 |  iteration: 9734 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1033 loss: 1.36948 acc: 0.69499 | v_loss: 1.31096 v_acc: 0.69661 |  iteration: 9735 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1034 loss: 1.29378 acc: 0.69173 | v_loss: 1.15031 v_acc: 0.70443 |  iteration: 9736 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1035 loss: 1.26674 acc: 0.70573 | v_loss: 1.43276 v_acc: 0.68132 |  iteration: 9737 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1036 loss: 1.28901 acc: 0.70605 | v_loss: 1.19129 v_acc: 0.71647 |  iteration: 9738 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1037 loss: 1.28465 acc: 0.70247 | v_loss: 1.45789 v_acc: 0.67708 |  iteration: 9739 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1038 loss: 1.22796 acc: 0.70768 | v_loss: 1.31845 v_acc: 0.70117 |  iteration: 9740 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1039 loss: 1.22462 acc: 0.71257 | v_loss: 1.31913 v_acc: 0.69303 |  iteration: 9741 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1040 loss: 1.30140 acc: 0.70052 | v_loss: 1.26741 v_acc: 0.70280 |  iteration: 9742 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1041 loss: 1.27031 acc: 0.70410 | v_loss: 1.21454 v_acc: 0.70671 |  iteration: 9743 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1042 loss: 1.24197 acc: 0.70703 | v_loss: 1.23967 v_acc: 0.70312 |  iteration: 9744 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1043 loss: 1.42290 acc: 0.68294 | v_loss: 1.19999 v_acc: 0.71745 |  iteration: 9745 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1044 loss: 1.30717 acc: 0.71224 | v_loss: 1.37253 v_acc: 0.68815 |  iteration: 9746 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1045 loss: 1.36199 acc: 0.69303 | v_loss: 1.26431 v_acc: 0.71029 |  iteration: 9747 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1046 loss: 1.33700 acc: 0.69857 | v_loss: 1.16089 v_acc: 0.71224 |  iteration: 9748 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1047 loss: 1.30291 acc: 0.70833 | v_loss: 1.25240 v_acc: 0.71517 |  iteration: 9749 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1048 loss: 1.38277 acc: 0.68783 | v_loss: 1.16044 v_acc: 0.70378 |  iteration: 9750 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1049 loss: 1.37827 acc: 0.69434 | v_loss: 1.24239 v_acc: 0.69792 |  iteration: 9751 teacher: 1 stage: sketch lr: 0.000448\n",
      "batch 1050 loss: 1.28770 acc: 0.69857 | v_loss: 1.21942 v_acc: 0.71419 |  iteration: 9752 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1051 loss: 1.30260 acc: 0.70443 | v_loss: 1.17939 v_acc: 0.71615 |  iteration: 9753 teacher: 0 stage: sketch lr: 0.000448\n",
      "batch 1052 loss: 1.27595 acc: 0.70638 | v_loss: 1.13223 v_acc: 0.72917 |  iteration: 9754 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1053 loss: 1.30079 acc: 0.69564 | v_loss: 1.24657 v_acc: 0.71875 |  iteration: 9755 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1054 loss: 1.31505 acc: 0.70605 | v_loss: 1.24229 v_acc: 0.70573 |  iteration: 9756 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1055 loss: 1.22613 acc: 0.70345 | v_loss: 1.24106 v_acc: 0.70866 |  iteration: 9757 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1056 loss: 1.29835 acc: 0.69759 | v_loss: 1.09593 v_acc: 0.72591 |  iteration: 9758 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1057 loss: 1.28783 acc: 0.70378 | v_loss: 1.23234 v_acc: 0.73145 |  iteration: 9759 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1058 loss: 1.22622 acc: 0.71777 | v_loss: 1.28996 v_acc: 0.69759 |  iteration: 9760 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1059 loss: 1.25863 acc: 0.70150 | v_loss: 1.29552 v_acc: 0.72201 |  iteration: 9761 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1060 loss: 1.29947 acc: 0.69987 | v_loss: 1.14759 v_acc: 0.72103 |  iteration: 9762 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1061 loss: 1.22962 acc: 0.70964 | v_loss: 1.09897 v_acc: 0.74023 |  iteration: 9763 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1062 loss: 1.24424 acc: 0.70280 | v_loss: 1.10047 v_acc: 0.72233 |  iteration: 9764 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1063 loss: 1.22605 acc: 0.71452 | v_loss: 1.19629 v_acc: 0.70898 |  iteration: 9765 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1064 loss: 1.35089 acc: 0.70247 | v_loss: 1.22754 v_acc: 0.69727 |  iteration: 9766 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1065 loss: 1.34045 acc: 0.70345 | v_loss: 1.20079 v_acc: 0.71322 |  iteration: 9767 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1066 loss: 1.37934 acc: 0.69434 | v_loss: 1.31013 v_acc: 0.71549 |  iteration: 9768 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1067 loss: 1.25186 acc: 0.70996 | v_loss: 1.45372 v_acc: 0.69043 |  iteration: 9769 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1068 loss: 1.25348 acc: 0.70898 | v_loss: 1.33560 v_acc: 0.70085 |  iteration: 9770 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1069 loss: 1.27884 acc: 0.70410 | v_loss: 1.19936 v_acc: 0.72005 |  iteration: 9771 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1070 loss: 1.36933 acc: 0.69108 | v_loss: 1.16349 v_acc: 0.70312 |  iteration: 9772 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1071 loss: 1.20755 acc: 0.71257 | v_loss: 1.14499 v_acc: 0.72168 |  iteration: 9773 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1072 loss: 1.34374 acc: 0.69857 | v_loss: 1.20861 v_acc: 0.70898 |  iteration: 9774 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1073 loss: 1.22896 acc: 0.71745 | v_loss: 1.24039 v_acc: 0.72201 |  iteration: 9775 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1074 loss: 1.27847 acc: 0.70898 | v_loss: 1.20297 v_acc: 0.72884 |  iteration: 9776 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1075 loss: 1.51052 acc: 0.67285 | v_loss: 1.23073 v_acc: 0.72070 |  iteration: 9777 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1076 loss: 1.31567 acc: 0.70410 | v_loss: 1.23875 v_acc: 0.70898 |  iteration: 9778 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1077 loss: 1.27455 acc: 0.70833 | v_loss: 1.15222 v_acc: 0.72656 |  iteration: 9779 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1078 loss: 1.29949 acc: 0.69824 | v_loss: 1.12123 v_acc: 0.71842 |  iteration: 9780 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1079 loss: 1.34842 acc: 0.71452 | v_loss: 1.45641 v_acc: 0.69173 |  iteration: 9781 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1080 loss: 1.37188 acc: 0.69694 | v_loss: 1.24143 v_acc: 0.70443 |  iteration: 9782 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1081 loss: 1.30038 acc: 0.69792 | v_loss: 1.30874 v_acc: 0.70573 |  iteration: 9783 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1082 loss: 1.24510 acc: 0.71061 | v_loss: 1.27498 v_acc: 0.70573 |  iteration: 9784 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1083 loss: 1.39889 acc: 0.69173 | v_loss: 1.58142 v_acc: 0.68294 |  iteration: 9785 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1084 loss: 1.68490 acc: 0.68099 | v_loss: 1.68784 v_acc: 0.71159 |  iteration: 9786 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1085 loss: 1.62568 acc: 0.66960 | v_loss: 1.78255 v_acc: 0.71029 |  iteration: 9787 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1086 loss: 1.31600 acc: 0.71354 | v_loss: 1.60295 v_acc: 0.70085 |  iteration: 9788 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1087 loss: 1.36454 acc: 0.69401 | v_loss: 1.42118 v_acc: 0.70312 |  iteration: 9789 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1088 loss: 1.34320 acc: 0.70020 | v_loss: 2.32202 v_acc: 0.70443 |  iteration: 9790 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1089 loss: 1.80795 acc: 0.68945 | v_loss: 1.91088 v_acc: 0.70801 |  iteration: 9791 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1090 loss: 1.70858 acc: 0.69336 | v_loss: 1.89639 v_acc: 0.69303 |  iteration: 9792 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1091 loss: 1.52534 acc: 0.69987 | v_loss: 1.71407 v_acc: 0.70768 |  iteration: 9793 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1092 loss: 1.45733 acc: 0.70020 | v_loss: 1.87143 v_acc: 0.70736 |  iteration: 9794 teacher: 0 stage: sketch lr: 0.000447\n",
      "batch 1093 loss: 1.69675 acc: 0.67839 | v_loss: 1.68884 v_acc: 0.70703 |  iteration: 9795 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1094 loss: 1.36464 acc: 0.70215 | v_loss: 1.46567 v_acc: 0.70703 |  iteration: 9796 teacher: 1 stage: sketch lr: 0.000447\n",
      "batch 1095 loss: 1.39571 acc: 0.69857 | v_loss: 1.77007 v_acc: 0.71842 |  iteration: 9797 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1096 loss: 1.41446 acc: 0.69857 | v_loss: 1.46719 v_acc: 0.72201 |  iteration: 9798 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1097 loss: 1.37707 acc: 0.69954 | v_loss: 1.39581 v_acc: 0.71745 |  iteration: 9799 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 1098 loss: 1.45132 acc: 0.69824 | v_loss: 1.57870 v_acc: 0.70833 |  iteration: 9800 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1099 loss: 1.29447 acc: 0.70573 | v_loss: 1.66849 v_acc: 0.70378 |  iteration: 9801 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 1100 loss: 1.60864 acc: 0.70085 | v_loss: 1.73659 v_acc: 0.70801 |  iteration: 9802 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1101 loss: 1.36492 acc: 0.69596 | v_loss: 2.14162 v_acc: 0.69824 |  iteration: 9803 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 1102 loss: 1.43198 acc: 0.71094 | v_loss: 1.55388 v_acc: 0.71191 |  iteration: 9804 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1103 loss: 1.42079 acc: 0.70833 | v_loss: 1.69544 v_acc: 0.70443 |  iteration: 9805 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 1104 loss: 1.22066 acc: 0.71322 | v_loss: 1.55312 v_acc: 0.73405 |  iteration: 9806 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 1105 loss: 1.39193 acc: 0.69727 | v_loss: 1.56697 v_acc: 0.72298 |  iteration: 9807 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 1106 loss: 1.41727 acc: 0.71908 | v_loss: 1.57260 v_acc: 0.73763 |  iteration: 9808 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1107 loss: 1.32167 acc: 0.72201 | v_loss: 1.49157 v_acc: 0.72949 |  iteration: 9809 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 1108 loss: 1.42064 acc: 0.69466 | v_loss: 1.54420 v_acc: 0.71647 |  iteration: 9810 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1109 loss: 1.32386 acc: 0.70964 | v_loss: 1.67084 v_acc: 0.70964 |  iteration: 9811 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 1110 loss: 1.34787 acc: 0.70703 | v_loss: 1.63566 v_acc: 0.72363 |  iteration: 9812 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 1111 loss: 1.37449 acc: 0.69889 | v_loss: 1.79018 v_acc: 0.69857 |  iteration: 9813 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 1112 loss: 1.46919 acc: 0.69434 | v_loss: 1.63704 v_acc: 0.71387 |  iteration: 9814 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1113 loss: 1.38769 acc: 0.69043 | v_loss: 1.36324 v_acc: 0.73926 |  iteration: 9815 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 1114 loss: 1.31149 acc: 0.71354 | v_loss: 1.31834 v_acc: 0.70280 |  iteration: 9816 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1115 loss: 1.27066 acc: 0.71061 | v_loss: 1.62654 v_acc: 0.70736 |  iteration: 9817 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1116 loss: 1.34483 acc: 0.70312 | v_loss: 1.35265 v_acc: 0.69499 |  iteration: 9818 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 1117 loss: 1.42952 acc: 0.69792 | v_loss: 1.67195 v_acc: 0.70052 |  iteration: 9819 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 1118 loss: 1.46569 acc: 0.70410 | v_loss: 1.85510 v_acc: 0.68066 |  iteration: 9820 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1119 loss: 1.36190 acc: 0.70020 | v_loss: 1.35509 v_acc: 0.71549 |  iteration: 9821 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1120 loss: 1.37517 acc: 0.69987 | v_loss: 1.47391 v_acc: 0.69661 |  iteration: 9822 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 1121 loss: 1.40756 acc: 0.70573 | v_loss: 1.74538 v_acc: 0.70150 |  iteration: 9823 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1122 loss: 1.42258 acc: 0.70182 | v_loss: 1.71617 v_acc: 0.70508 |  iteration: 9824 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1123 loss: 1.35484 acc: 0.70247 | v_loss: 1.79982 v_acc: 0.69564 |  iteration: 9825 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 1124 loss: 1.30511 acc: 0.70931 | v_loss: 1.65248 v_acc: 0.69596 |  iteration: 9826 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 1125 loss: 1.34751 acc: 0.70573 | v_loss: 1.62710 v_acc: 0.70020 |  iteration: 9827 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1126 loss: 1.31255 acc: 0.71191 | v_loss: 1.87130 v_acc: 0.67676 |  iteration: 9828 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1127 loss: 1.38862 acc: 0.70671 | v_loss: 1.38474 v_acc: 0.72070 |  iteration: 9829 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1128 loss: 1.39237 acc: 0.69238 | v_loss: 1.65884 v_acc: 0.68717 |  iteration: 9830 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 1129 loss: 1.31898 acc: 0.70345 | v_loss: 1.50771 v_acc: 0.70638 |  iteration: 9831 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 1130 loss: 1.28603 acc: 0.70540 | v_loss: 1.67227 v_acc: 0.69141 |  iteration: 9832 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1131 loss: 1.29510 acc: 0.70508 | v_loss: 1.58312 v_acc: 0.70215 |  iteration: 9833 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 1132 loss: 1.28554 acc: 0.70671 | v_loss: 1.35928 v_acc: 0.70475 |  iteration: 9834 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 1133 loss: 1.27683 acc: 0.69824 | v_loss: 1.41956 v_acc: 0.70540 |  iteration: 9835 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1134 loss: 1.42385 acc: 0.69922 | v_loss: 1.45529 v_acc: 0.71875 |  iteration: 9836 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1135 loss: 1.35417 acc: 0.71257 | v_loss: 1.52695 v_acc: 0.68620 |  iteration: 9837 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1136 loss: 1.28843 acc: 0.71582 | v_loss: 1.48866 v_acc: 0.70833 |  iteration: 9838 teacher: 0 stage: sketch lr: 0.000446\n",
      "batch 1137 loss: 1.30231 acc: 0.70768 | v_loss: 1.36184 v_acc: 0.71387 |  iteration: 9839 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1138 loss: 1.35576 acc: 0.69499 | v_loss: 1.42696 v_acc: 0.71322 |  iteration: 9840 teacher: 1 stage: sketch lr: 0.000446\n",
      "batch 1139 loss: 1.33256 acc: 0.69466 | v_loss: 1.38232 v_acc: 0.70150 |  iteration: 9841 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1140 loss: 1.36190 acc: 0.69531 | v_loss: 1.41220 v_acc: 0.70247 |  iteration: 9842 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1141 loss: 1.28756 acc: 0.70085 | v_loss: 1.38104 v_acc: 0.71647 |  iteration: 9843 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1142 loss: 1.40818 acc: 0.69759 | v_loss: 1.18095 v_acc: 0.72168 |  iteration: 9844 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1143 loss: 1.29720 acc: 0.70638 | v_loss: 1.32080 v_acc: 0.72363 |  iteration: 9845 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1144 loss: 1.28746 acc: 0.70964 | v_loss: 1.40818 v_acc: 0.71745 |  iteration: 9846 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1145 loss: 1.35845 acc: 0.69922 | v_loss: 1.55654 v_acc: 0.70052 |  iteration: 9847 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1146 loss: 1.35053 acc: 0.70573 | v_loss: 1.52775 v_acc: 0.70703 |  iteration: 9848 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1147 loss: 1.27754 acc: 0.69954 | v_loss: 1.28387 v_acc: 0.71419 |  iteration: 9849 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1148 loss: 1.33535 acc: 0.70573 | v_loss: 1.38857 v_acc: 0.72721 |  iteration: 9850 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1149 loss: 1.43835 acc: 0.70117 | v_loss: 1.54015 v_acc: 0.70247 |  iteration: 9851 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1150 loss: 1.43986 acc: 0.70182 | v_loss: 1.40050 v_acc: 0.72070 |  iteration: 9852 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1151 loss: 1.30912 acc: 0.70052 | v_loss: 1.42914 v_acc: 0.71647 |  iteration: 9853 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1152 loss: 1.33660 acc: 0.70117 | v_loss: 1.21498 v_acc: 0.73600 |  iteration: 9854 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1153 loss: 1.29945 acc: 0.70312 | v_loss: 1.30504 v_acc: 0.72428 |  iteration: 9855 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1154 loss: 1.31714 acc: 0.70801 | v_loss: 1.27060 v_acc: 0.71094 |  iteration: 9856 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1155 loss: 1.23581 acc: 0.71061 | v_loss: 1.47515 v_acc: 0.70736 |  iteration: 9857 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1156 loss: 1.28894 acc: 0.70020 | v_loss: 1.31619 v_acc: 0.71745 |  iteration: 9858 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1157 loss: 1.37072 acc: 0.70117 | v_loss: 1.40431 v_acc: 0.70866 |  iteration: 9859 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1158 loss: 1.25303 acc: 0.71322 | v_loss: 1.57507 v_acc: 0.69531 |  iteration: 9860 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1159 loss: 1.37605 acc: 0.70898 | v_loss: 1.60425 v_acc: 0.69499 |  iteration: 9861 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1160 loss: 1.28184 acc: 0.70996 | v_loss: 1.26409 v_acc: 0.72233 |  iteration: 9862 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1161 loss: 1.39326 acc: 0.70052 | v_loss: 1.34398 v_acc: 0.70638 |  iteration: 9863 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1162 loss: 1.29060 acc: 0.70280 | v_loss: 1.33269 v_acc: 0.71973 |  iteration: 9864 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1163 loss: 1.46492 acc: 0.69694 | v_loss: 1.40612 v_acc: 0.70280 |  iteration: 9865 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1164 loss: 1.37754 acc: 0.71126 | v_loss: 1.28161 v_acc: 0.70898 |  iteration: 9866 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1165 loss: 1.43014 acc: 0.69889 | v_loss: 1.33674 v_acc: 0.72526 |  iteration: 9867 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1166 loss: 1.33107 acc: 0.70150 | v_loss: 1.38058 v_acc: 0.71517 |  iteration: 9868 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1167 loss: 1.36749 acc: 0.69336 | v_loss: 1.35311 v_acc: 0.70866 |  iteration: 9869 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1168 loss: 1.29123 acc: 0.70378 | v_loss: 1.28505 v_acc: 0.72135 |  iteration: 9870 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1169 loss: 1.28763 acc: 0.70931 | v_loss: 1.37232 v_acc: 0.71810 |  iteration: 9871 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1170 loss: 1.38527 acc: 0.69954 | v_loss: 1.66940 v_acc: 0.69043 |  iteration: 9872 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1171 loss: 1.33183 acc: 0.69824 | v_loss: 1.34212 v_acc: 0.70866 |  iteration: 9873 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1172 loss: 1.36588 acc: 0.70443 | v_loss: 1.26928 v_acc: 0.71484 |  iteration: 9874 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1173 loss: 1.41173 acc: 0.69661 | v_loss: 1.42365 v_acc: 0.71777 |  iteration: 9875 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1174 loss: 1.28121 acc: 0.70540 | v_loss: 1.52735 v_acc: 0.70410 |  iteration: 9876 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1175 loss: 1.23453 acc: 0.70247 | v_loss: 1.21842 v_acc: 0.73079 |  iteration: 9877 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1176 loss: 1.33148 acc: 0.70345 | v_loss: 1.46295 v_acc: 0.71647 |  iteration: 9878 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1177 loss: 1.29400 acc: 0.70443 | v_loss: 1.37210 v_acc: 0.69368 |  iteration: 9879 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1178 loss: 1.35724 acc: 0.70117 | v_loss: 1.30690 v_acc: 0.69596 |  iteration: 9880 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1179 loss: 1.32604 acc: 0.69401 | v_loss: 1.37103 v_acc: 0.70052 |  iteration: 9881 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1180 loss: 1.25061 acc: 0.70866 | v_loss: 1.48464 v_acc: 0.69141 |  iteration: 9882 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1181 loss: 1.28455 acc: 0.70247 | v_loss: 1.62690 v_acc: 0.66829 |  iteration: 9883 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1182 loss: 1.29379 acc: 0.71973 | v_loss: 1.46612 v_acc: 0.69857 |  iteration: 9884 teacher: 0 stage: sketch lr: 0.000445\n",
      "batch 1183 loss: 1.25911 acc: 0.71387 | v_loss: 1.36043 v_acc: 0.69792 |  iteration: 9885 teacher: 1 stage: sketch lr: 0.000445\n",
      "batch 1184 loss: 1.33104 acc: 0.70020 | v_loss: 1.27161 v_acc: 0.70475 |  iteration: 9886 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1185 loss: 1.31649 acc: 0.70378 | v_loss: 1.38107 v_acc: 0.70703 |  iteration: 9887 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1186 loss: 1.45343 acc: 0.69694 | v_loss: 1.21838 v_acc: 0.71191 |  iteration: 9888 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1187 loss: 1.29940 acc: 0.70247 | v_loss: 1.11246 v_acc: 0.72852 |  iteration: 9889 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1188 loss: 1.44533 acc: 0.68783 | v_loss: 1.16509 v_acc: 0.70540 |  iteration: 9890 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1189 loss: 1.33346 acc: 0.69629 | v_loss: 1.28806 v_acc: 0.70182 |  iteration: 9891 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1190 loss: 1.37773 acc: 0.69206 | v_loss: 1.31672 v_acc: 0.68913 |  iteration: 9892 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1191 loss: 1.33996 acc: 0.70410 | v_loss: 1.15390 v_acc: 0.71582 |  iteration: 9893 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1192 loss: 1.33942 acc: 0.69857 | v_loss: 1.19565 v_acc: 0.70150 |  iteration: 9894 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1193 loss: 1.32075 acc: 0.69889 | v_loss: 1.22238 v_acc: 0.71354 |  iteration: 9895 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1194 loss: 1.23775 acc: 0.71452 | v_loss: 1.24313 v_acc: 0.70052 |  iteration: 9896 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1195 loss: 1.22326 acc: 0.70573 | v_loss: 1.04456 v_acc: 0.73958 |  iteration: 9897 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1196 loss: 1.31801 acc: 0.70410 | v_loss: 1.17745 v_acc: 0.72038 |  iteration: 9898 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1197 loss: 1.26556 acc: 0.69824 | v_loss: 1.11568 v_acc: 0.72721 |  iteration: 9899 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1198 loss: 1.30154 acc: 0.70671 | v_loss: 1.11552 v_acc: 0.73210 |  iteration: 9900 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1199 loss: 1.28523 acc: 0.70312 | v_loss: 1.18715 v_acc: 0.71973 |  iteration: 9901 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1200 loss: 1.33776 acc: 0.70508 | v_loss: 1.20814 v_acc: 0.71289 |  iteration: 9902 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1201 loss: 1.37566 acc: 0.69531 | v_loss: 1.18344 v_acc: 0.72624 |  iteration: 9903 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1202 loss: 1.23703 acc: 0.70768 | v_loss: 1.39798 v_acc: 0.69857 |  iteration: 9904 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1203 loss: 1.32156 acc: 0.70996 | v_loss: 1.25783 v_acc: 0.72168 |  iteration: 9905 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1204 loss: 1.35218 acc: 0.69434 | v_loss: 1.05229 v_acc: 0.74154 |  iteration: 9906 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1205 loss: 1.31499 acc: 0.70215 | v_loss: 1.20814 v_acc: 0.70573 |  iteration: 9907 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1206 loss: 1.28939 acc: 0.70540 | v_loss: 1.26387 v_acc: 0.70182 |  iteration: 9908 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1207 loss: 1.24444 acc: 0.70378 | v_loss: 1.19030 v_acc: 0.71159 |  iteration: 9909 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1208 loss: 1.29806 acc: 0.70085 | v_loss: 1.25416 v_acc: 0.71680 |  iteration: 9910 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1209 loss: 1.27743 acc: 0.71126 | v_loss: 1.25509 v_acc: 0.69238 |  iteration: 9911 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1210 loss: 1.33730 acc: 0.69824 | v_loss: 1.20955 v_acc: 0.71582 |  iteration: 9912 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1211 loss: 1.32364 acc: 0.69759 | v_loss: 1.25284 v_acc: 0.70182 |  iteration: 9913 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1212 loss: 1.35162 acc: 0.69368 | v_loss: 1.16823 v_acc: 0.71973 |  iteration: 9914 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1213 loss: 1.35560 acc: 0.69694 | v_loss: 1.17794 v_acc: 0.72103 |  iteration: 9915 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1214 loss: 1.37066 acc: 0.69499 | v_loss: 1.21894 v_acc: 0.70475 |  iteration: 9916 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1215 loss: 1.31311 acc: 0.70508 | v_loss: 1.36338 v_acc: 0.69499 |  iteration: 9917 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1216 loss: 1.32123 acc: 0.69564 | v_loss: 1.16484 v_acc: 0.70703 |  iteration: 9918 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1217 loss: 1.31380 acc: 0.69792 | v_loss: 1.41712 v_acc: 0.68490 |  iteration: 9919 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1218 loss: 1.30111 acc: 0.70182 | v_loss: 1.15889 v_acc: 0.72624 |  iteration: 9920 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1219 loss: 1.30249 acc: 0.69368 | v_loss: 1.46949 v_acc: 0.68490 |  iteration: 9921 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1220 loss: 1.25080 acc: 0.70312 | v_loss: 1.35481 v_acc: 0.69759 |  iteration: 9922 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1221 loss: 1.27686 acc: 0.71224 | v_loss: 1.32357 v_acc: 0.69206 |  iteration: 9923 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1222 loss: 1.38361 acc: 0.70475 | v_loss: 1.30700 v_acc: 0.69792 |  iteration: 9924 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1223 loss: 1.29907 acc: 0.70475 | v_loss: 1.22616 v_acc: 0.70443 |  iteration: 9925 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1224 loss: 1.31475 acc: 0.70540 | v_loss: 1.26309 v_acc: 0.70605 |  iteration: 9926 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1225 loss: 1.29461 acc: 0.71354 | v_loss: 1.22214 v_acc: 0.71973 |  iteration: 9927 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1226 loss: 1.28894 acc: 0.70475 | v_loss: 1.42188 v_acc: 0.69141 |  iteration: 9928 teacher: 0 stage: sketch lr: 0.000444\n",
      "batch 1227 loss: 1.23556 acc: 0.71029 | v_loss: 1.29499 v_acc: 0.71159 |  iteration: 9929 teacher: 1 stage: sketch lr: 0.000444\n",
      "batch 1228 loss: 1.26653 acc: 0.70768 | v_loss: 1.17148 v_acc: 0.71029 |  iteration: 9930 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 1229 loss: 1.21630 acc: 0.71484 | v_loss: 1.26934 v_acc: 0.70931 |  iteration: 9931 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 1230 loss: 1.31353 acc: 0.70312 | v_loss: 1.18453 v_acc: 0.70605 |  iteration: 9932 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 1231 loss: 1.28075 acc: 0.69922 | v_loss: 1.27736 v_acc: 0.70085 |  iteration: 9933 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 1232 loss: 1.31915 acc: 0.70182 | v_loss: 1.24972 v_acc: 0.71126 |  iteration: 9934 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 1233 loss: 1.33266 acc: 0.69336 | v_loss: 1.17026 v_acc: 0.71615 |  iteration: 9935 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 1234 loss: 1.35856 acc: 0.69238 | v_loss: 1.15817 v_acc: 0.71908 |  iteration: 9936 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 1235 loss: 1.30548 acc: 0.71029 | v_loss: 1.28312 v_acc: 0.70996 |  iteration: 9937 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 1236 loss: 1.29466 acc: 0.70508 | v_loss: 1.25211 v_acc: 0.70508 |  iteration: 9938 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 1237 loss: 1.32797 acc: 0.69727 | v_loss: 1.25223 v_acc: 0.70833 |  iteration: 9939 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 1238 loss: 1.37547 acc: 0.69792 | v_loss: 1.12548 v_acc: 0.71549 |  iteration: 9940 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 1239 loss: 1.30698 acc: 0.70475 | v_loss: 1.24445 v_acc: 0.72917 |  iteration: 9941 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 1240 loss: 1.27040 acc: 0.69889 | v_loss: 1.30061 v_acc: 0.69759 |  iteration: 9942 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 1241 loss: 1.27462 acc: 0.69694 | v_loss: 1.30022 v_acc: 0.72233 |  iteration: 9943 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 1242 loss: 1.22790 acc: 0.71061 | v_loss: 1.15433 v_acc: 0.71940 |  iteration: 9944 teacher: 1 stage: sketch lr: 0.000443\n",
      "epoch 7 loss: 1.29819 acc: 0.70390 | v_loss: 1.25724 v_acc: 0.71015 \n",
      "epoch: 8\n",
      "__________________________________________\n",
      "batch 0 loss: 1.31486 acc: 0.70508 | v_loss: 1.28653 v_acc: 0.70410 |  iteration: 9945 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 1 loss: 1.28420 acc: 0.70866 | v_loss: 1.22102 v_acc: 0.70768 |  iteration: 9946 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 2 loss: 1.26445 acc: 0.71647 | v_loss: 1.30965 v_acc: 0.70475 |  iteration: 9947 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 3 loss: 1.29124 acc: 0.71061 | v_loss: 1.21242 v_acc: 0.71354 |  iteration: 9948 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 4 loss: 1.30320 acc: 0.70801 | v_loss: 1.13378 v_acc: 0.72526 |  iteration: 9949 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 5 loss: 1.27189 acc: 0.70703 | v_loss: 1.13453 v_acc: 0.71126 |  iteration: 9950 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 6 loss: 1.35259 acc: 0.69727 | v_loss: 1.25621 v_acc: 0.70215 |  iteration: 9951 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 7 loss: 1.36086 acc: 0.69792 | v_loss: 1.33116 v_acc: 0.68880 |  iteration: 9952 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 8 loss: 1.29454 acc: 0.70215 | v_loss: 1.14988 v_acc: 0.71582 |  iteration: 9953 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 9 loss: 1.24076 acc: 0.71484 | v_loss: 1.19926 v_acc: 0.70020 |  iteration: 9954 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 10 loss: 1.32561 acc: 0.69141 | v_loss: 1.18871 v_acc: 0.70996 |  iteration: 9955 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 11 loss: 1.34784 acc: 0.69987 | v_loss: 1.20631 v_acc: 0.71061 |  iteration: 9956 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 12 loss: 1.29817 acc: 0.70117 | v_loss: 1.07398 v_acc: 0.72852 |  iteration: 9957 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 13 loss: 1.25532 acc: 0.70964 | v_loss: 1.16982 v_acc: 0.71419 |  iteration: 9958 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 14 loss: 1.29458 acc: 0.70150 | v_loss: 1.16625 v_acc: 0.69596 |  iteration: 9959 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 15 loss: 1.25140 acc: 0.70378 | v_loss: 1.12853 v_acc: 0.72005 |  iteration: 9960 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 16 loss: 1.28955 acc: 0.70378 | v_loss: 1.20730 v_acc: 0.71680 |  iteration: 9961 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 17 loss: 1.26752 acc: 0.70964 | v_loss: 1.22512 v_acc: 0.71191 |  iteration: 9962 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 18 loss: 1.32100 acc: 0.70345 | v_loss: 1.19781 v_acc: 0.72298 |  iteration: 9963 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 19 loss: 1.29337 acc: 0.71354 | v_loss: 1.38607 v_acc: 0.69954 |  iteration: 9964 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 20 loss: 1.33476 acc: 0.69499 | v_loss: 1.25681 v_acc: 0.71908 |  iteration: 9965 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 21 loss: 1.25619 acc: 0.71191 | v_loss: 1.05417 v_acc: 0.74479 |  iteration: 9966 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 22 loss: 1.25545 acc: 0.70508 | v_loss: 1.22293 v_acc: 0.70638 |  iteration: 9967 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 23 loss: 1.19858 acc: 0.71484 | v_loss: 1.25389 v_acc: 0.69694 |  iteration: 9968 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 24 loss: 1.34639 acc: 0.70052 | v_loss: 1.20773 v_acc: 0.70573 |  iteration: 9969 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 25 loss: 1.28645 acc: 0.70508 | v_loss: 1.24726 v_acc: 0.71191 |  iteration: 9970 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 26 loss: 1.43704 acc: 0.70085 | v_loss: 1.24734 v_acc: 0.69303 |  iteration: 9971 teacher: 1 stage: sketch lr: 0.000443\n",
      "batch 27 loss: 1.26325 acc: 0.71029 | v_loss: 1.21206 v_acc: 0.71191 |  iteration: 9972 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 28 loss: 1.21625 acc: 0.71484 | v_loss: 1.25264 v_acc: 0.69434 |  iteration: 9973 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 29 loss: 1.31299 acc: 0.70312 | v_loss: 1.18606 v_acc: 0.71257 |  iteration: 9974 teacher: 0 stage: sketch lr: 0.000443\n",
      "batch 30 loss: 1.17383 acc: 0.71159 | v_loss: 1.18302 v_acc: 0.72819 |  iteration: 9975 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 31 loss: 1.19764 acc: 0.71680 | v_loss: 1.24098 v_acc: 0.70312 |  iteration: 9976 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 32 loss: 1.24983 acc: 0.70768 | v_loss: 1.32733 v_acc: 0.69954 |  iteration: 9977 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 33 loss: 1.28581 acc: 0.70703 | v_loss: 1.15454 v_acc: 0.70964 |  iteration: 9978 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 34 loss: 1.31926 acc: 0.69987 | v_loss: 1.40307 v_acc: 0.68913 |  iteration: 9979 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 35 loss: 1.21812 acc: 0.71615 | v_loss: 1.15808 v_acc: 0.72135 |  iteration: 9980 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 36 loss: 1.25326 acc: 0.70671 | v_loss: 1.47505 v_acc: 0.68457 |  iteration: 9981 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 37 loss: 1.29786 acc: 0.70898 | v_loss: 1.36733 v_acc: 0.69629 |  iteration: 9982 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 38 loss: 1.38382 acc: 0.69108 | v_loss: 1.32157 v_acc: 0.69271 |  iteration: 9983 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 39 loss: 1.29438 acc: 0.69629 | v_loss: 1.31491 v_acc: 0.69629 |  iteration: 9984 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 40 loss: 1.21505 acc: 0.71647 | v_loss: 1.22982 v_acc: 0.70638 |  iteration: 9985 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 41 loss: 1.33808 acc: 0.69629 | v_loss: 1.26085 v_acc: 0.70345 |  iteration: 9986 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 42 loss: 1.31596 acc: 0.69466 | v_loss: 1.21095 v_acc: 0.71940 |  iteration: 9987 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 43 loss: 1.35316 acc: 0.69694 | v_loss: 1.40389 v_acc: 0.68848 |  iteration: 9988 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 44 loss: 1.34394 acc: 0.69889 | v_loss: 1.29761 v_acc: 0.70378 |  iteration: 9989 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 45 loss: 1.19644 acc: 0.71322 | v_loss: 1.18889 v_acc: 0.71126 |  iteration: 9990 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 46 loss: 1.26426 acc: 0.71582 | v_loss: 1.24938 v_acc: 0.71484 |  iteration: 9991 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 47 loss: 1.29749 acc: 0.69694 | v_loss: 1.16428 v_acc: 0.70801 |  iteration: 9992 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 48 loss: 1.22955 acc: 0.70866 | v_loss: 1.26393 v_acc: 0.70085 |  iteration: 9993 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 49 loss: 1.23964 acc: 0.70898 | v_loss: 1.22880 v_acc: 0.71289 |  iteration: 9994 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 50 loss: 1.29156 acc: 0.69694 | v_loss: 1.16345 v_acc: 0.71875 |  iteration: 9995 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 51 loss: 1.28656 acc: 0.70150 | v_loss: 1.13021 v_acc: 0.72689 |  iteration: 9996 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 52 loss: 1.23817 acc: 0.70833 | v_loss: 1.26530 v_acc: 0.72038 |  iteration: 9997 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 53 loss: 1.30064 acc: 0.70508 | v_loss: 1.24097 v_acc: 0.70605 |  iteration: 9998 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 54 loss: 1.33747 acc: 0.71126 | v_loss: 1.24626 v_acc: 0.70931 |  iteration: 9999 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 55 loss: 1.24606 acc: 0.70931 | v_loss: 1.09763 v_acc: 0.72331 |  iteration: 10000 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 56 loss: 1.29794 acc: 0.70085 | v_loss: 1.24249 v_acc: 0.73145 |  iteration: 10001 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 57 loss: 1.27649 acc: 0.70573 | v_loss: 1.29397 v_acc: 0.69531 |  iteration: 10002 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 58 loss: 1.21614 acc: 0.71615 | v_loss: 1.31114 v_acc: 0.72233 |  iteration: 10003 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 59 loss: 1.26321 acc: 0.70215 | v_loss: 1.15353 v_acc: 0.72201 |  iteration: 10004 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 60 loss: 1.23813 acc: 0.71029 | v_loss: 1.09949 v_acc: 0.73503 |  iteration: 10005 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 61 loss: 1.35828 acc: 0.69173 | v_loss: 1.10760 v_acc: 0.72266 |  iteration: 10006 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 62 loss: 1.28251 acc: 0.70736 | v_loss: 1.18561 v_acc: 0.71061 |  iteration: 10007 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 63 loss: 1.24256 acc: 0.70573 | v_loss: 1.23818 v_acc: 0.70410 |  iteration: 10008 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 64 loss: 1.21798 acc: 0.70833 | v_loss: 1.19302 v_acc: 0.71257 |  iteration: 10009 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 65 loss: 1.20417 acc: 0.70833 | v_loss: 1.32759 v_acc: 0.70378 |  iteration: 10010 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 66 loss: 1.31447 acc: 0.69238 | v_loss: 1.46393 v_acc: 0.69564 |  iteration: 10011 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 67 loss: 1.29905 acc: 0.71061 | v_loss: 1.33506 v_acc: 0.70052 |  iteration: 10012 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 68 loss: 1.19684 acc: 0.71484 | v_loss: 1.19369 v_acc: 0.72266 |  iteration: 10013 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 69 loss: 1.28807 acc: 0.69238 | v_loss: 1.14892 v_acc: 0.70247 |  iteration: 10014 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 70 loss: 1.30799 acc: 0.69824 | v_loss: 1.15832 v_acc: 0.71777 |  iteration: 10015 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 71 loss: 1.31908 acc: 0.70833 | v_loss: 1.20524 v_acc: 0.70378 |  iteration: 10016 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 72 loss: 1.31089 acc: 0.70280 | v_loss: 1.26191 v_acc: 0.70833 |  iteration: 10017 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 73 loss: 1.26932 acc: 0.70345 | v_loss: 1.20878 v_acc: 0.73079 |  iteration: 10018 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 74 loss: 1.29721 acc: 0.70052 | v_loss: 1.24820 v_acc: 0.71777 |  iteration: 10019 teacher: 0 stage: sketch lr: 0.000442\n",
      "batch 75 loss: 1.33674 acc: 0.70020 | v_loss: 1.25130 v_acc: 0.70345 |  iteration: 10020 teacher: 1 stage: sketch lr: 0.000442\n",
      "batch 76 loss: 1.30118 acc: 0.71061 | v_loss: 1.15385 v_acc: 0.72363 |  iteration: 10021 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 77 loss: 1.27171 acc: 0.70345 | v_loss: 1.12468 v_acc: 0.72070 |  iteration: 10022 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 78 loss: 1.26623 acc: 0.70410 | v_loss: 1.39712 v_acc: 0.69368 |  iteration: 10023 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 79 loss: 1.26893 acc: 0.70508 | v_loss: 1.20829 v_acc: 0.70605 |  iteration: 10024 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 80 loss: 1.30747 acc: 0.69889 | v_loss: 1.22149 v_acc: 0.71842 |  iteration: 10025 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 81 loss: 1.24870 acc: 0.70768 | v_loss: 1.23097 v_acc: 0.70931 |  iteration: 10026 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 82 loss: 1.34763 acc: 0.69368 | v_loss: 1.27387 v_acc: 0.70508 |  iteration: 10027 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 83 loss: 1.33662 acc: 0.69531 | v_loss: 1.13906 v_acc: 0.73470 |  iteration: 10028 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 84 loss: 1.34151 acc: 0.68880 | v_loss: 1.37028 v_acc: 0.71354 |  iteration: 10029 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 85 loss: 1.37200 acc: 0.69824 | v_loss: 1.19449 v_acc: 0.70052 |  iteration: 10030 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 86 loss: 1.36549 acc: 0.69596 | v_loss: 1.21661 v_acc: 0.70247 |  iteration: 10031 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 87 loss: 1.37128 acc: 0.69499 | v_loss: 1.25560 v_acc: 0.70247 |  iteration: 10032 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 88 loss: 1.27947 acc: 0.70117 | v_loss: 1.26372 v_acc: 0.70573 |  iteration: 10033 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 89 loss: 1.28590 acc: 0.70020 | v_loss: 1.32347 v_acc: 0.69499 |  iteration: 10034 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 90 loss: 1.32512 acc: 0.69336 | v_loss: 1.36260 v_acc: 0.70085 |  iteration: 10035 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 91 loss: 1.19141 acc: 0.71387 | v_loss: 1.28060 v_acc: 0.70605 |  iteration: 10036 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 92 loss: 1.33171 acc: 0.69922 | v_loss: 1.20190 v_acc: 0.70508 |  iteration: 10037 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 93 loss: 1.26185 acc: 0.70833 | v_loss: 1.31790 v_acc: 0.70605 |  iteration: 10038 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 94 loss: 1.24348 acc: 0.71224 | v_loss: 1.22825 v_acc: 0.71289 |  iteration: 10039 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 95 loss: 1.30889 acc: 0.70638 | v_loss: 1.13229 v_acc: 0.72559 |  iteration: 10040 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 96 loss: 1.22178 acc: 0.71842 | v_loss: 1.13750 v_acc: 0.70964 |  iteration: 10041 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 97 loss: 1.25753 acc: 0.69466 | v_loss: 1.24965 v_acc: 0.70964 |  iteration: 10042 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 98 loss: 1.28992 acc: 0.69889 | v_loss: 1.31729 v_acc: 0.69987 |  iteration: 10043 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 99 loss: 1.35035 acc: 0.70540 | v_loss: 1.14938 v_acc: 0.71517 |  iteration: 10044 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 100 loss: 1.28732 acc: 0.70182 | v_loss: 1.18848 v_acc: 0.70117 |  iteration: 10045 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 101 loss: 1.25000 acc: 0.70475 | v_loss: 1.18558 v_acc: 0.71224 |  iteration: 10046 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 102 loss: 1.35764 acc: 0.68815 | v_loss: 1.20982 v_acc: 0.70280 |  iteration: 10047 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 103 loss: 1.40497 acc: 0.68815 | v_loss: 1.06483 v_acc: 0.73600 |  iteration: 10048 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 104 loss: 1.23559 acc: 0.71191 | v_loss: 1.18550 v_acc: 0.71647 |  iteration: 10049 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 105 loss: 1.31475 acc: 0.69922 | v_loss: 1.12487 v_acc: 0.73633 |  iteration: 10050 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 106 loss: 1.29668 acc: 0.70150 | v_loss: 1.12404 v_acc: 0.72298 |  iteration: 10051 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 107 loss: 1.38361 acc: 0.69759 | v_loss: 1.19790 v_acc: 0.72168 |  iteration: 10052 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 108 loss: 1.24992 acc: 0.70638 | v_loss: 1.21566 v_acc: 0.71452 |  iteration: 10053 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 109 loss: 1.28340 acc: 0.70475 | v_loss: 1.20168 v_acc: 0.72298 |  iteration: 10054 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 110 loss: 1.28734 acc: 0.71842 | v_loss: 1.39095 v_acc: 0.70020 |  iteration: 10055 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 111 loss: 1.24121 acc: 0.70052 | v_loss: 1.26467 v_acc: 0.72168 |  iteration: 10056 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 112 loss: 1.31403 acc: 0.70378 | v_loss: 1.05459 v_acc: 0.74154 |  iteration: 10057 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 113 loss: 1.30420 acc: 0.70280 | v_loss: 1.21178 v_acc: 0.70247 |  iteration: 10058 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 114 loss: 1.27144 acc: 0.70117 | v_loss: 1.26212 v_acc: 0.69922 |  iteration: 10059 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 115 loss: 1.33617 acc: 0.70866 | v_loss: 1.19869 v_acc: 0.71029 |  iteration: 10060 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 116 loss: 1.28260 acc: 0.70573 | v_loss: 1.24933 v_acc: 0.71549 |  iteration: 10061 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 117 loss: 1.26174 acc: 0.70573 | v_loss: 1.25090 v_acc: 0.69629 |  iteration: 10062 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 118 loss: 1.25519 acc: 0.70605 | v_loss: 1.23738 v_acc: 0.70475 |  iteration: 10063 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 119 loss: 1.27885 acc: 0.70605 | v_loss: 1.27753 v_acc: 0.69466 |  iteration: 10064 teacher: 0 stage: sketch lr: 0.000441\n",
      "batch 120 loss: 1.25514 acc: 0.71029 | v_loss: 1.17424 v_acc: 0.71940 |  iteration: 10065 teacher: 1 stage: sketch lr: 0.000441\n",
      "batch 121 loss: 1.29125 acc: 0.70345 | v_loss: 1.17869 v_acc: 0.72070 |  iteration: 10066 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 122 loss: 1.33390 acc: 0.70052 | v_loss: 1.22853 v_acc: 0.70801 |  iteration: 10067 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 123 loss: 1.27910 acc: 0.70671 | v_loss: 1.33681 v_acc: 0.69889 |  iteration: 10068 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 124 loss: 1.37278 acc: 0.70150 | v_loss: 1.15028 v_acc: 0.70931 |  iteration: 10069 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 125 loss: 1.38714 acc: 0.70052 | v_loss: 1.39815 v_acc: 0.68913 |  iteration: 10070 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 126 loss: 1.33979 acc: 0.70833 | v_loss: 1.15711 v_acc: 0.72168 |  iteration: 10071 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 127 loss: 1.37124 acc: 0.69759 | v_loss: 1.47440 v_acc: 0.68359 |  iteration: 10072 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 128 loss: 1.30933 acc: 0.70052 | v_loss: 1.36463 v_acc: 0.69434 |  iteration: 10073 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 129 loss: 1.23818 acc: 0.71224 | v_loss: 1.31818 v_acc: 0.69173 |  iteration: 10074 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 130 loss: 1.30914 acc: 0.69857 | v_loss: 1.32482 v_acc: 0.69759 |  iteration: 10075 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 131 loss: 1.30779 acc: 0.70573 | v_loss: 1.22897 v_acc: 0.70345 |  iteration: 10076 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 132 loss: 1.19554 acc: 0.71549 | v_loss: 1.27295 v_acc: 0.70085 |  iteration: 10077 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 133 loss: 1.39492 acc: 0.70020 | v_loss: 1.21970 v_acc: 0.71517 |  iteration: 10078 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 134 loss: 1.21756 acc: 0.71680 | v_loss: 1.41351 v_acc: 0.68848 |  iteration: 10079 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 135 loss: 1.25185 acc: 0.70736 | v_loss: 1.29568 v_acc: 0.71224 |  iteration: 10080 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 136 loss: 1.26389 acc: 0.70866 | v_loss: 1.19771 v_acc: 0.71061 |  iteration: 10081 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 137 loss: 1.32075 acc: 0.70085 | v_loss: 1.26230 v_acc: 0.71452 |  iteration: 10082 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 138 loss: 1.26961 acc: 0.70801 | v_loss: 1.15688 v_acc: 0.70736 |  iteration: 10083 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 139 loss: 1.25140 acc: 0.70573 | v_loss: 1.25344 v_acc: 0.70052 |  iteration: 10084 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 140 loss: 1.29307 acc: 0.70508 | v_loss: 1.22682 v_acc: 0.71354 |  iteration: 10085 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 141 loss: 1.24504 acc: 0.71810 | v_loss: 1.16698 v_acc: 0.72103 |  iteration: 10086 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 142 loss: 1.29330 acc: 0.70345 | v_loss: 1.13154 v_acc: 0.72526 |  iteration: 10087 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 143 loss: 1.19979 acc: 0.71647 | v_loss: 1.25456 v_acc: 0.71908 |  iteration: 10088 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 144 loss: 1.26470 acc: 0.70247 | v_loss: 1.23729 v_acc: 0.70378 |  iteration: 10089 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 145 loss: 1.27204 acc: 0.70247 | v_loss: 1.24936 v_acc: 0.71061 |  iteration: 10090 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 146 loss: 1.36328 acc: 0.69368 | v_loss: 1.10610 v_acc: 0.71615 |  iteration: 10091 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 147 loss: 1.24321 acc: 0.70898 | v_loss: 1.23271 v_acc: 0.73177 |  iteration: 10092 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 148 loss: 1.22159 acc: 0.70638 | v_loss: 1.29211 v_acc: 0.70020 |  iteration: 10093 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 149 loss: 1.30489 acc: 0.69759 | v_loss: 1.30298 v_acc: 0.72233 |  iteration: 10094 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 150 loss: 1.25737 acc: 0.70475 | v_loss: 1.16945 v_acc: 0.72005 |  iteration: 10095 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 151 loss: 1.34051 acc: 0.69173 | v_loss: 1.11155 v_acc: 0.73535 |  iteration: 10096 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 152 loss: 1.36043 acc: 0.69401 | v_loss: 1.10101 v_acc: 0.72754 |  iteration: 10097 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 153 loss: 1.30144 acc: 0.70866 | v_loss: 1.18102 v_acc: 0.70768 |  iteration: 10098 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 154 loss: 1.25978 acc: 0.70150 | v_loss: 1.23857 v_acc: 0.69727 |  iteration: 10099 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 155 loss: 1.22469 acc: 0.71126 | v_loss: 1.19010 v_acc: 0.71745 |  iteration: 10100 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 156 loss: 1.27967 acc: 0.71029 | v_loss: 1.30272 v_acc: 0.70410 |  iteration: 10101 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 157 loss: 1.39543 acc: 0.69206 | v_loss: 1.47755 v_acc: 0.69271 |  iteration: 10102 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 158 loss: 1.22676 acc: 0.71289 | v_loss: 1.35050 v_acc: 0.69759 |  iteration: 10103 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 159 loss: 1.32805 acc: 0.70801 | v_loss: 1.19443 v_acc: 0.72331 |  iteration: 10104 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 160 loss: 1.35171 acc: 0.69629 | v_loss: 1.15236 v_acc: 0.70866 |  iteration: 10105 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 161 loss: 1.22775 acc: 0.70964 | v_loss: 1.14890 v_acc: 0.71908 |  iteration: 10106 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 162 loss: 1.34323 acc: 0.69076 | v_loss: 1.20541 v_acc: 0.70475 |  iteration: 10107 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 163 loss: 1.27765 acc: 0.70345 | v_loss: 1.26751 v_acc: 0.70931 |  iteration: 10108 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 164 loss: 1.36672 acc: 0.69922 | v_loss: 1.21093 v_acc: 0.72493 |  iteration: 10109 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 165 loss: 1.41991 acc: 0.68978 | v_loss: 1.23344 v_acc: 0.72493 |  iteration: 10110 teacher: 0 stage: sketch lr: 0.000440\n",
      "batch 166 loss: 1.28084 acc: 0.70703 | v_loss: 1.24273 v_acc: 0.71159 |  iteration: 10111 teacher: 1 stage: sketch lr: 0.000440\n",
      "batch 167 loss: 1.34537 acc: 0.69466 | v_loss: 1.15946 v_acc: 0.72070 |  iteration: 10112 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 168 loss: 1.29469 acc: 0.70931 | v_loss: 1.12738 v_acc: 0.72103 |  iteration: 10113 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 169 loss: 1.34118 acc: 0.69759 | v_loss: 1.46245 v_acc: 0.68652 |  iteration: 10114 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 170 loss: 1.33832 acc: 0.69271 | v_loss: 1.20751 v_acc: 0.71159 |  iteration: 10115 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 171 loss: 1.28032 acc: 0.70378 | v_loss: 1.24092 v_acc: 0.71289 |  iteration: 10116 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 172 loss: 1.33164 acc: 0.69987 | v_loss: 1.22664 v_acc: 0.71582 |  iteration: 10117 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 173 loss: 1.32783 acc: 0.71061 | v_loss: 1.28411 v_acc: 0.70410 |  iteration: 10118 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 174 loss: 1.36396 acc: 0.70378 | v_loss: 1.13487 v_acc: 0.73210 |  iteration: 10119 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 175 loss: 1.30095 acc: 0.70150 | v_loss: 1.36000 v_acc: 0.71615 |  iteration: 10120 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 176 loss: 1.32613 acc: 0.70280 | v_loss: 1.20589 v_acc: 0.69694 |  iteration: 10121 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 177 loss: 1.26211 acc: 0.70410 | v_loss: 1.21861 v_acc: 0.70573 |  iteration: 10122 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 178 loss: 1.23852 acc: 0.71354 | v_loss: 1.25191 v_acc: 0.70443 |  iteration: 10123 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 179 loss: 1.27415 acc: 0.70736 | v_loss: 1.25498 v_acc: 0.70378 |  iteration: 10124 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 180 loss: 1.32832 acc: 0.70573 | v_loss: 1.31791 v_acc: 0.69336 |  iteration: 10125 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 181 loss: 1.18889 acc: 0.71549 | v_loss: 1.36517 v_acc: 0.70671 |  iteration: 10126 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 182 loss: 1.29576 acc: 0.69531 | v_loss: 1.28158 v_acc: 0.70020 |  iteration: 10127 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 183 loss: 1.24359 acc: 0.71061 | v_loss: 1.17676 v_acc: 0.70768 |  iteration: 10128 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 184 loss: 1.34611 acc: 0.71029 | v_loss: 1.34107 v_acc: 0.70605 |  iteration: 10129 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 185 loss: 1.26089 acc: 0.71387 | v_loss: 1.23457 v_acc: 0.71257 |  iteration: 10130 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 186 loss: 1.29131 acc: 0.70540 | v_loss: 1.12850 v_acc: 0.72656 |  iteration: 10131 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 187 loss: 1.24738 acc: 0.70931 | v_loss: 1.14730 v_acc: 0.70508 |  iteration: 10132 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 188 loss: 1.30614 acc: 0.70280 | v_loss: 1.26716 v_acc: 0.70247 |  iteration: 10133 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 189 loss: 1.37274 acc: 0.68359 | v_loss: 1.32123 v_acc: 0.69401 |  iteration: 10134 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 190 loss: 1.22947 acc: 0.70508 | v_loss: 1.16895 v_acc: 0.70247 |  iteration: 10135 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 191 loss: 1.25935 acc: 0.70801 | v_loss: 1.21867 v_acc: 0.69434 |  iteration: 10136 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 192 loss: 1.29316 acc: 0.70898 | v_loss: 1.18270 v_acc: 0.70801 |  iteration: 10137 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 193 loss: 1.33157 acc: 0.70475 | v_loss: 1.20363 v_acc: 0.70345 |  iteration: 10138 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 194 loss: 1.22149 acc: 0.72493 | v_loss: 1.08134 v_acc: 0.73633 |  iteration: 10139 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 195 loss: 1.27588 acc: 0.70671 | v_loss: 1.15912 v_acc: 0.72461 |  iteration: 10140 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 196 loss: 1.22103 acc: 0.71224 | v_loss: 1.15908 v_acc: 0.72689 |  iteration: 10141 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 197 loss: 1.28675 acc: 0.69922 | v_loss: 1.12128 v_acc: 0.72852 |  iteration: 10142 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 198 loss: 1.26887 acc: 0.70150 | v_loss: 1.19003 v_acc: 0.72168 |  iteration: 10143 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 199 loss: 1.26972 acc: 0.69987 | v_loss: 1.21869 v_acc: 0.71387 |  iteration: 10144 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 200 loss: 1.33328 acc: 0.70475 | v_loss: 1.19594 v_acc: 0.72298 |  iteration: 10145 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 201 loss: 1.21006 acc: 0.70964 | v_loss: 1.39954 v_acc: 0.69954 |  iteration: 10146 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 202 loss: 1.28804 acc: 0.70215 | v_loss: 1.27361 v_acc: 0.71973 |  iteration: 10147 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 203 loss: 1.23510 acc: 0.70573 | v_loss: 1.05512 v_acc: 0.74512 |  iteration: 10148 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 204 loss: 1.38974 acc: 0.69141 | v_loss: 1.21007 v_acc: 0.70443 |  iteration: 10149 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 205 loss: 1.29434 acc: 0.70150 | v_loss: 1.26846 v_acc: 0.69987 |  iteration: 10150 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 206 loss: 1.32697 acc: 0.70443 | v_loss: 1.18648 v_acc: 0.71029 |  iteration: 10151 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 207 loss: 1.24588 acc: 0.70182 | v_loss: 1.24350 v_acc: 0.71257 |  iteration: 10152 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 208 loss: 1.26682 acc: 0.70898 | v_loss: 1.23466 v_acc: 0.68978 |  iteration: 10153 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 209 loss: 1.31111 acc: 0.71191 | v_loss: 1.20612 v_acc: 0.71126 |  iteration: 10154 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 210 loss: 1.19642 acc: 0.70833 | v_loss: 1.23738 v_acc: 0.69531 |  iteration: 10155 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 211 loss: 1.38513 acc: 0.68750 | v_loss: 1.19948 v_acc: 0.71191 |  iteration: 10156 teacher: 0 stage: sketch lr: 0.000439\n",
      "batch 212 loss: 1.30732 acc: 0.70508 | v_loss: 1.17953 v_acc: 0.72461 |  iteration: 10157 teacher: 1 stage: sketch lr: 0.000439\n",
      "batch 213 loss: 1.31380 acc: 0.70410 | v_loss: 1.24345 v_acc: 0.70215 |  iteration: 10158 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 214 loss: 1.28761 acc: 0.70931 | v_loss: 1.32078 v_acc: 0.69954 |  iteration: 10159 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 215 loss: 1.22967 acc: 0.71159 | v_loss: 1.15693 v_acc: 0.70768 |  iteration: 10160 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 216 loss: 1.28004 acc: 0.70117 | v_loss: 1.40257 v_acc: 0.68783 |  iteration: 10161 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 217 loss: 1.29839 acc: 0.71224 | v_loss: 1.16052 v_acc: 0.71810 |  iteration: 10162 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 218 loss: 1.23520 acc: 0.70508 | v_loss: 1.47614 v_acc: 0.68327 |  iteration: 10163 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 219 loss: 1.31127 acc: 0.70345 | v_loss: 1.36575 v_acc: 0.69694 |  iteration: 10164 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 220 loss: 1.30001 acc: 0.70247 | v_loss: 1.31944 v_acc: 0.69076 |  iteration: 10165 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 221 loss: 1.30038 acc: 0.70247 | v_loss: 1.31970 v_acc: 0.69759 |  iteration: 10166 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 222 loss: 1.33444 acc: 0.70020 | v_loss: 1.22178 v_acc: 0.70508 |  iteration: 10167 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 223 loss: 1.28462 acc: 0.70443 | v_loss: 1.26356 v_acc: 0.70215 |  iteration: 10168 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 224 loss: 1.27114 acc: 0.71061 | v_loss: 1.21324 v_acc: 0.71777 |  iteration: 10169 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 225 loss: 1.29092 acc: 0.70638 | v_loss: 1.40365 v_acc: 0.69108 |  iteration: 10170 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 226 loss: 1.28199 acc: 0.70475 | v_loss: 1.28199 v_acc: 0.71191 |  iteration: 10171 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 227 loss: 1.28298 acc: 0.71582 | v_loss: 1.18509 v_acc: 0.70866 |  iteration: 10172 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 228 loss: 1.26490 acc: 0.70378 | v_loss: 1.26111 v_acc: 0.71354 |  iteration: 10173 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 229 loss: 1.36317 acc: 0.69238 | v_loss: 1.16805 v_acc: 0.70605 |  iteration: 10174 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 230 loss: 1.26692 acc: 0.70182 | v_loss: 1.27116 v_acc: 0.70052 |  iteration: 10175 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 231 loss: 1.30799 acc: 0.70280 | v_loss: 1.22906 v_acc: 0.71582 |  iteration: 10176 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 232 loss: 1.25979 acc: 0.70573 | v_loss: 1.16716 v_acc: 0.71810 |  iteration: 10177 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 233 loss: 1.25508 acc: 0.70768 | v_loss: 1.13992 v_acc: 0.72689 |  iteration: 10178 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 234 loss: 1.20913 acc: 0.71582 | v_loss: 1.26460 v_acc: 0.71549 |  iteration: 10179 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 235 loss: 1.24081 acc: 0.70996 | v_loss: 1.25380 v_acc: 0.70085 |  iteration: 10180 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 236 loss: 1.24321 acc: 0.71517 | v_loss: 1.25549 v_acc: 0.70540 |  iteration: 10181 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 237 loss: 1.39463 acc: 0.69238 | v_loss: 1.11014 v_acc: 0.71517 |  iteration: 10182 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 238 loss: 1.27868 acc: 0.71061 | v_loss: 1.23371 v_acc: 0.72852 |  iteration: 10183 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 239 loss: 1.24378 acc: 0.70638 | v_loss: 1.29505 v_acc: 0.69954 |  iteration: 10184 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 240 loss: 1.25853 acc: 0.70182 | v_loss: 1.31107 v_acc: 0.72363 |  iteration: 10185 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 241 loss: 1.24739 acc: 0.70703 | v_loss: 1.17591 v_acc: 0.71842 |  iteration: 10186 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 242 loss: 1.26809 acc: 0.70801 | v_loss: 1.12425 v_acc: 0.73633 |  iteration: 10187 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 243 loss: 1.25600 acc: 0.71289 | v_loss: 1.09791 v_acc: 0.72396 |  iteration: 10188 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 244 loss: 1.33615 acc: 0.69727 | v_loss: 1.18327 v_acc: 0.70768 |  iteration: 10189 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 245 loss: 1.28472 acc: 0.70378 | v_loss: 1.21850 v_acc: 0.69596 |  iteration: 10190 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 246 loss: 1.29549 acc: 0.70801 | v_loss: 1.19274 v_acc: 0.71224 |  iteration: 10191 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 247 loss: 1.21627 acc: 0.71712 | v_loss: 1.28902 v_acc: 0.71615 |  iteration: 10192 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 248 loss: 1.28601 acc: 0.70508 | v_loss: 1.46334 v_acc: 0.68978 |  iteration: 10193 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 249 loss: 1.27812 acc: 0.70020 | v_loss: 1.33620 v_acc: 0.69987 |  iteration: 10194 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 250 loss: 1.24572 acc: 0.71615 | v_loss: 1.20382 v_acc: 0.72135 |  iteration: 10195 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 251 loss: 1.29130 acc: 0.69531 | v_loss: 1.16068 v_acc: 0.70573 |  iteration: 10196 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 252 loss: 1.32712 acc: 0.70117 | v_loss: 1.15293 v_acc: 0.72168 |  iteration: 10197 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 253 loss: 1.25995 acc: 0.70117 | v_loss: 1.22578 v_acc: 0.70475 |  iteration: 10198 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 254 loss: 1.27290 acc: 0.69954 | v_loss: 1.24655 v_acc: 0.71842 |  iteration: 10199 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 255 loss: 1.30229 acc: 0.69043 | v_loss: 1.20029 v_acc: 0.73210 |  iteration: 10200 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 256 loss: 1.23786 acc: 0.70410 | v_loss: 1.22480 v_acc: 0.71973 |  iteration: 10201 teacher: 0 stage: sketch lr: 0.000438\n",
      "batch 257 loss: 1.29498 acc: 0.70378 | v_loss: 1.23089 v_acc: 0.71126 |  iteration: 10202 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 258 loss: 1.36828 acc: 0.69271 | v_loss: 1.16031 v_acc: 0.72591 |  iteration: 10203 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 259 loss: 1.35885 acc: 0.69303 | v_loss: 1.11974 v_acc: 0.72135 |  iteration: 10204 teacher: 1 stage: sketch lr: 0.000438\n",
      "batch 260 loss: 1.33536 acc: 0.70280 | v_loss: 1.48541 v_acc: 0.69303 |  iteration: 10205 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 261 loss: 1.35870 acc: 0.69857 | v_loss: 1.19102 v_acc: 0.70931 |  iteration: 10206 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 262 loss: 1.33599 acc: 0.70052 | v_loss: 1.22556 v_acc: 0.71777 |  iteration: 10207 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 263 loss: 1.26950 acc: 0.70443 | v_loss: 1.22191 v_acc: 0.71354 |  iteration: 10208 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 264 loss: 1.30033 acc: 0.69889 | v_loss: 1.27215 v_acc: 0.70150 |  iteration: 10209 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 265 loss: 1.28235 acc: 0.69596 | v_loss: 1.14038 v_acc: 0.73405 |  iteration: 10210 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 266 loss: 1.28804 acc: 0.69303 | v_loss: 1.37886 v_acc: 0.71191 |  iteration: 10211 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 267 loss: 1.25258 acc: 0.71354 | v_loss: 1.18184 v_acc: 0.69694 |  iteration: 10212 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 268 loss: 1.37750 acc: 0.70085 | v_loss: 1.19911 v_acc: 0.70247 |  iteration: 10213 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 269 loss: 1.37549 acc: 0.70247 | v_loss: 1.25944 v_acc: 0.70378 |  iteration: 10214 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 270 loss: 1.38830 acc: 0.69271 | v_loss: 1.26165 v_acc: 0.70475 |  iteration: 10215 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 271 loss: 1.25783 acc: 0.71452 | v_loss: 1.31396 v_acc: 0.69629 |  iteration: 10216 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 272 loss: 1.25541 acc: 0.71484 | v_loss: 1.37375 v_acc: 0.70378 |  iteration: 10217 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 273 loss: 1.25555 acc: 0.71517 | v_loss: 1.28835 v_acc: 0.70182 |  iteration: 10218 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 274 loss: 1.18957 acc: 0.72819 | v_loss: 1.18062 v_acc: 0.71419 |  iteration: 10219 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 275 loss: 1.35709 acc: 0.71094 | v_loss: 1.33517 v_acc: 0.70280 |  iteration: 10220 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 276 loss: 1.26006 acc: 0.70312 | v_loss: 1.23709 v_acc: 0.71387 |  iteration: 10221 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 277 loss: 1.29879 acc: 0.70475 | v_loss: 1.12143 v_acc: 0.72689 |  iteration: 10222 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 278 loss: 1.25067 acc: 0.71224 | v_loss: 1.15108 v_acc: 0.70866 |  iteration: 10223 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 279 loss: 1.37408 acc: 0.69466 | v_loss: 1.25557 v_acc: 0.70410 |  iteration: 10224 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 280 loss: 1.26908 acc: 0.70898 | v_loss: 1.30406 v_acc: 0.69987 |  iteration: 10225 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 281 loss: 1.34671 acc: 0.70345 | v_loss: 1.15409 v_acc: 0.71191 |  iteration: 10226 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 282 loss: 1.30007 acc: 0.70475 | v_loss: 1.19479 v_acc: 0.69401 |  iteration: 10227 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 283 loss: 1.24341 acc: 0.70475 | v_loss: 1.20395 v_acc: 0.70638 |  iteration: 10228 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 284 loss: 1.36737 acc: 0.69076 | v_loss: 1.22823 v_acc: 0.70020 |  iteration: 10229 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 285 loss: 1.28020 acc: 0.69954 | v_loss: 1.04499 v_acc: 0.73861 |  iteration: 10230 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 286 loss: 1.25211 acc: 0.70605 | v_loss: 1.19602 v_acc: 0.71647 |  iteration: 10231 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 287 loss: 1.27681 acc: 0.69694 | v_loss: 1.08993 v_acc: 0.73372 |  iteration: 10232 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 288 loss: 1.43245 acc: 0.68913 | v_loss: 1.11336 v_acc: 0.72005 |  iteration: 10233 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 289 loss: 1.27863 acc: 0.70573 | v_loss: 1.20210 v_acc: 0.71940 |  iteration: 10234 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 290 loss: 1.38077 acc: 0.69206 | v_loss: 1.21587 v_acc: 0.71549 |  iteration: 10235 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 291 loss: 1.37919 acc: 0.70150 | v_loss: 1.19096 v_acc: 0.72070 |  iteration: 10236 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 292 loss: 1.20879 acc: 0.71517 | v_loss: 1.39089 v_acc: 0.69694 |  iteration: 10237 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 293 loss: 1.20847 acc: 0.71940 | v_loss: 1.25379 v_acc: 0.71810 |  iteration: 10238 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 294 loss: 1.36490 acc: 0.69238 | v_loss: 1.06700 v_acc: 0.74023 |  iteration: 10239 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 295 loss: 1.31529 acc: 0.70020 | v_loss: 1.20880 v_acc: 0.70768 |  iteration: 10240 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 296 loss: 1.34617 acc: 0.69661 | v_loss: 1.26568 v_acc: 0.70345 |  iteration: 10241 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 297 loss: 1.27023 acc: 0.71647 | v_loss: 1.18173 v_acc: 0.70996 |  iteration: 10242 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 298 loss: 1.26580 acc: 0.70736 | v_loss: 1.24489 v_acc: 0.71322 |  iteration: 10243 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 299 loss: 1.28293 acc: 0.71224 | v_loss: 1.25025 v_acc: 0.69108 |  iteration: 10244 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 300 loss: 1.25938 acc: 0.70671 | v_loss: 1.21488 v_acc: 0.71126 |  iteration: 10245 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 301 loss: 1.31101 acc: 0.70117 | v_loss: 1.25335 v_acc: 0.69531 |  iteration: 10246 teacher: 1 stage: sketch lr: 0.000437\n",
      "batch 302 loss: 1.33333 acc: 0.70508 | v_loss: 1.16532 v_acc: 0.71582 |  iteration: 10247 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 303 loss: 1.30318 acc: 0.70671 | v_loss: 1.15536 v_acc: 0.72819 |  iteration: 10248 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 304 loss: 1.29871 acc: 0.70605 | v_loss: 1.21739 v_acc: 0.70898 |  iteration: 10249 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 305 loss: 1.28761 acc: 0.70215 | v_loss: 1.34778 v_acc: 0.69596 |  iteration: 10250 teacher: 0 stage: sketch lr: 0.000437\n",
      "batch 306 loss: 1.19301 acc: 0.70996 | v_loss: 1.15730 v_acc: 0.71061 |  iteration: 10251 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 307 loss: 1.34859 acc: 0.70117 | v_loss: 1.42337 v_acc: 0.68066 |  iteration: 10252 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 308 loss: 1.29984 acc: 0.70085 | v_loss: 1.15670 v_acc: 0.72526 |  iteration: 10253 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 309 loss: 1.30136 acc: 0.70475 | v_loss: 1.49116 v_acc: 0.67611 |  iteration: 10254 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 310 loss: 1.29088 acc: 0.70736 | v_loss: 1.36835 v_acc: 0.68717 |  iteration: 10255 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 311 loss: 1.25642 acc: 0.70768 | v_loss: 1.31833 v_acc: 0.69857 |  iteration: 10256 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 312 loss: 1.23966 acc: 0.70964 | v_loss: 1.29920 v_acc: 0.70182 |  iteration: 10257 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 313 loss: 1.27290 acc: 0.71029 | v_loss: 1.22809 v_acc: 0.70605 |  iteration: 10258 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 314 loss: 1.31521 acc: 0.69629 | v_loss: 1.25324 v_acc: 0.70671 |  iteration: 10259 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 315 loss: 1.26708 acc: 0.70671 | v_loss: 1.20577 v_acc: 0.72038 |  iteration: 10260 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 316 loss: 1.25183 acc: 0.70931 | v_loss: 1.39833 v_acc: 0.68848 |  iteration: 10261 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 317 loss: 1.23079 acc: 0.71452 | v_loss: 1.28713 v_acc: 0.70801 |  iteration: 10262 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 318 loss: 1.40979 acc: 0.69987 | v_loss: 1.17786 v_acc: 0.71191 |  iteration: 10263 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 319 loss: 1.32182 acc: 0.70020 | v_loss: 1.24951 v_acc: 0.71712 |  iteration: 10264 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 320 loss: 1.37813 acc: 0.69466 | v_loss: 1.17420 v_acc: 0.70508 |  iteration: 10265 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 321 loss: 1.34365 acc: 0.69141 | v_loss: 1.25662 v_acc: 0.69889 |  iteration: 10266 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 322 loss: 1.30513 acc: 0.70020 | v_loss: 1.22288 v_acc: 0.71549 |  iteration: 10267 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 323 loss: 1.43476 acc: 0.68262 | v_loss: 1.16768 v_acc: 0.71810 |  iteration: 10268 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 324 loss: 1.29853 acc: 0.70475 | v_loss: 1.14677 v_acc: 0.72070 |  iteration: 10269 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 325 loss: 1.36223 acc: 0.70280 | v_loss: 1.27521 v_acc: 0.71061 |  iteration: 10270 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 326 loss: 1.28552 acc: 0.70931 | v_loss: 1.25291 v_acc: 0.70605 |  iteration: 10271 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 327 loss: 1.28788 acc: 0.70085 | v_loss: 1.25338 v_acc: 0.70898 |  iteration: 10272 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 328 loss: 1.24866 acc: 0.70605 | v_loss: 1.12206 v_acc: 0.71973 |  iteration: 10273 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 329 loss: 1.37029 acc: 0.68750 | v_loss: 1.24285 v_acc: 0.73210 |  iteration: 10274 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 330 loss: 1.27829 acc: 0.70996 | v_loss: 1.30214 v_acc: 0.69824 |  iteration: 10275 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 331 loss: 1.22831 acc: 0.70638 | v_loss: 1.31281 v_acc: 0.72396 |  iteration: 10276 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 332 loss: 1.30041 acc: 0.70443 | v_loss: 1.14575 v_acc: 0.72298 |  iteration: 10277 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 333 loss: 1.33335 acc: 0.70378 | v_loss: 1.09035 v_acc: 0.73796 |  iteration: 10278 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 334 loss: 1.27580 acc: 0.71061 | v_loss: 1.10086 v_acc: 0.72526 |  iteration: 10279 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 335 loss: 1.32031 acc: 0.70703 | v_loss: 1.17597 v_acc: 0.71126 |  iteration: 10280 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 336 loss: 1.30488 acc: 0.70833 | v_loss: 1.22584 v_acc: 0.70736 |  iteration: 10281 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 337 loss: 1.29959 acc: 0.69238 | v_loss: 1.19652 v_acc: 0.71387 |  iteration: 10282 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 338 loss: 1.27179 acc: 0.69954 | v_loss: 1.31714 v_acc: 0.70801 |  iteration: 10283 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 339 loss: 1.28387 acc: 0.70898 | v_loss: 1.45183 v_acc: 0.69531 |  iteration: 10284 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 340 loss: 1.26383 acc: 0.69824 | v_loss: 1.33021 v_acc: 0.70215 |  iteration: 10285 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 341 loss: 1.31621 acc: 0.69922 | v_loss: 1.19745 v_acc: 0.72135 |  iteration: 10286 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 342 loss: 1.28351 acc: 0.70931 | v_loss: 1.14976 v_acc: 0.70475 |  iteration: 10287 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 343 loss: 1.29726 acc: 0.70085 | v_loss: 1.15618 v_acc: 0.72038 |  iteration: 10288 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 344 loss: 1.32963 acc: 0.70182 | v_loss: 1.19769 v_acc: 0.70638 |  iteration: 10289 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 345 loss: 1.38991 acc: 0.69596 | v_loss: 1.26600 v_acc: 0.70964 |  iteration: 10290 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 346 loss: 1.36646 acc: 0.69629 | v_loss: 1.20369 v_acc: 0.72982 |  iteration: 10291 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 347 loss: 1.37656 acc: 0.69564 | v_loss: 1.23773 v_acc: 0.72168 |  iteration: 10292 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 348 loss: 1.31619 acc: 0.70345 | v_loss: 1.24204 v_acc: 0.71549 |  iteration: 10293 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 349 loss: 1.28335 acc: 0.70866 | v_loss: 1.16404 v_acc: 0.72331 |  iteration: 10294 teacher: 0 stage: sketch lr: 0.000436\n",
      "batch 350 loss: 1.24984 acc: 0.70508 | v_loss: 1.12758 v_acc: 0.71712 |  iteration: 10295 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 351 loss: 1.35670 acc: 0.70345 | v_loss: 1.40961 v_acc: 0.68522 |  iteration: 10296 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 352 loss: 1.31701 acc: 0.69629 | v_loss: 1.20521 v_acc: 0.71257 |  iteration: 10297 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 353 loss: 1.32275 acc: 0.69857 | v_loss: 1.23080 v_acc: 0.71484 |  iteration: 10298 teacher: 1 stage: sketch lr: 0.000436\n",
      "batch 354 loss: 1.25275 acc: 0.71029 | v_loss: 1.23725 v_acc: 0.70898 |  iteration: 10299 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 355 loss: 1.26926 acc: 0.70150 | v_loss: 1.26796 v_acc: 0.70638 |  iteration: 10300 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 356 loss: 1.33135 acc: 0.69661 | v_loss: 1.12703 v_acc: 0.73438 |  iteration: 10301 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 357 loss: 1.24002 acc: 0.71126 | v_loss: 1.35848 v_acc: 0.71224 |  iteration: 10302 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 358 loss: 1.30169 acc: 0.70150 | v_loss: 1.18800 v_acc: 0.69792 |  iteration: 10303 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 359 loss: 1.25874 acc: 0.71322 | v_loss: 1.20198 v_acc: 0.70443 |  iteration: 10304 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 360 loss: 1.17918 acc: 0.71842 | v_loss: 1.26167 v_acc: 0.70475 |  iteration: 10305 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 361 loss: 1.29012 acc: 0.70280 | v_loss: 1.26045 v_acc: 0.70703 |  iteration: 10306 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 362 loss: 1.33115 acc: 0.70150 | v_loss: 1.31949 v_acc: 0.69336 |  iteration: 10307 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 363 loss: 1.30767 acc: 0.69531 | v_loss: 1.37817 v_acc: 0.70540 |  iteration: 10308 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 364 loss: 1.22060 acc: 0.70833 | v_loss: 1.26598 v_acc: 0.70671 |  iteration: 10309 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 365 loss: 1.31392 acc: 0.70573 | v_loss: 1.17683 v_acc: 0.71517 |  iteration: 10310 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 366 loss: 1.35815 acc: 0.70020 | v_loss: 1.32591 v_acc: 0.70312 |  iteration: 10311 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 367 loss: 1.27347 acc: 0.70638 | v_loss: 1.22259 v_acc: 0.71159 |  iteration: 10312 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 368 loss: 1.42468 acc: 0.69238 | v_loss: 1.12772 v_acc: 0.72786 |  iteration: 10313 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 369 loss: 1.26365 acc: 0.69596 | v_loss: 1.14347 v_acc: 0.70410 |  iteration: 10314 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 370 loss: 1.24076 acc: 0.70931 | v_loss: 1.25335 v_acc: 0.70540 |  iteration: 10315 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 371 loss: 1.25436 acc: 0.71061 | v_loss: 1.31582 v_acc: 0.69792 |  iteration: 10316 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 372 loss: 1.23559 acc: 0.70312 | v_loss: 1.15384 v_acc: 0.70736 |  iteration: 10317 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 373 loss: 1.29425 acc: 0.69727 | v_loss: 1.19505 v_acc: 0.69727 |  iteration: 10318 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 374 loss: 1.27226 acc: 0.70443 | v_loss: 1.19251 v_acc: 0.70866 |  iteration: 10319 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 375 loss: 1.19315 acc: 0.72591 | v_loss: 1.20494 v_acc: 0.70443 |  iteration: 10320 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 376 loss: 1.23953 acc: 0.70605 | v_loss: 1.05118 v_acc: 0.74186 |  iteration: 10321 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 377 loss: 1.23951 acc: 0.71191 | v_loss: 1.17551 v_acc: 0.71842 |  iteration: 10322 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 378 loss: 1.24145 acc: 0.71094 | v_loss: 1.11034 v_acc: 0.72689 |  iteration: 10323 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 379 loss: 1.21068 acc: 0.71322 | v_loss: 1.11455 v_acc: 0.72559 |  iteration: 10324 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 380 loss: 1.31748 acc: 0.70638 | v_loss: 1.18535 v_acc: 0.72591 |  iteration: 10325 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 381 loss: 1.23163 acc: 0.71061 | v_loss: 1.20563 v_acc: 0.71647 |  iteration: 10326 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 382 loss: 1.21856 acc: 0.71842 | v_loss: 1.18612 v_acc: 0.72559 |  iteration: 10327 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 383 loss: 1.30030 acc: 0.71322 | v_loss: 1.38638 v_acc: 0.70280 |  iteration: 10328 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 384 loss: 1.25638 acc: 0.70801 | v_loss: 1.26162 v_acc: 0.71973 |  iteration: 10329 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 385 loss: 1.25430 acc: 0.71322 | v_loss: 1.04380 v_acc: 0.74805 |  iteration: 10330 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 386 loss: 1.30585 acc: 0.70443 | v_loss: 1.21021 v_acc: 0.70378 |  iteration: 10331 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 387 loss: 1.28046 acc: 0.70410 | v_loss: 1.25970 v_acc: 0.69629 |  iteration: 10332 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 388 loss: 1.18153 acc: 0.71224 | v_loss: 1.19730 v_acc: 0.70996 |  iteration: 10333 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 389 loss: 1.23356 acc: 0.70996 | v_loss: 1.24798 v_acc: 0.71842 |  iteration: 10334 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 390 loss: 1.22933 acc: 0.70085 | v_loss: 1.23999 v_acc: 0.69499 |  iteration: 10335 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 391 loss: 1.24966 acc: 0.70768 | v_loss: 1.20239 v_acc: 0.71549 |  iteration: 10336 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 392 loss: 1.38429 acc: 0.69694 | v_loss: 1.24457 v_acc: 0.69987 |  iteration: 10337 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 393 loss: 1.34868 acc: 0.68717 | v_loss: 1.17135 v_acc: 0.71387 |  iteration: 10338 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 394 loss: 1.24157 acc: 0.70898 | v_loss: 1.17151 v_acc: 0.72624 |  iteration: 10339 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 395 loss: 1.24778 acc: 0.70573 | v_loss: 1.22488 v_acc: 0.70378 |  iteration: 10340 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 396 loss: 1.31598 acc: 0.69954 | v_loss: 1.33990 v_acc: 0.69954 |  iteration: 10341 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 397 loss: 1.32635 acc: 0.70312 | v_loss: 1.15166 v_acc: 0.70931 |  iteration: 10342 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 398 loss: 1.28093 acc: 0.70801 | v_loss: 1.41628 v_acc: 0.68294 |  iteration: 10343 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 399 loss: 1.36607 acc: 0.69727 | v_loss: 1.15273 v_acc: 0.71973 |  iteration: 10344 teacher: 0 stage: sketch lr: 0.000435\n",
      "batch 400 loss: 1.27350 acc: 0.71387 | v_loss: 1.49646 v_acc: 0.67806 |  iteration: 10345 teacher: 1 stage: sketch lr: 0.000435\n",
      "batch 401 loss: 1.21124 acc: 0.71289 | v_loss: 1.37659 v_acc: 0.69206 |  iteration: 10346 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 402 loss: 1.38641 acc: 0.69401 | v_loss: 1.31000 v_acc: 0.69238 |  iteration: 10347 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 403 loss: 1.34647 acc: 0.70475 | v_loss: 1.31599 v_acc: 0.69661 |  iteration: 10348 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 404 loss: 1.20995 acc: 0.71484 | v_loss: 1.23214 v_acc: 0.70443 |  iteration: 10349 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 405 loss: 1.36771 acc: 0.69206 | v_loss: 1.27174 v_acc: 0.70215 |  iteration: 10350 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 406 loss: 1.22736 acc: 0.71094 | v_loss: 1.22029 v_acc: 0.71680 |  iteration: 10351 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 407 loss: 1.28211 acc: 0.70866 | v_loss: 1.41606 v_acc: 0.68587 |  iteration: 10352 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 408 loss: 1.26185 acc: 0.71159 | v_loss: 1.30319 v_acc: 0.70443 |  iteration: 10353 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 409 loss: 1.31566 acc: 0.68978 | v_loss: 1.16843 v_acc: 0.71094 |  iteration: 10354 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 410 loss: 1.26457 acc: 0.70605 | v_loss: 1.24995 v_acc: 0.71322 |  iteration: 10355 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 411 loss: 1.23006 acc: 0.71647 | v_loss: 1.16357 v_acc: 0.70540 |  iteration: 10356 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 412 loss: 1.24454 acc: 0.70703 | v_loss: 1.25997 v_acc: 0.70117 |  iteration: 10357 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 413 loss: 1.29307 acc: 0.70768 | v_loss: 1.21517 v_acc: 0.71810 |  iteration: 10358 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 414 loss: 1.33928 acc: 0.69661 | v_loss: 1.16021 v_acc: 0.71712 |  iteration: 10359 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 415 loss: 1.34584 acc: 0.69596 | v_loss: 1.12351 v_acc: 0.72786 |  iteration: 10360 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 416 loss: 1.28349 acc: 0.70703 | v_loss: 1.26296 v_acc: 0.71257 |  iteration: 10361 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 417 loss: 1.23151 acc: 0.70280 | v_loss: 1.24101 v_acc: 0.70312 |  iteration: 10362 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 418 loss: 1.32149 acc: 0.70150 | v_loss: 1.23773 v_acc: 0.70898 |  iteration: 10363 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 419 loss: 1.29323 acc: 0.71419 | v_loss: 1.09850 v_acc: 0.72038 |  iteration: 10364 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 420 loss: 1.22822 acc: 0.70605 | v_loss: 1.23815 v_acc: 0.73014 |  iteration: 10365 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 421 loss: 1.33056 acc: 0.69857 | v_loss: 1.28446 v_acc: 0.69889 |  iteration: 10366 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 422 loss: 1.27523 acc: 0.71094 | v_loss: 1.28446 v_acc: 0.72461 |  iteration: 10367 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 423 loss: 1.26418 acc: 0.70443 | v_loss: 1.16050 v_acc: 0.71615 |  iteration: 10368 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 424 loss: 1.24793 acc: 0.71322 | v_loss: 1.11044 v_acc: 0.73665 |  iteration: 10369 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 425 loss: 1.28768 acc: 0.70052 | v_loss: 1.10024 v_acc: 0.72493 |  iteration: 10370 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 426 loss: 1.34806 acc: 0.69824 | v_loss: 1.18910 v_acc: 0.70931 |  iteration: 10371 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 427 loss: 1.25255 acc: 0.70605 | v_loss: 1.20684 v_acc: 0.71387 |  iteration: 10372 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 428 loss: 1.30674 acc: 0.70378 | v_loss: 1.19579 v_acc: 0.71257 |  iteration: 10373 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 429 loss: 1.33417 acc: 0.70573 | v_loss: 1.33041 v_acc: 0.70085 |  iteration: 10374 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 430 loss: 1.33419 acc: 0.70605 | v_loss: 1.45159 v_acc: 0.69401 |  iteration: 10375 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 431 loss: 1.25571 acc: 0.71159 | v_loss: 1.33164 v_acc: 0.70117 |  iteration: 10376 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 432 loss: 1.30143 acc: 0.70703 | v_loss: 1.19985 v_acc: 0.71940 |  iteration: 10377 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 433 loss: 1.32469 acc: 0.71484 | v_loss: 1.14907 v_acc: 0.70898 |  iteration: 10378 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 434 loss: 1.31981 acc: 0.69759 | v_loss: 1.15771 v_acc: 0.72135 |  iteration: 10379 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 435 loss: 1.26779 acc: 0.70638 | v_loss: 1.20682 v_acc: 0.70671 |  iteration: 10380 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 436 loss: 1.30325 acc: 0.69466 | v_loss: 1.23592 v_acc: 0.71452 |  iteration: 10381 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 437 loss: 1.26570 acc: 0.70312 | v_loss: 1.20029 v_acc: 0.73079 |  iteration: 10382 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 438 loss: 1.33952 acc: 0.69401 | v_loss: 1.22857 v_acc: 0.72070 |  iteration: 10383 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 439 loss: 1.29449 acc: 0.70410 | v_loss: 1.22149 v_acc: 0.71061 |  iteration: 10384 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 440 loss: 1.33538 acc: 0.69466 | v_loss: 1.15129 v_acc: 0.73014 |  iteration: 10385 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 441 loss: 1.27854 acc: 0.71126 | v_loss: 1.12419 v_acc: 0.71908 |  iteration: 10386 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 442 loss: 1.26603 acc: 0.71647 | v_loss: 1.47286 v_acc: 0.68880 |  iteration: 10387 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 443 loss: 1.26669 acc: 0.71387 | v_loss: 1.19951 v_acc: 0.70833 |  iteration: 10388 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 444 loss: 1.30729 acc: 0.70996 | v_loss: 1.25120 v_acc: 0.70898 |  iteration: 10389 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 445 loss: 1.27238 acc: 0.70215 | v_loss: 1.24953 v_acc: 0.70540 |  iteration: 10390 teacher: 1 stage: sketch lr: 0.000434\n",
      "batch 446 loss: 1.28115 acc: 0.70931 | v_loss: 1.28242 v_acc: 0.69954 |  iteration: 10391 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 447 loss: 1.23307 acc: 0.71582 | v_loss: 1.11299 v_acc: 0.73568 |  iteration: 10392 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 448 loss: 1.20795 acc: 0.71777 | v_loss: 1.35219 v_acc: 0.71289 |  iteration: 10393 teacher: 0 stage: sketch lr: 0.000434\n",
      "batch 449 loss: 1.31120 acc: 0.71582 | v_loss: 1.18933 v_acc: 0.70247 |  iteration: 10394 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 450 loss: 1.17756 acc: 0.70996 | v_loss: 1.21455 v_acc: 0.70573 |  iteration: 10395 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 451 loss: 1.29577 acc: 0.70736 | v_loss: 1.25816 v_acc: 0.70410 |  iteration: 10396 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 452 loss: 1.29065 acc: 0.70052 | v_loss: 1.24909 v_acc: 0.70378 |  iteration: 10397 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 453 loss: 1.32137 acc: 0.70964 | v_loss: 1.31654 v_acc: 0.69010 |  iteration: 10398 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 454 loss: 1.33509 acc: 0.70605 | v_loss: 1.35650 v_acc: 0.70931 |  iteration: 10399 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 455 loss: 1.34599 acc: 0.69857 | v_loss: 1.26159 v_acc: 0.70345 |  iteration: 10400 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 456 loss: 1.34838 acc: 0.69629 | v_loss: 1.15352 v_acc: 0.71680 |  iteration: 10401 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 457 loss: 1.29133 acc: 0.70508 | v_loss: 1.32243 v_acc: 0.70378 |  iteration: 10402 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 458 loss: 1.27865 acc: 0.69954 | v_loss: 1.22202 v_acc: 0.71094 |  iteration: 10403 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 459 loss: 1.33471 acc: 0.69336 | v_loss: 1.13510 v_acc: 0.72461 |  iteration: 10404 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 460 loss: 1.27180 acc: 0.70703 | v_loss: 1.17328 v_acc: 0.70247 |  iteration: 10405 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 461 loss: 1.30742 acc: 0.70540 | v_loss: 1.27361 v_acc: 0.70215 |  iteration: 10406 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 462 loss: 1.24316 acc: 0.70768 | v_loss: 1.28552 v_acc: 0.70182 |  iteration: 10407 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 463 loss: 1.24866 acc: 0.70215 | v_loss: 1.14102 v_acc: 0.70768 |  iteration: 10408 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 464 loss: 1.28353 acc: 0.70247 | v_loss: 1.19581 v_acc: 0.69694 |  iteration: 10409 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 465 loss: 1.20784 acc: 0.71354 | v_loss: 1.19286 v_acc: 0.70801 |  iteration: 10410 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 466 loss: 1.34675 acc: 0.70085 | v_loss: 1.19129 v_acc: 0.70475 |  iteration: 10411 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 467 loss: 1.24254 acc: 0.71159 | v_loss: 1.03934 v_acc: 0.74056 |  iteration: 10412 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 468 loss: 1.27344 acc: 0.70931 | v_loss: 1.16690 v_acc: 0.72135 |  iteration: 10413 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 469 loss: 1.31875 acc: 0.70801 | v_loss: 1.12265 v_acc: 0.73047 |  iteration: 10414 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 470 loss: 1.31164 acc: 0.69922 | v_loss: 1.09561 v_acc: 0.72591 |  iteration: 10415 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 471 loss: 1.37922 acc: 0.69238 | v_loss: 1.17454 v_acc: 0.72103 |  iteration: 10416 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 472 loss: 1.28625 acc: 0.70898 | v_loss: 1.18243 v_acc: 0.71940 |  iteration: 10417 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 473 loss: 1.22936 acc: 0.71419 | v_loss: 1.17297 v_acc: 0.72363 |  iteration: 10418 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 474 loss: 1.19267 acc: 0.71615 | v_loss: 1.40744 v_acc: 0.69922 |  iteration: 10419 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 475 loss: 1.30311 acc: 0.70378 | v_loss: 1.25187 v_acc: 0.72168 |  iteration: 10420 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 476 loss: 1.24917 acc: 0.70638 | v_loss: 1.03240 v_acc: 0.74284 |  iteration: 10421 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 477 loss: 1.31698 acc: 0.70378 | v_loss: 1.24145 v_acc: 0.70573 |  iteration: 10422 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 478 loss: 1.28341 acc: 0.69336 | v_loss: 1.24479 v_acc: 0.69759 |  iteration: 10423 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 479 loss: 1.36692 acc: 0.70150 | v_loss: 1.20713 v_acc: 0.70410 |  iteration: 10424 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 480 loss: 1.22948 acc: 0.70182 | v_loss: 1.23933 v_acc: 0.71419 |  iteration: 10425 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 481 loss: 1.31169 acc: 0.69694 | v_loss: 1.23364 v_acc: 0.69759 |  iteration: 10426 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 482 loss: 1.24991 acc: 0.71484 | v_loss: 1.20127 v_acc: 0.71647 |  iteration: 10427 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 483 loss: 1.30355 acc: 0.70085 | v_loss: 1.23302 v_acc: 0.70540 |  iteration: 10428 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 484 loss: 1.34421 acc: 0.69954 | v_loss: 1.15926 v_acc: 0.72526 |  iteration: 10429 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 485 loss: 1.26742 acc: 0.70182 | v_loss: 1.16871 v_acc: 0.72917 |  iteration: 10430 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 486 loss: 1.29042 acc: 0.70020 | v_loss: 1.20349 v_acc: 0.70736 |  iteration: 10431 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 487 loss: 1.30504 acc: 0.70150 | v_loss: 1.34364 v_acc: 0.70247 |  iteration: 10432 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 488 loss: 1.22685 acc: 0.70703 | v_loss: 1.15019 v_acc: 0.71029 |  iteration: 10433 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 489 loss: 1.40759 acc: 0.69368 | v_loss: 1.42563 v_acc: 0.68555 |  iteration: 10434 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 490 loss: 1.30407 acc: 0.69629 | v_loss: 1.14874 v_acc: 0.72298 |  iteration: 10435 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 491 loss: 1.35078 acc: 0.70182 | v_loss: 1.51947 v_acc: 0.67871 |  iteration: 10436 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 492 loss: 1.28993 acc: 0.70866 | v_loss: 1.40856 v_acc: 0.68457 |  iteration: 10437 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 493 loss: 1.28774 acc: 0.70117 | v_loss: 1.30848 v_acc: 0.69629 |  iteration: 10438 teacher: 1 stage: sketch lr: 0.000433\n",
      "batch 494 loss: 1.24882 acc: 0.70638 | v_loss: 1.35305 v_acc: 0.69336 |  iteration: 10439 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 495 loss: 1.27691 acc: 0.69694 | v_loss: 1.21834 v_acc: 0.70736 |  iteration: 10440 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 496 loss: 1.25488 acc: 0.70215 | v_loss: 1.28001 v_acc: 0.70312 |  iteration: 10441 teacher: 0 stage: sketch lr: 0.000433\n",
      "batch 497 loss: 1.24889 acc: 0.70215 | v_loss: 1.22610 v_acc: 0.71647 |  iteration: 10442 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 498 loss: 1.29004 acc: 0.70020 | v_loss: 1.41114 v_acc: 0.68717 |  iteration: 10443 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 499 loss: 1.31499 acc: 0.70671 | v_loss: 1.30532 v_acc: 0.70345 |  iteration: 10444 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 500 loss: 1.27430 acc: 0.71777 | v_loss: 1.17988 v_acc: 0.71094 |  iteration: 10445 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 501 loss: 1.31652 acc: 0.69792 | v_loss: 1.26380 v_acc: 0.71061 |  iteration: 10446 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 502 loss: 1.30085 acc: 0.69694 | v_loss: 1.15471 v_acc: 0.70703 |  iteration: 10447 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 503 loss: 1.38001 acc: 0.70020 | v_loss: 1.26440 v_acc: 0.69727 |  iteration: 10448 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 504 loss: 1.25847 acc: 0.70964 | v_loss: 1.21550 v_acc: 0.72005 |  iteration: 10449 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 505 loss: 1.36073 acc: 0.69889 | v_loss: 1.14942 v_acc: 0.71940 |  iteration: 10450 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 506 loss: 1.21702 acc: 0.70671 | v_loss: 1.12749 v_acc: 0.72786 |  iteration: 10451 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 507 loss: 1.25621 acc: 0.70508 | v_loss: 1.28240 v_acc: 0.71257 |  iteration: 10452 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 508 loss: 1.32624 acc: 0.69889 | v_loss: 1.24207 v_acc: 0.70605 |  iteration: 10453 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 509 loss: 1.20470 acc: 0.71159 | v_loss: 1.23486 v_acc: 0.71289 |  iteration: 10454 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 510 loss: 1.26471 acc: 0.70898 | v_loss: 1.10621 v_acc: 0.72331 |  iteration: 10455 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 511 loss: 1.27048 acc: 0.70410 | v_loss: 1.22405 v_acc: 0.73275 |  iteration: 10456 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 512 loss: 1.37217 acc: 0.68359 | v_loss: 1.27821 v_acc: 0.69987 |  iteration: 10457 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 513 loss: 1.27034 acc: 0.72005 | v_loss: 1.29760 v_acc: 0.72201 |  iteration: 10458 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 514 loss: 1.23202 acc: 0.71680 | v_loss: 1.15811 v_acc: 0.72070 |  iteration: 10459 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 515 loss: 1.30698 acc: 0.70573 | v_loss: 1.10592 v_acc: 0.73893 |  iteration: 10460 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 516 loss: 1.25526 acc: 0.70866 | v_loss: 1.09838 v_acc: 0.72461 |  iteration: 10461 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 517 loss: 1.16379 acc: 0.72266 | v_loss: 1.19946 v_acc: 0.70671 |  iteration: 10462 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 518 loss: 1.41583 acc: 0.69434 | v_loss: 1.23219 v_acc: 0.69564 |  iteration: 10463 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 519 loss: 1.23200 acc: 0.70866 | v_loss: 1.20015 v_acc: 0.71484 |  iteration: 10464 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 520 loss: 1.24558 acc: 0.71549 | v_loss: 1.25978 v_acc: 0.74219 |  iteration: 10465 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 521 loss: 1.28424 acc: 0.70996 | v_loss: 1.42473 v_acc: 0.69694 |  iteration: 10466 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 522 loss: 1.24759 acc: 0.71452 | v_loss: 1.32767 v_acc: 0.70605 |  iteration: 10467 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 523 loss: 1.30343 acc: 0.69889 | v_loss: 1.19526 v_acc: 0.71940 |  iteration: 10468 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 524 loss: 1.37070 acc: 0.68913 | v_loss: 1.14690 v_acc: 0.70475 |  iteration: 10469 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 525 loss: 1.26050 acc: 0.70573 | v_loss: 1.14590 v_acc: 0.72201 |  iteration: 10470 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 526 loss: 1.36894 acc: 0.69727 | v_loss: 1.20350 v_acc: 0.70345 |  iteration: 10471 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 527 loss: 1.24048 acc: 0.70801 | v_loss: 1.26648 v_acc: 0.70996 |  iteration: 10472 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 528 loss: 1.30685 acc: 0.71159 | v_loss: 1.20750 v_acc: 0.72656 |  iteration: 10473 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 529 loss: 1.41225 acc: 0.68848 | v_loss: 1.23727 v_acc: 0.72526 |  iteration: 10474 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 530 loss: 1.31819 acc: 0.70638 | v_loss: 1.25268 v_acc: 0.70573 |  iteration: 10475 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 531 loss: 1.31204 acc: 0.70117 | v_loss: 1.15922 v_acc: 0.72168 |  iteration: 10476 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 532 loss: 1.27274 acc: 0.70182 | v_loss: 1.13435 v_acc: 0.71973 |  iteration: 10477 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 533 loss: 1.28130 acc: 0.70833 | v_loss: 1.44278 v_acc: 0.68783 |  iteration: 10478 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 534 loss: 1.37160 acc: 0.69303 | v_loss: 1.21643 v_acc: 0.71029 |  iteration: 10479 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 535 loss: 1.26622 acc: 0.71191 | v_loss: 1.24018 v_acc: 0.71452 |  iteration: 10480 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 536 loss: 1.31517 acc: 0.69987 | v_loss: 1.21938 v_acc: 0.71419 |  iteration: 10481 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 537 loss: 1.22913 acc: 0.71159 | v_loss: 1.26784 v_acc: 0.70866 |  iteration: 10482 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 538 loss: 1.26917 acc: 0.70964 | v_loss: 1.12232 v_acc: 0.73698 |  iteration: 10483 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 539 loss: 1.39728 acc: 0.70052 | v_loss: 1.35839 v_acc: 0.71517 |  iteration: 10484 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 540 loss: 1.36022 acc: 0.69466 | v_loss: 1.18794 v_acc: 0.70117 |  iteration: 10485 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 541 loss: 1.25804 acc: 0.70638 | v_loss: 1.19996 v_acc: 0.70378 |  iteration: 10486 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 542 loss: 1.30895 acc: 0.69434 | v_loss: 1.25333 v_acc: 0.70247 |  iteration: 10487 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 543 loss: 1.34491 acc: 0.69824 | v_loss: 1.25428 v_acc: 0.70312 |  iteration: 10488 teacher: 0 stage: sketch lr: 0.000432\n",
      "batch 544 loss: 1.26322 acc: 0.70410 | v_loss: 1.31476 v_acc: 0.69206 |  iteration: 10489 teacher: 1 stage: sketch lr: 0.000432\n",
      "batch 545 loss: 1.34443 acc: 0.70117 | v_loss: 1.37583 v_acc: 0.70573 |  iteration: 10490 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 546 loss: 1.29707 acc: 0.70508 | v_loss: 1.28190 v_acc: 0.70508 |  iteration: 10491 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 547 loss: 1.26291 acc: 0.70931 | v_loss: 1.17556 v_acc: 0.71029 |  iteration: 10492 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 548 loss: 1.32796 acc: 0.70964 | v_loss: 1.34490 v_acc: 0.70280 |  iteration: 10493 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 549 loss: 1.30677 acc: 0.69727 | v_loss: 1.22698 v_acc: 0.71126 |  iteration: 10494 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 550 loss: 1.32598 acc: 0.70898 | v_loss: 1.13122 v_acc: 0.72721 |  iteration: 10495 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 551 loss: 1.25168 acc: 0.70898 | v_loss: 1.14777 v_acc: 0.70736 |  iteration: 10496 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 552 loss: 1.37593 acc: 0.69629 | v_loss: 1.26599 v_acc: 0.70182 |  iteration: 10497 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 553 loss: 1.30052 acc: 0.69499 | v_loss: 1.33006 v_acc: 0.69434 |  iteration: 10498 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 554 loss: 1.37195 acc: 0.70312 | v_loss: 1.17062 v_acc: 0.70475 |  iteration: 10499 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 555 loss: 1.30653 acc: 0.68880 | v_loss: 1.20351 v_acc: 0.69499 |  iteration: 10500 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 556 loss: 1.35142 acc: 0.69564 | v_loss: 1.17309 v_acc: 0.70768 |  iteration: 10501 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 557 loss: 1.29681 acc: 0.70345 | v_loss: 1.20127 v_acc: 0.70703 |  iteration: 10502 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 558 loss: 1.38087 acc: 0.69792 | v_loss: 1.05896 v_acc: 0.73633 |  iteration: 10503 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 559 loss: 1.26621 acc: 0.71126 | v_loss: 1.16228 v_acc: 0.72396 |  iteration: 10504 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 560 loss: 1.27473 acc: 0.71029 | v_loss: 1.11353 v_acc: 0.73112 |  iteration: 10505 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 561 loss: 1.31427 acc: 0.70443 | v_loss: 1.10992 v_acc: 0.72852 |  iteration: 10506 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 562 loss: 1.28514 acc: 0.70768 | v_loss: 1.19020 v_acc: 0.72298 |  iteration: 10507 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 563 loss: 1.36040 acc: 0.69141 | v_loss: 1.21059 v_acc: 0.71647 |  iteration: 10508 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 564 loss: 1.33663 acc: 0.70410 | v_loss: 1.19376 v_acc: 0.72461 |  iteration: 10509 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 565 loss: 1.35337 acc: 0.70247 | v_loss: 1.38782 v_acc: 0.69857 |  iteration: 10510 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 566 loss: 1.32527 acc: 0.69694 | v_loss: 1.26069 v_acc: 0.72201 |  iteration: 10511 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 567 loss: 1.23518 acc: 0.71159 | v_loss: 1.05164 v_acc: 0.74967 |  iteration: 10512 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 568 loss: 1.33080 acc: 0.70020 | v_loss: 1.22790 v_acc: 0.70410 |  iteration: 10513 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 569 loss: 1.34168 acc: 0.69792 | v_loss: 1.26028 v_acc: 0.70182 |  iteration: 10514 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 570 loss: 1.27436 acc: 0.70508 | v_loss: 1.20655 v_acc: 0.70671 |  iteration: 10515 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 571 loss: 1.23257 acc: 0.71159 | v_loss: 1.25056 v_acc: 0.71484 |  iteration: 10516 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 572 loss: 1.32086 acc: 0.70833 | v_loss: 1.24326 v_acc: 0.69596 |  iteration: 10517 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 573 loss: 1.30559 acc: 0.70410 | v_loss: 1.20621 v_acc: 0.71289 |  iteration: 10518 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 574 loss: 1.39025 acc: 0.68978 | v_loss: 1.25114 v_acc: 0.69564 |  iteration: 10519 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 575 loss: 1.30646 acc: 0.70215 | v_loss: 1.18156 v_acc: 0.71126 |  iteration: 10520 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 576 loss: 1.31380 acc: 0.70312 | v_loss: 1.17755 v_acc: 0.72331 |  iteration: 10521 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 577 loss: 1.30107 acc: 0.69661 | v_loss: 1.23282 v_acc: 0.70215 |  iteration: 10522 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 578 loss: 1.32581 acc: 0.69857 | v_loss: 1.35461 v_acc: 0.70020 |  iteration: 10523 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 579 loss: 1.29706 acc: 0.70085 | v_loss: 1.15249 v_acc: 0.70996 |  iteration: 10524 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 580 loss: 1.26336 acc: 0.70378 | v_loss: 1.40985 v_acc: 0.68359 |  iteration: 10525 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 581 loss: 1.27431 acc: 0.71029 | v_loss: 1.15764 v_acc: 0.72005 |  iteration: 10526 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 582 loss: 1.25899 acc: 0.71289 | v_loss: 1.48838 v_acc: 0.67936 |  iteration: 10527 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 583 loss: 1.25349 acc: 0.71061 | v_loss: 1.38330 v_acc: 0.68880 |  iteration: 10528 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 584 loss: 1.30933 acc: 0.69368 | v_loss: 1.32771 v_acc: 0.69661 |  iteration: 10529 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 585 loss: 1.34944 acc: 0.69564 | v_loss: 1.32599 v_acc: 0.69466 |  iteration: 10530 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 586 loss: 1.27627 acc: 0.70117 | v_loss: 1.23044 v_acc: 0.70573 |  iteration: 10531 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 587 loss: 1.30206 acc: 0.70312 | v_loss: 1.28009 v_acc: 0.70150 |  iteration: 10532 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 588 loss: 1.30643 acc: 0.69824 | v_loss: 1.22533 v_acc: 0.72005 |  iteration: 10533 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 589 loss: 1.19981 acc: 0.71029 | v_loss: 1.40541 v_acc: 0.68750 |  iteration: 10534 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 590 loss: 1.21270 acc: 0.70801 | v_loss: 1.30650 v_acc: 0.70345 |  iteration: 10535 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 591 loss: 1.17604 acc: 0.72103 | v_loss: 1.19452 v_acc: 0.71126 |  iteration: 10536 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 592 loss: 1.33828 acc: 0.69824 | v_loss: 1.24999 v_acc: 0.71615 |  iteration: 10537 teacher: 0 stage: sketch lr: 0.000431\n",
      "batch 593 loss: 1.28554 acc: 0.70736 | v_loss: 1.16622 v_acc: 0.70768 |  iteration: 10538 teacher: 1 stage: sketch lr: 0.000431\n",
      "batch 594 loss: 1.21743 acc: 0.70801 | v_loss: 1.25700 v_acc: 0.70150 |  iteration: 10539 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 595 loss: 1.23856 acc: 0.70280 | v_loss: 1.21638 v_acc: 0.71582 |  iteration: 10540 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 596 loss: 1.34546 acc: 0.69531 | v_loss: 1.15762 v_acc: 0.72168 |  iteration: 10541 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 597 loss: 1.38893 acc: 0.69792 | v_loss: 1.12520 v_acc: 0.72754 |  iteration: 10542 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 598 loss: 1.34419 acc: 0.69629 | v_loss: 1.26092 v_acc: 0.71908 |  iteration: 10543 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 599 loss: 1.36854 acc: 0.69954 | v_loss: 1.23804 v_acc: 0.70898 |  iteration: 10544 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 600 loss: 1.31362 acc: 0.70540 | v_loss: 1.24808 v_acc: 0.70931 |  iteration: 10545 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 601 loss: 1.31503 acc: 0.69368 | v_loss: 1.11457 v_acc: 0.71517 |  iteration: 10546 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 602 loss: 1.25947 acc: 0.70573 | v_loss: 1.23836 v_acc: 0.73242 |  iteration: 10547 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 603 loss: 1.30837 acc: 0.70573 | v_loss: 1.29759 v_acc: 0.69954 |  iteration: 10548 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 604 loss: 1.32311 acc: 0.69824 | v_loss: 1.30407 v_acc: 0.72559 |  iteration: 10549 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 605 loss: 1.24214 acc: 0.70996 | v_loss: 1.16416 v_acc: 0.71745 |  iteration: 10550 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 606 loss: 1.32150 acc: 0.69238 | v_loss: 1.11968 v_acc: 0.73079 |  iteration: 10551 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 607 loss: 1.21038 acc: 0.72070 | v_loss: 1.11169 v_acc: 0.72396 |  iteration: 10552 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 608 loss: 1.35262 acc: 0.69010 | v_loss: 1.19393 v_acc: 0.70801 |  iteration: 10553 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 609 loss: 1.30394 acc: 0.70150 | v_loss: 1.24080 v_acc: 0.69596 |  iteration: 10554 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 610 loss: 1.36030 acc: 0.70052 | v_loss: 1.18954 v_acc: 0.71387 |  iteration: 10555 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 611 loss: 1.39541 acc: 0.69271 | v_loss: 1.28749 v_acc: 0.71615 |  iteration: 10556 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 612 loss: 1.29454 acc: 0.70833 | v_loss: 1.44386 v_acc: 0.69499 |  iteration: 10557 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 613 loss: 1.19638 acc: 0.70605 | v_loss: 1.33102 v_acc: 0.70052 |  iteration: 10558 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 614 loss: 1.30749 acc: 0.70703 | v_loss: 1.20529 v_acc: 0.72461 |  iteration: 10559 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 615 loss: 1.30477 acc: 0.70898 | v_loss: 1.15993 v_acc: 0.70801 |  iteration: 10560 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 616 loss: 1.37082 acc: 0.70443 | v_loss: 1.17435 v_acc: 0.72005 |  iteration: 10561 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 617 loss: 1.21785 acc: 0.71224 | v_loss: 1.21010 v_acc: 0.70671 |  iteration: 10562 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 618 loss: 1.26161 acc: 0.70540 | v_loss: 1.26927 v_acc: 0.71289 |  iteration: 10563 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 619 loss: 1.33520 acc: 0.69499 | v_loss: 1.20694 v_acc: 0.73210 |  iteration: 10564 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 620 loss: 1.28604 acc: 0.70931 | v_loss: 1.24678 v_acc: 0.71842 |  iteration: 10565 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 621 loss: 1.20557 acc: 0.71191 | v_loss: 1.25245 v_acc: 0.70410 |  iteration: 10566 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 622 loss: 1.24852 acc: 0.71094 | v_loss: 1.14872 v_acc: 0.72656 |  iteration: 10567 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 623 loss: 1.25963 acc: 0.71484 | v_loss: 1.12128 v_acc: 0.72070 |  iteration: 10568 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 624 loss: 1.28434 acc: 0.71257 | v_loss: 1.40390 v_acc: 0.69271 |  iteration: 10569 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 625 loss: 1.25968 acc: 0.70996 | v_loss: 1.20553 v_acc: 0.70833 |  iteration: 10570 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 626 loss: 1.28539 acc: 0.70443 | v_loss: 1.21693 v_acc: 0.71908 |  iteration: 10571 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 627 loss: 1.22143 acc: 0.70736 | v_loss: 1.21965 v_acc: 0.71777 |  iteration: 10572 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 628 loss: 1.30056 acc: 0.70540 | v_loss: 1.26599 v_acc: 0.70964 |  iteration: 10573 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 629 loss: 1.28461 acc: 0.70215 | v_loss: 1.12630 v_acc: 0.73600 |  iteration: 10574 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 630 loss: 1.15959 acc: 0.70866 | v_loss: 1.35602 v_acc: 0.71549 |  iteration: 10575 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 631 loss: 1.26033 acc: 0.69954 | v_loss: 1.19548 v_acc: 0.69987 |  iteration: 10576 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 632 loss: 1.26804 acc: 0.69987 | v_loss: 1.21887 v_acc: 0.70150 |  iteration: 10577 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 633 loss: 1.29762 acc: 0.69466 | v_loss: 1.25878 v_acc: 0.70410 |  iteration: 10578 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 634 loss: 1.24256 acc: 0.71191 | v_loss: 1.25817 v_acc: 0.70443 |  iteration: 10579 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 635 loss: 1.21228 acc: 0.71354 | v_loss: 1.31809 v_acc: 0.69076 |  iteration: 10580 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 636 loss: 1.24784 acc: 0.71126 | v_loss: 1.36631 v_acc: 0.70443 |  iteration: 10581 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 637 loss: 1.18214 acc: 0.71615 | v_loss: 1.27640 v_acc: 0.70378 |  iteration: 10582 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 638 loss: 1.23753 acc: 0.70996 | v_loss: 1.18939 v_acc: 0.70573 |  iteration: 10583 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 639 loss: 1.24591 acc: 0.70671 | v_loss: 1.32501 v_acc: 0.70378 |  iteration: 10584 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 640 loss: 1.28868 acc: 0.70964 | v_loss: 1.21602 v_acc: 0.71224 |  iteration: 10585 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 641 loss: 1.17547 acc: 0.71126 | v_loss: 1.12960 v_acc: 0.72591 |  iteration: 10586 teacher: 1 stage: sketch lr: 0.000430\n",
      "batch 642 loss: 1.24149 acc: 0.71354 | v_loss: 1.12831 v_acc: 0.71029 |  iteration: 10587 teacher: 0 stage: sketch lr: 0.000430\n",
      "batch 643 loss: 1.38989 acc: 0.69857 | v_loss: 1.26137 v_acc: 0.70475 |  iteration: 10588 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 644 loss: 1.34774 acc: 0.70345 | v_loss: 1.32127 v_acc: 0.69661 |  iteration: 10589 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 645 loss: 1.33493 acc: 0.69694 | v_loss: 1.15009 v_acc: 0.70703 |  iteration: 10590 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 646 loss: 1.13999 acc: 0.72298 | v_loss: 1.20782 v_acc: 0.69629 |  iteration: 10591 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 647 loss: 1.36910 acc: 0.69303 | v_loss: 1.18860 v_acc: 0.71029 |  iteration: 10592 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 648 loss: 1.26610 acc: 0.70280 | v_loss: 1.21305 v_acc: 0.70638 |  iteration: 10593 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 649 loss: 1.24249 acc: 0.71387 | v_loss: 1.06289 v_acc: 0.73568 |  iteration: 10594 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 650 loss: 1.30794 acc: 0.69954 | v_loss: 1.16912 v_acc: 0.72038 |  iteration: 10595 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 651 loss: 1.25179 acc: 0.69661 | v_loss: 1.14725 v_acc: 0.71842 |  iteration: 10596 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 652 loss: 1.28886 acc: 0.70020 | v_loss: 1.12193 v_acc: 0.72689 |  iteration: 10597 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 653 loss: 1.34411 acc: 0.70410 | v_loss: 1.19929 v_acc: 0.71810 |  iteration: 10598 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 654 loss: 1.28356 acc: 0.70247 | v_loss: 1.22232 v_acc: 0.71973 |  iteration: 10599 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 655 loss: 1.31636 acc: 0.70703 | v_loss: 1.19791 v_acc: 0.72884 |  iteration: 10600 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 656 loss: 1.29599 acc: 0.69824 | v_loss: 1.37638 v_acc: 0.69564 |  iteration: 10601 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 657 loss: 1.28123 acc: 0.70964 | v_loss: 1.26406 v_acc: 0.72363 |  iteration: 10602 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 658 loss: 1.25549 acc: 0.71159 | v_loss: 1.05924 v_acc: 0.74186 |  iteration: 10603 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 659 loss: 1.37904 acc: 0.69238 | v_loss: 1.22405 v_acc: 0.70638 |  iteration: 10604 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 660 loss: 1.31097 acc: 0.70280 | v_loss: 1.26081 v_acc: 0.70280 |  iteration: 10605 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 661 loss: 1.26426 acc: 0.71680 | v_loss: 1.19976 v_acc: 0.70964 |  iteration: 10606 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 662 loss: 1.22873 acc: 0.71908 | v_loss: 1.24271 v_acc: 0.71126 |  iteration: 10607 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 663 loss: 1.31504 acc: 0.69954 | v_loss: 1.25124 v_acc: 0.69043 |  iteration: 10608 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 664 loss: 1.25683 acc: 0.70475 | v_loss: 1.22569 v_acc: 0.70931 |  iteration: 10609 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 665 loss: 1.38336 acc: 0.69759 | v_loss: 1.26088 v_acc: 0.69271 |  iteration: 10610 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 666 loss: 1.32549 acc: 0.70020 | v_loss: 1.17321 v_acc: 0.71159 |  iteration: 10611 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 667 loss: 1.31013 acc: 0.69889 | v_loss: 1.17262 v_acc: 0.72363 |  iteration: 10612 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 668 loss: 1.27097 acc: 0.71354 | v_loss: 1.21156 v_acc: 0.70215 |  iteration: 10613 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 669 loss: 1.35792 acc: 0.70247 | v_loss: 1.35061 v_acc: 0.69987 |  iteration: 10614 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 670 loss: 1.19400 acc: 0.71289 | v_loss: 1.16049 v_acc: 0.70833 |  iteration: 10615 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 671 loss: 1.26657 acc: 0.70410 | v_loss: 1.42755 v_acc: 0.68359 |  iteration: 10616 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 672 loss: 1.24265 acc: 0.70833 | v_loss: 1.15385 v_acc: 0.72461 |  iteration: 10617 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 673 loss: 1.38142 acc: 0.69434 | v_loss: 1.49366 v_acc: 0.67871 |  iteration: 10618 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 674 loss: 1.40732 acc: 0.69889 | v_loss: 1.36332 v_acc: 0.69922 |  iteration: 10619 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 675 loss: 1.33458 acc: 0.69238 | v_loss: 1.31327 v_acc: 0.69108 |  iteration: 10620 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 676 loss: 1.24572 acc: 0.71354 | v_loss: 1.31982 v_acc: 0.69661 |  iteration: 10621 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 677 loss: 1.35213 acc: 0.69499 | v_loss: 1.23349 v_acc: 0.70410 |  iteration: 10622 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 678 loss: 1.20851 acc: 0.71647 | v_loss: 1.26611 v_acc: 0.70312 |  iteration: 10623 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 679 loss: 1.32047 acc: 0.70182 | v_loss: 1.21924 v_acc: 0.72005 |  iteration: 10624 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 680 loss: 1.30684 acc: 0.70020 | v_loss: 1.39583 v_acc: 0.68880 |  iteration: 10625 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 681 loss: 1.31179 acc: 0.70020 | v_loss: 1.29172 v_acc: 0.70573 |  iteration: 10626 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 682 loss: 1.21863 acc: 0.71517 | v_loss: 1.18462 v_acc: 0.70996 |  iteration: 10627 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 683 loss: 1.31355 acc: 0.70378 | v_loss: 1.24846 v_acc: 0.71745 |  iteration: 10628 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 684 loss: 1.17503 acc: 0.71777 | v_loss: 1.16209 v_acc: 0.70898 |  iteration: 10629 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 685 loss: 1.24384 acc: 0.70247 | v_loss: 1.25726 v_acc: 0.69661 |  iteration: 10630 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 686 loss: 1.20926 acc: 0.71289 | v_loss: 1.21926 v_acc: 0.71224 |  iteration: 10631 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 687 loss: 1.19684 acc: 0.71745 | v_loss: 1.15767 v_acc: 0.71810 |  iteration: 10632 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 688 loss: 1.33407 acc: 0.70605 | v_loss: 1.12832 v_acc: 0.72233 |  iteration: 10633 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 689 loss: 1.29511 acc: 0.70182 | v_loss: 1.26591 v_acc: 0.71484 |  iteration: 10634 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 690 loss: 1.30001 acc: 0.71712 | v_loss: 1.24059 v_acc: 0.70573 |  iteration: 10635 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 691 loss: 1.23843 acc: 0.70280 | v_loss: 1.24384 v_acc: 0.70964 |  iteration: 10636 teacher: 0 stage: sketch lr: 0.000429\n",
      "batch 692 loss: 1.28686 acc: 0.70345 | v_loss: 1.10993 v_acc: 0.71517 |  iteration: 10637 teacher: 1 stage: sketch lr: 0.000429\n",
      "batch 693 loss: 1.26387 acc: 0.70280 | v_loss: 1.23671 v_acc: 0.73307 |  iteration: 10638 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 694 loss: 1.20162 acc: 0.71029 | v_loss: 1.29407 v_acc: 0.70052 |  iteration: 10639 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 695 loss: 1.25450 acc: 0.70996 | v_loss: 1.30966 v_acc: 0.72559 |  iteration: 10640 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 696 loss: 1.28659 acc: 0.70410 | v_loss: 1.16454 v_acc: 0.71745 |  iteration: 10641 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 697 loss: 1.36681 acc: 0.69824 | v_loss: 1.11854 v_acc: 0.72819 |  iteration: 10642 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 698 loss: 1.25066 acc: 0.70833 | v_loss: 1.10213 v_acc: 0.72396 |  iteration: 10643 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 699 loss: 1.29744 acc: 0.69824 | v_loss: 1.19526 v_acc: 0.70443 |  iteration: 10644 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 700 loss: 1.28352 acc: 0.70410 | v_loss: 1.22240 v_acc: 0.69792 |  iteration: 10645 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 701 loss: 1.26561 acc: 0.70410 | v_loss: 1.19031 v_acc: 0.71549 |  iteration: 10646 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 702 loss: 1.41127 acc: 0.68620 | v_loss: 1.28019 v_acc: 0.73047 |  iteration: 10647 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 703 loss: 1.36330 acc: 0.69141 | v_loss: 1.45599 v_acc: 0.69564 |  iteration: 10648 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 704 loss: 1.25625 acc: 0.70638 | v_loss: 1.33019 v_acc: 0.69889 |  iteration: 10649 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 705 loss: 1.35929 acc: 0.69954 | v_loss: 1.19394 v_acc: 0.72135 |  iteration: 10650 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 706 loss: 1.31381 acc: 0.69954 | v_loss: 1.15317 v_acc: 0.70312 |  iteration: 10651 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 707 loss: 1.35025 acc: 0.70345 | v_loss: 1.14859 v_acc: 0.72168 |  iteration: 10652 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 708 loss: 1.26128 acc: 0.70573 | v_loss: 1.21532 v_acc: 0.70378 |  iteration: 10653 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 709 loss: 1.29834 acc: 0.70475 | v_loss: 1.24688 v_acc: 0.70996 |  iteration: 10654 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 710 loss: 1.20794 acc: 0.71484 | v_loss: 1.19691 v_acc: 0.73145 |  iteration: 10655 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 711 loss: 1.31686 acc: 0.69889 | v_loss: 1.22449 v_acc: 0.71973 |  iteration: 10656 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 712 loss: 1.31650 acc: 0.71191 | v_loss: 1.24673 v_acc: 0.70345 |  iteration: 10657 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 713 loss: 1.28146 acc: 0.71224 | v_loss: 1.16061 v_acc: 0.72461 |  iteration: 10658 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 714 loss: 1.26805 acc: 0.70736 | v_loss: 1.12991 v_acc: 0.71908 |  iteration: 10659 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 715 loss: 1.31987 acc: 0.69922 | v_loss: 1.48641 v_acc: 0.69010 |  iteration: 10660 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 716 loss: 1.32772 acc: 0.69564 | v_loss: 1.19879 v_acc: 0.71061 |  iteration: 10661 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 717 loss: 1.23928 acc: 0.70931 | v_loss: 1.23753 v_acc: 0.71289 |  iteration: 10662 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 718 loss: 1.28161 acc: 0.70768 | v_loss: 1.23882 v_acc: 0.70703 |  iteration: 10663 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 719 loss: 1.24085 acc: 0.70638 | v_loss: 1.27887 v_acc: 0.69401 |  iteration: 10664 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 720 loss: 1.33390 acc: 0.70378 | v_loss: 1.12872 v_acc: 0.73405 |  iteration: 10665 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 721 loss: 1.23888 acc: 0.70443 | v_loss: 1.35750 v_acc: 0.72331 |  iteration: 10666 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 722 loss: 1.20958 acc: 0.70931 | v_loss: 1.18283 v_acc: 0.70117 |  iteration: 10667 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 723 loss: 1.24860 acc: 0.70736 | v_loss: 1.20487 v_acc: 0.70638 |  iteration: 10668 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 724 loss: 1.25991 acc: 0.71419 | v_loss: 1.26820 v_acc: 0.70215 |  iteration: 10669 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 725 loss: 1.28356 acc: 0.69759 | v_loss: 1.27716 v_acc: 0.69987 |  iteration: 10670 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 726 loss: 1.36109 acc: 0.69238 | v_loss: 1.33786 v_acc: 0.68913 |  iteration: 10671 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 727 loss: 1.37452 acc: 0.69727 | v_loss: 1.35632 v_acc: 0.70638 |  iteration: 10672 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 728 loss: 1.26854 acc: 0.70638 | v_loss: 1.27423 v_acc: 0.70443 |  iteration: 10673 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 729 loss: 1.32984 acc: 0.69531 | v_loss: 1.18593 v_acc: 0.70736 |  iteration: 10674 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 730 loss: 1.22493 acc: 0.70833 | v_loss: 1.33287 v_acc: 0.70345 |  iteration: 10675 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 731 loss: 1.27210 acc: 0.70182 | v_loss: 1.24554 v_acc: 0.71029 |  iteration: 10676 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 732 loss: 1.33889 acc: 0.70020 | v_loss: 1.12430 v_acc: 0.72721 |  iteration: 10677 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 733 loss: 1.28051 acc: 0.70378 | v_loss: 1.18660 v_acc: 0.70540 |  iteration: 10678 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 734 loss: 1.35638 acc: 0.69434 | v_loss: 1.28542 v_acc: 0.70215 |  iteration: 10679 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 735 loss: 1.19665 acc: 0.72038 | v_loss: 1.30840 v_acc: 0.69727 |  iteration: 10680 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 736 loss: 1.23375 acc: 0.71224 | v_loss: 1.14676 v_acc: 0.71387 |  iteration: 10681 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 737 loss: 1.33528 acc: 0.71029 | v_loss: 1.19741 v_acc: 0.69434 |  iteration: 10682 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 738 loss: 1.26675 acc: 0.70280 | v_loss: 1.20445 v_acc: 0.70703 |  iteration: 10683 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 739 loss: 1.23883 acc: 0.71647 | v_loss: 1.21741 v_acc: 0.70052 |  iteration: 10684 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 740 loss: 1.35217 acc: 0.70540 | v_loss: 1.05419 v_acc: 0.73600 |  iteration: 10685 teacher: 0 stage: sketch lr: 0.000428\n",
      "batch 741 loss: 1.31270 acc: 0.69987 | v_loss: 1.17282 v_acc: 0.71680 |  iteration: 10686 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 742 loss: 1.22728 acc: 0.72038 | v_loss: 1.12088 v_acc: 0.73405 |  iteration: 10687 teacher: 1 stage: sketch lr: 0.000428\n",
      "batch 743 loss: 1.29601 acc: 0.70280 | v_loss: 1.12288 v_acc: 0.72298 |  iteration: 10688 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 744 loss: 1.28045 acc: 0.70898 | v_loss: 1.19123 v_acc: 0.71908 |  iteration: 10689 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 745 loss: 1.28203 acc: 0.70964 | v_loss: 1.21759 v_acc: 0.71322 |  iteration: 10690 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 746 loss: 1.18349 acc: 0.71224 | v_loss: 1.19022 v_acc: 0.72005 |  iteration: 10691 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 747 loss: 1.24112 acc: 0.70443 | v_loss: 1.38618 v_acc: 0.69987 |  iteration: 10692 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 748 loss: 1.30416 acc: 0.70605 | v_loss: 1.26242 v_acc: 0.71842 |  iteration: 10693 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 749 loss: 1.29801 acc: 0.71810 | v_loss: 1.04504 v_acc: 0.74349 |  iteration: 10694 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 750 loss: 1.29315 acc: 0.70508 | v_loss: 1.21286 v_acc: 0.70866 |  iteration: 10695 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 751 loss: 1.28127 acc: 0.70020 | v_loss: 1.24426 v_acc: 0.69824 |  iteration: 10696 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 752 loss: 1.32233 acc: 0.69336 | v_loss: 1.19944 v_acc: 0.70475 |  iteration: 10697 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 753 loss: 1.26699 acc: 0.70508 | v_loss: 1.25244 v_acc: 0.71126 |  iteration: 10698 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 754 loss: 1.32064 acc: 0.69531 | v_loss: 1.24369 v_acc: 0.69759 |  iteration: 10699 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 755 loss: 1.27204 acc: 0.71061 | v_loss: 1.23082 v_acc: 0.70898 |  iteration: 10700 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 756 loss: 1.19844 acc: 0.71452 | v_loss: 1.25827 v_acc: 0.69596 |  iteration: 10701 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 757 loss: 1.30434 acc: 0.70833 | v_loss: 1.18501 v_acc: 0.71191 |  iteration: 10702 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 758 loss: 1.38694 acc: 0.69336 | v_loss: 1.17310 v_acc: 0.72493 |  iteration: 10703 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 759 loss: 1.33446 acc: 0.69824 | v_loss: 1.22860 v_acc: 0.70117 |  iteration: 10704 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 760 loss: 1.20563 acc: 0.71680 | v_loss: 1.34119 v_acc: 0.69987 |  iteration: 10705 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 761 loss: 1.29773 acc: 0.69759 | v_loss: 1.16139 v_acc: 0.70801 |  iteration: 10706 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 762 loss: 1.30926 acc: 0.70508 | v_loss: 1.40336 v_acc: 0.68652 |  iteration: 10707 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 763 loss: 1.25969 acc: 0.71094 | v_loss: 1.15199 v_acc: 0.71875 |  iteration: 10708 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 764 loss: 1.41348 acc: 0.69368 | v_loss: 1.47476 v_acc: 0.68327 |  iteration: 10709 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 765 loss: 1.30513 acc: 0.70117 | v_loss: 1.35366 v_acc: 0.69694 |  iteration: 10710 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 766 loss: 1.39881 acc: 0.69531 | v_loss: 1.31066 v_acc: 0.69141 |  iteration: 10711 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 767 loss: 1.20983 acc: 0.71712 | v_loss: 1.31932 v_acc: 0.69629 |  iteration: 10712 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 768 loss: 1.25840 acc: 0.70378 | v_loss: 1.21507 v_acc: 0.70378 |  iteration: 10713 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 769 loss: 1.27949 acc: 0.70410 | v_loss: 1.27190 v_acc: 0.69987 |  iteration: 10714 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 770 loss: 1.26436 acc: 0.70931 | v_loss: 1.21017 v_acc: 0.71419 |  iteration: 10715 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 771 loss: 1.26922 acc: 0.70475 | v_loss: 1.40819 v_acc: 0.68913 |  iteration: 10716 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 772 loss: 1.28226 acc: 0.71061 | v_loss: 1.30194 v_acc: 0.70443 |  iteration: 10717 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 773 loss: 1.33481 acc: 0.69954 | v_loss: 1.17378 v_acc: 0.71094 |  iteration: 10718 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 774 loss: 1.33524 acc: 0.69368 | v_loss: 1.24124 v_acc: 0.71908 |  iteration: 10719 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 775 loss: 1.23465 acc: 0.71810 | v_loss: 1.16867 v_acc: 0.70410 |  iteration: 10720 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 776 loss: 1.29481 acc: 0.69922 | v_loss: 1.27312 v_acc: 0.69889 |  iteration: 10721 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 777 loss: 1.34794 acc: 0.70150 | v_loss: 1.21889 v_acc: 0.71549 |  iteration: 10722 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 778 loss: 1.17483 acc: 0.71126 | v_loss: 1.16068 v_acc: 0.71549 |  iteration: 10723 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 779 loss: 1.29043 acc: 0.69889 | v_loss: 1.12945 v_acc: 0.72526 |  iteration: 10724 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 780 loss: 1.31818 acc: 0.70508 | v_loss: 1.27420 v_acc: 0.71126 |  iteration: 10725 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 781 loss: 1.24254 acc: 0.71387 | v_loss: 1.24837 v_acc: 0.70117 |  iteration: 10726 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 782 loss: 1.31555 acc: 0.69824 | v_loss: 1.24273 v_acc: 0.70378 |  iteration: 10727 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 783 loss: 1.32521 acc: 0.70247 | v_loss: 1.11287 v_acc: 0.71582 |  iteration: 10728 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 784 loss: 1.28222 acc: 0.69987 | v_loss: 1.23306 v_acc: 0.72982 |  iteration: 10729 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 785 loss: 1.34840 acc: 0.69661 | v_loss: 1.28499 v_acc: 0.69922 |  iteration: 10730 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 786 loss: 1.33891 acc: 0.69987 | v_loss: 1.29569 v_acc: 0.72233 |  iteration: 10731 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 787 loss: 1.33315 acc: 0.70573 | v_loss: 1.15260 v_acc: 0.72168 |  iteration: 10732 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 788 loss: 1.26921 acc: 0.71452 | v_loss: 1.11121 v_acc: 0.73372 |  iteration: 10733 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 789 loss: 1.27292 acc: 0.70182 | v_loss: 1.09950 v_acc: 0.72624 |  iteration: 10734 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 790 loss: 1.32746 acc: 0.69694 | v_loss: 1.18631 v_acc: 0.71224 |  iteration: 10735 teacher: 0 stage: sketch lr: 0.000427\n",
      "batch 791 loss: 1.26241 acc: 0.70150 | v_loss: 1.23917 v_acc: 0.70768 |  iteration: 10736 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 792 loss: 1.24434 acc: 0.70703 | v_loss: 1.20038 v_acc: 0.71289 |  iteration: 10737 teacher: 1 stage: sketch lr: 0.000427\n",
      "batch 793 loss: 1.26945 acc: 0.70508 | v_loss: 1.32644 v_acc: 0.70540 |  iteration: 10738 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 794 loss: 1.29544 acc: 0.70605 | v_loss: 1.46821 v_acc: 0.69043 |  iteration: 10739 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 795 loss: 1.35148 acc: 0.70378 | v_loss: 1.33488 v_acc: 0.69954 |  iteration: 10740 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 796 loss: 1.27215 acc: 0.70378 | v_loss: 1.19615 v_acc: 0.72070 |  iteration: 10741 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 797 loss: 1.33997 acc: 0.69727 | v_loss: 1.14100 v_acc: 0.70378 |  iteration: 10742 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 798 loss: 1.32408 acc: 0.71159 | v_loss: 1.14846 v_acc: 0.71973 |  iteration: 10743 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 799 loss: 1.22507 acc: 0.71322 | v_loss: 1.22416 v_acc: 0.69987 |  iteration: 10744 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 800 loss: 1.31823 acc: 0.70117 | v_loss: 1.25147 v_acc: 0.71191 |  iteration: 10745 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 801 loss: 1.27953 acc: 0.70866 | v_loss: 1.19993 v_acc: 0.73275 |  iteration: 10746 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 802 loss: 1.37139 acc: 0.70215 | v_loss: 1.22684 v_acc: 0.71875 |  iteration: 10747 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 803 loss: 1.30752 acc: 0.69238 | v_loss: 1.24013 v_acc: 0.70736 |  iteration: 10748 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 804 loss: 1.26422 acc: 0.70573 | v_loss: 1.15524 v_acc: 0.72266 |  iteration: 10749 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 805 loss: 1.27371 acc: 0.70540 | v_loss: 1.11820 v_acc: 0.72168 |  iteration: 10750 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 806 loss: 1.22736 acc: 0.70833 | v_loss: 1.45073 v_acc: 0.69173 |  iteration: 10751 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 807 loss: 1.28501 acc: 0.70801 | v_loss: 1.18473 v_acc: 0.71289 |  iteration: 10752 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 808 loss: 1.32350 acc: 0.70736 | v_loss: 1.22856 v_acc: 0.71777 |  iteration: 10753 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 809 loss: 1.22409 acc: 0.71517 | v_loss: 1.23398 v_acc: 0.71842 |  iteration: 10754 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 810 loss: 1.30908 acc: 0.70410 | v_loss: 1.28027 v_acc: 0.70573 |  iteration: 10755 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 811 loss: 1.34582 acc: 0.70540 | v_loss: 1.13088 v_acc: 0.73112 |  iteration: 10756 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 812 loss: 1.29547 acc: 0.70182 | v_loss: 1.36400 v_acc: 0.71289 |  iteration: 10757 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 813 loss: 1.36832 acc: 0.69727 | v_loss: 1.20546 v_acc: 0.69661 |  iteration: 10758 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 814 loss: 1.25008 acc: 0.70605 | v_loss: 1.21440 v_acc: 0.69889 |  iteration: 10759 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 815 loss: 1.26251 acc: 0.70378 | v_loss: 1.26556 v_acc: 0.70410 |  iteration: 10760 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 816 loss: 1.24252 acc: 0.70703 | v_loss: 1.26117 v_acc: 0.70638 |  iteration: 10761 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 817 loss: 1.25379 acc: 0.71647 | v_loss: 1.33286 v_acc: 0.69238 |  iteration: 10762 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 818 loss: 1.25043 acc: 0.71387 | v_loss: 1.36628 v_acc: 0.70410 |  iteration: 10763 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 819 loss: 1.23828 acc: 0.71354 | v_loss: 1.27201 v_acc: 0.71224 |  iteration: 10764 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 820 loss: 1.20824 acc: 0.71289 | v_loss: 1.19370 v_acc: 0.70931 |  iteration: 10765 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 821 loss: 1.30291 acc: 0.70020 | v_loss: 1.33346 v_acc: 0.70736 |  iteration: 10766 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 822 loss: 1.34555 acc: 0.69010 | v_loss: 1.23145 v_acc: 0.71257 |  iteration: 10767 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 823 loss: 1.19489 acc: 0.71582 | v_loss: 1.11092 v_acc: 0.72624 |  iteration: 10768 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 824 loss: 1.33352 acc: 0.70443 | v_loss: 1.15529 v_acc: 0.70703 |  iteration: 10769 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 825 loss: 1.26187 acc: 0.71257 | v_loss: 1.25637 v_acc: 0.70280 |  iteration: 10770 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 826 loss: 1.26264 acc: 0.70898 | v_loss: 1.30791 v_acc: 0.69987 |  iteration: 10771 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 827 loss: 1.20439 acc: 0.71419 | v_loss: 1.14702 v_acc: 0.71029 |  iteration: 10772 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 828 loss: 1.40723 acc: 0.70052 | v_loss: 1.17454 v_acc: 0.69792 |  iteration: 10773 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 829 loss: 1.29006 acc: 0.70247 | v_loss: 1.19398 v_acc: 0.70996 |  iteration: 10774 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 830 loss: 1.28001 acc: 0.71289 | v_loss: 1.20434 v_acc: 0.70508 |  iteration: 10775 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 831 loss: 1.20901 acc: 0.70931 | v_loss: 1.05946 v_acc: 0.73730 |  iteration: 10776 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 832 loss: 1.31356 acc: 0.69661 | v_loss: 1.16544 v_acc: 0.71940 |  iteration: 10777 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 833 loss: 1.22861 acc: 0.71517 | v_loss: 1.14579 v_acc: 0.73014 |  iteration: 10778 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 834 loss: 1.31830 acc: 0.70150 | v_loss: 1.12703 v_acc: 0.72624 |  iteration: 10779 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 835 loss: 1.30060 acc: 0.69303 | v_loss: 1.19920 v_acc: 0.71973 |  iteration: 10780 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 836 loss: 1.23755 acc: 0.70605 | v_loss: 1.20811 v_acc: 0.72038 |  iteration: 10781 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 837 loss: 1.28795 acc: 0.70020 | v_loss: 1.19885 v_acc: 0.72363 |  iteration: 10782 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 838 loss: 1.24410 acc: 0.71582 | v_loss: 1.41660 v_acc: 0.69629 |  iteration: 10783 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 839 loss: 1.26268 acc: 0.70475 | v_loss: 1.26422 v_acc: 0.72168 |  iteration: 10784 teacher: 1 stage: sketch lr: 0.000426\n",
      "batch 840 loss: 1.35745 acc: 0.69596 | v_loss: 1.06396 v_acc: 0.74023 |  iteration: 10785 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 841 loss: 1.24306 acc: 0.70703 | v_loss: 1.22839 v_acc: 0.70312 |  iteration: 10786 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 842 loss: 1.24898 acc: 0.70736 | v_loss: 1.23517 v_acc: 0.70345 |  iteration: 10787 teacher: 0 stage: sketch lr: 0.000426\n",
      "batch 843 loss: 1.29803 acc: 0.70247 | v_loss: 1.18281 v_acc: 0.70866 |  iteration: 10788 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 844 loss: 1.35423 acc: 0.69661 | v_loss: 1.24045 v_acc: 0.71322 |  iteration: 10789 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 845 loss: 1.40903 acc: 0.69694 | v_loss: 1.22443 v_acc: 0.70085 |  iteration: 10790 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 846 loss: 1.20531 acc: 0.71354 | v_loss: 1.21568 v_acc: 0.71257 |  iteration: 10791 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 847 loss: 1.26615 acc: 0.70215 | v_loss: 1.25812 v_acc: 0.69629 |  iteration: 10792 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 848 loss: 1.24506 acc: 0.70605 | v_loss: 1.15502 v_acc: 0.72363 |  iteration: 10793 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 849 loss: 1.37225 acc: 0.69596 | v_loss: 1.16451 v_acc: 0.72428 |  iteration: 10794 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 850 loss: 1.26887 acc: 0.70182 | v_loss: 1.20459 v_acc: 0.70573 |  iteration: 10795 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 851 loss: 1.25059 acc: 0.70345 | v_loss: 1.40528 v_acc: 0.69466 |  iteration: 10796 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 852 loss: 1.27879 acc: 0.69564 | v_loss: 1.16873 v_acc: 0.71029 |  iteration: 10797 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 853 loss: 1.38639 acc: 0.69336 | v_loss: 1.43550 v_acc: 0.68392 |  iteration: 10798 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 854 loss: 1.36371 acc: 0.69727 | v_loss: 1.15342 v_acc: 0.72135 |  iteration: 10799 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 855 loss: 1.39281 acc: 0.70475 | v_loss: 1.47770 v_acc: 0.68652 |  iteration: 10800 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 856 loss: 1.31649 acc: 0.70671 | v_loss: 1.34463 v_acc: 0.70378 |  iteration: 10801 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 857 loss: 1.33693 acc: 0.70508 | v_loss: 1.30524 v_acc: 0.69336 |  iteration: 10802 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 858 loss: 1.33616 acc: 0.70312 | v_loss: 1.29526 v_acc: 0.70378 |  iteration: 10803 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 859 loss: 1.22714 acc: 0.71029 | v_loss: 1.23875 v_acc: 0.70312 |  iteration: 10804 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 860 loss: 1.27522 acc: 0.69596 | v_loss: 1.25739 v_acc: 0.69792 |  iteration: 10805 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 861 loss: 1.23310 acc: 0.70866 | v_loss: 1.21518 v_acc: 0.71777 |  iteration: 10806 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 862 loss: 1.29612 acc: 0.69499 | v_loss: 1.40591 v_acc: 0.68522 |  iteration: 10807 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 863 loss: 1.26890 acc: 0.70540 | v_loss: 1.26978 v_acc: 0.70898 |  iteration: 10808 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 864 loss: 1.23674 acc: 0.70768 | v_loss: 1.18962 v_acc: 0.70638 |  iteration: 10809 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 865 loss: 1.29859 acc: 0.70020 | v_loss: 1.24773 v_acc: 0.71159 |  iteration: 10810 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 866 loss: 1.30111 acc: 0.69987 | v_loss: 1.14863 v_acc: 0.71126 |  iteration: 10811 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 867 loss: 1.27374 acc: 0.70410 | v_loss: 1.25031 v_acc: 0.70052 |  iteration: 10812 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 868 loss: 1.28801 acc: 0.70638 | v_loss: 1.22305 v_acc: 0.71745 |  iteration: 10813 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 869 loss: 1.30438 acc: 0.70052 | v_loss: 1.15538 v_acc: 0.72005 |  iteration: 10814 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 870 loss: 1.27803 acc: 0.69954 | v_loss: 1.12317 v_acc: 0.72819 |  iteration: 10815 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 871 loss: 1.23133 acc: 0.71452 | v_loss: 1.24871 v_acc: 0.71745 |  iteration: 10816 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 872 loss: 1.28095 acc: 0.70475 | v_loss: 1.24213 v_acc: 0.70410 |  iteration: 10817 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 873 loss: 1.24037 acc: 0.71061 | v_loss: 1.23996 v_acc: 0.70898 |  iteration: 10818 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 874 loss: 1.34741 acc: 0.70605 | v_loss: 1.10713 v_acc: 0.71647 |  iteration: 10819 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 875 loss: 1.29300 acc: 0.70801 | v_loss: 1.24384 v_acc: 0.72721 |  iteration: 10820 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 876 loss: 1.36899 acc: 0.69661 | v_loss: 1.28449 v_acc: 0.69824 |  iteration: 10821 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 877 loss: 1.30447 acc: 0.70215 | v_loss: 1.28753 v_acc: 0.71973 |  iteration: 10822 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 878 loss: 1.27862 acc: 0.70215 | v_loss: 1.15322 v_acc: 0.72266 |  iteration: 10823 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 879 loss: 1.23515 acc: 0.70345 | v_loss: 1.09783 v_acc: 0.73665 |  iteration: 10824 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 880 loss: 1.34344 acc: 0.69759 | v_loss: 1.09542 v_acc: 0.72266 |  iteration: 10825 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 881 loss: 1.23785 acc: 0.71029 | v_loss: 1.17086 v_acc: 0.71322 |  iteration: 10826 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 882 loss: 1.37294 acc: 0.69857 | v_loss: 1.22942 v_acc: 0.70280 |  iteration: 10827 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 883 loss: 1.22318 acc: 0.70540 | v_loss: 1.18812 v_acc: 0.71647 |  iteration: 10828 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 884 loss: 1.28216 acc: 0.71029 | v_loss: 1.33178 v_acc: 0.70410 |  iteration: 10829 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 885 loss: 1.20061 acc: 0.70540 | v_loss: 1.47091 v_acc: 0.69336 |  iteration: 10830 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 886 loss: 1.30370 acc: 0.70247 | v_loss: 1.34242 v_acc: 0.69694 |  iteration: 10831 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 887 loss: 1.23040 acc: 0.70736 | v_loss: 1.19195 v_acc: 0.72266 |  iteration: 10832 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 888 loss: 1.29595 acc: 0.70410 | v_loss: 1.15389 v_acc: 0.70833 |  iteration: 10833 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 889 loss: 1.27931 acc: 0.70280 | v_loss: 1.13895 v_acc: 0.72428 |  iteration: 10834 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 890 loss: 1.28491 acc: 0.69922 | v_loss: 1.21122 v_acc: 0.70443 |  iteration: 10835 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 891 loss: 1.31596 acc: 0.70052 | v_loss: 1.24687 v_acc: 0.72135 |  iteration: 10836 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 892 loss: 1.28174 acc: 0.70540 | v_loss: 1.20084 v_acc: 0.73014 |  iteration: 10837 teacher: 0 stage: sketch lr: 0.000425\n",
      "batch 893 loss: 1.41019 acc: 0.68652 | v_loss: 1.24054 v_acc: 0.72005 |  iteration: 10838 teacher: 1 stage: sketch lr: 0.000425\n",
      "batch 894 loss: 1.25926 acc: 0.69987 | v_loss: 1.24448 v_acc: 0.70345 |  iteration: 10839 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 895 loss: 1.26377 acc: 0.70833 | v_loss: 1.15458 v_acc: 0.72201 |  iteration: 10840 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 896 loss: 1.28396 acc: 0.70378 | v_loss: 1.12196 v_acc: 0.72135 |  iteration: 10841 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 897 loss: 1.32294 acc: 0.70540 | v_loss: 1.44886 v_acc: 0.69076 |  iteration: 10842 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 898 loss: 1.36642 acc: 0.69889 | v_loss: 1.19855 v_acc: 0.70768 |  iteration: 10843 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 899 loss: 1.33770 acc: 0.69824 | v_loss: 1.22828 v_acc: 0.71322 |  iteration: 10844 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 900 loss: 1.29157 acc: 0.69727 | v_loss: 1.23337 v_acc: 0.71387 |  iteration: 10845 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 901 loss: 1.33080 acc: 0.70443 | v_loss: 1.27490 v_acc: 0.69987 |  iteration: 10846 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 902 loss: 1.34864 acc: 0.69271 | v_loss: 1.14180 v_acc: 0.73047 |  iteration: 10847 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 903 loss: 1.20595 acc: 0.70215 | v_loss: 1.37230 v_acc: 0.70964 |  iteration: 10848 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 904 loss: 1.30815 acc: 0.69792 | v_loss: 1.18574 v_acc: 0.69987 |  iteration: 10849 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 905 loss: 1.23342 acc: 0.70215 | v_loss: 1.19569 v_acc: 0.70605 |  iteration: 10850 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 906 loss: 1.27563 acc: 0.70345 | v_loss: 1.25615 v_acc: 0.70345 |  iteration: 10851 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 907 loss: 1.15903 acc: 0.70866 | v_loss: 1.26182 v_acc: 0.70085 |  iteration: 10852 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 908 loss: 1.26518 acc: 0.70964 | v_loss: 1.32894 v_acc: 0.69434 |  iteration: 10853 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 909 loss: 1.26370 acc: 0.70801 | v_loss: 1.38523 v_acc: 0.70605 |  iteration: 10854 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 910 loss: 1.20862 acc: 0.70866 | v_loss: 1.28177 v_acc: 0.70475 |  iteration: 10855 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 911 loss: 1.32019 acc: 0.70280 | v_loss: 1.19212 v_acc: 0.70573 |  iteration: 10856 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 912 loss: 1.27829 acc: 0.70736 | v_loss: 1.32638 v_acc: 0.70540 |  iteration: 10857 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 913 loss: 1.30382 acc: 0.70182 | v_loss: 1.19526 v_acc: 0.71289 |  iteration: 10858 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 914 loss: 1.34059 acc: 0.70215 | v_loss: 1.13309 v_acc: 0.72526 |  iteration: 10859 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 915 loss: 1.31271 acc: 0.70247 | v_loss: 1.11027 v_acc: 0.70866 |  iteration: 10860 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 916 loss: 1.29284 acc: 0.69954 | v_loss: 1.25683 v_acc: 0.69954 |  iteration: 10861 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 917 loss: 1.32780 acc: 0.69629 | v_loss: 1.33702 v_acc: 0.69303 |  iteration: 10862 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 918 loss: 1.34528 acc: 0.69759 | v_loss: 1.14644 v_acc: 0.70573 |  iteration: 10863 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 919 loss: 1.21261 acc: 0.72624 | v_loss: 1.21463 v_acc: 0.69694 |  iteration: 10864 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 920 loss: 1.26233 acc: 0.71061 | v_loss: 1.17759 v_acc: 0.71061 |  iteration: 10865 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 921 loss: 1.32538 acc: 0.70182 | v_loss: 1.21753 v_acc: 0.70573 |  iteration: 10866 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 922 loss: 1.37066 acc: 0.69661 | v_loss: 1.10918 v_acc: 0.73405 |  iteration: 10867 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 923 loss: 1.22811 acc: 0.72201 | v_loss: 1.17718 v_acc: 0.71745 |  iteration: 10868 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 924 loss: 1.29491 acc: 0.70020 | v_loss: 1.15337 v_acc: 0.72754 |  iteration: 10869 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 925 loss: 1.26753 acc: 0.70345 | v_loss: 1.12208 v_acc: 0.72852 |  iteration: 10870 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 926 loss: 1.28940 acc: 0.70085 | v_loss: 1.19334 v_acc: 0.72038 |  iteration: 10871 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 927 loss: 1.22362 acc: 0.70898 | v_loss: 1.22989 v_acc: 0.71224 |  iteration: 10872 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 928 loss: 1.28536 acc: 0.71322 | v_loss: 1.19996 v_acc: 0.72428 |  iteration: 10873 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 929 loss: 1.19085 acc: 0.70736 | v_loss: 1.38194 v_acc: 0.70247 |  iteration: 10874 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 930 loss: 1.22921 acc: 0.70150 | v_loss: 1.26021 v_acc: 0.71940 |  iteration: 10875 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 931 loss: 1.37966 acc: 0.69531 | v_loss: 1.05328 v_acc: 0.74154 |  iteration: 10876 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 932 loss: 1.35439 acc: 0.68945 | v_loss: 1.19795 v_acc: 0.70931 |  iteration: 10877 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 933 loss: 1.26045 acc: 0.70475 | v_loss: 1.24807 v_acc: 0.70345 |  iteration: 10878 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 934 loss: 1.26851 acc: 0.71126 | v_loss: 1.17592 v_acc: 0.71517 |  iteration: 10879 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 935 loss: 1.33310 acc: 0.71615 | v_loss: 1.23954 v_acc: 0.71191 |  iteration: 10880 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 936 loss: 1.34884 acc: 0.71029 | v_loss: 1.25145 v_acc: 0.68978 |  iteration: 10881 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 937 loss: 1.26378 acc: 0.71419 | v_loss: 1.20293 v_acc: 0.70964 |  iteration: 10882 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 938 loss: 1.28428 acc: 0.70443 | v_loss: 1.23811 v_acc: 0.69954 |  iteration: 10883 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 939 loss: 1.30495 acc: 0.70736 | v_loss: 1.21629 v_acc: 0.70540 |  iteration: 10884 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 940 loss: 1.22506 acc: 0.71517 | v_loss: 1.18936 v_acc: 0.72331 |  iteration: 10885 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 941 loss: 1.31748 acc: 0.70475 | v_loss: 1.23577 v_acc: 0.70345 |  iteration: 10886 teacher: 1 stage: sketch lr: 0.000424\n",
      "batch 942 loss: 1.24489 acc: 0.70931 | v_loss: 1.31764 v_acc: 0.70020 |  iteration: 10887 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 943 loss: 1.30745 acc: 0.70312 | v_loss: 1.14424 v_acc: 0.70801 |  iteration: 10888 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 944 loss: 1.17971 acc: 0.70345 | v_loss: 1.39046 v_acc: 0.68652 |  iteration: 10889 teacher: 0 stage: sketch lr: 0.000424\n",
      "batch 945 loss: 1.20640 acc: 0.70736 | v_loss: 1.15808 v_acc: 0.72168 |  iteration: 10890 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 946 loss: 1.30509 acc: 0.69466 | v_loss: 1.47438 v_acc: 0.68034 |  iteration: 10891 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 947 loss: 1.33360 acc: 0.70378 | v_loss: 1.36037 v_acc: 0.69694 |  iteration: 10892 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 948 loss: 1.38998 acc: 0.69531 | v_loss: 1.31678 v_acc: 0.69401 |  iteration: 10893 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 949 loss: 1.26709 acc: 0.70410 | v_loss: 1.31762 v_acc: 0.70052 |  iteration: 10894 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 950 loss: 1.34894 acc: 0.69824 | v_loss: 1.20256 v_acc: 0.70801 |  iteration: 10895 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 951 loss: 1.18933 acc: 0.71322 | v_loss: 1.25475 v_acc: 0.70605 |  iteration: 10896 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 952 loss: 1.30079 acc: 0.70052 | v_loss: 1.21786 v_acc: 0.71680 |  iteration: 10897 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 953 loss: 1.30058 acc: 0.70638 | v_loss: 1.40116 v_acc: 0.68913 |  iteration: 10898 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 954 loss: 1.18078 acc: 0.72233 | v_loss: 1.29008 v_acc: 0.70410 |  iteration: 10899 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 955 loss: 1.26523 acc: 0.70052 | v_loss: 1.20907 v_acc: 0.70736 |  iteration: 10900 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 956 loss: 1.29371 acc: 0.70117 | v_loss: 1.26638 v_acc: 0.71322 |  iteration: 10901 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 957 loss: 1.35901 acc: 0.69336 | v_loss: 1.16235 v_acc: 0.70573 |  iteration: 10902 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 958 loss: 1.25698 acc: 0.71842 | v_loss: 1.28076 v_acc: 0.69759 |  iteration: 10903 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 959 loss: 1.24420 acc: 0.71322 | v_loss: 1.23036 v_acc: 0.71257 |  iteration: 10904 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 960 loss: 1.35294 acc: 0.70280 | v_loss: 1.16476 v_acc: 0.71908 |  iteration: 10905 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 961 loss: 1.32980 acc: 0.70020 | v_loss: 1.13280 v_acc: 0.72624 |  iteration: 10906 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 962 loss: 1.25746 acc: 0.70280 | v_loss: 1.25718 v_acc: 0.71810 |  iteration: 10907 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 963 loss: 1.31920 acc: 0.70345 | v_loss: 1.24182 v_acc: 0.70150 |  iteration: 10908 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 964 loss: 1.25070 acc: 0.71322 | v_loss: 1.24296 v_acc: 0.70931 |  iteration: 10909 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 965 loss: 1.39609 acc: 0.69531 | v_loss: 1.09295 v_acc: 0.72591 |  iteration: 10910 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 966 loss: 1.25009 acc: 0.71289 | v_loss: 1.24103 v_acc: 0.73145 |  iteration: 10911 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 967 loss: 1.34412 acc: 0.70150 | v_loss: 1.28406 v_acc: 0.69857 |  iteration: 10912 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 968 loss: 1.28035 acc: 0.70931 | v_loss: 1.29865 v_acc: 0.72103 |  iteration: 10913 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 969 loss: 1.38820 acc: 0.69010 | v_loss: 1.16421 v_acc: 0.71875 |  iteration: 10914 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 970 loss: 1.32471 acc: 0.69368 | v_loss: 1.12064 v_acc: 0.73535 |  iteration: 10915 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 971 loss: 1.32713 acc: 0.69596 | v_loss: 1.10183 v_acc: 0.72331 |  iteration: 10916 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 972 loss: 1.25172 acc: 0.70996 | v_loss: 1.19225 v_acc: 0.70866 |  iteration: 10917 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 973 loss: 1.27559 acc: 0.70638 | v_loss: 1.23340 v_acc: 0.69661 |  iteration: 10918 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 974 loss: 1.34794 acc: 0.69987 | v_loss: 1.19506 v_acc: 0.71322 |  iteration: 10919 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 975 loss: 1.35333 acc: 0.70117 | v_loss: 1.28712 v_acc: 0.71517 |  iteration: 10920 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 976 loss: 1.31205 acc: 0.70280 | v_loss: 1.46490 v_acc: 0.69401 |  iteration: 10921 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 977 loss: 1.25839 acc: 0.71582 | v_loss: 1.34627 v_acc: 0.69922 |  iteration: 10922 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 978 loss: 1.34448 acc: 0.69466 | v_loss: 1.19605 v_acc: 0.72103 |  iteration: 10923 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 979 loss: 1.27420 acc: 0.69792 | v_loss: 1.15901 v_acc: 0.70768 |  iteration: 10924 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 980 loss: 1.22538 acc: 0.71257 | v_loss: 1.14306 v_acc: 0.72331 |  iteration: 10925 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 981 loss: 1.22876 acc: 0.70573 | v_loss: 1.23213 v_acc: 0.70378 |  iteration: 10926 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 982 loss: 1.23463 acc: 0.71549 | v_loss: 1.24719 v_acc: 0.71810 |  iteration: 10927 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 983 loss: 1.38812 acc: 0.69889 | v_loss: 1.21235 v_acc: 0.73014 |  iteration: 10928 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 984 loss: 1.31772 acc: 0.70866 | v_loss: 1.23799 v_acc: 0.71973 |  iteration: 10929 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 985 loss: 1.26121 acc: 0.70508 | v_loss: 1.23251 v_acc: 0.71029 |  iteration: 10930 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 986 loss: 1.25281 acc: 0.71159 | v_loss: 1.15138 v_acc: 0.72493 |  iteration: 10931 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 987 loss: 1.26099 acc: 0.70801 | v_loss: 1.11258 v_acc: 0.72038 |  iteration: 10932 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 988 loss: 1.35811 acc: 0.69759 | v_loss: 1.43429 v_acc: 0.69271 |  iteration: 10933 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 989 loss: 1.23691 acc: 0.70866 | v_loss: 1.19407 v_acc: 0.71029 |  iteration: 10934 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 990 loss: 1.20456 acc: 0.72005 | v_loss: 1.22508 v_acc: 0.71615 |  iteration: 10935 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 991 loss: 1.29328 acc: 0.70573 | v_loss: 1.22575 v_acc: 0.71289 |  iteration: 10936 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 992 loss: 1.21610 acc: 0.70443 | v_loss: 1.26965 v_acc: 0.70638 |  iteration: 10937 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 993 loss: 1.23365 acc: 0.70866 | v_loss: 1.12826 v_acc: 0.73145 |  iteration: 10938 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 994 loss: 1.28590 acc: 0.70573 | v_loss: 1.35264 v_acc: 0.71484 |  iteration: 10939 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 995 loss: 1.22625 acc: 0.71647 | v_loss: 1.20360 v_acc: 0.69629 |  iteration: 10940 teacher: 0 stage: sketch lr: 0.000423\n",
      "batch 996 loss: 1.25209 acc: 0.70312 | v_loss: 1.20895 v_acc: 0.70215 |  iteration: 10941 teacher: 1 stage: sketch lr: 0.000423\n",
      "batch 997 loss: 1.26676 acc: 0.71257 | v_loss: 1.26606 v_acc: 0.70345 |  iteration: 10942 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 998 loss: 1.42314 acc: 0.68880 | v_loss: 1.26781 v_acc: 0.70605 |  iteration: 10943 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 999 loss: 1.27477 acc: 0.70215 | v_loss: 1.33912 v_acc: 0.69303 |  iteration: 10944 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1000 loss: 1.30225 acc: 0.70345 | v_loss: 1.36768 v_acc: 0.70117 |  iteration: 10945 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1001 loss: 1.26460 acc: 0.70540 | v_loss: 1.27753 v_acc: 0.70345 |  iteration: 10946 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1002 loss: 1.27003 acc: 0.69857 | v_loss: 1.18699 v_acc: 0.70833 |  iteration: 10947 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1003 loss: 1.23773 acc: 0.70671 | v_loss: 1.31924 v_acc: 0.70410 |  iteration: 10948 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1004 loss: 1.16970 acc: 0.72266 | v_loss: 1.21472 v_acc: 0.71159 |  iteration: 10949 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1005 loss: 1.24384 acc: 0.69531 | v_loss: 1.13133 v_acc: 0.72493 |  iteration: 10950 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1006 loss: 1.24587 acc: 0.70443 | v_loss: 1.11509 v_acc: 0.71615 |  iteration: 10951 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1007 loss: 1.26525 acc: 0.70312 | v_loss: 1.24083 v_acc: 0.71126 |  iteration: 10952 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1008 loss: 1.26435 acc: 0.70020 | v_loss: 1.32654 v_acc: 0.69857 |  iteration: 10953 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1009 loss: 1.27111 acc: 0.70605 | v_loss: 1.15883 v_acc: 0.71517 |  iteration: 10954 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1010 loss: 1.27923 acc: 0.70508 | v_loss: 1.17886 v_acc: 0.70312 |  iteration: 10955 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1011 loss: 1.35082 acc: 0.69629 | v_loss: 1.17725 v_acc: 0.71777 |  iteration: 10956 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1012 loss: 1.30140 acc: 0.70443 | v_loss: 1.19113 v_acc: 0.70801 |  iteration: 10957 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1013 loss: 1.29421 acc: 0.70182 | v_loss: 1.05899 v_acc: 0.73568 |  iteration: 10958 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1014 loss: 1.27983 acc: 0.70312 | v_loss: 1.16583 v_acc: 0.72331 |  iteration: 10959 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1015 loss: 1.31891 acc: 0.69531 | v_loss: 1.15036 v_acc: 0.70964 |  iteration: 10960 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1016 loss: 1.25718 acc: 0.70833 | v_loss: 1.12881 v_acc: 0.72331 |  iteration: 10961 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1017 loss: 1.26060 acc: 0.70378 | v_loss: 1.19636 v_acc: 0.71582 |  iteration: 10962 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1018 loss: 1.29136 acc: 0.69466 | v_loss: 1.21263 v_acc: 0.72005 |  iteration: 10963 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1019 loss: 1.38601 acc: 0.68913 | v_loss: 1.19889 v_acc: 0.72493 |  iteration: 10964 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1020 loss: 1.27394 acc: 0.70020 | v_loss: 1.40676 v_acc: 0.69596 |  iteration: 10965 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1021 loss: 1.27551 acc: 0.69629 | v_loss: 1.27633 v_acc: 0.72233 |  iteration: 10966 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1022 loss: 1.24639 acc: 0.70736 | v_loss: 1.05535 v_acc: 0.74707 |  iteration: 10967 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1023 loss: 1.29630 acc: 0.70443 | v_loss: 1.20884 v_acc: 0.70833 |  iteration: 10968 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1024 loss: 1.23733 acc: 0.70866 | v_loss: 1.26474 v_acc: 0.69727 |  iteration: 10969 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1025 loss: 1.31774 acc: 0.70247 | v_loss: 1.18080 v_acc: 0.70768 |  iteration: 10970 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1026 loss: 1.28415 acc: 0.70378 | v_loss: 1.25048 v_acc: 0.71224 |  iteration: 10971 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1027 loss: 1.33415 acc: 0.69629 | v_loss: 1.25366 v_acc: 0.69010 |  iteration: 10972 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1028 loss: 1.29078 acc: 0.69954 | v_loss: 1.19776 v_acc: 0.71777 |  iteration: 10973 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1029 loss: 1.35769 acc: 0.69206 | v_loss: 1.24670 v_acc: 0.70085 |  iteration: 10974 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1030 loss: 1.33375 acc: 0.69792 | v_loss: 1.20046 v_acc: 0.71712 |  iteration: 10975 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1031 loss: 1.22275 acc: 0.71875 | v_loss: 1.18207 v_acc: 0.72754 |  iteration: 10976 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1032 loss: 1.30563 acc: 0.70671 | v_loss: 1.23676 v_acc: 0.70378 |  iteration: 10977 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1033 loss: 1.25149 acc: 0.70866 | v_loss: 1.32829 v_acc: 0.69954 |  iteration: 10978 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1034 loss: 1.38068 acc: 0.69694 | v_loss: 1.15043 v_acc: 0.71029 |  iteration: 10979 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1035 loss: 1.24835 acc: 0.71745 | v_loss: 1.39173 v_acc: 0.68815 |  iteration: 10980 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1036 loss: 1.29689 acc: 0.70768 | v_loss: 1.15502 v_acc: 0.72201 |  iteration: 10981 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1037 loss: 1.34921 acc: 0.70117 | v_loss: 1.47210 v_acc: 0.68457 |  iteration: 10982 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1038 loss: 1.39376 acc: 0.69108 | v_loss: 1.36514 v_acc: 0.69271 |  iteration: 10983 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1039 loss: 1.30877 acc: 0.70508 | v_loss: 1.31786 v_acc: 0.69434 |  iteration: 10984 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1040 loss: 1.24586 acc: 0.71745 | v_loss: 1.31507 v_acc: 0.69466 |  iteration: 10985 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1041 loss: 1.35296 acc: 0.70410 | v_loss: 1.22354 v_acc: 0.70703 |  iteration: 10986 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1042 loss: 1.27416 acc: 0.70703 | v_loss: 1.26111 v_acc: 0.70540 |  iteration: 10987 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1043 loss: 1.34786 acc: 0.70247 | v_loss: 1.20930 v_acc: 0.72005 |  iteration: 10988 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1044 loss: 1.31692 acc: 0.70182 | v_loss: 1.40554 v_acc: 0.69173 |  iteration: 10989 teacher: 1 stage: sketch lr: 0.000422\n",
      "batch 1045 loss: 1.29722 acc: 0.70801 | v_loss: 1.29157 v_acc: 0.71126 |  iteration: 10990 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1046 loss: 1.26343 acc: 0.70540 | v_loss: 1.17609 v_acc: 0.71061 |  iteration: 10991 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1047 loss: 1.25896 acc: 0.70866 | v_loss: 1.25361 v_acc: 0.71452 |  iteration: 10992 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1048 loss: 1.23033 acc: 0.70703 | v_loss: 1.16595 v_acc: 0.70736 |  iteration: 10993 teacher: 0 stage: sketch lr: 0.000422\n",
      "batch 1049 loss: 1.24663 acc: 0.70736 | v_loss: 1.26385 v_acc: 0.70052 |  iteration: 10994 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1050 loss: 1.26041 acc: 0.71387 | v_loss: 1.22736 v_acc: 0.71191 |  iteration: 10995 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1051 loss: 1.33850 acc: 0.69629 | v_loss: 1.15698 v_acc: 0.71973 |  iteration: 10996 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1052 loss: 1.25310 acc: 0.70150 | v_loss: 1.13504 v_acc: 0.72331 |  iteration: 10997 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1053 loss: 1.26572 acc: 0.70475 | v_loss: 1.26649 v_acc: 0.71647 |  iteration: 10998 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1054 loss: 1.28486 acc: 0.70475 | v_loss: 1.24896 v_acc: 0.70150 |  iteration: 10999 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1055 loss: 1.25050 acc: 0.69824 | v_loss: 1.24651 v_acc: 0.71061 |  iteration: 11000 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1056 loss: 1.28176 acc: 0.70573 | v_loss: 1.09563 v_acc: 0.72526 |  iteration: 11001 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1057 loss: 1.40430 acc: 0.70052 | v_loss: 1.24071 v_acc: 0.72949 |  iteration: 11002 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1058 loss: 1.22889 acc: 0.70671 | v_loss: 1.29874 v_acc: 0.69661 |  iteration: 11003 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1059 loss: 1.26374 acc: 0.70280 | v_loss: 1.30327 v_acc: 0.72135 |  iteration: 11004 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1060 loss: 1.31028 acc: 0.70020 | v_loss: 1.14956 v_acc: 0.72266 |  iteration: 11005 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1061 loss: 1.25701 acc: 0.71126 | v_loss: 1.09841 v_acc: 0.73503 |  iteration: 11006 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1062 loss: 1.25785 acc: 0.71484 | v_loss: 1.10091 v_acc: 0.72721 |  iteration: 11007 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1063 loss: 1.27240 acc: 0.71029 | v_loss: 1.18381 v_acc: 0.70833 |  iteration: 11008 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1064 loss: 1.26901 acc: 0.71224 | v_loss: 1.22291 v_acc: 0.69629 |  iteration: 11009 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1065 loss: 1.29272 acc: 0.70312 | v_loss: 1.19770 v_acc: 0.71387 |  iteration: 11010 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1066 loss: 1.28243 acc: 0.71191 | v_loss: 1.30438 v_acc: 0.71647 |  iteration: 11011 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1067 loss: 1.29553 acc: 0.71094 | v_loss: 1.46101 v_acc: 0.69206 |  iteration: 11012 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1068 loss: 1.30761 acc: 0.70378 | v_loss: 1.34431 v_acc: 0.69922 |  iteration: 11013 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1069 loss: 1.33907 acc: 0.70768 | v_loss: 1.19648 v_acc: 0.71875 |  iteration: 11014 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1070 loss: 1.35102 acc: 0.69922 | v_loss: 1.16052 v_acc: 0.70605 |  iteration: 11015 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1071 loss: 1.29895 acc: 0.70410 | v_loss: 1.15069 v_acc: 0.72363 |  iteration: 11016 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1072 loss: 1.24082 acc: 0.70573 | v_loss: 1.23446 v_acc: 0.70540 |  iteration: 11017 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1073 loss: 1.33476 acc: 0.70312 | v_loss: 1.23395 v_acc: 0.71419 |  iteration: 11018 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1074 loss: 1.23941 acc: 0.70703 | v_loss: 1.20178 v_acc: 0.72689 |  iteration: 11019 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1075 loss: 1.35973 acc: 0.69889 | v_loss: 1.23352 v_acc: 0.71842 |  iteration: 11020 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1076 loss: 1.32966 acc: 0.70508 | v_loss: 1.23082 v_acc: 0.71322 |  iteration: 11021 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1077 loss: 1.27051 acc: 0.70866 | v_loss: 1.15488 v_acc: 0.72493 |  iteration: 11022 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1078 loss: 1.29930 acc: 0.70443 | v_loss: 1.11419 v_acc: 0.72038 |  iteration: 11023 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1079 loss: 1.36200 acc: 0.69792 | v_loss: 1.45723 v_acc: 0.69368 |  iteration: 11024 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1080 loss: 1.27369 acc: 0.70117 | v_loss: 1.19917 v_acc: 0.71159 |  iteration: 11025 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1081 loss: 1.36114 acc: 0.68880 | v_loss: 1.23128 v_acc: 0.71549 |  iteration: 11026 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1082 loss: 1.31468 acc: 0.70801 | v_loss: 1.21763 v_acc: 0.71810 |  iteration: 11027 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1083 loss: 1.26928 acc: 0.70247 | v_loss: 1.26653 v_acc: 0.70768 |  iteration: 11028 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1084 loss: 1.33762 acc: 0.70671 | v_loss: 1.14002 v_acc: 0.73210 |  iteration: 11029 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1085 loss: 1.34334 acc: 0.69401 | v_loss: 1.35319 v_acc: 0.71452 |  iteration: 11030 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1086 loss: 1.31362 acc: 0.70150 | v_loss: 1.20452 v_acc: 0.69661 |  iteration: 11031 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1087 loss: 1.26601 acc: 0.71159 | v_loss: 1.21138 v_acc: 0.70280 |  iteration: 11032 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1088 loss: 1.29890 acc: 0.69564 | v_loss: 1.26501 v_acc: 0.70312 |  iteration: 11033 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1089 loss: 1.31336 acc: 0.70182 | v_loss: 1.26361 v_acc: 0.70573 |  iteration: 11034 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1090 loss: 1.34309 acc: 0.70020 | v_loss: 1.32321 v_acc: 0.69010 |  iteration: 11035 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1091 loss: 1.29642 acc: 0.70280 | v_loss: 1.35811 v_acc: 0.70573 |  iteration: 11036 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1092 loss: 1.23279 acc: 0.71810 | v_loss: 1.27393 v_acc: 0.70475 |  iteration: 11037 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1093 loss: 1.29247 acc: 0.69954 | v_loss: 1.17862 v_acc: 0.71257 |  iteration: 11038 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1094 loss: 1.22702 acc: 0.70410 | v_loss: 1.33788 v_acc: 0.70345 |  iteration: 11039 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1095 loss: 1.25461 acc: 0.70866 | v_loss: 1.22939 v_acc: 0.71484 |  iteration: 11040 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1096 loss: 1.23985 acc: 0.70475 | v_loss: 1.12766 v_acc: 0.72624 |  iteration: 11041 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1097 loss: 1.33254 acc: 0.70247 | v_loss: 1.12396 v_acc: 0.70931 |  iteration: 11042 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1098 loss: 1.39801 acc: 0.70378 | v_loss: 1.24852 v_acc: 0.70443 |  iteration: 11043 teacher: 0 stage: sketch lr: 0.000421\n",
      "batch 1099 loss: 1.23248 acc: 0.71224 | v_loss: 1.33222 v_acc: 0.69661 |  iteration: 11044 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1100 loss: 1.31311 acc: 0.69368 | v_loss: 1.18245 v_acc: 0.70508 |  iteration: 11045 teacher: 1 stage: sketch lr: 0.000421\n",
      "batch 1101 loss: 1.25913 acc: 0.70638 | v_loss: 1.20434 v_acc: 0.69629 |  iteration: 11046 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1102 loss: 1.33069 acc: 0.70540 | v_loss: 1.18483 v_acc: 0.70833 |  iteration: 11047 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1103 loss: 1.21980 acc: 0.70736 | v_loss: 1.18524 v_acc: 0.70508 |  iteration: 11048 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1104 loss: 1.34926 acc: 0.70215 | v_loss: 1.06968 v_acc: 0.73438 |  iteration: 11049 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1105 loss: 1.32818 acc: 0.70703 | v_loss: 1.17222 v_acc: 0.72070 |  iteration: 11050 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1106 loss: 1.35242 acc: 0.69792 | v_loss: 1.15619 v_acc: 0.72656 |  iteration: 11051 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1107 loss: 1.28169 acc: 0.70605 | v_loss: 1.12094 v_acc: 0.72461 |  iteration: 11052 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1108 loss: 1.24705 acc: 0.70182 | v_loss: 1.19174 v_acc: 0.72135 |  iteration: 11053 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1109 loss: 1.29088 acc: 0.70508 | v_loss: 1.20576 v_acc: 0.71680 |  iteration: 11054 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1110 loss: 1.32897 acc: 0.70964 | v_loss: 1.18323 v_acc: 0.72852 |  iteration: 11055 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1111 loss: 1.25585 acc: 0.70573 | v_loss: 1.39081 v_acc: 0.70247 |  iteration: 11056 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1112 loss: 1.32610 acc: 0.69727 | v_loss: 1.25794 v_acc: 0.72070 |  iteration: 11057 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1113 loss: 1.23065 acc: 0.71875 | v_loss: 1.05870 v_acc: 0.74089 |  iteration: 11058 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1114 loss: 1.35018 acc: 0.70117 | v_loss: 1.25375 v_acc: 0.70443 |  iteration: 11059 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1115 loss: 1.28777 acc: 0.71257 | v_loss: 1.23986 v_acc: 0.70150 |  iteration: 11060 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1116 loss: 1.32784 acc: 0.69661 | v_loss: 1.20698 v_acc: 0.70866 |  iteration: 11061 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1117 loss: 1.25220 acc: 0.70736 | v_loss: 1.24302 v_acc: 0.71159 |  iteration: 11062 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1118 loss: 1.38027 acc: 0.69596 | v_loss: 1.24447 v_acc: 0.69010 |  iteration: 11063 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1119 loss: 1.25233 acc: 0.70736 | v_loss: 1.19526 v_acc: 0.71126 |  iteration: 11064 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1120 loss: 1.25357 acc: 0.70247 | v_loss: 1.24710 v_acc: 0.69531 |  iteration: 11065 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1121 loss: 1.24653 acc: 0.70736 | v_loss: 1.21029 v_acc: 0.70866 |  iteration: 11066 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1122 loss: 1.21587 acc: 0.71387 | v_loss: 1.18994 v_acc: 0.72331 |  iteration: 11067 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1123 loss: 1.30174 acc: 0.70280 | v_loss: 1.24604 v_acc: 0.70312 |  iteration: 11068 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1124 loss: 1.28914 acc: 0.70020 | v_loss: 1.31839 v_acc: 0.69857 |  iteration: 11069 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1125 loss: 1.36121 acc: 0.69661 | v_loss: 1.14445 v_acc: 0.70866 |  iteration: 11070 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1126 loss: 1.33410 acc: 0.69434 | v_loss: 1.40868 v_acc: 0.68522 |  iteration: 11071 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1127 loss: 1.25657 acc: 0.71322 | v_loss: 1.14682 v_acc: 0.72168 |  iteration: 11072 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1128 loss: 1.25532 acc: 0.70573 | v_loss: 1.45768 v_acc: 0.68197 |  iteration: 11073 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1129 loss: 1.29108 acc: 0.71029 | v_loss: 1.36285 v_acc: 0.69694 |  iteration: 11074 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1130 loss: 1.29000 acc: 0.70931 | v_loss: 1.32233 v_acc: 0.69206 |  iteration: 11075 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1131 loss: 1.34194 acc: 0.70410 | v_loss: 1.30837 v_acc: 0.69922 |  iteration: 11076 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1132 loss: 1.32178 acc: 0.70182 | v_loss: 1.21921 v_acc: 0.70833 |  iteration: 11077 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1133 loss: 1.38058 acc: 0.70638 | v_loss: 1.26245 v_acc: 0.70768 |  iteration: 11078 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1134 loss: 1.33396 acc: 0.70085 | v_loss: 1.21585 v_acc: 0.71940 |  iteration: 11079 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1135 loss: 1.22919 acc: 0.70540 | v_loss: 1.41007 v_acc: 0.69010 |  iteration: 11080 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1136 loss: 1.25817 acc: 0.69531 | v_loss: 1.27954 v_acc: 0.71322 |  iteration: 11081 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1137 loss: 1.40205 acc: 0.69857 | v_loss: 1.19029 v_acc: 0.70801 |  iteration: 11082 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1138 loss: 1.24202 acc: 0.70085 | v_loss: 1.25701 v_acc: 0.71322 |  iteration: 11083 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1139 loss: 1.28191 acc: 0.71322 | v_loss: 1.15823 v_acc: 0.70768 |  iteration: 11084 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1140 loss: 1.29487 acc: 0.70443 | v_loss: 1.25572 v_acc: 0.70020 |  iteration: 11085 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1141 loss: 1.24214 acc: 0.71484 | v_loss: 1.22264 v_acc: 0.71322 |  iteration: 11086 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1142 loss: 1.28246 acc: 0.70443 | v_loss: 1.16200 v_acc: 0.71973 |  iteration: 11087 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1143 loss: 1.33028 acc: 0.71191 | v_loss: 1.12560 v_acc: 0.72591 |  iteration: 11088 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1144 loss: 1.17871 acc: 0.71159 | v_loss: 1.24813 v_acc: 0.72266 |  iteration: 11089 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1145 loss: 1.36111 acc: 0.70020 | v_loss: 1.23977 v_acc: 0.70410 |  iteration: 11090 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1146 loss: 1.30047 acc: 0.70052 | v_loss: 1.24001 v_acc: 0.70898 |  iteration: 11091 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1147 loss: 1.32659 acc: 0.70247 | v_loss: 1.09816 v_acc: 0.72396 |  iteration: 11092 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1148 loss: 1.31031 acc: 0.71029 | v_loss: 1.24234 v_acc: 0.73242 |  iteration: 11093 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1149 loss: 1.26334 acc: 0.70703 | v_loss: 1.29092 v_acc: 0.70020 |  iteration: 11094 teacher: 1 stage: sketch lr: 0.000420\n",
      "batch 1150 loss: 1.28966 acc: 0.69531 | v_loss: 1.29912 v_acc: 0.72526 |  iteration: 11095 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1151 loss: 1.27719 acc: 0.69922 | v_loss: 1.15635 v_acc: 0.71908 |  iteration: 11096 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1152 loss: 1.18695 acc: 0.71745 | v_loss: 1.11464 v_acc: 0.73112 |  iteration: 11097 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1153 loss: 1.24304 acc: 0.70508 | v_loss: 1.10337 v_acc: 0.72656 |  iteration: 11098 teacher: 0 stage: sketch lr: 0.000420\n",
      "batch 1154 loss: 1.22116 acc: 0.70312 | v_loss: 1.18831 v_acc: 0.70833 |  iteration: 11099 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1155 loss: 1.21133 acc: 0.71257 | v_loss: 1.22098 v_acc: 0.69727 |  iteration: 11100 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1156 loss: 1.25844 acc: 0.70671 | v_loss: 1.18873 v_acc: 0.71549 |  iteration: 11101 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1157 loss: 1.26876 acc: 0.71354 | v_loss: 1.32254 v_acc: 0.70475 |  iteration: 11102 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1158 loss: 1.32889 acc: 0.69922 | v_loss: 1.47637 v_acc: 0.69108 |  iteration: 11103 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1159 loss: 1.27032 acc: 0.71126 | v_loss: 1.33937 v_acc: 0.69564 |  iteration: 11104 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1160 loss: 1.20970 acc: 0.71094 | v_loss: 1.18890 v_acc: 0.72168 |  iteration: 11105 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1161 loss: 1.26856 acc: 0.69889 | v_loss: 1.14517 v_acc: 0.70931 |  iteration: 11106 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1162 loss: 1.32551 acc: 0.70247 | v_loss: 1.14146 v_acc: 0.72396 |  iteration: 11107 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1163 loss: 1.16479 acc: 0.72005 | v_loss: 1.23007 v_acc: 0.70443 |  iteration: 11108 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1164 loss: 1.29035 acc: 0.69206 | v_loss: 1.24170 v_acc: 0.71257 |  iteration: 11109 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1165 loss: 1.30301 acc: 0.70605 | v_loss: 1.21126 v_acc: 0.72852 |  iteration: 11110 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1166 loss: 1.29930 acc: 0.69922 | v_loss: 1.24290 v_acc: 0.71745 |  iteration: 11111 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1167 loss: 1.25321 acc: 0.70150 | v_loss: 1.23323 v_acc: 0.70866 |  iteration: 11112 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1168 loss: 1.25171 acc: 0.70671 | v_loss: 1.16054 v_acc: 0.72135 |  iteration: 11113 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1169 loss: 1.31883 acc: 0.70736 | v_loss: 1.11478 v_acc: 0.71875 |  iteration: 11114 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1170 loss: 1.31100 acc: 0.69889 | v_loss: 1.45774 v_acc: 0.69303 |  iteration: 11115 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1171 loss: 1.30848 acc: 0.70443 | v_loss: 1.18534 v_acc: 0.71061 |  iteration: 11116 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1172 loss: 1.24592 acc: 0.70703 | v_loss: 1.23242 v_acc: 0.71875 |  iteration: 11117 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1173 loss: 1.26713 acc: 0.70020 | v_loss: 1.23201 v_acc: 0.71452 |  iteration: 11118 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1174 loss: 1.27278 acc: 0.70020 | v_loss: 1.27947 v_acc: 0.70703 |  iteration: 11119 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1175 loss: 1.38558 acc: 0.69271 | v_loss: 1.12655 v_acc: 0.73079 |  iteration: 11120 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1176 loss: 1.34401 acc: 0.69629 | v_loss: 1.34723 v_acc: 0.71517 |  iteration: 11121 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1177 loss: 1.29726 acc: 0.70378 | v_loss: 1.21018 v_acc: 0.69564 |  iteration: 11122 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1178 loss: 1.31201 acc: 0.70736 | v_loss: 1.21334 v_acc: 0.69987 |  iteration: 11123 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1179 loss: 1.30061 acc: 0.71159 | v_loss: 1.26261 v_acc: 0.70312 |  iteration: 11124 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1180 loss: 1.31490 acc: 0.70052 | v_loss: 1.26723 v_acc: 0.70605 |  iteration: 11125 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1181 loss: 1.22341 acc: 0.71517 | v_loss: 1.34106 v_acc: 0.69238 |  iteration: 11126 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1182 loss: 1.31463 acc: 0.70443 | v_loss: 1.35146 v_acc: 0.70443 |  iteration: 11127 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1183 loss: 1.27730 acc: 0.70312 | v_loss: 1.27775 v_acc: 0.70671 |  iteration: 11128 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1184 loss: 1.31752 acc: 0.70378 | v_loss: 1.20729 v_acc: 0.70671 |  iteration: 11129 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1185 loss: 1.26425 acc: 0.71354 | v_loss: 1.29542 v_acc: 0.70898 |  iteration: 11130 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1186 loss: 1.31225 acc: 0.69889 | v_loss: 1.20311 v_acc: 0.71191 |  iteration: 11131 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1187 loss: 1.20262 acc: 0.71061 | v_loss: 1.13946 v_acc: 0.72331 |  iteration: 11132 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1188 loss: 1.24398 acc: 0.70182 | v_loss: 1.13027 v_acc: 0.70898 |  iteration: 11133 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1189 loss: 1.28940 acc: 0.70215 | v_loss: 1.25059 v_acc: 0.70898 |  iteration: 11134 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1190 loss: 1.35747 acc: 0.69434 | v_loss: 1.32867 v_acc: 0.69889 |  iteration: 11135 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1191 loss: 1.19016 acc: 0.71191 | v_loss: 1.15302 v_acc: 0.71387 |  iteration: 11136 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1192 loss: 1.18568 acc: 0.70898 | v_loss: 1.17653 v_acc: 0.70475 |  iteration: 11137 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1193 loss: 1.27583 acc: 0.70150 | v_loss: 1.18395 v_acc: 0.71452 |  iteration: 11138 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1194 loss: 1.34315 acc: 0.69857 | v_loss: 1.21219 v_acc: 0.70410 |  iteration: 11139 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1195 loss: 1.33736 acc: 0.70052 | v_loss: 1.04748 v_acc: 0.74121 |  iteration: 11140 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1196 loss: 1.36482 acc: 0.69336 | v_loss: 1.17507 v_acc: 0.71810 |  iteration: 11141 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1197 loss: 1.22613 acc: 0.70540 | v_loss: 1.12452 v_acc: 0.72624 |  iteration: 11142 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1198 loss: 1.30553 acc: 0.70573 | v_loss: 1.12663 v_acc: 0.72168 |  iteration: 11143 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1199 loss: 1.21391 acc: 0.71224 | v_loss: 1.20132 v_acc: 0.71842 |  iteration: 11144 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1200 loss: 1.35504 acc: 0.69271 | v_loss: 1.22042 v_acc: 0.71940 |  iteration: 11145 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1201 loss: 1.26497 acc: 0.70638 | v_loss: 1.20824 v_acc: 0.72168 |  iteration: 11146 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1202 loss: 1.27947 acc: 0.69954 | v_loss: 1.38790 v_acc: 0.70215 |  iteration: 11147 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1203 loss: 1.31134 acc: 0.69694 | v_loss: 1.26043 v_acc: 0.71777 |  iteration: 11148 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1204 loss: 1.20656 acc: 0.71712 | v_loss: 1.04925 v_acc: 0.74512 |  iteration: 11149 teacher: 0 stage: sketch lr: 0.000419\n",
      "batch 1205 loss: 1.33347 acc: 0.71061 | v_loss: 1.20803 v_acc: 0.70508 |  iteration: 11150 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1206 loss: 1.30840 acc: 0.70540 | v_loss: 1.25880 v_acc: 0.70247 |  iteration: 11151 teacher: 1 stage: sketch lr: 0.000419\n",
      "batch 1207 loss: 1.26526 acc: 0.70996 | v_loss: 1.18869 v_acc: 0.70898 |  iteration: 11152 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1208 loss: 1.30974 acc: 0.70150 | v_loss: 1.23926 v_acc: 0.71387 |  iteration: 11153 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1209 loss: 1.30689 acc: 0.70378 | v_loss: 1.23542 v_acc: 0.69564 |  iteration: 11154 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1210 loss: 1.25066 acc: 0.70898 | v_loss: 1.20162 v_acc: 0.71647 |  iteration: 11155 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1211 loss: 1.27956 acc: 0.70866 | v_loss: 1.24707 v_acc: 0.69954 |  iteration: 11156 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1212 loss: 1.35551 acc: 0.69466 | v_loss: 1.16469 v_acc: 0.72461 |  iteration: 11157 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1213 loss: 1.27620 acc: 0.70020 | v_loss: 1.16012 v_acc: 0.72428 |  iteration: 11158 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1214 loss: 1.32509 acc: 0.70085 | v_loss: 1.21023 v_acc: 0.70443 |  iteration: 11159 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1215 loss: 1.27757 acc: 0.70964 | v_loss: 1.37013 v_acc: 0.69271 |  iteration: 11160 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1216 loss: 1.31113 acc: 0.69792 | v_loss: 1.16346 v_acc: 0.70866 |  iteration: 11161 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1217 loss: 1.27968 acc: 0.71126 | v_loss: 1.42415 v_acc: 0.68066 |  iteration: 11162 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1218 loss: 1.23547 acc: 0.70898 | v_loss: 1.15335 v_acc: 0.72852 |  iteration: 11163 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1219 loss: 1.31961 acc: 0.70638 | v_loss: 1.47422 v_acc: 0.68555 |  iteration: 11164 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1220 loss: 1.24521 acc: 0.70898 | v_loss: 1.35951 v_acc: 0.69857 |  iteration: 11165 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1221 loss: 1.22683 acc: 0.70312 | v_loss: 1.31718 v_acc: 0.69336 |  iteration: 11166 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1222 loss: 1.31163 acc: 0.69824 | v_loss: 1.30499 v_acc: 0.69824 |  iteration: 11167 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1223 loss: 1.37598 acc: 0.69499 | v_loss: 1.21775 v_acc: 0.70378 |  iteration: 11168 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1224 loss: 1.31611 acc: 0.70247 | v_loss: 1.26242 v_acc: 0.70215 |  iteration: 11169 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1225 loss: 1.20912 acc: 0.70996 | v_loss: 1.19540 v_acc: 0.71745 |  iteration: 11170 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1226 loss: 1.26849 acc: 0.70638 | v_loss: 1.40508 v_acc: 0.68978 |  iteration: 11171 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1227 loss: 1.23317 acc: 0.71191 | v_loss: 1.27620 v_acc: 0.70931 |  iteration: 11172 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1228 loss: 1.33070 acc: 0.70378 | v_loss: 1.20267 v_acc: 0.71029 |  iteration: 11173 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1229 loss: 1.38177 acc: 0.70280 | v_loss: 1.25800 v_acc: 0.71582 |  iteration: 11174 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1230 loss: 1.25711 acc: 0.70768 | v_loss: 1.15597 v_acc: 0.70768 |  iteration: 11175 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1231 loss: 1.31051 acc: 0.71549 | v_loss: 1.26290 v_acc: 0.69564 |  iteration: 11176 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1232 loss: 1.32354 acc: 0.70736 | v_loss: 1.23518 v_acc: 0.71419 |  iteration: 11177 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1233 loss: 1.38894 acc: 0.69434 | v_loss: 1.17501 v_acc: 0.71777 |  iteration: 11178 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1234 loss: 1.28939 acc: 0.71159 | v_loss: 1.15037 v_acc: 0.72493 |  iteration: 11179 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1235 loss: 1.35690 acc: 0.69076 | v_loss: 1.25288 v_acc: 0.71549 |  iteration: 11180 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1236 loss: 1.49599 acc: 0.68880 | v_loss: 1.25670 v_acc: 0.70215 |  iteration: 11181 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1237 loss: 1.38805 acc: 0.69759 | v_loss: 1.25843 v_acc: 0.70964 |  iteration: 11182 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1238 loss: 1.29948 acc: 0.70768 | v_loss: 1.10935 v_acc: 0.72103 |  iteration: 11183 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1239 loss: 1.36419 acc: 0.70215 | v_loss: 1.23845 v_acc: 0.73047 |  iteration: 11184 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1240 loss: 1.24022 acc: 0.71517 | v_loss: 1.29454 v_acc: 0.69922 |  iteration: 11185 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 1241 loss: 1.29773 acc: 0.70182 | v_loss: 1.29127 v_acc: 0.72135 |  iteration: 11186 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1242 loss: 1.32114 acc: 0.70312 | v_loss: 1.16867 v_acc: 0.72461 |  iteration: 11187 teacher: 1 stage: sketch lr: 0.000418\n",
      "epoch 8 loss: 1.29018 acc: 0.70440 | v_loss: 1.23202 v_acc: 0.71053 \n",
      "epoch: 9\n",
      "__________________________________________\n",
      "batch 0 loss: 1.37022 acc: 0.70117 | v_loss: 1.28357 v_acc: 0.70475 |  iteration: 11188 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 1 loss: 1.38972 acc: 0.69954 | v_loss: 1.18192 v_acc: 0.70605 |  iteration: 11189 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 2 loss: 1.38783 acc: 0.70475 | v_loss: 1.33511 v_acc: 0.70540 |  iteration: 11190 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 3 loss: 1.39410 acc: 0.69401 | v_loss: 1.24262 v_acc: 0.71191 |  iteration: 11191 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 4 loss: 1.25279 acc: 0.71745 | v_loss: 1.12895 v_acc: 0.72917 |  iteration: 11192 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 5 loss: 1.31221 acc: 0.70475 | v_loss: 1.16498 v_acc: 0.70736 |  iteration: 11193 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 6 loss: 1.25311 acc: 0.71224 | v_loss: 1.25821 v_acc: 0.70312 |  iteration: 11194 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 7 loss: 1.34120 acc: 0.69368 | v_loss: 1.31425 v_acc: 0.69792 |  iteration: 11195 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 8 loss: 1.20037 acc: 0.71973 | v_loss: 1.16673 v_acc: 0.70768 |  iteration: 11196 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 9 loss: 1.25014 acc: 0.70573 | v_loss: 1.18672 v_acc: 0.69694 |  iteration: 11197 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 10 loss: 1.33520 acc: 0.69792 | v_loss: 1.19025 v_acc: 0.71094 |  iteration: 11198 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 11 loss: 1.31155 acc: 0.71029 | v_loss: 1.20078 v_acc: 0.70312 |  iteration: 11199 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 12 loss: 1.30928 acc: 0.71452 | v_loss: 1.06187 v_acc: 0.73503 |  iteration: 11200 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 13 loss: 1.21194 acc: 0.71484 | v_loss: 1.17359 v_acc: 0.71712 |  iteration: 11201 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 14 loss: 1.28851 acc: 0.70801 | v_loss: 1.13238 v_acc: 0.73470 |  iteration: 11202 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 15 loss: 1.34110 acc: 0.70540 | v_loss: 1.11871 v_acc: 0.72266 |  iteration: 11203 teacher: 0 stage: sketch lr: 0.000418\n",
      "batch 16 loss: 1.27291 acc: 0.70736 | v_loss: 1.19525 v_acc: 0.71940 |  iteration: 11204 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 17 loss: 1.26693 acc: 0.71029 | v_loss: 1.21664 v_acc: 0.71322 |  iteration: 11205 teacher: 1 stage: sketch lr: 0.000418\n",
      "batch 18 loss: 1.17864 acc: 0.71973 | v_loss: 1.19213 v_acc: 0.71940 |  iteration: 11206 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 19 loss: 1.25893 acc: 0.70736 | v_loss: 1.39438 v_acc: 0.69824 |  iteration: 11207 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 20 loss: 1.25486 acc: 0.70410 | v_loss: 1.25579 v_acc: 0.71908 |  iteration: 11208 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 21 loss: 1.29982 acc: 0.69824 | v_loss: 1.04839 v_acc: 0.74219 |  iteration: 11209 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 22 loss: 1.35176 acc: 0.70247 | v_loss: 1.20416 v_acc: 0.70736 |  iteration: 11210 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 23 loss: 1.31036 acc: 0.70150 | v_loss: 1.25926 v_acc: 0.70020 |  iteration: 11211 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 24 loss: 1.23887 acc: 0.70280 | v_loss: 1.18466 v_acc: 0.70605 |  iteration: 11212 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 25 loss: 1.29622 acc: 0.70833 | v_loss: 1.25306 v_acc: 0.71647 |  iteration: 11213 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 26 loss: 1.21218 acc: 0.71419 | v_loss: 1.25000 v_acc: 0.69076 |  iteration: 11214 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 27 loss: 1.20996 acc: 0.70996 | v_loss: 1.20204 v_acc: 0.71322 |  iteration: 11215 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 28 loss: 1.23783 acc: 0.70150 | v_loss: 1.24313 v_acc: 0.70150 |  iteration: 11216 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 29 loss: 1.22631 acc: 0.71029 | v_loss: 1.19208 v_acc: 0.71322 |  iteration: 11217 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 30 loss: 1.27457 acc: 0.69889 | v_loss: 1.17829 v_acc: 0.72559 |  iteration: 11218 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 31 loss: 1.31037 acc: 0.70280 | v_loss: 1.25485 v_acc: 0.70312 |  iteration: 11219 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 32 loss: 1.28940 acc: 0.70410 | v_loss: 1.32758 v_acc: 0.69889 |  iteration: 11220 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 33 loss: 1.28730 acc: 0.70215 | v_loss: 1.15096 v_acc: 0.70801 |  iteration: 11221 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 34 loss: 1.24813 acc: 0.70898 | v_loss: 1.40787 v_acc: 0.68522 |  iteration: 11222 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 35 loss: 1.44488 acc: 0.69661 | v_loss: 1.15894 v_acc: 0.72038 |  iteration: 11223 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 36 loss: 1.27479 acc: 0.70215 | v_loss: 1.47328 v_acc: 0.67904 |  iteration: 11224 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 37 loss: 1.29715 acc: 0.70898 | v_loss: 1.35740 v_acc: 0.69499 |  iteration: 11225 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 38 loss: 1.25407 acc: 0.70573 | v_loss: 1.32538 v_acc: 0.69434 |  iteration: 11226 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 39 loss: 1.27032 acc: 0.70671 | v_loss: 1.31253 v_acc: 0.69466 |  iteration: 11227 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 40 loss: 1.24829 acc: 0.70410 | v_loss: 1.22156 v_acc: 0.70671 |  iteration: 11228 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 41 loss: 1.29473 acc: 0.70736 | v_loss: 1.27318 v_acc: 0.70020 |  iteration: 11229 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 42 loss: 1.35093 acc: 0.69336 | v_loss: 1.21806 v_acc: 0.71452 |  iteration: 11230 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 43 loss: 1.32953 acc: 0.69629 | v_loss: 1.40686 v_acc: 0.68880 |  iteration: 11231 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 44 loss: 1.27797 acc: 0.69792 | v_loss: 1.29834 v_acc: 0.70573 |  iteration: 11232 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 45 loss: 1.26853 acc: 0.69824 | v_loss: 1.17692 v_acc: 0.70964 |  iteration: 11233 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 46 loss: 1.30716 acc: 0.70801 | v_loss: 1.24605 v_acc: 0.71680 |  iteration: 11234 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 47 loss: 1.34249 acc: 0.69238 | v_loss: 1.15907 v_acc: 0.70931 |  iteration: 11235 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 48 loss: 1.29816 acc: 0.70573 | v_loss: 1.26474 v_acc: 0.70150 |  iteration: 11236 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 49 loss: 1.21736 acc: 0.70540 | v_loss: 1.22957 v_acc: 0.71582 |  iteration: 11237 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 50 loss: 1.24825 acc: 0.69531 | v_loss: 1.15443 v_acc: 0.72103 |  iteration: 11238 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 51 loss: 1.25409 acc: 0.71094 | v_loss: 1.12861 v_acc: 0.72591 |  iteration: 11239 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 52 loss: 1.32762 acc: 0.70833 | v_loss: 1.25371 v_acc: 0.72266 |  iteration: 11240 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 53 loss: 1.28426 acc: 0.70703 | v_loss: 1.24818 v_acc: 0.70443 |  iteration: 11241 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 54 loss: 1.22894 acc: 0.70312 | v_loss: 1.26690 v_acc: 0.70768 |  iteration: 11242 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 55 loss: 1.32264 acc: 0.69824 | v_loss: 1.09825 v_acc: 0.72493 |  iteration: 11243 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 56 loss: 1.23336 acc: 0.70443 | v_loss: 1.25328 v_acc: 0.73112 |  iteration: 11244 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 57 loss: 1.25144 acc: 0.70573 | v_loss: 1.30381 v_acc: 0.69531 |  iteration: 11245 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 58 loss: 1.28344 acc: 0.70964 | v_loss: 1.31309 v_acc: 0.72233 |  iteration: 11246 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 59 loss: 1.29928 acc: 0.70117 | v_loss: 1.14911 v_acc: 0.72266 |  iteration: 11247 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 60 loss: 1.25208 acc: 0.71224 | v_loss: 1.09886 v_acc: 0.73763 |  iteration: 11248 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 61 loss: 1.34993 acc: 0.69076 | v_loss: 1.10450 v_acc: 0.72363 |  iteration: 11249 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 62 loss: 1.23201 acc: 0.71322 | v_loss: 1.18096 v_acc: 0.70833 |  iteration: 11250 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 63 loss: 1.25593 acc: 0.70736 | v_loss: 1.22807 v_acc: 0.69857 |  iteration: 11251 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 64 loss: 1.32481 acc: 0.70052 | v_loss: 1.19355 v_acc: 0.71354 |  iteration: 11252 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 65 loss: 1.29480 acc: 0.70182 | v_loss: 1.29963 v_acc: 0.71582 |  iteration: 11253 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 66 loss: 1.32209 acc: 0.69759 | v_loss: 1.46459 v_acc: 0.69434 |  iteration: 11254 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 67 loss: 1.20647 acc: 0.71549 | v_loss: 1.33683 v_acc: 0.69954 |  iteration: 11255 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 68 loss: 1.28666 acc: 0.70508 | v_loss: 1.19250 v_acc: 0.72103 |  iteration: 11256 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 69 loss: 1.28044 acc: 0.70475 | v_loss: 1.14911 v_acc: 0.70345 |  iteration: 11257 teacher: 1 stage: sketch lr: 0.000417\n",
      "batch 70 loss: 1.24959 acc: 0.70443 | v_loss: 1.14915 v_acc: 0.71842 |  iteration: 11258 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 71 loss: 1.33710 acc: 0.70866 | v_loss: 1.20563 v_acc: 0.70410 |  iteration: 11259 teacher: 0 stage: sketch lr: 0.000417\n",
      "batch 72 loss: 1.28097 acc: 0.70150 | v_loss: 1.25306 v_acc: 0.71615 |  iteration: 11260 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 73 loss: 1.37238 acc: 0.70150 | v_loss: 1.20019 v_acc: 0.73145 |  iteration: 11261 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 74 loss: 1.34234 acc: 0.70052 | v_loss: 1.22549 v_acc: 0.71777 |  iteration: 11262 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 75 loss: 1.26545 acc: 0.70085 | v_loss: 1.23595 v_acc: 0.70345 |  iteration: 11263 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 76 loss: 1.30993 acc: 0.69824 | v_loss: 1.16345 v_acc: 0.72363 |  iteration: 11264 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 77 loss: 1.26874 acc: 0.71387 | v_loss: 1.11824 v_acc: 0.72135 |  iteration: 11265 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 78 loss: 1.34036 acc: 0.70052 | v_loss: 1.45485 v_acc: 0.69271 |  iteration: 11266 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 79 loss: 1.26107 acc: 0.69922 | v_loss: 1.19702 v_acc: 0.70768 |  iteration: 11267 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 80 loss: 1.35241 acc: 0.69564 | v_loss: 1.21962 v_acc: 0.71973 |  iteration: 11268 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 81 loss: 1.26873 acc: 0.71126 | v_loss: 1.21700 v_acc: 0.71810 |  iteration: 11269 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 82 loss: 1.31220 acc: 0.71094 | v_loss: 1.27051 v_acc: 0.70573 |  iteration: 11270 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 83 loss: 1.29364 acc: 0.69987 | v_loss: 1.13808 v_acc: 0.73503 |  iteration: 11271 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 84 loss: 1.36218 acc: 0.69824 | v_loss: 1.37144 v_acc: 0.71289 |  iteration: 11272 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 85 loss: 1.25305 acc: 0.70671 | v_loss: 1.18504 v_acc: 0.69954 |  iteration: 11273 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 86 loss: 1.25206 acc: 0.70312 | v_loss: 1.19794 v_acc: 0.70573 |  iteration: 11274 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 87 loss: 1.28028 acc: 0.70540 | v_loss: 1.27758 v_acc: 0.70215 |  iteration: 11275 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 88 loss: 1.31204 acc: 0.70280 | v_loss: 1.28034 v_acc: 0.70052 |  iteration: 11276 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 89 loss: 1.34712 acc: 0.69694 | v_loss: 1.33522 v_acc: 0.69238 |  iteration: 11277 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 90 loss: 1.29831 acc: 0.71322 | v_loss: 1.35730 v_acc: 0.70833 |  iteration: 11278 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 91 loss: 1.28741 acc: 0.69694 | v_loss: 1.27536 v_acc: 0.70052 |  iteration: 11279 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 92 loss: 1.24536 acc: 0.71224 | v_loss: 1.18640 v_acc: 0.70931 |  iteration: 11280 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 93 loss: 1.24035 acc: 0.70964 | v_loss: 1.30949 v_acc: 0.70866 |  iteration: 11281 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 94 loss: 1.25479 acc: 0.70833 | v_loss: 1.19870 v_acc: 0.71875 |  iteration: 11282 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 95 loss: 1.33235 acc: 0.69401 | v_loss: 1.13543 v_acc: 0.72786 |  iteration: 11283 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 96 loss: 1.31738 acc: 0.70996 | v_loss: 1.11446 v_acc: 0.71126 |  iteration: 11284 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 97 loss: 1.31295 acc: 0.70085 | v_loss: 1.24055 v_acc: 0.70736 |  iteration: 11285 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 98 loss: 1.32595 acc: 0.69954 | v_loss: 1.31404 v_acc: 0.69596 |  iteration: 11286 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 99 loss: 1.28367 acc: 0.71712 | v_loss: 1.15887 v_acc: 0.70638 |  iteration: 11287 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 100 loss: 1.31054 acc: 0.70540 | v_loss: 1.20456 v_acc: 0.69629 |  iteration: 11288 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 101 loss: 1.30884 acc: 0.70833 | v_loss: 1.17468 v_acc: 0.70833 |  iteration: 11289 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 102 loss: 1.29499 acc: 0.70150 | v_loss: 1.20418 v_acc: 0.70475 |  iteration: 11290 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 103 loss: 1.29712 acc: 0.70410 | v_loss: 1.07403 v_acc: 0.73535 |  iteration: 11291 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 104 loss: 1.36856 acc: 0.70312 | v_loss: 1.16261 v_acc: 0.71940 |  iteration: 11292 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 105 loss: 1.18733 acc: 0.71615 | v_loss: 1.14172 v_acc: 0.73177 |  iteration: 11293 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 106 loss: 1.36274 acc: 0.69954 | v_loss: 1.12578 v_acc: 0.72201 |  iteration: 11294 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 107 loss: 1.27422 acc: 0.70475 | v_loss: 1.19548 v_acc: 0.71940 |  iteration: 11295 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 108 loss: 1.28444 acc: 0.69889 | v_loss: 1.22142 v_acc: 0.71289 |  iteration: 11296 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 109 loss: 1.33570 acc: 0.69076 | v_loss: 1.20215 v_acc: 0.72428 |  iteration: 11297 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 110 loss: 1.29976 acc: 0.70736 | v_loss: 1.38314 v_acc: 0.70215 |  iteration: 11298 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 111 loss: 1.29762 acc: 0.70182 | v_loss: 1.27209 v_acc: 0.71680 |  iteration: 11299 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 112 loss: 1.35994 acc: 0.69954 | v_loss: 1.12557 v_acc: 0.73730 |  iteration: 11300 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 113 loss: 1.21823 acc: 0.71419 | v_loss: 1.18227 v_acc: 0.70768 |  iteration: 11301 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 114 loss: 1.27933 acc: 0.70150 | v_loss: 1.27621 v_acc: 0.69922 |  iteration: 11302 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 115 loss: 1.20510 acc: 0.71191 | v_loss: 1.16038 v_acc: 0.69857 |  iteration: 11303 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 116 loss: 1.26805 acc: 0.70833 | v_loss: 1.25559 v_acc: 0.71126 |  iteration: 11304 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 117 loss: 1.36447 acc: 0.69434 | v_loss: 1.24677 v_acc: 0.69206 |  iteration: 11305 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 118 loss: 1.24399 acc: 0.71745 | v_loss: 1.18813 v_acc: 0.71517 |  iteration: 11306 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 119 loss: 1.34959 acc: 0.69987 | v_loss: 1.23621 v_acc: 0.70312 |  iteration: 11307 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 120 loss: 1.30234 acc: 0.71615 | v_loss: 1.20487 v_acc: 0.70605 |  iteration: 11308 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 121 loss: 1.27818 acc: 0.70378 | v_loss: 1.18158 v_acc: 0.72201 |  iteration: 11309 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 122 loss: 1.27481 acc: 0.71387 | v_loss: 1.22541 v_acc: 0.70117 |  iteration: 11310 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 123 loss: 1.26260 acc: 0.70898 | v_loss: 1.31944 v_acc: 0.70052 |  iteration: 11311 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 124 loss: 1.20756 acc: 0.71484 | v_loss: 1.13267 v_acc: 0.70898 |  iteration: 11312 teacher: 1 stage: sketch lr: 0.000416\n",
      "batch 125 loss: 1.27435 acc: 0.70671 | v_loss: 1.39507 v_acc: 0.68620 |  iteration: 11313 teacher: 0 stage: sketch lr: 0.000416\n",
      "batch 126 loss: 1.30722 acc: 0.69596 | v_loss: 1.14616 v_acc: 0.72396 |  iteration: 11314 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 127 loss: 1.26153 acc: 0.70996 | v_loss: 1.46370 v_acc: 0.67936 |  iteration: 11315 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 128 loss: 1.20787 acc: 0.72103 | v_loss: 1.34504 v_acc: 0.69987 |  iteration: 11316 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 129 loss: 1.40389 acc: 0.68783 | v_loss: 1.31091 v_acc: 0.69206 |  iteration: 11317 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 130 loss: 1.30104 acc: 0.69954 | v_loss: 1.29261 v_acc: 0.70020 |  iteration: 11318 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 131 loss: 1.27890 acc: 0.70150 | v_loss: 1.21172 v_acc: 0.70410 |  iteration: 11319 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 132 loss: 1.33930 acc: 0.70312 | v_loss: 1.24652 v_acc: 0.70671 |  iteration: 11320 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 133 loss: 1.27928 acc: 0.69531 | v_loss: 1.19567 v_acc: 0.71810 |  iteration: 11321 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 134 loss: 1.21962 acc: 0.71549 | v_loss: 1.38438 v_acc: 0.68978 |  iteration: 11322 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 135 loss: 1.30372 acc: 0.70182 | v_loss: 1.26542 v_acc: 0.71289 |  iteration: 11323 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 136 loss: 1.34164 acc: 0.70085 | v_loss: 1.19726 v_acc: 0.70833 |  iteration: 11324 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 137 loss: 1.33588 acc: 0.68620 | v_loss: 1.24841 v_acc: 0.71549 |  iteration: 11325 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 138 loss: 1.33785 acc: 0.70150 | v_loss: 1.14369 v_acc: 0.70898 |  iteration: 11326 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 139 loss: 1.22403 acc: 0.70964 | v_loss: 1.23776 v_acc: 0.69824 |  iteration: 11327 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 140 loss: 1.28429 acc: 0.69987 | v_loss: 1.20455 v_acc: 0.71387 |  iteration: 11328 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 141 loss: 1.30671 acc: 0.70312 | v_loss: 1.14718 v_acc: 0.72038 |  iteration: 11329 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 142 loss: 1.34275 acc: 0.69336 | v_loss: 1.12274 v_acc: 0.72363 |  iteration: 11330 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 143 loss: 1.27610 acc: 0.70182 | v_loss: 1.25008 v_acc: 0.71680 |  iteration: 11331 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 144 loss: 1.38851 acc: 0.68815 | v_loss: 1.24507 v_acc: 0.70475 |  iteration: 11332 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 145 loss: 1.30545 acc: 0.69987 | v_loss: 1.23417 v_acc: 0.71029 |  iteration: 11333 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 146 loss: 1.33035 acc: 0.69466 | v_loss: 1.09118 v_acc: 0.71908 |  iteration: 11334 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 147 loss: 1.29910 acc: 0.70345 | v_loss: 1.23311 v_acc: 0.72917 |  iteration: 11335 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 148 loss: 1.35864 acc: 0.69368 | v_loss: 1.29081 v_acc: 0.69661 |  iteration: 11336 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 149 loss: 1.31635 acc: 0.69857 | v_loss: 1.29725 v_acc: 0.72168 |  iteration: 11337 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 150 loss: 1.45749 acc: 0.69596 | v_loss: 1.15327 v_acc: 0.72201 |  iteration: 11338 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 151 loss: 1.24272 acc: 0.70410 | v_loss: 1.09520 v_acc: 0.73535 |  iteration: 11339 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 152 loss: 1.32537 acc: 0.70182 | v_loss: 1.11427 v_acc: 0.72624 |  iteration: 11340 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 153 loss: 1.29573 acc: 0.70475 | v_loss: 1.17411 v_acc: 0.70736 |  iteration: 11341 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 154 loss: 1.40073 acc: 0.69336 | v_loss: 1.24051 v_acc: 0.69792 |  iteration: 11342 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 155 loss: 1.27311 acc: 0.70410 | v_loss: 1.18311 v_acc: 0.71680 |  iteration: 11343 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 156 loss: 1.25101 acc: 0.71322 | v_loss: 1.30657 v_acc: 0.69889 |  iteration: 11344 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 157 loss: 1.31420 acc: 0.69694 | v_loss: 1.46116 v_acc: 0.69108 |  iteration: 11345 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 158 loss: 1.34034 acc: 0.70150 | v_loss: 1.34005 v_acc: 0.69922 |  iteration: 11346 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 159 loss: 1.27261 acc: 0.70052 | v_loss: 1.18758 v_acc: 0.72396 |  iteration: 11347 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 160 loss: 1.24346 acc: 0.70312 | v_loss: 1.15171 v_acc: 0.71094 |  iteration: 11348 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 161 loss: 1.34130 acc: 0.69824 | v_loss: 1.13883 v_acc: 0.72396 |  iteration: 11349 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 162 loss: 1.30388 acc: 0.70247 | v_loss: 1.20403 v_acc: 0.70866 |  iteration: 11350 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 163 loss: 1.24042 acc: 0.69792 | v_loss: 1.24512 v_acc: 0.71582 |  iteration: 11351 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 164 loss: 1.23793 acc: 0.70866 | v_loss: 1.20155 v_acc: 0.73405 |  iteration: 11352 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 165 loss: 1.19822 acc: 0.71126 | v_loss: 1.22093 v_acc: 0.71745 |  iteration: 11353 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 166 loss: 1.26506 acc: 0.70703 | v_loss: 1.22717 v_acc: 0.70508 |  iteration: 11354 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 167 loss: 1.20322 acc: 0.71029 | v_loss: 1.13692 v_acc: 0.72461 |  iteration: 11355 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 168 loss: 1.17686 acc: 0.72493 | v_loss: 1.10532 v_acc: 0.72070 |  iteration: 11356 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 169 loss: 1.31801 acc: 0.70215 | v_loss: 1.45524 v_acc: 0.69303 |  iteration: 11357 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 170 loss: 1.28603 acc: 0.70475 | v_loss: 1.19597 v_acc: 0.70801 |  iteration: 11358 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 171 loss: 1.28773 acc: 0.70573 | v_loss: 1.19286 v_acc: 0.72005 |  iteration: 11359 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 172 loss: 1.25659 acc: 0.70215 | v_loss: 1.19698 v_acc: 0.71452 |  iteration: 11360 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 173 loss: 1.28178 acc: 0.71712 | v_loss: 1.25931 v_acc: 0.70833 |  iteration: 11361 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 174 loss: 1.28903 acc: 0.70215 | v_loss: 1.12309 v_acc: 0.73470 |  iteration: 11362 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 175 loss: 1.21211 acc: 0.71061 | v_loss: 1.37121 v_acc: 0.71419 |  iteration: 11363 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 176 loss: 1.27850 acc: 0.70345 | v_loss: 1.16027 v_acc: 0.70182 |  iteration: 11364 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 177 loss: 1.32939 acc: 0.70150 | v_loss: 1.18102 v_acc: 0.70801 |  iteration: 11365 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 178 loss: 1.27107 acc: 0.70671 | v_loss: 1.25910 v_acc: 0.70378 |  iteration: 11366 teacher: 0 stage: sketch lr: 0.000415\n",
      "batch 179 loss: 1.30634 acc: 0.70378 | v_loss: 1.25292 v_acc: 0.70312 |  iteration: 11367 teacher: 1 stage: sketch lr: 0.000415\n",
      "batch 180 loss: 1.27187 acc: 0.70703 | v_loss: 1.32324 v_acc: 0.69010 |  iteration: 11368 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 181 loss: 1.28146 acc: 0.70085 | v_loss: 1.35057 v_acc: 0.70768 |  iteration: 11369 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 182 loss: 1.29408 acc: 0.70117 | v_loss: 1.27895 v_acc: 0.70573 |  iteration: 11370 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 183 loss: 1.34255 acc: 0.69531 | v_loss: 1.18504 v_acc: 0.70996 |  iteration: 11371 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 184 loss: 1.35857 acc: 0.69499 | v_loss: 1.29972 v_acc: 0.70964 |  iteration: 11372 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 185 loss: 1.32722 acc: 0.70801 | v_loss: 1.19898 v_acc: 0.71354 |  iteration: 11373 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 186 loss: 1.33073 acc: 0.69889 | v_loss: 1.14167 v_acc: 0.72396 |  iteration: 11374 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 187 loss: 1.26959 acc: 0.70736 | v_loss: 1.11562 v_acc: 0.71029 |  iteration: 11375 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 188 loss: 1.33178 acc: 0.70540 | v_loss: 1.24371 v_acc: 0.70573 |  iteration: 11376 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 189 loss: 1.22402 acc: 0.71257 | v_loss: 1.30260 v_acc: 0.70052 |  iteration: 11377 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 190 loss: 1.29569 acc: 0.70931 | v_loss: 1.15050 v_acc: 0.70801 |  iteration: 11378 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 191 loss: 1.22298 acc: 0.70964 | v_loss: 1.18146 v_acc: 0.69499 |  iteration: 11379 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 192 loss: 1.31186 acc: 0.70833 | v_loss: 1.16727 v_acc: 0.71094 |  iteration: 11380 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 193 loss: 1.29860 acc: 0.71712 | v_loss: 1.18437 v_acc: 0.70801 |  iteration: 11381 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 194 loss: 1.26989 acc: 0.70443 | v_loss: 1.04399 v_acc: 0.73698 |  iteration: 11382 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 195 loss: 1.23254 acc: 0.70898 | v_loss: 1.15918 v_acc: 0.72233 |  iteration: 11383 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 196 loss: 1.21079 acc: 0.70638 | v_loss: 1.12832 v_acc: 0.72689 |  iteration: 11384 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 197 loss: 1.21312 acc: 0.72591 | v_loss: 1.10163 v_acc: 0.72982 |  iteration: 11385 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 198 loss: 1.26967 acc: 0.71517 | v_loss: 1.18631 v_acc: 0.71973 |  iteration: 11386 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 199 loss: 1.19011 acc: 0.72331 | v_loss: 1.21724 v_acc: 0.71452 |  iteration: 11387 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 200 loss: 1.32055 acc: 0.71029 | v_loss: 1.18400 v_acc: 0.72070 |  iteration: 11388 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 201 loss: 1.33861 acc: 0.70866 | v_loss: 1.38159 v_acc: 0.69987 |  iteration: 11389 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 202 loss: 1.31652 acc: 0.69987 | v_loss: 1.25584 v_acc: 0.71582 |  iteration: 11390 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 203 loss: 1.27108 acc: 0.70378 | v_loss: 1.05264 v_acc: 0.74512 |  iteration: 11391 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 204 loss: 1.30449 acc: 0.69531 | v_loss: 1.19408 v_acc: 0.70736 |  iteration: 11392 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 205 loss: 1.28378 acc: 0.70215 | v_loss: 1.26196 v_acc: 0.70345 |  iteration: 11393 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 206 loss: 1.25181 acc: 0.70247 | v_loss: 1.16456 v_acc: 0.71354 |  iteration: 11394 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 207 loss: 1.26788 acc: 0.70345 | v_loss: 1.24372 v_acc: 0.71094 |  iteration: 11395 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 208 loss: 1.26360 acc: 0.70345 | v_loss: 1.22475 v_acc: 0.69336 |  iteration: 11396 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 209 loss: 1.30376 acc: 0.69141 | v_loss: 1.19282 v_acc: 0.71322 |  iteration: 11397 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 210 loss: 1.21717 acc: 0.70312 | v_loss: 1.22199 v_acc: 0.69824 |  iteration: 11398 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 211 loss: 1.25762 acc: 0.70833 | v_loss: 1.16681 v_acc: 0.71419 |  iteration: 11399 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 212 loss: 1.21454 acc: 0.71647 | v_loss: 1.16382 v_acc: 0.72656 |  iteration: 11400 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 213 loss: 1.26943 acc: 0.69727 | v_loss: 1.22272 v_acc: 0.70345 |  iteration: 11401 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 214 loss: 1.24988 acc: 0.70801 | v_loss: 1.32569 v_acc: 0.70052 |  iteration: 11402 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 215 loss: 1.27344 acc: 0.71322 | v_loss: 1.12767 v_acc: 0.70833 |  iteration: 11403 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 216 loss: 1.37116 acc: 0.69889 | v_loss: 1.38965 v_acc: 0.68392 |  iteration: 11404 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 217 loss: 1.29374 acc: 0.70996 | v_loss: 1.14784 v_acc: 0.72070 |  iteration: 11405 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 218 loss: 1.25373 acc: 0.70931 | v_loss: 1.45115 v_acc: 0.68034 |  iteration: 11406 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 219 loss: 1.23939 acc: 0.70280 | v_loss: 1.33898 v_acc: 0.70280 |  iteration: 11407 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 220 loss: 1.34658 acc: 0.69922 | v_loss: 1.31570 v_acc: 0.69303 |  iteration: 11408 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 221 loss: 1.25584 acc: 0.70833 | v_loss: 1.28993 v_acc: 0.70410 |  iteration: 11409 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 222 loss: 1.29018 acc: 0.70638 | v_loss: 1.21874 v_acc: 0.70736 |  iteration: 11410 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 223 loss: 1.30575 acc: 0.69922 | v_loss: 1.24400 v_acc: 0.70671 |  iteration: 11411 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 224 loss: 1.20843 acc: 0.72103 | v_loss: 1.19244 v_acc: 0.71973 |  iteration: 11412 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 225 loss: 1.27712 acc: 0.70931 | v_loss: 1.38976 v_acc: 0.68359 |  iteration: 11413 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 226 loss: 1.34377 acc: 0.69596 | v_loss: 1.26343 v_acc: 0.71419 |  iteration: 11414 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 227 loss: 1.27530 acc: 0.69564 | v_loss: 1.18803 v_acc: 0.70833 |  iteration: 11415 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 228 loss: 1.29045 acc: 0.69727 | v_loss: 1.24358 v_acc: 0.70866 |  iteration: 11416 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 229 loss: 1.26721 acc: 0.70671 | v_loss: 1.14572 v_acc: 0.70898 |  iteration: 11417 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 230 loss: 1.31927 acc: 0.70475 | v_loss: 1.23866 v_acc: 0.69824 |  iteration: 11418 teacher: 0 stage: sketch lr: 0.000414\n",
      "batch 231 loss: 1.28867 acc: 0.69987 | v_loss: 1.21577 v_acc: 0.71257 |  iteration: 11419 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 232 loss: 1.33755 acc: 0.70150 | v_loss: 1.14776 v_acc: 0.72005 |  iteration: 11420 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 233 loss: 1.30351 acc: 0.70378 | v_loss: 1.11446 v_acc: 0.72819 |  iteration: 11421 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 234 loss: 1.26592 acc: 0.70801 | v_loss: 1.24611 v_acc: 0.72168 |  iteration: 11422 teacher: 1 stage: sketch lr: 0.000414\n",
      "batch 235 loss: 1.22890 acc: 0.70150 | v_loss: 1.23674 v_acc: 0.70280 |  iteration: 11423 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 236 loss: 1.25720 acc: 0.71224 | v_loss: 1.22880 v_acc: 0.70866 |  iteration: 11424 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 237 loss: 1.29071 acc: 0.69499 | v_loss: 1.08415 v_acc: 0.72005 |  iteration: 11425 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 238 loss: 1.26863 acc: 0.70475 | v_loss: 1.23102 v_acc: 0.72917 |  iteration: 11426 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 239 loss: 1.32825 acc: 0.69661 | v_loss: 1.27981 v_acc: 0.69824 |  iteration: 11427 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 240 loss: 1.30716 acc: 0.70312 | v_loss: 1.28669 v_acc: 0.72168 |  iteration: 11428 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 241 loss: 1.29772 acc: 0.71224 | v_loss: 1.13664 v_acc: 0.72266 |  iteration: 11429 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 242 loss: 1.37023 acc: 0.68880 | v_loss: 1.08924 v_acc: 0.73372 |  iteration: 11430 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 243 loss: 1.28792 acc: 0.71191 | v_loss: 1.09108 v_acc: 0.72786 |  iteration: 11431 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 244 loss: 1.23817 acc: 0.70671 | v_loss: 1.17531 v_acc: 0.70931 |  iteration: 11432 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 245 loss: 1.26125 acc: 0.70117 | v_loss: 1.22651 v_acc: 0.69954 |  iteration: 11433 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 246 loss: 1.24489 acc: 0.70964 | v_loss: 1.16551 v_acc: 0.71680 |  iteration: 11434 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 247 loss: 1.23955 acc: 0.70475 | v_loss: 1.28585 v_acc: 0.71061 |  iteration: 11435 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 248 loss: 1.25831 acc: 0.70475 | v_loss: 1.46686 v_acc: 0.68945 |  iteration: 11436 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 249 loss: 1.21934 acc: 0.70768 | v_loss: 1.33093 v_acc: 0.69922 |  iteration: 11437 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 250 loss: 1.25171 acc: 0.70866 | v_loss: 1.18752 v_acc: 0.72103 |  iteration: 11438 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 251 loss: 1.28805 acc: 0.70215 | v_loss: 1.14117 v_acc: 0.70768 |  iteration: 11439 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 252 loss: 1.33777 acc: 0.69954 | v_loss: 1.13501 v_acc: 0.72298 |  iteration: 11440 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 253 loss: 1.14860 acc: 0.71224 | v_loss: 1.20742 v_acc: 0.70866 |  iteration: 11441 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 254 loss: 1.27622 acc: 0.71126 | v_loss: 1.22260 v_acc: 0.72201 |  iteration: 11442 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 255 loss: 1.24022 acc: 0.69954 | v_loss: 1.19880 v_acc: 0.72526 |  iteration: 11443 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 256 loss: 1.23238 acc: 0.70410 | v_loss: 1.24301 v_acc: 0.71810 |  iteration: 11444 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 257 loss: 1.30288 acc: 0.70443 | v_loss: 1.22242 v_acc: 0.70996 |  iteration: 11445 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 258 loss: 1.24418 acc: 0.70703 | v_loss: 1.14617 v_acc: 0.72168 |  iteration: 11446 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 259 loss: 1.35463 acc: 0.69499 | v_loss: 1.11614 v_acc: 0.72233 |  iteration: 11447 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 260 loss: 1.32013 acc: 0.69922 | v_loss: 1.43418 v_acc: 0.69010 |  iteration: 11448 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 261 loss: 1.27175 acc: 0.70475 | v_loss: 1.20134 v_acc: 0.70703 |  iteration: 11449 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 262 loss: 1.30724 acc: 0.69922 | v_loss: 1.17292 v_acc: 0.71615 |  iteration: 11450 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 263 loss: 1.33381 acc: 0.70150 | v_loss: 1.20377 v_acc: 0.71517 |  iteration: 11451 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 264 loss: 1.24156 acc: 0.70703 | v_loss: 1.24318 v_acc: 0.70182 |  iteration: 11452 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 265 loss: 1.31456 acc: 0.70312 | v_loss: 1.12616 v_acc: 0.73177 |  iteration: 11453 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 266 loss: 1.31844 acc: 0.68815 | v_loss: 1.35362 v_acc: 0.71484 |  iteration: 11454 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 267 loss: 1.24412 acc: 0.71582 | v_loss: 1.17381 v_acc: 0.69987 |  iteration: 11455 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 268 loss: 1.26848 acc: 0.70150 | v_loss: 1.17106 v_acc: 0.70475 |  iteration: 11456 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 269 loss: 1.38406 acc: 0.69629 | v_loss: 1.26016 v_acc: 0.70378 |  iteration: 11457 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 270 loss: 1.28438 acc: 0.70052 | v_loss: 1.28025 v_acc: 0.69987 |  iteration: 11458 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 271 loss: 1.29603 acc: 0.71126 | v_loss: 1.33027 v_acc: 0.69043 |  iteration: 11459 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 272 loss: 1.30886 acc: 0.70345 | v_loss: 1.32401 v_acc: 0.70833 |  iteration: 11460 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 273 loss: 1.39932 acc: 0.68945 | v_loss: 1.27573 v_acc: 0.70378 |  iteration: 11461 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 274 loss: 1.30716 acc: 0.69401 | v_loss: 1.18043 v_acc: 0.70638 |  iteration: 11462 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 275 loss: 1.20081 acc: 0.72233 | v_loss: 1.27770 v_acc: 0.70573 |  iteration: 11463 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 276 loss: 1.24932 acc: 0.70605 | v_loss: 1.20551 v_acc: 0.71419 |  iteration: 11464 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 277 loss: 1.41551 acc: 0.69661 | v_loss: 1.12188 v_acc: 0.72559 |  iteration: 11465 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 278 loss: 1.22347 acc: 0.71842 | v_loss: 1.10075 v_acc: 0.71029 |  iteration: 11466 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 279 loss: 1.31976 acc: 0.69922 | v_loss: 1.25991 v_acc: 0.70801 |  iteration: 11467 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 280 loss: 1.21459 acc: 0.71159 | v_loss: 1.28959 v_acc: 0.69954 |  iteration: 11468 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 281 loss: 1.30695 acc: 0.70345 | v_loss: 1.13731 v_acc: 0.71322 |  iteration: 11469 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 282 loss: 1.26641 acc: 0.70150 | v_loss: 1.19586 v_acc: 0.70540 |  iteration: 11470 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 283 loss: 1.23144 acc: 0.70605 | v_loss: 1.14049 v_acc: 0.71940 |  iteration: 11471 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 284 loss: 1.24703 acc: 0.71094 | v_loss: 1.17445 v_acc: 0.70866 |  iteration: 11472 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 285 loss: 1.37507 acc: 0.70020 | v_loss: 1.06953 v_acc: 0.73600 |  iteration: 11473 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 286 loss: 1.23914 acc: 0.70898 | v_loss: 1.15351 v_acc: 0.72266 |  iteration: 11474 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 287 loss: 1.32850 acc: 0.70410 | v_loss: 1.14435 v_acc: 0.73112 |  iteration: 11475 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 288 loss: 1.28911 acc: 0.70443 | v_loss: 1.11680 v_acc: 0.72526 |  iteration: 11476 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 289 loss: 1.33587 acc: 0.69596 | v_loss: 1.18752 v_acc: 0.71908 |  iteration: 11477 teacher: 0 stage: sketch lr: 0.000413\n",
      "batch 290 loss: 1.32065 acc: 0.69661 | v_loss: 1.20345 v_acc: 0.71973 |  iteration: 11478 teacher: 1 stage: sketch lr: 0.000413\n",
      "batch 291 loss: 1.26133 acc: 0.70898 | v_loss: 1.20866 v_acc: 0.72428 |  iteration: 11479 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 292 loss: 1.30767 acc: 0.71419 | v_loss: 1.37228 v_acc: 0.69661 |  iteration: 11480 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 293 loss: 1.28116 acc: 0.70280 | v_loss: 1.26629 v_acc: 0.71973 |  iteration: 11481 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 294 loss: 1.37513 acc: 0.69531 | v_loss: 1.04158 v_acc: 0.75098 |  iteration: 11482 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 295 loss: 1.31511 acc: 0.69922 | v_loss: 1.21332 v_acc: 0.69954 |  iteration: 11483 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 296 loss: 1.29432 acc: 0.70671 | v_loss: 1.24729 v_acc: 0.70085 |  iteration: 11484 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 297 loss: 1.25688 acc: 0.70768 | v_loss: 1.18176 v_acc: 0.69629 |  iteration: 11485 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 298 loss: 1.28330 acc: 0.70801 | v_loss: 1.23673 v_acc: 0.71029 |  iteration: 11486 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 299 loss: 1.29057 acc: 0.70573 | v_loss: 1.23043 v_acc: 0.69173 |  iteration: 11487 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 300 loss: 1.30470 acc: 0.69987 | v_loss: 1.18399 v_acc: 0.71517 |  iteration: 11488 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 301 loss: 1.28161 acc: 0.70736 | v_loss: 1.21906 v_acc: 0.70475 |  iteration: 11489 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 302 loss: 1.28926 acc: 0.69954 | v_loss: 1.19527 v_acc: 0.71387 |  iteration: 11490 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 303 loss: 1.22779 acc: 0.70605 | v_loss: 1.17939 v_acc: 0.72754 |  iteration: 11491 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 304 loss: 1.27849 acc: 0.71615 | v_loss: 1.22713 v_acc: 0.70378 |  iteration: 11492 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 305 loss: 1.27105 acc: 0.70378 | v_loss: 1.29679 v_acc: 0.69759 |  iteration: 11493 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 306 loss: 1.28551 acc: 0.70182 | v_loss: 1.13973 v_acc: 0.70671 |  iteration: 11494 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 307 loss: 1.31281 acc: 0.70182 | v_loss: 1.40618 v_acc: 0.68620 |  iteration: 11495 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 308 loss: 1.29589 acc: 0.70312 | v_loss: 1.15556 v_acc: 0.72266 |  iteration: 11496 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 309 loss: 1.26847 acc: 0.70736 | v_loss: 1.44761 v_acc: 0.68359 |  iteration: 11497 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 310 loss: 1.27958 acc: 0.70508 | v_loss: 1.33402 v_acc: 0.69954 |  iteration: 11498 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 311 loss: 1.37361 acc: 0.69727 | v_loss: 1.31290 v_acc: 0.69076 |  iteration: 11499 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 312 loss: 1.22514 acc: 0.70996 | v_loss: 1.28636 v_acc: 0.70020 |  iteration: 11500 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 313 loss: 1.33332 acc: 0.70671 | v_loss: 1.18987 v_acc: 0.70508 |  iteration: 11501 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 314 loss: 1.35235 acc: 0.70182 | v_loss: 1.23687 v_acc: 0.70378 |  iteration: 11502 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 315 loss: 1.36860 acc: 0.70247 | v_loss: 1.19248 v_acc: 0.71810 |  iteration: 11503 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 316 loss: 1.22374 acc: 0.70671 | v_loss: 1.38936 v_acc: 0.68913 |  iteration: 11504 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 317 loss: 1.27241 acc: 0.69889 | v_loss: 1.26134 v_acc: 0.70866 |  iteration: 11505 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 318 loss: 1.31856 acc: 0.69694 | v_loss: 1.16513 v_acc: 0.70833 |  iteration: 11506 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 319 loss: 1.29778 acc: 0.70671 | v_loss: 1.23565 v_acc: 0.71419 |  iteration: 11507 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 320 loss: 1.33442 acc: 0.70638 | v_loss: 1.13849 v_acc: 0.70475 |  iteration: 11508 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 321 loss: 1.23199 acc: 0.71061 | v_loss: 1.24339 v_acc: 0.69759 |  iteration: 11509 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 322 loss: 1.20335 acc: 0.71810 | v_loss: 1.21275 v_acc: 0.71126 |  iteration: 11510 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 323 loss: 1.25434 acc: 0.69759 | v_loss: 1.14383 v_acc: 0.71777 |  iteration: 11511 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 324 loss: 1.30467 acc: 0.69889 | v_loss: 1.10963 v_acc: 0.72526 |  iteration: 11512 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 325 loss: 1.28862 acc: 0.70020 | v_loss: 1.24994 v_acc: 0.71973 |  iteration: 11513 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 326 loss: 1.28431 acc: 0.70052 | v_loss: 1.22382 v_acc: 0.70443 |  iteration: 11514 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 327 loss: 1.24248 acc: 0.70931 | v_loss: 1.24607 v_acc: 0.70801 |  iteration: 11515 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 328 loss: 1.30005 acc: 0.70280 | v_loss: 1.06649 v_acc: 0.72786 |  iteration: 11516 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 329 loss: 1.24281 acc: 0.70736 | v_loss: 1.24374 v_acc: 0.73210 |  iteration: 11517 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 330 loss: 1.25672 acc: 0.69987 | v_loss: 1.28534 v_acc: 0.69531 |  iteration: 11518 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 331 loss: 1.31706 acc: 0.69857 | v_loss: 1.28937 v_acc: 0.71973 |  iteration: 11519 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 332 loss: 1.29977 acc: 0.70898 | v_loss: 1.12961 v_acc: 0.72038 |  iteration: 11520 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 333 loss: 1.41514 acc: 0.68848 | v_loss: 1.07699 v_acc: 0.73535 |  iteration: 11521 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 334 loss: 1.23150 acc: 0.71126 | v_loss: 1.09006 v_acc: 0.72135 |  iteration: 11522 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 335 loss: 1.28575 acc: 0.69434 | v_loss: 1.18327 v_acc: 0.70866 |  iteration: 11523 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 336 loss: 1.31142 acc: 0.70052 | v_loss: 1.21740 v_acc: 0.69889 |  iteration: 11524 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 337 loss: 1.36773 acc: 0.69759 | v_loss: 1.16553 v_acc: 0.71712 |  iteration: 11525 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 338 loss: 1.33715 acc: 0.69792 | v_loss: 1.28033 v_acc: 0.69792 |  iteration: 11526 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 339 loss: 1.25478 acc: 0.72363 | v_loss: 1.44228 v_acc: 0.69141 |  iteration: 11527 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 340 loss: 1.27119 acc: 0.70540 | v_loss: 1.31985 v_acc: 0.69889 |  iteration: 11528 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 341 loss: 1.35099 acc: 0.70052 | v_loss: 1.16919 v_acc: 0.72233 |  iteration: 11529 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 342 loss: 1.38142 acc: 0.69596 | v_loss: 1.15308 v_acc: 0.70671 |  iteration: 11530 teacher: 1 stage: sketch lr: 0.000412\n",
      "batch 343 loss: 1.22710 acc: 0.71029 | v_loss: 1.12042 v_acc: 0.72168 |  iteration: 11531 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 344 loss: 1.21882 acc: 0.71973 | v_loss: 1.20460 v_acc: 0.70573 |  iteration: 11532 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 345 loss: 1.31100 acc: 0.69759 | v_loss: 1.21442 v_acc: 0.71810 |  iteration: 11533 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 346 loss: 1.29155 acc: 0.69727 | v_loss: 1.19407 v_acc: 0.72949 |  iteration: 11534 teacher: 0 stage: sketch lr: 0.000412\n",
      "batch 347 loss: 1.21411 acc: 0.71908 | v_loss: 1.22665 v_acc: 0.71875 |  iteration: 11535 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 348 loss: 1.28953 acc: 0.70540 | v_loss: 1.21884 v_acc: 0.71289 |  iteration: 11536 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 349 loss: 1.24569 acc: 0.70508 | v_loss: 1.13600 v_acc: 0.72689 |  iteration: 11537 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 350 loss: 1.30162 acc: 0.70898 | v_loss: 1.10911 v_acc: 0.72201 |  iteration: 11538 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 351 loss: 1.32020 acc: 0.70052 | v_loss: 1.41761 v_acc: 0.69303 |  iteration: 11539 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 352 loss: 1.28867 acc: 0.71224 | v_loss: 1.19677 v_acc: 0.70996 |  iteration: 11540 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 353 loss: 1.23606 acc: 0.70020 | v_loss: 1.19740 v_acc: 0.71973 |  iteration: 11541 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 354 loss: 1.34854 acc: 0.69954 | v_loss: 1.20059 v_acc: 0.71484 |  iteration: 11542 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 355 loss: 1.33685 acc: 0.70345 | v_loss: 1.24820 v_acc: 0.70605 |  iteration: 11543 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 356 loss: 1.25164 acc: 0.70573 | v_loss: 1.12211 v_acc: 0.73665 |  iteration: 11544 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 357 loss: 1.34880 acc: 0.69987 | v_loss: 1.35409 v_acc: 0.71126 |  iteration: 11545 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 358 loss: 1.33703 acc: 0.69271 | v_loss: 1.18364 v_acc: 0.70182 |  iteration: 11546 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 359 loss: 1.36736 acc: 0.68783 | v_loss: 1.18874 v_acc: 0.70703 |  iteration: 11547 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 360 loss: 1.31518 acc: 0.70833 | v_loss: 1.27094 v_acc: 0.70020 |  iteration: 11548 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 361 loss: 1.25276 acc: 0.70898 | v_loss: 1.27794 v_acc: 0.69727 |  iteration: 11549 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 362 loss: 1.23023 acc: 0.71224 | v_loss: 1.33447 v_acc: 0.69271 |  iteration: 11550 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 363 loss: 1.26795 acc: 0.70247 | v_loss: 1.35139 v_acc: 0.70410 |  iteration: 11551 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 364 loss: 1.17322 acc: 0.72103 | v_loss: 1.26160 v_acc: 0.70475 |  iteration: 11552 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 365 loss: 1.22412 acc: 0.71257 | v_loss: 1.18035 v_acc: 0.70996 |  iteration: 11553 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 366 loss: 1.19840 acc: 0.70247 | v_loss: 1.30210 v_acc: 0.70736 |  iteration: 11554 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 367 loss: 1.26173 acc: 0.70801 | v_loss: 1.21481 v_acc: 0.71680 |  iteration: 11555 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 368 loss: 1.28448 acc: 0.70117 | v_loss: 1.12338 v_acc: 0.72624 |  iteration: 11556 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 369 loss: 1.31980 acc: 0.71257 | v_loss: 1.15371 v_acc: 0.70898 |  iteration: 11557 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 370 loss: 1.19321 acc: 0.71061 | v_loss: 1.24870 v_acc: 0.70508 |  iteration: 11558 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 371 loss: 1.35311 acc: 0.70931 | v_loss: 1.30248 v_acc: 0.70052 |  iteration: 11559 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 372 loss: 1.27427 acc: 0.70898 | v_loss: 1.15614 v_acc: 0.70508 |  iteration: 11560 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 373 loss: 1.33322 acc: 0.69661 | v_loss: 1.20071 v_acc: 0.69499 |  iteration: 11561 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 374 loss: 1.29938 acc: 0.70085 | v_loss: 1.17745 v_acc: 0.70801 |  iteration: 11562 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 375 loss: 1.15290 acc: 0.73079 | v_loss: 1.19073 v_acc: 0.70540 |  iteration: 11563 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 376 loss: 1.44374 acc: 0.69141 | v_loss: 1.10953 v_acc: 0.73405 |  iteration: 11564 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 377 loss: 1.31530 acc: 0.70150 | v_loss: 1.16756 v_acc: 0.71712 |  iteration: 11565 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 378 loss: 1.26594 acc: 0.71061 | v_loss: 1.22554 v_acc: 0.72266 |  iteration: 11566 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 379 loss: 1.24913 acc: 0.70833 | v_loss: 1.14732 v_acc: 0.72331 |  iteration: 11567 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 380 loss: 1.27472 acc: 0.70247 | v_loss: 1.22351 v_acc: 0.71615 |  iteration: 11568 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 381 loss: 1.25243 acc: 0.70866 | v_loss: 1.24516 v_acc: 0.71159 |  iteration: 11569 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 382 loss: 1.31197 acc: 0.69857 | v_loss: 1.21288 v_acc: 0.71908 |  iteration: 11570 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 383 loss: 1.23760 acc: 0.70182 | v_loss: 1.37978 v_acc: 0.70020 |  iteration: 11571 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 384 loss: 1.35057 acc: 0.69564 | v_loss: 1.26385 v_acc: 0.72005 |  iteration: 11572 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 385 loss: 1.32520 acc: 0.69271 | v_loss: 1.04135 v_acc: 0.74870 |  iteration: 11573 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 386 loss: 1.28695 acc: 0.70443 | v_loss: 1.21156 v_acc: 0.70345 |  iteration: 11574 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 387 loss: 1.31819 acc: 0.70085 | v_loss: 1.25345 v_acc: 0.70378 |  iteration: 11575 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 388 loss: 1.35572 acc: 0.70378 | v_loss: 1.17865 v_acc: 0.70898 |  iteration: 11576 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 389 loss: 1.25961 acc: 0.70475 | v_loss: 1.22580 v_acc: 0.71257 |  iteration: 11577 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 390 loss: 1.22592 acc: 0.70996 | v_loss: 1.24023 v_acc: 0.69303 |  iteration: 11578 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 391 loss: 1.25268 acc: 0.70638 | v_loss: 1.20440 v_acc: 0.71029 |  iteration: 11579 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 392 loss: 1.27986 acc: 0.70182 | v_loss: 1.24618 v_acc: 0.69368 |  iteration: 11580 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 393 loss: 1.33717 acc: 0.69434 | v_loss: 1.18207 v_acc: 0.71191 |  iteration: 11581 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 394 loss: 1.18072 acc: 0.71484 | v_loss: 1.17174 v_acc: 0.72526 |  iteration: 11582 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 395 loss: 1.31100 acc: 0.70150 | v_loss: 1.22846 v_acc: 0.70410 |  iteration: 11583 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 396 loss: 1.30370 acc: 0.70768 | v_loss: 1.31145 v_acc: 0.69661 |  iteration: 11584 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 397 loss: 1.28886 acc: 0.70410 | v_loss: 1.14900 v_acc: 0.70703 |  iteration: 11585 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 398 loss: 1.32280 acc: 0.69857 | v_loss: 1.40560 v_acc: 0.68490 |  iteration: 11586 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 399 loss: 1.30855 acc: 0.70378 | v_loss: 1.17425 v_acc: 0.72070 |  iteration: 11587 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 400 loss: 1.26760 acc: 0.69954 | v_loss: 1.46676 v_acc: 0.67448 |  iteration: 11588 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 401 loss: 1.23385 acc: 0.70378 | v_loss: 1.34928 v_acc: 0.69206 |  iteration: 11589 teacher: 1 stage: sketch lr: 0.000411\n",
      "batch 402 loss: 1.27437 acc: 0.70280 | v_loss: 1.34427 v_acc: 0.69108 |  iteration: 11590 teacher: 0 stage: sketch lr: 0.000411\n",
      "batch 403 loss: 1.23961 acc: 0.70768 | v_loss: 1.29340 v_acc: 0.70378 |  iteration: 11591 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 404 loss: 1.29766 acc: 0.70931 | v_loss: 1.22668 v_acc: 0.70703 |  iteration: 11592 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 405 loss: 1.27685 acc: 0.70117 | v_loss: 1.24315 v_acc: 0.70931 |  iteration: 11593 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 406 loss: 1.27108 acc: 0.69987 | v_loss: 1.19406 v_acc: 0.72201 |  iteration: 11594 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 407 loss: 1.27485 acc: 0.70540 | v_loss: 1.39942 v_acc: 0.68652 |  iteration: 11595 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 408 loss: 1.29317 acc: 0.69499 | v_loss: 1.26891 v_acc: 0.70996 |  iteration: 11596 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 409 loss: 1.24908 acc: 0.70996 | v_loss: 1.18812 v_acc: 0.70671 |  iteration: 11597 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 410 loss: 1.20489 acc: 0.71354 | v_loss: 1.24092 v_acc: 0.71419 |  iteration: 11598 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 411 loss: 1.27117 acc: 0.70052 | v_loss: 1.15066 v_acc: 0.70703 |  iteration: 11599 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 412 loss: 1.33314 acc: 0.69857 | v_loss: 1.24974 v_acc: 0.69824 |  iteration: 11600 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 413 loss: 1.31882 acc: 0.69824 | v_loss: 1.22518 v_acc: 0.71582 |  iteration: 11601 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 414 loss: 1.31317 acc: 0.70052 | v_loss: 1.15419 v_acc: 0.72168 |  iteration: 11602 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 415 loss: 1.32488 acc: 0.69727 | v_loss: 1.13375 v_acc: 0.72656 |  iteration: 11603 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 416 loss: 1.23626 acc: 0.70410 | v_loss: 1.24822 v_acc: 0.71647 |  iteration: 11604 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 417 loss: 1.27867 acc: 0.70540 | v_loss: 1.26271 v_acc: 0.70085 |  iteration: 11605 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 418 loss: 1.26734 acc: 0.70020 | v_loss: 1.27840 v_acc: 0.70410 |  iteration: 11606 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 419 loss: 1.31998 acc: 0.71387 | v_loss: 1.10755 v_acc: 0.71615 |  iteration: 11607 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 420 loss: 1.20507 acc: 0.71289 | v_loss: 1.26807 v_acc: 0.72786 |  iteration: 11608 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 421 loss: 1.25002 acc: 0.70964 | v_loss: 1.31715 v_acc: 0.69596 |  iteration: 11609 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 422 loss: 1.25578 acc: 0.70605 | v_loss: 1.29428 v_acc: 0.72038 |  iteration: 11610 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 423 loss: 1.19741 acc: 0.71452 | v_loss: 1.12988 v_acc: 0.72461 |  iteration: 11611 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 424 loss: 1.30147 acc: 0.70736 | v_loss: 1.07550 v_acc: 0.74219 |  iteration: 11612 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 425 loss: 1.23490 acc: 0.69629 | v_loss: 1.10141 v_acc: 0.72559 |  iteration: 11613 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 426 loss: 1.21051 acc: 0.70964 | v_loss: 1.16389 v_acc: 0.71029 |  iteration: 11614 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 427 loss: 1.26288 acc: 0.70768 | v_loss: 1.22804 v_acc: 0.70996 |  iteration: 11615 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 428 loss: 1.31799 acc: 0.70508 | v_loss: 1.15305 v_acc: 0.71940 |  iteration: 11616 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 429 loss: 1.29375 acc: 0.69759 | v_loss: 1.30784 v_acc: 0.69434 |  iteration: 11617 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 430 loss: 1.29779 acc: 0.69694 | v_loss: 1.49334 v_acc: 0.68620 |  iteration: 11618 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 431 loss: 1.24651 acc: 0.70964 | v_loss: 1.33761 v_acc: 0.69661 |  iteration: 11619 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 432 loss: 1.26440 acc: 0.71159 | v_loss: 1.19943 v_acc: 0.72070 |  iteration: 11620 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 433 loss: 1.23527 acc: 0.70671 | v_loss: 1.15464 v_acc: 0.70964 |  iteration: 11621 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 434 loss: 1.32935 acc: 0.69466 | v_loss: 1.13260 v_acc: 0.72168 |  iteration: 11622 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 435 loss: 1.23385 acc: 0.70898 | v_loss: 1.26026 v_acc: 0.70117 |  iteration: 11623 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 436 loss: 1.23029 acc: 0.70931 | v_loss: 1.23840 v_acc: 0.71549 |  iteration: 11624 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 437 loss: 1.23575 acc: 0.71549 | v_loss: 1.22133 v_acc: 0.72852 |  iteration: 11625 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 438 loss: 1.25019 acc: 0.70378 | v_loss: 1.23207 v_acc: 0.71289 |  iteration: 11626 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 439 loss: 1.32738 acc: 0.70312 | v_loss: 1.22262 v_acc: 0.70540 |  iteration: 11627 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 440 loss: 1.29233 acc: 0.70540 | v_loss: 1.14831 v_acc: 0.72005 |  iteration: 11628 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 441 loss: 1.21561 acc: 0.70866 | v_loss: 1.12294 v_acc: 0.71940 |  iteration: 11629 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 442 loss: 1.31789 acc: 0.69987 | v_loss: 1.42712 v_acc: 0.69368 |  iteration: 11630 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 443 loss: 1.21484 acc: 0.70801 | v_loss: 1.19613 v_acc: 0.71126 |  iteration: 11631 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 444 loss: 1.28393 acc: 0.71159 | v_loss: 1.19197 v_acc: 0.72135 |  iteration: 11632 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 445 loss: 1.26952 acc: 0.70638 | v_loss: 1.19232 v_acc: 0.71484 |  iteration: 11633 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 446 loss: 1.22552 acc: 0.71159 | v_loss: 1.25369 v_acc: 0.70768 |  iteration: 11634 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 447 loss: 1.35740 acc: 0.70508 | v_loss: 1.12150 v_acc: 0.73210 |  iteration: 11635 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 448 loss: 1.30295 acc: 0.70410 | v_loss: 1.35416 v_acc: 0.71875 |  iteration: 11636 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 449 loss: 1.41388 acc: 0.69824 | v_loss: 1.14051 v_acc: 0.69889 |  iteration: 11637 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 450 loss: 1.27076 acc: 0.70638 | v_loss: 1.17466 v_acc: 0.70540 |  iteration: 11638 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 451 loss: 1.27677 acc: 0.70540 | v_loss: 1.29136 v_acc: 0.70345 |  iteration: 11639 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 452 loss: 1.31752 acc: 0.71159 | v_loss: 1.29761 v_acc: 0.69954 |  iteration: 11640 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 453 loss: 1.26618 acc: 0.70703 | v_loss: 1.32285 v_acc: 0.69531 |  iteration: 11641 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 454 loss: 1.20008 acc: 0.71354 | v_loss: 1.33633 v_acc: 0.70801 |  iteration: 11642 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 455 loss: 1.32315 acc: 0.69596 | v_loss: 1.27343 v_acc: 0.70345 |  iteration: 11643 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 456 loss: 1.16825 acc: 0.70996 | v_loss: 1.16694 v_acc: 0.71061 |  iteration: 11644 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 457 loss: 1.24476 acc: 0.70182 | v_loss: 1.27427 v_acc: 0.70866 |  iteration: 11645 teacher: 0 stage: sketch lr: 0.000410\n",
      "batch 458 loss: 1.22754 acc: 0.71810 | v_loss: 1.18166 v_acc: 0.71875 |  iteration: 11646 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 459 loss: 1.40214 acc: 0.68620 | v_loss: 1.12054 v_acc: 0.72591 |  iteration: 11647 teacher: 1 stage: sketch lr: 0.000410\n",
      "batch 460 loss: 1.27457 acc: 0.69727 | v_loss: 1.11764 v_acc: 0.71094 |  iteration: 11648 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 461 loss: 1.32242 acc: 0.69954 | v_loss: 1.22207 v_acc: 0.70573 |  iteration: 11649 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 462 loss: 1.23945 acc: 0.70345 | v_loss: 1.27166 v_acc: 0.69987 |  iteration: 11650 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 463 loss: 1.28866 acc: 0.71094 | v_loss: 1.13489 v_acc: 0.71419 |  iteration: 11651 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 464 loss: 1.27433 acc: 0.71322 | v_loss: 1.18039 v_acc: 0.69531 |  iteration: 11652 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 465 loss: 1.22848 acc: 0.70378 | v_loss: 1.15806 v_acc: 0.70703 |  iteration: 11653 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 466 loss: 1.36685 acc: 0.69368 | v_loss: 1.17180 v_acc: 0.70540 |  iteration: 11654 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 467 loss: 1.21238 acc: 0.70964 | v_loss: 1.09002 v_acc: 0.73698 |  iteration: 11655 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 468 loss: 1.40831 acc: 0.69499 | v_loss: 1.16464 v_acc: 0.71484 |  iteration: 11656 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 469 loss: 1.35405 acc: 0.69629 | v_loss: 1.17459 v_acc: 0.72917 |  iteration: 11657 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 470 loss: 1.39831 acc: 0.69629 | v_loss: 1.12019 v_acc: 0.71842 |  iteration: 11658 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 471 loss: 1.34479 acc: 0.70345 | v_loss: 1.21695 v_acc: 0.71224 |  iteration: 11659 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 472 loss: 1.24671 acc: 0.70996 | v_loss: 1.24848 v_acc: 0.71029 |  iteration: 11660 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 473 loss: 1.37861 acc: 0.68490 | v_loss: 1.26672 v_acc: 0.71940 |  iteration: 11661 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 474 loss: 1.33422 acc: 0.69368 | v_loss: 1.37159 v_acc: 0.69499 |  iteration: 11662 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 475 loss: 1.26268 acc: 0.70540 | v_loss: 1.30590 v_acc: 0.72135 |  iteration: 11663 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 476 loss: 1.27438 acc: 0.70768 | v_loss: 1.04670 v_acc: 0.74056 |  iteration: 11664 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 477 loss: 1.27677 acc: 0.70052 | v_loss: 1.16192 v_acc: 0.70410 |  iteration: 11665 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 478 loss: 1.26421 acc: 0.70703 | v_loss: 1.27034 v_acc: 0.69629 |  iteration: 11666 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 479 loss: 1.27403 acc: 0.70964 | v_loss: 1.18302 v_acc: 0.69173 |  iteration: 11667 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 480 loss: 1.28325 acc: 0.70410 | v_loss: 1.24367 v_acc: 0.70312 |  iteration: 11668 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 481 loss: 1.31601 acc: 0.69401 | v_loss: 1.22446 v_acc: 0.69271 |  iteration: 11669 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 482 loss: 1.25886 acc: 0.71224 | v_loss: 1.18731 v_acc: 0.72070 |  iteration: 11670 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 483 loss: 1.29284 acc: 0.70410 | v_loss: 1.20724 v_acc: 0.70964 |  iteration: 11671 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 484 loss: 1.36691 acc: 0.70475 | v_loss: 1.17533 v_acc: 0.72201 |  iteration: 11672 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 485 loss: 1.23487 acc: 0.70215 | v_loss: 1.14405 v_acc: 0.72786 |  iteration: 11673 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 486 loss: 1.31338 acc: 0.70117 | v_loss: 1.20114 v_acc: 0.70410 |  iteration: 11674 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 487 loss: 1.30975 acc: 0.69954 | v_loss: 1.29914 v_acc: 0.69954 |  iteration: 11675 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 488 loss: 1.20742 acc: 0.70801 | v_loss: 1.13612 v_acc: 0.70833 |  iteration: 11676 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 489 loss: 1.26435 acc: 0.71354 | v_loss: 1.37965 v_acc: 0.68620 |  iteration: 11677 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 490 loss: 1.25794 acc: 0.70345 | v_loss: 1.12358 v_acc: 0.72103 |  iteration: 11678 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 491 loss: 1.18626 acc: 0.72038 | v_loss: 1.45818 v_acc: 0.68001 |  iteration: 11679 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 492 loss: 1.23336 acc: 0.70866 | v_loss: 1.32717 v_acc: 0.70182 |  iteration: 11680 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 493 loss: 1.33633 acc: 0.69564 | v_loss: 1.33717 v_acc: 0.69271 |  iteration: 11681 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 494 loss: 1.34566 acc: 0.70475 | v_loss: 1.26915 v_acc: 0.70410 |  iteration: 11682 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 495 loss: 1.28107 acc: 0.70833 | v_loss: 1.21514 v_acc: 0.70866 |  iteration: 11683 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 496 loss: 1.22667 acc: 0.71257 | v_loss: 1.24537 v_acc: 0.70573 |  iteration: 11684 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 497 loss: 1.33380 acc: 0.70378 | v_loss: 1.18386 v_acc: 0.72559 |  iteration: 11685 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 498 loss: 1.27539 acc: 0.70801 | v_loss: 1.38591 v_acc: 0.68750 |  iteration: 11686 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 499 loss: 1.32677 acc: 0.69922 | v_loss: 1.25635 v_acc: 0.71322 |  iteration: 11687 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 500 loss: 1.36266 acc: 0.69661 | v_loss: 1.17060 v_acc: 0.70964 |  iteration: 11688 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 501 loss: 1.30860 acc: 0.69564 | v_loss: 1.25575 v_acc: 0.71094 |  iteration: 11689 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 502 loss: 1.32329 acc: 0.69987 | v_loss: 1.14332 v_acc: 0.70508 |  iteration: 11690 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 503 loss: 1.36774 acc: 0.69694 | v_loss: 1.24688 v_acc: 0.69792 |  iteration: 11691 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 504 loss: 1.25153 acc: 0.71322 | v_loss: 1.20808 v_acc: 0.71842 |  iteration: 11692 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 505 loss: 1.25034 acc: 0.71126 | v_loss: 1.15171 v_acc: 0.71777 |  iteration: 11693 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 506 loss: 1.28552 acc: 0.70020 | v_loss: 1.13986 v_acc: 0.72852 |  iteration: 11694 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 507 loss: 1.33147 acc: 0.69661 | v_loss: 1.23292 v_acc: 0.71745 |  iteration: 11695 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 508 loss: 1.32715 acc: 0.69792 | v_loss: 1.24852 v_acc: 0.70280 |  iteration: 11696 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 509 loss: 1.31749 acc: 0.69238 | v_loss: 1.24063 v_acc: 0.70964 |  iteration: 11697 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 510 loss: 1.30252 acc: 0.69922 | v_loss: 1.06694 v_acc: 0.72266 |  iteration: 11698 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 511 loss: 1.30190 acc: 0.70312 | v_loss: 1.24404 v_acc: 0.73014 |  iteration: 11699 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 512 loss: 1.29494 acc: 0.69987 | v_loss: 1.28054 v_acc: 0.69987 |  iteration: 11700 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 513 loss: 1.32448 acc: 0.70280 | v_loss: 1.27624 v_acc: 0.72266 |  iteration: 11701 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 514 loss: 1.28176 acc: 0.69792 | v_loss: 1.12230 v_acc: 0.72005 |  iteration: 11702 teacher: 1 stage: sketch lr: 0.000409\n",
      "batch 515 loss: 1.27356 acc: 0.69727 | v_loss: 1.08731 v_acc: 0.73861 |  iteration: 11703 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 516 loss: 1.29621 acc: 0.70150 | v_loss: 1.09256 v_acc: 0.72461 |  iteration: 11704 teacher: 0 stage: sketch lr: 0.000409\n",
      "batch 517 loss: 1.37661 acc: 0.69889 | v_loss: 1.15899 v_acc: 0.71452 |  iteration: 11705 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 518 loss: 1.36512 acc: 0.69954 | v_loss: 1.20483 v_acc: 0.70150 |  iteration: 11706 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 519 loss: 1.21325 acc: 0.71191 | v_loss: 1.17226 v_acc: 0.72070 |  iteration: 11707 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 520 loss: 1.20405 acc: 0.70736 | v_loss: 1.29197 v_acc: 0.70410 |  iteration: 11708 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 521 loss: 1.29313 acc: 0.70768 | v_loss: 1.43358 v_acc: 0.69010 |  iteration: 11709 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 522 loss: 1.32133 acc: 0.70215 | v_loss: 1.32004 v_acc: 0.70280 |  iteration: 11710 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 523 loss: 1.30602 acc: 0.70964 | v_loss: 1.17651 v_acc: 0.72363 |  iteration: 11711 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 524 loss: 1.27583 acc: 0.70052 | v_loss: 1.13159 v_acc: 0.70898 |  iteration: 11712 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 525 loss: 1.26521 acc: 0.69987 | v_loss: 1.12302 v_acc: 0.72233 |  iteration: 11713 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 526 loss: 1.26128 acc: 0.69759 | v_loss: 1.19095 v_acc: 0.70964 |  iteration: 11714 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 527 loss: 1.31748 acc: 0.69857 | v_loss: 1.22520 v_acc: 0.72135 |  iteration: 11715 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 528 loss: 1.19822 acc: 0.70833 | v_loss: 1.19723 v_acc: 0.72949 |  iteration: 11716 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 529 loss: 1.29223 acc: 0.70573 | v_loss: 1.21112 v_acc: 0.72070 |  iteration: 11717 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 530 loss: 1.21743 acc: 0.70540 | v_loss: 1.20765 v_acc: 0.71289 |  iteration: 11718 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 531 loss: 1.37085 acc: 0.69499 | v_loss: 1.12848 v_acc: 0.72689 |  iteration: 11719 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 532 loss: 1.26520 acc: 0.70540 | v_loss: 1.11505 v_acc: 0.72135 |  iteration: 11720 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 533 loss: 1.25449 acc: 0.69759 | v_loss: 1.43762 v_acc: 0.69206 |  iteration: 11721 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 534 loss: 1.24478 acc: 0.69824 | v_loss: 1.15889 v_acc: 0.70996 |  iteration: 11722 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 535 loss: 1.22281 acc: 0.70964 | v_loss: 1.17772 v_acc: 0.71940 |  iteration: 11723 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 536 loss: 1.21976 acc: 0.71517 | v_loss: 1.18835 v_acc: 0.71940 |  iteration: 11724 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 537 loss: 1.25543 acc: 0.69596 | v_loss: 1.23640 v_acc: 0.70801 |  iteration: 11725 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 538 loss: 1.26857 acc: 0.69987 | v_loss: 1.12171 v_acc: 0.73112 |  iteration: 11726 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 539 loss: 1.21945 acc: 0.70410 | v_loss: 1.34943 v_acc: 0.71159 |  iteration: 11727 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 540 loss: 1.32845 acc: 0.69889 | v_loss: 1.15186 v_acc: 0.70150 |  iteration: 11728 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 541 loss: 1.30542 acc: 0.70638 | v_loss: 1.17388 v_acc: 0.70345 |  iteration: 11729 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 542 loss: 1.34906 acc: 0.70378 | v_loss: 1.26831 v_acc: 0.70605 |  iteration: 11730 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 543 loss: 1.29280 acc: 0.69987 | v_loss: 1.26555 v_acc: 0.70345 |  iteration: 11731 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 544 loss: 1.26388 acc: 0.70508 | v_loss: 1.32560 v_acc: 0.69434 |  iteration: 11732 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 545 loss: 1.27466 acc: 0.69922 | v_loss: 1.33946 v_acc: 0.71029 |  iteration: 11733 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 546 loss: 1.26778 acc: 0.70768 | v_loss: 1.26500 v_acc: 0.70508 |  iteration: 11734 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 547 loss: 1.32937 acc: 0.70736 | v_loss: 1.16730 v_acc: 0.71615 |  iteration: 11735 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 548 loss: 1.40512 acc: 0.69076 | v_loss: 1.25540 v_acc: 0.70964 |  iteration: 11736 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 549 loss: 1.27021 acc: 0.70898 | v_loss: 1.19009 v_acc: 0.71712 |  iteration: 11737 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 550 loss: 1.26003 acc: 0.71061 | v_loss: 1.12928 v_acc: 0.72754 |  iteration: 11738 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 551 loss: 1.25592 acc: 0.71484 | v_loss: 1.07954 v_acc: 0.70996 |  iteration: 11739 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 552 loss: 1.31176 acc: 0.70508 | v_loss: 1.23118 v_acc: 0.70964 |  iteration: 11740 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 553 loss: 1.19915 acc: 0.70801 | v_loss: 1.27673 v_acc: 0.69954 |  iteration: 11741 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 554 loss: 1.27872 acc: 0.70671 | v_loss: 1.11213 v_acc: 0.71549 |  iteration: 11742 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 555 loss: 1.23927 acc: 0.70280 | v_loss: 1.20398 v_acc: 0.69954 |  iteration: 11743 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 556 loss: 1.26511 acc: 0.70182 | v_loss: 1.14951 v_acc: 0.71224 |  iteration: 11744 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 557 loss: 1.21121 acc: 0.70833 | v_loss: 1.16462 v_acc: 0.70540 |  iteration: 11745 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 558 loss: 1.30645 acc: 0.69661 | v_loss: 1.04747 v_acc: 0.73665 |  iteration: 11746 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 559 loss: 1.19997 acc: 0.71582 | v_loss: 1.16837 v_acc: 0.71908 |  iteration: 11747 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 560 loss: 1.29154 acc: 0.70280 | v_loss: 1.09435 v_acc: 0.73372 |  iteration: 11748 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 561 loss: 1.28571 acc: 0.70443 | v_loss: 1.07037 v_acc: 0.72493 |  iteration: 11749 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 562 loss: 1.33250 acc: 0.69401 | v_loss: 1.15413 v_acc: 0.72135 |  iteration: 11750 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 563 loss: 1.29876 acc: 0.69661 | v_loss: 1.20137 v_acc: 0.71908 |  iteration: 11751 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 564 loss: 1.42546 acc: 0.69954 | v_loss: 1.20183 v_acc: 0.72103 |  iteration: 11752 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 565 loss: 1.24704 acc: 0.71257 | v_loss: 1.37330 v_acc: 0.69694 |  iteration: 11753 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 566 loss: 1.30898 acc: 0.70182 | v_loss: 1.25602 v_acc: 0.72233 |  iteration: 11754 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 567 loss: 1.30353 acc: 0.70182 | v_loss: 1.04104 v_acc: 0.74772 |  iteration: 11755 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 568 loss: 1.33443 acc: 0.70117 | v_loss: 1.18503 v_acc: 0.70703 |  iteration: 11756 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 569 loss: 1.25554 acc: 0.70964 | v_loss: 1.26969 v_acc: 0.69987 |  iteration: 11757 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 570 loss: 1.21401 acc: 0.71517 | v_loss: 1.19404 v_acc: 0.69531 |  iteration: 11758 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 571 loss: 1.32590 acc: 0.69694 | v_loss: 1.23263 v_acc: 0.71257 |  iteration: 11759 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 572 loss: 1.32599 acc: 0.70150 | v_loss: 1.20502 v_acc: 0.70052 |  iteration: 11760 teacher: 0 stage: sketch lr: 0.000408\n",
      "batch 573 loss: 1.28694 acc: 0.71354 | v_loss: 1.18263 v_acc: 0.71484 |  iteration: 11761 teacher: 1 stage: sketch lr: 0.000408\n",
      "batch 574 loss: 1.27596 acc: 0.70345 | v_loss: 1.22069 v_acc: 0.70410 |  iteration: 11762 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 575 loss: 1.33666 acc: 0.70020 | v_loss: 1.16690 v_acc: 0.71615 |  iteration: 11763 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 576 loss: 1.17147 acc: 0.71452 | v_loss: 1.13085 v_acc: 0.72852 |  iteration: 11764 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 577 loss: 1.30857 acc: 0.70215 | v_loss: 1.18069 v_acc: 0.70345 |  iteration: 11765 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 578 loss: 1.27835 acc: 0.70573 | v_loss: 1.29492 v_acc: 0.69889 |  iteration: 11766 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 579 loss: 1.29595 acc: 0.70996 | v_loss: 1.13801 v_acc: 0.70833 |  iteration: 11767 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 580 loss: 1.38962 acc: 0.70475 | v_loss: 1.38858 v_acc: 0.68555 |  iteration: 11768 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 581 loss: 1.21756 acc: 0.70768 | v_loss: 1.13087 v_acc: 0.72982 |  iteration: 11769 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 582 loss: 1.33554 acc: 0.69727 | v_loss: 1.44277 v_acc: 0.67806 |  iteration: 11770 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 583 loss: 1.26452 acc: 0.71615 | v_loss: 1.32860 v_acc: 0.69792 |  iteration: 11771 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 584 loss: 1.34066 acc: 0.69499 | v_loss: 1.30477 v_acc: 0.69661 |  iteration: 11772 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 585 loss: 1.19670 acc: 0.70964 | v_loss: 1.25959 v_acc: 0.70801 |  iteration: 11773 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 586 loss: 1.24861 acc: 0.70280 | v_loss: 1.18896 v_acc: 0.71257 |  iteration: 11774 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 587 loss: 1.27767 acc: 0.70508 | v_loss: 1.22839 v_acc: 0.70768 |  iteration: 11775 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 588 loss: 1.32575 acc: 0.69434 | v_loss: 1.17397 v_acc: 0.72493 |  iteration: 11776 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 589 loss: 1.34295 acc: 0.70312 | v_loss: 1.37291 v_acc: 0.68880 |  iteration: 11777 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 590 loss: 1.28523 acc: 0.70247 | v_loss: 1.24918 v_acc: 0.71289 |  iteration: 11778 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 591 loss: 1.26963 acc: 0.71517 | v_loss: 1.15759 v_acc: 0.71029 |  iteration: 11779 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 592 loss: 1.24153 acc: 0.70085 | v_loss: 1.23232 v_acc: 0.71452 |  iteration: 11780 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 593 loss: 1.28133 acc: 0.69987 | v_loss: 1.12551 v_acc: 0.71224 |  iteration: 11781 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 594 loss: 1.23430 acc: 0.70052 | v_loss: 1.24832 v_acc: 0.69922 |  iteration: 11782 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 595 loss: 1.28805 acc: 0.70638 | v_loss: 1.20054 v_acc: 0.71419 |  iteration: 11783 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 596 loss: 1.24989 acc: 0.71029 | v_loss: 1.14008 v_acc: 0.72331 |  iteration: 11784 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 597 loss: 1.31616 acc: 0.70573 | v_loss: 1.10571 v_acc: 0.72591 |  iteration: 11785 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 598 loss: 1.25044 acc: 0.71387 | v_loss: 1.23161 v_acc: 0.71647 |  iteration: 11786 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 599 loss: 1.22408 acc: 0.71615 | v_loss: 1.21831 v_acc: 0.70378 |  iteration: 11787 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 600 loss: 1.35271 acc: 0.69564 | v_loss: 1.23354 v_acc: 0.70638 |  iteration: 11788 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 601 loss: 1.28258 acc: 0.70052 | v_loss: 1.05889 v_acc: 0.72168 |  iteration: 11789 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 602 loss: 1.30966 acc: 0.70801 | v_loss: 1.23165 v_acc: 0.73242 |  iteration: 11790 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 603 loss: 1.26751 acc: 0.71159 | v_loss: 1.27459 v_acc: 0.70020 |  iteration: 11791 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 604 loss: 1.24013 acc: 0.70833 | v_loss: 1.30048 v_acc: 0.72624 |  iteration: 11792 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 605 loss: 1.26981 acc: 0.71224 | v_loss: 1.12527 v_acc: 0.72298 |  iteration: 11793 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 606 loss: 1.40293 acc: 0.68978 | v_loss: 1.07784 v_acc: 0.74089 |  iteration: 11794 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 607 loss: 1.29719 acc: 0.69954 | v_loss: 1.06896 v_acc: 0.72689 |  iteration: 11795 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 608 loss: 1.26617 acc: 0.69857 | v_loss: 1.15315 v_acc: 0.70898 |  iteration: 11796 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 609 loss: 1.21743 acc: 0.70182 | v_loss: 1.19074 v_acc: 0.71061 |  iteration: 11797 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 610 loss: 1.29914 acc: 0.70540 | v_loss: 1.15928 v_acc: 0.71517 |  iteration: 11798 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 611 loss: 1.29852 acc: 0.69141 | v_loss: 1.32836 v_acc: 0.69727 |  iteration: 11799 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 612 loss: 1.21379 acc: 0.70898 | v_loss: 1.41293 v_acc: 0.69792 |  iteration: 11800 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 613 loss: 1.23648 acc: 0.70443 | v_loss: 1.30734 v_acc: 0.70052 |  iteration: 11801 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 614 loss: 1.27953 acc: 0.70475 | v_loss: 1.15383 v_acc: 0.72298 |  iteration: 11802 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 615 loss: 1.28061 acc: 0.70443 | v_loss: 1.14151 v_acc: 0.71387 |  iteration: 11803 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 616 loss: 1.36843 acc: 0.69401 | v_loss: 1.11995 v_acc: 0.72559 |  iteration: 11804 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 617 loss: 1.26368 acc: 0.70475 | v_loss: 1.21242 v_acc: 0.70280 |  iteration: 11805 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 618 loss: 1.20743 acc: 0.71289 | v_loss: 1.20822 v_acc: 0.72168 |  iteration: 11806 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 619 loss: 1.28069 acc: 0.70410 | v_loss: 1.17641 v_acc: 0.73307 |  iteration: 11807 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 620 loss: 1.27750 acc: 0.69922 | v_loss: 1.22028 v_acc: 0.71940 |  iteration: 11808 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 621 loss: 1.24984 acc: 0.70475 | v_loss: 1.21874 v_acc: 0.71257 |  iteration: 11809 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 622 loss: 1.26088 acc: 0.71354 | v_loss: 1.12920 v_acc: 0.72461 |  iteration: 11810 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 623 loss: 1.22756 acc: 0.71745 | v_loss: 1.12121 v_acc: 0.72038 |  iteration: 11811 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 624 loss: 1.16952 acc: 0.71354 | v_loss: 1.43068 v_acc: 0.69076 |  iteration: 11812 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 625 loss: 1.25333 acc: 0.69889 | v_loss: 1.16659 v_acc: 0.71257 |  iteration: 11813 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 626 loss: 1.29870 acc: 0.71126 | v_loss: 1.18251 v_acc: 0.71875 |  iteration: 11814 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 627 loss: 1.22784 acc: 0.70931 | v_loss: 1.19036 v_acc: 0.71484 |  iteration: 11815 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 628 loss: 1.33888 acc: 0.70443 | v_loss: 1.22819 v_acc: 0.71029 |  iteration: 11816 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 629 loss: 1.27115 acc: 0.71029 | v_loss: 1.09617 v_acc: 0.73340 |  iteration: 11817 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 630 loss: 1.30452 acc: 0.69336 | v_loss: 1.32354 v_acc: 0.71842 |  iteration: 11818 teacher: 0 stage: sketch lr: 0.000407\n",
      "batch 631 loss: 1.34654 acc: 0.70671 | v_loss: 1.15679 v_acc: 0.70085 |  iteration: 11819 teacher: 1 stage: sketch lr: 0.000407\n",
      "batch 632 loss: 1.25025 acc: 0.70182 | v_loss: 1.16920 v_acc: 0.70736 |  iteration: 11820 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 633 loss: 1.19504 acc: 0.70671 | v_loss: 1.24313 v_acc: 0.70475 |  iteration: 11821 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 634 loss: 1.24575 acc: 0.70508 | v_loss: 1.25512 v_acc: 0.70443 |  iteration: 11822 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 635 loss: 1.38906 acc: 0.68945 | v_loss: 1.30696 v_acc: 0.69141 |  iteration: 11823 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 636 loss: 1.24730 acc: 0.71191 | v_loss: 1.32407 v_acc: 0.70703 |  iteration: 11824 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 637 loss: 1.25080 acc: 0.70247 | v_loss: 1.24320 v_acc: 0.70508 |  iteration: 11825 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 638 loss: 1.25255 acc: 0.70703 | v_loss: 1.16283 v_acc: 0.71061 |  iteration: 11826 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 639 loss: 1.33568 acc: 0.68848 | v_loss: 1.26544 v_acc: 0.70866 |  iteration: 11827 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 640 loss: 1.31157 acc: 0.70638 | v_loss: 1.15273 v_acc: 0.71484 |  iteration: 11828 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 641 loss: 1.18431 acc: 0.71029 | v_loss: 1.12905 v_acc: 0.72656 |  iteration: 11829 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 642 loss: 1.32079 acc: 0.69759 | v_loss: 1.07484 v_acc: 0.71061 |  iteration: 11830 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 643 loss: 1.30194 acc: 0.70996 | v_loss: 1.20545 v_acc: 0.71257 |  iteration: 11831 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 644 loss: 1.29056 acc: 0.69857 | v_loss: 1.28642 v_acc: 0.70280 |  iteration: 11832 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 645 loss: 1.21170 acc: 0.70573 | v_loss: 1.13351 v_acc: 0.71322 |  iteration: 11833 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 646 loss: 1.20499 acc: 0.70931 | v_loss: 1.19215 v_acc: 0.69987 |  iteration: 11834 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 647 loss: 1.23801 acc: 0.70898 | v_loss: 1.14600 v_acc: 0.71647 |  iteration: 11835 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 648 loss: 1.31508 acc: 0.70247 | v_loss: 1.16961 v_acc: 0.70703 |  iteration: 11836 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 649 loss: 1.24670 acc: 0.71257 | v_loss: 1.06445 v_acc: 0.73796 |  iteration: 11837 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 650 loss: 1.28606 acc: 0.70410 | v_loss: 1.15695 v_acc: 0.71908 |  iteration: 11838 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 651 loss: 1.29503 acc: 0.70052 | v_loss: 1.14096 v_acc: 0.72624 |  iteration: 11839 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 652 loss: 1.22079 acc: 0.71191 | v_loss: 1.09254 v_acc: 0.72884 |  iteration: 11840 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 653 loss: 1.25933 acc: 0.70605 | v_loss: 1.17060 v_acc: 0.72428 |  iteration: 11841 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 654 loss: 1.21044 acc: 0.71061 | v_loss: 1.20007 v_acc: 0.72168 |  iteration: 11842 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 655 loss: 1.24212 acc: 0.70150 | v_loss: 1.19997 v_acc: 0.72493 |  iteration: 11843 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 656 loss: 1.24087 acc: 0.70247 | v_loss: 1.35656 v_acc: 0.70378 |  iteration: 11844 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 657 loss: 1.20088 acc: 0.71517 | v_loss: 1.25006 v_acc: 0.72038 |  iteration: 11845 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 658 loss: 1.16219 acc: 0.70801 | v_loss: 1.02527 v_acc: 0.74740 |  iteration: 11846 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 659 loss: 1.25044 acc: 0.70964 | v_loss: 1.18384 v_acc: 0.70736 |  iteration: 11847 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 660 loss: 1.23824 acc: 0.70768 | v_loss: 1.23259 v_acc: 0.69987 |  iteration: 11848 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 661 loss: 1.24416 acc: 0.71191 | v_loss: 1.13879 v_acc: 0.69889 |  iteration: 11849 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 662 loss: 1.28877 acc: 0.70378 | v_loss: 1.21672 v_acc: 0.70964 |  iteration: 11850 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 663 loss: 1.22566 acc: 0.70508 | v_loss: 1.20305 v_acc: 0.69499 |  iteration: 11851 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 664 loss: 1.34983 acc: 0.69271 | v_loss: 1.17175 v_acc: 0.71908 |  iteration: 11852 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 665 loss: 1.27887 acc: 0.70378 | v_loss: 1.20853 v_acc: 0.70671 |  iteration: 11853 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 666 loss: 1.27461 acc: 0.71257 | v_loss: 1.17412 v_acc: 0.72135 |  iteration: 11854 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 667 loss: 1.20826 acc: 0.70768 | v_loss: 1.16044 v_acc: 0.72884 |  iteration: 11855 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 668 loss: 1.27027 acc: 0.70475 | v_loss: 1.18206 v_acc: 0.70280 |  iteration: 11856 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 669 loss: 1.19488 acc: 0.71777 | v_loss: 1.30080 v_acc: 0.69596 |  iteration: 11857 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 670 loss: 1.24386 acc: 0.70768 | v_loss: 1.11604 v_acc: 0.71094 |  iteration: 11858 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 671 loss: 1.30882 acc: 0.70085 | v_loss: 1.39586 v_acc: 0.68359 |  iteration: 11859 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 672 loss: 1.29233 acc: 0.69824 | v_loss: 1.15260 v_acc: 0.72168 |  iteration: 11860 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 673 loss: 1.32405 acc: 0.70085 | v_loss: 1.44978 v_acc: 0.67676 |  iteration: 11861 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 674 loss: 1.22214 acc: 0.70768 | v_loss: 1.34079 v_acc: 0.69857 |  iteration: 11862 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 675 loss: 1.29236 acc: 0.69954 | v_loss: 1.30562 v_acc: 0.69694 |  iteration: 11863 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 676 loss: 1.18293 acc: 0.71094 | v_loss: 1.25579 v_acc: 0.70605 |  iteration: 11864 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 677 loss: 1.27257 acc: 0.70736 | v_loss: 1.19401 v_acc: 0.71126 |  iteration: 11865 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 678 loss: 1.22663 acc: 0.71810 | v_loss: 1.21686 v_acc: 0.70671 |  iteration: 11866 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 679 loss: 1.20438 acc: 0.70638 | v_loss: 1.16604 v_acc: 0.72493 |  iteration: 11867 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 680 loss: 1.21839 acc: 0.71354 | v_loss: 1.38288 v_acc: 0.69043 |  iteration: 11868 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 681 loss: 1.25945 acc: 0.70182 | v_loss: 1.25485 v_acc: 0.71322 |  iteration: 11869 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 682 loss: 1.28844 acc: 0.69987 | v_loss: 1.15135 v_acc: 0.71354 |  iteration: 11870 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 683 loss: 1.28547 acc: 0.69857 | v_loss: 1.22581 v_acc: 0.71875 |  iteration: 11871 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 684 loss: 1.24717 acc: 0.70964 | v_loss: 1.14154 v_acc: 0.70931 |  iteration: 11872 teacher: 1 stage: sketch lr: 0.000406\n",
      "batch 685 loss: 1.31341 acc: 0.70150 | v_loss: 1.25910 v_acc: 0.69954 |  iteration: 11873 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 686 loss: 1.26525 acc: 0.69141 | v_loss: 1.24162 v_acc: 0.72298 |  iteration: 11874 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 687 loss: 1.35541 acc: 0.69727 | v_loss: 1.14389 v_acc: 0.72070 |  iteration: 11875 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 688 loss: 1.35632 acc: 0.69466 | v_loss: 1.13414 v_acc: 0.72396 |  iteration: 11876 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 689 loss: 1.24446 acc: 0.70117 | v_loss: 1.23987 v_acc: 0.71549 |  iteration: 11877 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 690 loss: 1.28427 acc: 0.70312 | v_loss: 1.22988 v_acc: 0.70410 |  iteration: 11878 teacher: 0 stage: sketch lr: 0.000406\n",
      "batch 691 loss: 1.26446 acc: 0.70475 | v_loss: 1.21180 v_acc: 0.71387 |  iteration: 11879 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 692 loss: 1.32313 acc: 0.69564 | v_loss: 1.06474 v_acc: 0.72721 |  iteration: 11880 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 693 loss: 1.28819 acc: 0.70280 | v_loss: 1.23171 v_acc: 0.73275 |  iteration: 11881 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 694 loss: 1.24771 acc: 0.70801 | v_loss: 1.26734 v_acc: 0.69987 |  iteration: 11882 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 695 loss: 1.24043 acc: 0.70703 | v_loss: 1.27505 v_acc: 0.72819 |  iteration: 11883 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 696 loss: 1.29885 acc: 0.69889 | v_loss: 1.14015 v_acc: 0.72168 |  iteration: 11884 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 697 loss: 1.24393 acc: 0.71126 | v_loss: 1.08913 v_acc: 0.73893 |  iteration: 11885 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 698 loss: 1.29035 acc: 0.70573 | v_loss: 1.07982 v_acc: 0.72559 |  iteration: 11886 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 699 loss: 1.28126 acc: 0.70508 | v_loss: 1.16988 v_acc: 0.71191 |  iteration: 11887 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 700 loss: 1.25742 acc: 0.71354 | v_loss: 1.21705 v_acc: 0.70573 |  iteration: 11888 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 701 loss: 1.28753 acc: 0.70768 | v_loss: 1.15111 v_acc: 0.71615 |  iteration: 11889 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 702 loss: 1.28181 acc: 0.70833 | v_loss: 1.29867 v_acc: 0.70247 |  iteration: 11890 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 703 loss: 1.29247 acc: 0.70182 | v_loss: 1.44629 v_acc: 0.69401 |  iteration: 11891 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 704 loss: 1.23828 acc: 0.72298 | v_loss: 1.32460 v_acc: 0.70052 |  iteration: 11892 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 705 loss: 1.34278 acc: 0.70182 | v_loss: 1.18576 v_acc: 0.72656 |  iteration: 11893 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 706 loss: 1.23638 acc: 0.70312 | v_loss: 1.15699 v_acc: 0.70866 |  iteration: 11894 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 707 loss: 1.27641 acc: 0.69954 | v_loss: 1.12000 v_acc: 0.72135 |  iteration: 11895 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 708 loss: 1.25211 acc: 0.70768 | v_loss: 1.20103 v_acc: 0.70638 |  iteration: 11896 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 709 loss: 1.25267 acc: 0.70605 | v_loss: 1.20477 v_acc: 0.71484 |  iteration: 11897 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 710 loss: 1.26265 acc: 0.70996 | v_loss: 1.19068 v_acc: 0.73177 |  iteration: 11898 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 711 loss: 1.34160 acc: 0.70410 | v_loss: 1.22572 v_acc: 0.71810 |  iteration: 11899 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 712 loss: 1.24627 acc: 0.70247 | v_loss: 1.21835 v_acc: 0.70833 |  iteration: 11900 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 713 loss: 1.30632 acc: 0.69824 | v_loss: 1.11882 v_acc: 0.73014 |  iteration: 11901 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 714 loss: 1.33644 acc: 0.69401 | v_loss: 1.10308 v_acc: 0.72298 |  iteration: 11902 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 715 loss: 1.33090 acc: 0.69824 | v_loss: 1.40604 v_acc: 0.69271 |  iteration: 11903 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 716 loss: 1.25375 acc: 0.70475 | v_loss: 1.18113 v_acc: 0.71289 |  iteration: 11904 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 717 loss: 1.25332 acc: 0.69727 | v_loss: 1.16247 v_acc: 0.72461 |  iteration: 11905 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 718 loss: 1.24588 acc: 0.70508 | v_loss: 1.19318 v_acc: 0.70020 |  iteration: 11906 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 719 loss: 1.26007 acc: 0.71061 | v_loss: 1.25205 v_acc: 0.70052 |  iteration: 11907 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 720 loss: 1.29371 acc: 0.70703 | v_loss: 1.12887 v_acc: 0.73210 |  iteration: 11908 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 721 loss: 1.25720 acc: 0.69661 | v_loss: 1.36239 v_acc: 0.71387 |  iteration: 11909 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 722 loss: 1.30084 acc: 0.70280 | v_loss: 1.15592 v_acc: 0.69629 |  iteration: 11910 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 723 loss: 1.31186 acc: 0.69629 | v_loss: 1.16249 v_acc: 0.70703 |  iteration: 11911 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 724 loss: 1.29600 acc: 0.69987 | v_loss: 1.25734 v_acc: 0.70508 |  iteration: 11912 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 725 loss: 1.21238 acc: 0.71484 | v_loss: 1.25680 v_acc: 0.70182 |  iteration: 11913 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 726 loss: 1.29134 acc: 0.70117 | v_loss: 1.32019 v_acc: 0.69401 |  iteration: 11914 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 727 loss: 1.23795 acc: 0.70605 | v_loss: 1.32928 v_acc: 0.71387 |  iteration: 11915 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 728 loss: 1.20342 acc: 0.71061 | v_loss: 1.24411 v_acc: 0.70736 |  iteration: 11916 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 729 loss: 1.26731 acc: 0.70605 | v_loss: 1.14397 v_acc: 0.71126 |  iteration: 11917 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 730 loss: 1.25757 acc: 0.70964 | v_loss: 1.28942 v_acc: 0.70931 |  iteration: 11918 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 731 loss: 1.27674 acc: 0.69889 | v_loss: 1.17575 v_acc: 0.71842 |  iteration: 11919 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 732 loss: 1.32286 acc: 0.69857 | v_loss: 1.10789 v_acc: 0.72559 |  iteration: 11920 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 733 loss: 1.28758 acc: 0.70182 | v_loss: 1.09686 v_acc: 0.71159 |  iteration: 11921 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 734 loss: 1.25795 acc: 0.71224 | v_loss: 1.20182 v_acc: 0.70671 |  iteration: 11922 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 735 loss: 1.25008 acc: 0.70833 | v_loss: 1.26958 v_acc: 0.69954 |  iteration: 11923 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 736 loss: 1.16443 acc: 0.71322 | v_loss: 1.13468 v_acc: 0.70866 |  iteration: 11924 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 737 loss: 1.19870 acc: 0.70703 | v_loss: 1.18551 v_acc: 0.69889 |  iteration: 11925 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 738 loss: 1.40747 acc: 0.68815 | v_loss: 1.14138 v_acc: 0.71126 |  iteration: 11926 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 739 loss: 1.21348 acc: 0.70085 | v_loss: 1.15268 v_acc: 0.71322 |  iteration: 11927 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 740 loss: 1.26749 acc: 0.70312 | v_loss: 1.08877 v_acc: 0.73796 |  iteration: 11928 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 741 loss: 1.21420 acc: 0.71582 | v_loss: 1.14476 v_acc: 0.71647 |  iteration: 11929 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 742 loss: 1.28512 acc: 0.70410 | v_loss: 1.13522 v_acc: 0.72396 |  iteration: 11930 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 743 loss: 1.36068 acc: 0.69629 | v_loss: 1.08852 v_acc: 0.73145 |  iteration: 11931 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 744 loss: 1.23872 acc: 0.70508 | v_loss: 1.17517 v_acc: 0.71973 |  iteration: 11932 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 745 loss: 1.21042 acc: 0.71029 | v_loss: 1.19318 v_acc: 0.71810 |  iteration: 11933 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 746 loss: 1.25877 acc: 0.69792 | v_loss: 1.18672 v_acc: 0.72526 |  iteration: 11934 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 747 loss: 1.25487 acc: 0.71159 | v_loss: 1.35353 v_acc: 0.70475 |  iteration: 11935 teacher: 1 stage: sketch lr: 0.000405\n",
      "batch 748 loss: 1.29285 acc: 0.70312 | v_loss: 1.22606 v_acc: 0.72135 |  iteration: 11936 teacher: 0 stage: sketch lr: 0.000405\n",
      "batch 749 loss: 1.26969 acc: 0.70410 | v_loss: 1.00952 v_acc: 0.74707 |  iteration: 11937 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 750 loss: 1.15054 acc: 0.71973 | v_loss: 1.17347 v_acc: 0.71061 |  iteration: 11938 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 751 loss: 1.23199 acc: 0.70866 | v_loss: 1.22852 v_acc: 0.70052 |  iteration: 11939 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 752 loss: 1.31163 acc: 0.70117 | v_loss: 1.14747 v_acc: 0.69824 |  iteration: 11940 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 753 loss: 1.37330 acc: 0.69857 | v_loss: 1.18933 v_acc: 0.71061 |  iteration: 11941 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 754 loss: 1.25484 acc: 0.70801 | v_loss: 1.20149 v_acc: 0.69987 |  iteration: 11942 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 755 loss: 1.24066 acc: 0.70247 | v_loss: 1.16621 v_acc: 0.71354 |  iteration: 11943 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 756 loss: 1.24357 acc: 0.71712 | v_loss: 1.20489 v_acc: 0.69857 |  iteration: 11944 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 757 loss: 1.26977 acc: 0.70345 | v_loss: 1.16362 v_acc: 0.71549 |  iteration: 11945 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 758 loss: 1.16428 acc: 0.70605 | v_loss: 1.12615 v_acc: 0.72689 |  iteration: 11946 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 759 loss: 1.17300 acc: 0.71810 | v_loss: 1.15356 v_acc: 0.70638 |  iteration: 11947 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 760 loss: 1.23128 acc: 0.71973 | v_loss: 1.27568 v_acc: 0.70573 |  iteration: 11948 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 761 loss: 1.27775 acc: 0.70540 | v_loss: 1.10340 v_acc: 0.71061 |  iteration: 11949 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 762 loss: 1.32830 acc: 0.69727 | v_loss: 1.33990 v_acc: 0.68945 |  iteration: 11950 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 763 loss: 1.26553 acc: 0.70443 | v_loss: 1.09765 v_acc: 0.72201 |  iteration: 11951 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 764 loss: 1.20997 acc: 0.72201 | v_loss: 1.42223 v_acc: 0.68327 |  iteration: 11952 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 765 loss: 1.20514 acc: 0.72201 | v_loss: 1.30671 v_acc: 0.69857 |  iteration: 11953 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 766 loss: 1.21857 acc: 0.70964 | v_loss: 1.29577 v_acc: 0.69303 |  iteration: 11954 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 767 loss: 1.31647 acc: 0.69694 | v_loss: 1.25179 v_acc: 0.70345 |  iteration: 11955 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 768 loss: 1.20011 acc: 0.71680 | v_loss: 1.18340 v_acc: 0.71224 |  iteration: 11956 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 769 loss: 1.33080 acc: 0.71061 | v_loss: 1.19972 v_acc: 0.71289 |  iteration: 11957 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 770 loss: 1.22711 acc: 0.71940 | v_loss: 1.16321 v_acc: 0.72233 |  iteration: 11958 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 771 loss: 1.20976 acc: 0.71615 | v_loss: 1.34677 v_acc: 0.69336 |  iteration: 11959 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 772 loss: 1.28600 acc: 0.71029 | v_loss: 1.24277 v_acc: 0.70801 |  iteration: 11960 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 773 loss: 1.14081 acc: 0.71419 | v_loss: 1.15325 v_acc: 0.71191 |  iteration: 11961 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 774 loss: 1.21976 acc: 0.71159 | v_loss: 1.20000 v_acc: 0.72103 |  iteration: 11962 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 775 loss: 1.20765 acc: 0.71224 | v_loss: 1.10681 v_acc: 0.71061 |  iteration: 11963 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 776 loss: 1.24035 acc: 0.71224 | v_loss: 1.20096 v_acc: 0.70085 |  iteration: 11964 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 777 loss: 1.32079 acc: 0.69303 | v_loss: 1.17406 v_acc: 0.72005 |  iteration: 11965 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 778 loss: 1.32469 acc: 0.69824 | v_loss: 1.12116 v_acc: 0.72070 |  iteration: 11966 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 779 loss: 1.25225 acc: 0.71712 | v_loss: 1.11385 v_acc: 0.72884 |  iteration: 11967 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 780 loss: 1.23865 acc: 0.71159 | v_loss: 1.21970 v_acc: 0.71549 |  iteration: 11968 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 781 loss: 1.39537 acc: 0.69792 | v_loss: 1.22433 v_acc: 0.70573 |  iteration: 11969 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 782 loss: 1.18819 acc: 0.70345 | v_loss: 1.21645 v_acc: 0.70964 |  iteration: 11970 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 783 loss: 1.31280 acc: 0.69857 | v_loss: 1.04365 v_acc: 0.72298 |  iteration: 11971 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 784 loss: 1.21456 acc: 0.70703 | v_loss: 1.21780 v_acc: 0.73340 |  iteration: 11972 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 785 loss: 1.26934 acc: 0.70605 | v_loss: 1.24802 v_acc: 0.69954 |  iteration: 11973 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 786 loss: 1.25781 acc: 0.70410 | v_loss: 1.25459 v_acc: 0.72721 |  iteration: 11974 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 787 loss: 1.38996 acc: 0.69694 | v_loss: 1.10774 v_acc: 0.72038 |  iteration: 11975 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 788 loss: 1.34004 acc: 0.70280 | v_loss: 1.06835 v_acc: 0.74121 |  iteration: 11976 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 789 loss: 1.24974 acc: 0.70508 | v_loss: 1.06300 v_acc: 0.72428 |  iteration: 11977 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 790 loss: 1.32043 acc: 0.70052 | v_loss: 1.14994 v_acc: 0.70671 |  iteration: 11978 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 791 loss: 1.27885 acc: 0.70475 | v_loss: 1.18703 v_acc: 0.70247 |  iteration: 11979 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 792 loss: 1.34154 acc: 0.68620 | v_loss: 1.14109 v_acc: 0.72103 |  iteration: 11980 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 793 loss: 1.14135 acc: 0.71126 | v_loss: 1.28171 v_acc: 0.70247 |  iteration: 11981 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 794 loss: 1.18703 acc: 0.71484 | v_loss: 1.42571 v_acc: 0.69238 |  iteration: 11982 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 795 loss: 1.23442 acc: 0.71094 | v_loss: 1.29574 v_acc: 0.70410 |  iteration: 11983 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 796 loss: 1.31885 acc: 0.70508 | v_loss: 1.15234 v_acc: 0.72689 |  iteration: 11984 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 797 loss: 1.30376 acc: 0.69629 | v_loss: 1.15158 v_acc: 0.70605 |  iteration: 11985 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 798 loss: 1.29331 acc: 0.70638 | v_loss: 1.09696 v_acc: 0.72201 |  iteration: 11986 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 799 loss: 1.37013 acc: 0.69499 | v_loss: 1.20624 v_acc: 0.70150 |  iteration: 11987 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 800 loss: 1.25774 acc: 0.70671 | v_loss: 1.21969 v_acc: 0.70996 |  iteration: 11988 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 801 loss: 1.18404 acc: 0.70312 | v_loss: 1.19696 v_acc: 0.72754 |  iteration: 11989 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 802 loss: 1.27618 acc: 0.70247 | v_loss: 1.21443 v_acc: 0.72233 |  iteration: 11990 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 803 loss: 1.28566 acc: 0.70182 | v_loss: 1.17738 v_acc: 0.71973 |  iteration: 11991 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 804 loss: 1.33171 acc: 0.70312 | v_loss: 1.11571 v_acc: 0.72786 |  iteration: 11992 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 805 loss: 1.31891 acc: 0.70247 | v_loss: 1.09499 v_acc: 0.72298 |  iteration: 11993 teacher: 1 stage: sketch lr: 0.000404\n",
      "batch 806 loss: 1.27000 acc: 0.71061 | v_loss: 1.45917 v_acc: 0.69141 |  iteration: 11994 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 807 loss: 1.31420 acc: 0.69694 | v_loss: 1.17123 v_acc: 0.71257 |  iteration: 11995 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 808 loss: 1.26108 acc: 0.70671 | v_loss: 1.17276 v_acc: 0.72038 |  iteration: 11996 teacher: 0 stage: sketch lr: 0.000404\n",
      "batch 809 loss: 1.17659 acc: 0.72331 | v_loss: 1.21062 v_acc: 0.70964 |  iteration: 11997 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 810 loss: 1.30540 acc: 0.71257 | v_loss: 1.23238 v_acc: 0.70378 |  iteration: 11998 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 811 loss: 1.20126 acc: 0.71484 | v_loss: 1.10369 v_acc: 0.73893 |  iteration: 11999 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 812 loss: 1.31793 acc: 0.70443 | v_loss: 1.31003 v_acc: 0.71842 |  iteration: 12000 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 813 loss: 1.15234 acc: 0.72070 | v_loss: 1.15350 v_acc: 0.70508 |  iteration: 12001 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 814 loss: 1.31186 acc: 0.69759 | v_loss: 1.16479 v_acc: 0.70475 |  iteration: 12002 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 815 loss: 1.26216 acc: 0.70443 | v_loss: 1.23249 v_acc: 0.70508 |  iteration: 12003 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 816 loss: 1.30122 acc: 0.70020 | v_loss: 1.22285 v_acc: 0.70312 |  iteration: 12004 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 817 loss: 1.26434 acc: 0.70964 | v_loss: 1.31231 v_acc: 0.69922 |  iteration: 12005 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 818 loss: 1.31748 acc: 0.70215 | v_loss: 1.32007 v_acc: 0.71094 |  iteration: 12006 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 819 loss: 1.21008 acc: 0.71126 | v_loss: 1.21951 v_acc: 0.70378 |  iteration: 12007 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 820 loss: 1.32892 acc: 0.69531 | v_loss: 1.14130 v_acc: 0.71517 |  iteration: 12008 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 821 loss: 1.20483 acc: 0.70182 | v_loss: 1.24508 v_acc: 0.71549 |  iteration: 12009 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 822 loss: 1.27626 acc: 0.69987 | v_loss: 1.14748 v_acc: 0.71875 |  iteration: 12010 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 823 loss: 1.30076 acc: 0.70052 | v_loss: 1.10025 v_acc: 0.72949 |  iteration: 12011 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 824 loss: 1.23351 acc: 0.71029 | v_loss: 1.05868 v_acc: 0.71387 |  iteration: 12012 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 825 loss: 1.18415 acc: 0.70573 | v_loss: 1.15977 v_acc: 0.71257 |  iteration: 12013 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 826 loss: 1.45788 acc: 0.68717 | v_loss: 1.21893 v_acc: 0.70345 |  iteration: 12014 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 827 loss: 1.30515 acc: 0.70312 | v_loss: 1.12602 v_acc: 0.72038 |  iteration: 12015 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 828 loss: 1.21831 acc: 0.70866 | v_loss: 1.15141 v_acc: 0.70508 |  iteration: 12016 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 829 loss: 1.22576 acc: 0.70085 | v_loss: 1.12642 v_acc: 0.72168 |  iteration: 12017 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 830 loss: 1.19339 acc: 0.71680 | v_loss: 1.15340 v_acc: 0.71061 |  iteration: 12018 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 831 loss: 1.31029 acc: 0.70150 | v_loss: 1.03139 v_acc: 0.74219 |  iteration: 12019 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 832 loss: 1.22090 acc: 0.70801 | v_loss: 1.11767 v_acc: 0.72526 |  iteration: 12020 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 833 loss: 1.27825 acc: 0.70117 | v_loss: 1.08847 v_acc: 0.71452 |  iteration: 12021 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 834 loss: 1.26711 acc: 0.70866 | v_loss: 1.07181 v_acc: 0.72949 |  iteration: 12022 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 835 loss: 1.21803 acc: 0.70866 | v_loss: 1.15358 v_acc: 0.72005 |  iteration: 12023 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 836 loss: 1.34972 acc: 0.69368 | v_loss: 1.13881 v_acc: 0.72233 |  iteration: 12024 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 837 loss: 1.15417 acc: 0.70866 | v_loss: 1.15709 v_acc: 0.72461 |  iteration: 12025 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 838 loss: 1.36780 acc: 0.69466 | v_loss: 1.38323 v_acc: 0.70150 |  iteration: 12026 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 839 loss: 1.23323 acc: 0.70345 | v_loss: 1.25525 v_acc: 0.72070 |  iteration: 12027 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 840 loss: 1.25682 acc: 0.70052 | v_loss: 1.01815 v_acc: 0.74577 |  iteration: 12028 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 841 loss: 1.18285 acc: 0.70703 | v_loss: 1.19866 v_acc: 0.70312 |  iteration: 12029 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 842 loss: 1.21774 acc: 0.71191 | v_loss: 1.19714 v_acc: 0.70540 |  iteration: 12030 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 843 loss: 1.28776 acc: 0.70182 | v_loss: 1.14632 v_acc: 0.70410 |  iteration: 12031 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 844 loss: 1.32575 acc: 0.69401 | v_loss: 1.20454 v_acc: 0.71452 |  iteration: 12032 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 845 loss: 1.28805 acc: 0.70996 | v_loss: 1.19359 v_acc: 0.70117 |  iteration: 12033 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 846 loss: 1.22999 acc: 0.71387 | v_loss: 1.15634 v_acc: 0.71354 |  iteration: 12034 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 847 loss: 1.23189 acc: 0.71517 | v_loss: 1.17429 v_acc: 0.70703 |  iteration: 12035 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 848 loss: 1.27999 acc: 0.71191 | v_loss: 1.15238 v_acc: 0.71647 |  iteration: 12036 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 849 loss: 1.31121 acc: 0.70475 | v_loss: 1.12974 v_acc: 0.73275 |  iteration: 12037 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 850 loss: 1.17381 acc: 0.71191 | v_loss: 1.13158 v_acc: 0.70378 |  iteration: 12038 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 851 loss: 1.26378 acc: 0.70150 | v_loss: 1.28321 v_acc: 0.69661 |  iteration: 12039 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 852 loss: 1.23047 acc: 0.71549 | v_loss: 1.11329 v_acc: 0.71126 |  iteration: 12040 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 853 loss: 1.20998 acc: 0.70573 | v_loss: 1.35142 v_acc: 0.68587 |  iteration: 12041 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 854 loss: 1.25393 acc: 0.70833 | v_loss: 1.10357 v_acc: 0.72721 |  iteration: 12042 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 855 loss: 1.18001 acc: 0.71094 | v_loss: 1.43044 v_acc: 0.68327 |  iteration: 12043 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 856 loss: 1.27749 acc: 0.70964 | v_loss: 1.31159 v_acc: 0.70117 |  iteration: 12044 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 857 loss: 1.24854 acc: 0.70898 | v_loss: 1.27341 v_acc: 0.69694 |  iteration: 12045 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 858 loss: 1.37383 acc: 0.69629 | v_loss: 1.24572 v_acc: 0.70508 |  iteration: 12046 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 859 loss: 1.22760 acc: 0.71452 | v_loss: 1.15035 v_acc: 0.71126 |  iteration: 12047 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 860 loss: 1.24347 acc: 0.70703 | v_loss: 1.20910 v_acc: 0.70736 |  iteration: 12048 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 861 loss: 1.24211 acc: 0.70671 | v_loss: 1.14397 v_acc: 0.72070 |  iteration: 12049 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 862 loss: 1.20623 acc: 0.70768 | v_loss: 1.35237 v_acc: 0.69336 |  iteration: 12050 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 863 loss: 1.24580 acc: 0.71224 | v_loss: 1.23290 v_acc: 0.70996 |  iteration: 12051 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 864 loss: 1.24297 acc: 0.70671 | v_loss: 1.13169 v_acc: 0.71191 |  iteration: 12052 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 865 loss: 1.21125 acc: 0.70898 | v_loss: 1.21176 v_acc: 0.71875 |  iteration: 12053 teacher: 1 stage: sketch lr: 0.000403\n",
      "batch 866 loss: 1.26717 acc: 0.70117 | v_loss: 1.11649 v_acc: 0.70801 |  iteration: 12054 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 867 loss: 1.25582 acc: 0.70475 | v_loss: 1.20199 v_acc: 0.69987 |  iteration: 12055 teacher: 0 stage: sketch lr: 0.000403\n",
      "batch 868 loss: 1.30445 acc: 0.71126 | v_loss: 1.18113 v_acc: 0.71745 |  iteration: 12056 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 869 loss: 1.21960 acc: 0.71094 | v_loss: 1.09279 v_acc: 0.72298 |  iteration: 12057 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 870 loss: 1.34977 acc: 0.69434 | v_loss: 1.08128 v_acc: 0.72819 |  iteration: 12058 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 871 loss: 1.21022 acc: 0.70280 | v_loss: 1.21828 v_acc: 0.71549 |  iteration: 12059 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 872 loss: 1.25721 acc: 0.69564 | v_loss: 1.19783 v_acc: 0.70638 |  iteration: 12060 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 873 loss: 1.24219 acc: 0.70833 | v_loss: 1.18166 v_acc: 0.71159 |  iteration: 12061 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 874 loss: 1.24631 acc: 0.70475 | v_loss: 1.02900 v_acc: 0.72363 |  iteration: 12062 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 875 loss: 1.24624 acc: 0.71061 | v_loss: 1.20322 v_acc: 0.73307 |  iteration: 12063 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 876 loss: 1.29037 acc: 0.70020 | v_loss: 1.24377 v_acc: 0.70280 |  iteration: 12064 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 877 loss: 1.21978 acc: 0.71061 | v_loss: 1.26854 v_acc: 0.72624 |  iteration: 12065 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 878 loss: 1.20273 acc: 0.70540 | v_loss: 1.09454 v_acc: 0.72103 |  iteration: 12066 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 879 loss: 1.24425 acc: 0.70573 | v_loss: 1.07598 v_acc: 0.73861 |  iteration: 12067 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 880 loss: 1.19062 acc: 0.71875 | v_loss: 1.06589 v_acc: 0.72168 |  iteration: 12068 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 881 loss: 1.21954 acc: 0.71126 | v_loss: 1.13492 v_acc: 0.70475 |  iteration: 12069 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 882 loss: 1.27364 acc: 0.69922 | v_loss: 1.14979 v_acc: 0.71191 |  iteration: 12070 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 883 loss: 1.30637 acc: 0.69629 | v_loss: 1.17040 v_acc: 0.71582 |  iteration: 12071 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 884 loss: 1.26764 acc: 0.70573 | v_loss: 1.25631 v_acc: 0.69694 |  iteration: 12072 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 885 loss: 1.40746 acc: 0.69792 | v_loss: 1.41324 v_acc: 0.70117 |  iteration: 12073 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 886 loss: 1.23245 acc: 0.70931 | v_loss: 1.29357 v_acc: 0.70638 |  iteration: 12074 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 887 loss: 1.32239 acc: 0.70768 | v_loss: 1.13266 v_acc: 0.72038 |  iteration: 12075 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 888 loss: 1.30769 acc: 0.69987 | v_loss: 1.12700 v_acc: 0.71257 |  iteration: 12076 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 889 loss: 1.26464 acc: 0.70475 | v_loss: 1.09072 v_acc: 0.72689 |  iteration: 12077 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 890 loss: 1.28300 acc: 0.70085 | v_loss: 1.15207 v_acc: 0.71126 |  iteration: 12078 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 891 loss: 1.24266 acc: 0.70573 | v_loss: 1.18200 v_acc: 0.71712 |  iteration: 12079 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 892 loss: 1.22994 acc: 0.70866 | v_loss: 1.15575 v_acc: 0.73568 |  iteration: 12080 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 893 loss: 1.20702 acc: 0.70898 | v_loss: 1.17428 v_acc: 0.72266 |  iteration: 12081 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 894 loss: 1.33778 acc: 0.69694 | v_loss: 1.16248 v_acc: 0.71191 |  iteration: 12082 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 895 loss: 1.18450 acc: 0.71094 | v_loss: 1.09595 v_acc: 0.72493 |  iteration: 12083 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 896 loss: 1.31385 acc: 0.69629 | v_loss: 1.09792 v_acc: 0.72005 |  iteration: 12084 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 897 loss: 1.19295 acc: 0.72005 | v_loss: 1.44969 v_acc: 0.69043 |  iteration: 12085 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 898 loss: 1.27861 acc: 0.70768 | v_loss: 1.13712 v_acc: 0.71257 |  iteration: 12086 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 899 loss: 1.34793 acc: 0.69954 | v_loss: 1.15181 v_acc: 0.72168 |  iteration: 12087 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 900 loss: 1.18691 acc: 0.72331 | v_loss: 1.18721 v_acc: 0.71745 |  iteration: 12088 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 901 loss: 1.24280 acc: 0.71517 | v_loss: 1.19513 v_acc: 0.70866 |  iteration: 12089 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 902 loss: 1.26715 acc: 0.70801 | v_loss: 1.08965 v_acc: 0.73828 |  iteration: 12090 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 903 loss: 1.21735 acc: 0.70964 | v_loss: 1.30528 v_acc: 0.72038 |  iteration: 12091 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 904 loss: 1.21039 acc: 0.71712 | v_loss: 1.16448 v_acc: 0.70150 |  iteration: 12092 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 905 loss: 1.29328 acc: 0.70671 | v_loss: 1.16543 v_acc: 0.70378 |  iteration: 12093 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 906 loss: 1.22024 acc: 0.71159 | v_loss: 1.23495 v_acc: 0.70443 |  iteration: 12094 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 907 loss: 1.22911 acc: 0.70312 | v_loss: 1.20766 v_acc: 0.70378 |  iteration: 12095 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 908 loss: 1.19228 acc: 0.71257 | v_loss: 1.29828 v_acc: 0.69499 |  iteration: 12096 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 909 loss: 1.23094 acc: 0.70833 | v_loss: 1.31183 v_acc: 0.71322 |  iteration: 12097 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 910 loss: 1.33643 acc: 0.69922 | v_loss: 1.25718 v_acc: 0.70443 |  iteration: 12098 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 911 loss: 1.20984 acc: 0.70671 | v_loss: 1.13689 v_acc: 0.71810 |  iteration: 12099 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 912 loss: 1.20464 acc: 0.71029 | v_loss: 1.24527 v_acc: 0.71647 |  iteration: 12100 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 913 loss: 1.28844 acc: 0.69271 | v_loss: 1.14476 v_acc: 0.71940 |  iteration: 12101 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 914 loss: 1.35338 acc: 0.69238 | v_loss: 1.08584 v_acc: 0.72982 |  iteration: 12102 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 915 loss: 1.25091 acc: 0.70833 | v_loss: 1.06081 v_acc: 0.71029 |  iteration: 12103 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 916 loss: 1.24603 acc: 0.70540 | v_loss: 1.17485 v_acc: 0.71094 |  iteration: 12104 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 917 loss: 1.24157 acc: 0.70117 | v_loss: 1.23754 v_acc: 0.70150 |  iteration: 12105 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 918 loss: 1.30604 acc: 0.69727 | v_loss: 1.10588 v_acc: 0.71973 |  iteration: 12106 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 919 loss: 1.19530 acc: 0.70410 | v_loss: 1.20014 v_acc: 0.69824 |  iteration: 12107 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 920 loss: 1.22322 acc: 0.70964 | v_loss: 1.13737 v_acc: 0.71647 |  iteration: 12108 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 921 loss: 1.27731 acc: 0.69889 | v_loss: 1.13867 v_acc: 0.70964 |  iteration: 12109 teacher: 0 stage: sketch lr: 0.000402\n",
      "batch 922 loss: 1.27162 acc: 0.69857 | v_loss: 1.03506 v_acc: 0.74186 |  iteration: 12110 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 923 loss: 1.24367 acc: 0.70085 | v_loss: 1.11889 v_acc: 0.72233 |  iteration: 12111 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 924 loss: 1.19277 acc: 0.70280 | v_loss: 1.04823 v_acc: 0.73242 |  iteration: 12112 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 925 loss: 1.28383 acc: 0.69694 | v_loss: 1.05294 v_acc: 0.73014 |  iteration: 12113 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 926 loss: 1.27356 acc: 0.71224 | v_loss: 1.14480 v_acc: 0.72266 |  iteration: 12114 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 927 loss: 1.18572 acc: 0.71094 | v_loss: 1.12724 v_acc: 0.72201 |  iteration: 12115 teacher: 1 stage: sketch lr: 0.000402\n",
      "batch 928 loss: 1.21962 acc: 0.71029 | v_loss: 1.16124 v_acc: 0.72786 |  iteration: 12116 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 929 loss: 1.19909 acc: 0.71647 | v_loss: 1.34632 v_acc: 0.70215 |  iteration: 12117 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 930 loss: 1.20593 acc: 0.70150 | v_loss: 1.23426 v_acc: 0.72721 |  iteration: 12118 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 931 loss: 1.18513 acc: 0.70964 | v_loss: 0.97802 v_acc: 0.74251 |  iteration: 12119 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 932 loss: 1.27004 acc: 0.70931 | v_loss: 1.19170 v_acc: 0.70703 |  iteration: 12120 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 933 loss: 1.17880 acc: 0.71061 | v_loss: 1.19201 v_acc: 0.70117 |  iteration: 12121 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 934 loss: 1.19400 acc: 0.71224 | v_loss: 1.14745 v_acc: 0.69694 |  iteration: 12122 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 935 loss: 1.35271 acc: 0.68620 | v_loss: 1.21228 v_acc: 0.71419 |  iteration: 12123 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 936 loss: 1.26603 acc: 0.70150 | v_loss: 1.17385 v_acc: 0.70247 |  iteration: 12124 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 937 loss: 1.30219 acc: 0.69661 | v_loss: 1.16305 v_acc: 0.71484 |  iteration: 12125 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 938 loss: 1.18873 acc: 0.71745 | v_loss: 1.17569 v_acc: 0.70443 |  iteration: 12126 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 939 loss: 1.24560 acc: 0.70475 | v_loss: 1.12496 v_acc: 0.71875 |  iteration: 12127 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 940 loss: 1.25942 acc: 0.70931 | v_loss: 1.11089 v_acc: 0.72949 |  iteration: 12128 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 941 loss: 1.24353 acc: 0.69922 | v_loss: 1.13225 v_acc: 0.70638 |  iteration: 12129 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 942 loss: 1.34033 acc: 0.69792 | v_loss: 1.24693 v_acc: 0.70475 |  iteration: 12130 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 943 loss: 1.15293 acc: 0.70605 | v_loss: 1.08820 v_acc: 0.71582 |  iteration: 12131 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 944 loss: 1.19852 acc: 0.71094 | v_loss: 1.33969 v_acc: 0.68685 |  iteration: 12132 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 945 loss: 1.17236 acc: 0.71810 | v_loss: 1.09160 v_acc: 0.73145 |  iteration: 12133 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 946 loss: 1.27614 acc: 0.70345 | v_loss: 1.41211 v_acc: 0.68262 |  iteration: 12134 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 947 loss: 1.31320 acc: 0.70703 | v_loss: 1.29756 v_acc: 0.69661 |  iteration: 12135 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 948 loss: 1.22738 acc: 0.70931 | v_loss: 1.25504 v_acc: 0.69596 |  iteration: 12136 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 949 loss: 1.23580 acc: 0.70508 | v_loss: 1.24337 v_acc: 0.70117 |  iteration: 12137 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 950 loss: 1.26897 acc: 0.70020 | v_loss: 1.15267 v_acc: 0.70996 |  iteration: 12138 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 951 loss: 1.27238 acc: 0.70247 | v_loss: 1.19445 v_acc: 0.70768 |  iteration: 12139 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 952 loss: 1.31319 acc: 0.69987 | v_loss: 1.14821 v_acc: 0.72201 |  iteration: 12140 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 953 loss: 1.35655 acc: 0.70020 | v_loss: 1.36369 v_acc: 0.69076 |  iteration: 12141 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 954 loss: 1.24352 acc: 0.70182 | v_loss: 1.23836 v_acc: 0.71126 |  iteration: 12142 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 955 loss: 1.26430 acc: 0.70052 | v_loss: 1.12774 v_acc: 0.71484 |  iteration: 12143 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 956 loss: 1.16928 acc: 0.71517 | v_loss: 1.22144 v_acc: 0.71973 |  iteration: 12144 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 957 loss: 1.16258 acc: 0.71159 | v_loss: 1.10373 v_acc: 0.71029 |  iteration: 12145 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 958 loss: 1.20278 acc: 0.71484 | v_loss: 1.22452 v_acc: 0.70638 |  iteration: 12146 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 959 loss: 1.19746 acc: 0.71159 | v_loss: 1.19073 v_acc: 0.72005 |  iteration: 12147 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 960 loss: 1.23099 acc: 0.70508 | v_loss: 1.09640 v_acc: 0.72331 |  iteration: 12148 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 961 loss: 1.14742 acc: 0.71712 | v_loss: 1.08738 v_acc: 0.73242 |  iteration: 12149 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 962 loss: 1.22718 acc: 0.70443 | v_loss: 1.21396 v_acc: 0.71745 |  iteration: 12150 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 963 loss: 1.27434 acc: 0.70671 | v_loss: 1.19358 v_acc: 0.71191 |  iteration: 12151 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 964 loss: 1.26755 acc: 0.69661 | v_loss: 1.19844 v_acc: 0.71354 |  iteration: 12152 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 965 loss: 1.20965 acc: 0.70638 | v_loss: 1.03243 v_acc: 0.72526 |  iteration: 12153 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 966 loss: 1.21343 acc: 0.70410 | v_loss: 1.20384 v_acc: 0.73438 |  iteration: 12154 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 967 loss: 1.23898 acc: 0.71126 | v_loss: 1.25174 v_acc: 0.70280 |  iteration: 12155 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 968 loss: 1.20475 acc: 0.70605 | v_loss: 1.24153 v_acc: 0.72624 |  iteration: 12156 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 969 loss: 1.36240 acc: 0.69141 | v_loss: 1.09127 v_acc: 0.72298 |  iteration: 12157 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 970 loss: 1.21630 acc: 0.70964 | v_loss: 1.09096 v_acc: 0.73340 |  iteration: 12158 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 971 loss: 1.37362 acc: 0.69173 | v_loss: 1.04638 v_acc: 0.72689 |  iteration: 12159 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 972 loss: 1.22618 acc: 0.70898 | v_loss: 1.14905 v_acc: 0.70540 |  iteration: 12160 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 973 loss: 1.20482 acc: 0.71354 | v_loss: 1.15532 v_acc: 0.70638 |  iteration: 12161 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 974 loss: 1.23278 acc: 0.70605 | v_loss: 1.14799 v_acc: 0.71419 |  iteration: 12162 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 975 loss: 1.25506 acc: 0.69401 | v_loss: 1.25724 v_acc: 0.71224 |  iteration: 12163 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 976 loss: 1.23992 acc: 0.70964 | v_loss: 1.40949 v_acc: 0.69531 |  iteration: 12164 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 977 loss: 1.27477 acc: 0.69857 | v_loss: 1.28605 v_acc: 0.70312 |  iteration: 12165 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 978 loss: 1.25522 acc: 0.70052 | v_loss: 1.16483 v_acc: 0.72038 |  iteration: 12166 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 979 loss: 1.21671 acc: 0.69303 | v_loss: 1.10218 v_acc: 0.70996 |  iteration: 12167 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 980 loss: 1.09772 acc: 0.72168 | v_loss: 1.06861 v_acc: 0.72428 |  iteration: 12168 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 981 loss: 1.26180 acc: 0.70931 | v_loss: 1.14987 v_acc: 0.71029 |  iteration: 12169 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 982 loss: 1.27668 acc: 0.70475 | v_loss: 1.18954 v_acc: 0.71712 |  iteration: 12170 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 983 loss: 1.21547 acc: 0.70605 | v_loss: 1.16379 v_acc: 0.72852 |  iteration: 12171 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 984 loss: 1.20690 acc: 0.70964 | v_loss: 1.17894 v_acc: 0.72363 |  iteration: 12172 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 985 loss: 1.17602 acc: 0.71712 | v_loss: 1.16453 v_acc: 0.71387 |  iteration: 12173 teacher: 0 stage: sketch lr: 0.000401\n",
      "batch 986 loss: 1.28567 acc: 0.70182 | v_loss: 1.10784 v_acc: 0.72852 |  iteration: 12174 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 987 loss: 1.19770 acc: 0.71061 | v_loss: 1.09143 v_acc: 0.72298 |  iteration: 12175 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 988 loss: 1.25213 acc: 0.71191 | v_loss: 1.47854 v_acc: 0.68978 |  iteration: 12176 teacher: 1 stage: sketch lr: 0.000401\n",
      "batch 989 loss: 1.26051 acc: 0.70215 | v_loss: 1.17119 v_acc: 0.71191 |  iteration: 12177 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 990 loss: 1.25010 acc: 0.71712 | v_loss: 1.18530 v_acc: 0.72233 |  iteration: 12178 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 991 loss: 1.22865 acc: 0.70996 | v_loss: 1.17928 v_acc: 0.71582 |  iteration: 12179 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 992 loss: 1.19430 acc: 0.71094 | v_loss: 1.20627 v_acc: 0.70475 |  iteration: 12180 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 993 loss: 1.22849 acc: 0.70475 | v_loss: 1.09182 v_acc: 0.73698 |  iteration: 12181 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 994 loss: 1.31634 acc: 0.69824 | v_loss: 1.32085 v_acc: 0.71940 |  iteration: 12182 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 995 loss: 1.24989 acc: 0.70117 | v_loss: 1.16649 v_acc: 0.70020 |  iteration: 12183 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 996 loss: 1.32894 acc: 0.69759 | v_loss: 1.17003 v_acc: 0.70378 |  iteration: 12184 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 997 loss: 1.30650 acc: 0.69694 | v_loss: 1.24957 v_acc: 0.70508 |  iteration: 12185 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 998 loss: 1.24909 acc: 0.71094 | v_loss: 1.23717 v_acc: 0.70410 |  iteration: 12186 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 999 loss: 1.26639 acc: 0.70280 | v_loss: 1.30834 v_acc: 0.69564 |  iteration: 12187 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1000 loss: 1.29184 acc: 0.69629 | v_loss: 1.34325 v_acc: 0.71061 |  iteration: 12188 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1001 loss: 1.32309 acc: 0.70020 | v_loss: 1.26643 v_acc: 0.70410 |  iteration: 12189 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1002 loss: 1.31170 acc: 0.70052 | v_loss: 1.16847 v_acc: 0.71094 |  iteration: 12190 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1003 loss: 1.23097 acc: 0.70345 | v_loss: 1.29914 v_acc: 0.70605 |  iteration: 12191 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1004 loss: 1.35301 acc: 0.69206 | v_loss: 1.20493 v_acc: 0.71322 |  iteration: 12192 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1005 loss: 1.19857 acc: 0.71354 | v_loss: 1.14507 v_acc: 0.72461 |  iteration: 12193 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1006 loss: 1.32613 acc: 0.70052 | v_loss: 1.13058 v_acc: 0.70996 |  iteration: 12194 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1007 loss: 1.27372 acc: 0.70833 | v_loss: 1.26145 v_acc: 0.70540 |  iteration: 12195 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1008 loss: 1.27179 acc: 0.69759 | v_loss: 1.30981 v_acc: 0.69206 |  iteration: 12196 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1009 loss: 1.25249 acc: 0.70573 | v_loss: 1.14090 v_acc: 0.71582 |  iteration: 12197 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1010 loss: 1.27791 acc: 0.69889 | v_loss: 1.19192 v_acc: 0.69661 |  iteration: 12198 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1011 loss: 1.24882 acc: 0.71061 | v_loss: 1.18739 v_acc: 0.70996 |  iteration: 12199 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1012 loss: 1.25655 acc: 0.70345 | v_loss: 1.19303 v_acc: 0.70638 |  iteration: 12200 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1013 loss: 1.27470 acc: 0.71191 | v_loss: 1.07034 v_acc: 0.73600 |  iteration: 12201 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1014 loss: 1.11812 acc: 0.72201 | v_loss: 1.16199 v_acc: 0.71875 |  iteration: 12202 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1015 loss: 1.29219 acc: 0.69922 | v_loss: 1.14477 v_acc: 0.72917 |  iteration: 12203 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1016 loss: 1.28294 acc: 0.70605 | v_loss: 1.11385 v_acc: 0.72070 |  iteration: 12204 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1017 loss: 1.30734 acc: 0.69889 | v_loss: 1.19565 v_acc: 0.71615 |  iteration: 12205 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1018 loss: 1.24293 acc: 0.71387 | v_loss: 1.22475 v_acc: 0.71419 |  iteration: 12206 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1019 loss: 1.33688 acc: 0.69596 | v_loss: 1.19948 v_acc: 0.72038 |  iteration: 12207 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1020 loss: 1.19073 acc: 0.71224 | v_loss: 1.38185 v_acc: 0.70020 |  iteration: 12208 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1021 loss: 1.17630 acc: 0.71680 | v_loss: 1.25369 v_acc: 0.72005 |  iteration: 12209 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1022 loss: 1.24443 acc: 0.70768 | v_loss: 1.03502 v_acc: 0.74447 |  iteration: 12210 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1023 loss: 1.21078 acc: 0.71549 | v_loss: 1.22626 v_acc: 0.70931 |  iteration: 12211 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1024 loss: 1.24662 acc: 0.70540 | v_loss: 1.25194 v_acc: 0.70182 |  iteration: 12212 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1025 loss: 1.29461 acc: 0.70410 | v_loss: 1.19934 v_acc: 0.70736 |  iteration: 12213 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1026 loss: 1.25671 acc: 0.71615 | v_loss: 1.22604 v_acc: 0.71289 |  iteration: 12214 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1027 loss: 1.27605 acc: 0.70280 | v_loss: 1.25249 v_acc: 0.69173 |  iteration: 12215 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1028 loss: 1.26671 acc: 0.70345 | v_loss: 1.20016 v_acc: 0.71322 |  iteration: 12216 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1029 loss: 1.33590 acc: 0.70540 | v_loss: 1.22414 v_acc: 0.69857 |  iteration: 12217 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1030 loss: 1.24489 acc: 0.70671 | v_loss: 1.21080 v_acc: 0.70605 |  iteration: 12218 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1031 loss: 1.35552 acc: 0.69303 | v_loss: 1.20425 v_acc: 0.72233 |  iteration: 12219 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1032 loss: 1.28034 acc: 0.70117 | v_loss: 1.26216 v_acc: 0.70215 |  iteration: 12220 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1033 loss: 1.30584 acc: 0.70247 | v_loss: 1.28461 v_acc: 0.69987 |  iteration: 12221 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1034 loss: 1.23884 acc: 0.70475 | v_loss: 1.15214 v_acc: 0.70833 |  iteration: 12222 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1035 loss: 1.24496 acc: 0.70866 | v_loss: 1.37868 v_acc: 0.68750 |  iteration: 12223 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1036 loss: 1.21900 acc: 0.70508 | v_loss: 1.18077 v_acc: 0.71810 |  iteration: 12224 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1037 loss: 1.29849 acc: 0.69759 | v_loss: 1.43904 v_acc: 0.68587 |  iteration: 12225 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1038 loss: 1.24427 acc: 0.71029 | v_loss: 1.31440 v_acc: 0.69922 |  iteration: 12226 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1039 loss: 1.23241 acc: 0.71517 | v_loss: 1.29756 v_acc: 0.69206 |  iteration: 12227 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1040 loss: 1.35642 acc: 0.70247 | v_loss: 1.29458 v_acc: 0.70085 |  iteration: 12228 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1041 loss: 1.30333 acc: 0.70443 | v_loss: 1.18716 v_acc: 0.70605 |  iteration: 12229 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1042 loss: 1.29803 acc: 0.70150 | v_loss: 1.24527 v_acc: 0.70671 |  iteration: 12230 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1043 loss: 1.25143 acc: 0.70280 | v_loss: 1.20208 v_acc: 0.72135 |  iteration: 12231 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1044 loss: 1.23473 acc: 0.70475 | v_loss: 1.39672 v_acc: 0.68652 |  iteration: 12232 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1045 loss: 1.33416 acc: 0.69824 | v_loss: 1.27293 v_acc: 0.70671 |  iteration: 12233 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1046 loss: 1.18441 acc: 0.71387 | v_loss: 1.18493 v_acc: 0.70605 |  iteration: 12234 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1047 loss: 1.27105 acc: 0.69954 | v_loss: 1.23663 v_acc: 0.71224 |  iteration: 12235 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1048 loss: 1.30250 acc: 0.70247 | v_loss: 1.15686 v_acc: 0.70475 |  iteration: 12236 teacher: 0 stage: sketch lr: 0.000400\n",
      "batch 1049 loss: 1.30844 acc: 0.70410 | v_loss: 1.24242 v_acc: 0.69629 |  iteration: 12237 teacher: 1 stage: sketch lr: 0.000400\n",
      "batch 1050 loss: 1.23507 acc: 0.70508 | v_loss: 1.22366 v_acc: 0.71322 |  iteration: 12238 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1051 loss: 1.29585 acc: 0.69954 | v_loss: 1.15996 v_acc: 0.71582 |  iteration: 12239 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1052 loss: 1.21803 acc: 0.69857 | v_loss: 1.12973 v_acc: 0.72754 |  iteration: 12240 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1053 loss: 1.19619 acc: 0.71484 | v_loss: 1.23360 v_acc: 0.71908 |  iteration: 12241 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1054 loss: 1.25377 acc: 0.70638 | v_loss: 1.21888 v_acc: 0.70410 |  iteration: 12242 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1055 loss: 1.32904 acc: 0.71159 | v_loss: 1.21512 v_acc: 0.70801 |  iteration: 12243 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1056 loss: 1.29316 acc: 0.70703 | v_loss: 1.06370 v_acc: 0.71745 |  iteration: 12244 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1057 loss: 1.28550 acc: 0.71354 | v_loss: 1.23901 v_acc: 0.73014 |  iteration: 12245 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1058 loss: 1.20297 acc: 0.71517 | v_loss: 1.27477 v_acc: 0.69889 |  iteration: 12246 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1059 loss: 1.22067 acc: 0.71257 | v_loss: 1.27462 v_acc: 0.72266 |  iteration: 12247 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1060 loss: 1.26292 acc: 0.70866 | v_loss: 1.13532 v_acc: 0.72428 |  iteration: 12248 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1061 loss: 1.27201 acc: 0.70443 | v_loss: 1.08407 v_acc: 0.73600 |  iteration: 12249 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1062 loss: 1.28980 acc: 0.70801 | v_loss: 1.08301 v_acc: 0.72786 |  iteration: 12250 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1063 loss: 1.29613 acc: 0.69987 | v_loss: 1.17923 v_acc: 0.70703 |  iteration: 12251 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1064 loss: 1.18740 acc: 0.71680 | v_loss: 1.22163 v_acc: 0.69759 |  iteration: 12252 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1065 loss: 1.28601 acc: 0.70410 | v_loss: 1.16158 v_acc: 0.71875 |  iteration: 12253 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1066 loss: 1.24310 acc: 0.71094 | v_loss: 1.29240 v_acc: 0.70475 |  iteration: 12254 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1067 loss: 1.29953 acc: 0.70052 | v_loss: 1.46099 v_acc: 0.69303 |  iteration: 12255 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1068 loss: 1.27776 acc: 0.71322 | v_loss: 1.33062 v_acc: 0.70280 |  iteration: 12256 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1069 loss: 1.30382 acc: 0.70801 | v_loss: 1.17780 v_acc: 0.71940 |  iteration: 12257 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1070 loss: 1.28125 acc: 0.70475 | v_loss: 1.13738 v_acc: 0.71289 |  iteration: 12258 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1071 loss: 1.40556 acc: 0.69727 | v_loss: 1.11893 v_acc: 0.72266 |  iteration: 12259 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1072 loss: 1.29480 acc: 0.70736 | v_loss: 1.19559 v_acc: 0.70345 |  iteration: 12260 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1073 loss: 1.23836 acc: 0.70443 | v_loss: 1.23223 v_acc: 0.72038 |  iteration: 12261 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1074 loss: 1.26433 acc: 0.70312 | v_loss: 1.19259 v_acc: 0.73210 |  iteration: 12262 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1075 loss: 1.27371 acc: 0.70443 | v_loss: 1.22374 v_acc: 0.72005 |  iteration: 12263 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1076 loss: 1.20757 acc: 0.70768 | v_loss: 1.22431 v_acc: 0.70768 |  iteration: 12264 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1077 loss: 1.19810 acc: 0.71810 | v_loss: 1.14435 v_acc: 0.72298 |  iteration: 12265 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1078 loss: 1.23749 acc: 0.70312 | v_loss: 1.09563 v_acc: 0.72233 |  iteration: 12266 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1079 loss: 1.26679 acc: 0.71126 | v_loss: 1.41604 v_acc: 0.69401 |  iteration: 12267 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1080 loss: 1.26798 acc: 0.69922 | v_loss: 1.18449 v_acc: 0.71126 |  iteration: 12268 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1081 loss: 1.32762 acc: 0.69987 | v_loss: 1.21318 v_acc: 0.71810 |  iteration: 12269 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1082 loss: 1.25704 acc: 0.69922 | v_loss: 1.19257 v_acc: 0.71973 |  iteration: 12270 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1083 loss: 1.26545 acc: 0.70540 | v_loss: 1.24410 v_acc: 0.70215 |  iteration: 12271 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1084 loss: 1.16993 acc: 0.71289 | v_loss: 1.11753 v_acc: 0.73275 |  iteration: 12272 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1085 loss: 1.24848 acc: 0.71257 | v_loss: 1.33647 v_acc: 0.71582 |  iteration: 12273 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1086 loss: 1.32952 acc: 0.70703 | v_loss: 1.17064 v_acc: 0.69954 |  iteration: 12274 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1087 loss: 1.24659 acc: 0.70410 | v_loss: 1.17689 v_acc: 0.70540 |  iteration: 12275 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1088 loss: 1.24549 acc: 0.70736 | v_loss: 1.25734 v_acc: 0.70443 |  iteration: 12276 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1089 loss: 1.30709 acc: 0.70117 | v_loss: 1.24339 v_acc: 0.70475 |  iteration: 12277 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1090 loss: 1.34102 acc: 0.70150 | v_loss: 1.31389 v_acc: 0.69434 |  iteration: 12278 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1091 loss: 1.23724 acc: 0.71452 | v_loss: 1.34279 v_acc: 0.70475 |  iteration: 12279 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1092 loss: 1.28379 acc: 0.70801 | v_loss: 1.27091 v_acc: 0.70573 |  iteration: 12280 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1093 loss: 1.32168 acc: 0.70150 | v_loss: 1.18015 v_acc: 0.71289 |  iteration: 12281 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1094 loss: 1.30808 acc: 0.70703 | v_loss: 1.26658 v_acc: 0.70898 |  iteration: 12282 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1095 loss: 1.29261 acc: 0.70671 | v_loss: 1.19071 v_acc: 0.71419 |  iteration: 12283 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1096 loss: 1.24021 acc: 0.70280 | v_loss: 1.10382 v_acc: 0.72982 |  iteration: 12284 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1097 loss: 1.34811 acc: 0.69661 | v_loss: 1.11184 v_acc: 0.71159 |  iteration: 12285 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1098 loss: 1.27560 acc: 0.69922 | v_loss: 1.22430 v_acc: 0.70931 |  iteration: 12286 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1099 loss: 1.30121 acc: 0.71810 | v_loss: 1.27197 v_acc: 0.69824 |  iteration: 12287 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1100 loss: 1.22249 acc: 0.70573 | v_loss: 1.12882 v_acc: 0.71842 |  iteration: 12288 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1101 loss: 1.35104 acc: 0.70898 | v_loss: 1.17394 v_acc: 0.70247 |  iteration: 12289 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1102 loss: 1.19362 acc: 0.71289 | v_loss: 1.16604 v_acc: 0.71908 |  iteration: 12290 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1103 loss: 1.31071 acc: 0.69141 | v_loss: 1.17754 v_acc: 0.71289 |  iteration: 12291 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1104 loss: 1.26035 acc: 0.70736 | v_loss: 1.04080 v_acc: 0.74316 |  iteration: 12292 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1105 loss: 1.18943 acc: 0.71354 | v_loss: 1.14686 v_acc: 0.72168 |  iteration: 12293 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1106 loss: 1.30128 acc: 0.70475 | v_loss: 1.09779 v_acc: 0.73177 |  iteration: 12294 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1107 loss: 1.27849 acc: 0.70345 | v_loss: 1.07639 v_acc: 0.72526 |  iteration: 12295 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1108 loss: 1.22212 acc: 0.70703 | v_loss: 1.17997 v_acc: 0.71387 |  iteration: 12296 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1109 loss: 1.33737 acc: 0.69759 | v_loss: 1.20450 v_acc: 0.71419 |  iteration: 12297 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1110 loss: 1.28705 acc: 0.70768 | v_loss: 1.21360 v_acc: 0.72168 |  iteration: 12298 teacher: 1 stage: sketch lr: 0.000399\n",
      "batch 1111 loss: 1.20520 acc: 0.70703 | v_loss: 1.34942 v_acc: 0.70410 |  iteration: 12299 teacher: 0 stage: sketch lr: 0.000399\n",
      "batch 1112 loss: 1.17439 acc: 0.70703 | v_loss: 1.27269 v_acc: 0.71712 |  iteration: 12300 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1113 loss: 1.26443 acc: 0.71354 | v_loss: 1.03886 v_acc: 0.74512 |  iteration: 12301 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1114 loss: 1.22211 acc: 0.70410 | v_loss: 1.18365 v_acc: 0.70768 |  iteration: 12302 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1115 loss: 1.24557 acc: 0.71322 | v_loss: 1.21583 v_acc: 0.70378 |  iteration: 12303 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1116 loss: 1.29650 acc: 0.70020 | v_loss: 1.16804 v_acc: 0.71029 |  iteration: 12304 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1117 loss: 1.28987 acc: 0.70085 | v_loss: 1.22432 v_acc: 0.71387 |  iteration: 12305 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1118 loss: 1.24033 acc: 0.70508 | v_loss: 1.20625 v_acc: 0.69824 |  iteration: 12306 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1119 loss: 1.23459 acc: 0.70866 | v_loss: 1.18659 v_acc: 0.71322 |  iteration: 12307 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1120 loss: 1.28203 acc: 0.69987 | v_loss: 1.20510 v_acc: 0.69857 |  iteration: 12308 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1121 loss: 1.27889 acc: 0.70182 | v_loss: 1.13859 v_acc: 0.71777 |  iteration: 12309 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1122 loss: 1.26565 acc: 0.70117 | v_loss: 1.14651 v_acc: 0.72721 |  iteration: 12310 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1123 loss: 1.27109 acc: 0.70671 | v_loss: 1.18523 v_acc: 0.70833 |  iteration: 12311 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1124 loss: 1.36767 acc: 0.69336 | v_loss: 1.30826 v_acc: 0.69954 |  iteration: 12312 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1125 loss: 1.30891 acc: 0.69824 | v_loss: 1.12027 v_acc: 0.71191 |  iteration: 12313 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1126 loss: 1.28233 acc: 0.70605 | v_loss: 1.37997 v_acc: 0.68945 |  iteration: 12314 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1127 loss: 1.22770 acc: 0.71224 | v_loss: 1.13913 v_acc: 0.73145 |  iteration: 12315 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1128 loss: 1.36477 acc: 0.69076 | v_loss: 1.47064 v_acc: 0.67806 |  iteration: 12316 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1129 loss: 1.19509 acc: 0.70182 | v_loss: 1.33707 v_acc: 0.69368 |  iteration: 12317 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1130 loss: 1.28233 acc: 0.69759 | v_loss: 1.30622 v_acc: 0.69792 |  iteration: 12318 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1131 loss: 1.30457 acc: 0.70085 | v_loss: 1.26545 v_acc: 0.70540 |  iteration: 12319 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1132 loss: 1.32248 acc: 0.69987 | v_loss: 1.20552 v_acc: 0.70931 |  iteration: 12320 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1133 loss: 1.21555 acc: 0.71257 | v_loss: 1.23599 v_acc: 0.70540 |  iteration: 12321 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1134 loss: 1.29675 acc: 0.71289 | v_loss: 1.18312 v_acc: 0.72396 |  iteration: 12322 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1135 loss: 1.21829 acc: 0.70182 | v_loss: 1.36864 v_acc: 0.69108 |  iteration: 12323 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1136 loss: 1.30427 acc: 0.71191 | v_loss: 1.25669 v_acc: 0.71126 |  iteration: 12324 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1137 loss: 1.23370 acc: 0.71159 | v_loss: 1.15491 v_acc: 0.71191 |  iteration: 12325 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1138 loss: 1.28777 acc: 0.70768 | v_loss: 1.21554 v_acc: 0.72201 |  iteration: 12326 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1139 loss: 1.21204 acc: 0.71126 | v_loss: 1.14749 v_acc: 0.70605 |  iteration: 12327 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1140 loss: 1.25469 acc: 0.70801 | v_loss: 1.24378 v_acc: 0.69954 |  iteration: 12328 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1141 loss: 1.37488 acc: 0.69727 | v_loss: 1.21563 v_acc: 0.71354 |  iteration: 12329 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1142 loss: 1.34068 acc: 0.69629 | v_loss: 1.12781 v_acc: 0.72168 |  iteration: 12330 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1143 loss: 1.21364 acc: 0.70866 | v_loss: 1.11627 v_acc: 0.73112 |  iteration: 12331 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1144 loss: 1.22048 acc: 0.70540 | v_loss: 1.22947 v_acc: 0.71745 |  iteration: 12332 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1145 loss: 1.17697 acc: 0.70996 | v_loss: 1.22162 v_acc: 0.70736 |  iteration: 12333 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1146 loss: 1.25208 acc: 0.70964 | v_loss: 1.21348 v_acc: 0.71191 |  iteration: 12334 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1147 loss: 1.28167 acc: 0.69824 | v_loss: 1.07366 v_acc: 0.72396 |  iteration: 12335 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1148 loss: 1.19880 acc: 0.71484 | v_loss: 1.22393 v_acc: 0.73145 |  iteration: 12336 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1149 loss: 1.30617 acc: 0.70247 | v_loss: 1.25940 v_acc: 0.69987 |  iteration: 12337 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1150 loss: 1.34189 acc: 0.69564 | v_loss: 1.26720 v_acc: 0.72754 |  iteration: 12338 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1151 loss: 1.32877 acc: 0.69987 | v_loss: 1.11729 v_acc: 0.72363 |  iteration: 12339 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1152 loss: 1.22533 acc: 0.71354 | v_loss: 1.07870 v_acc: 0.73503 |  iteration: 12340 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1153 loss: 1.27550 acc: 0.69434 | v_loss: 1.07978 v_acc: 0.72949 |  iteration: 12341 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1154 loss: 1.23859 acc: 0.69922 | v_loss: 1.15731 v_acc: 0.70964 |  iteration: 12342 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1155 loss: 1.31996 acc: 0.69108 | v_loss: 1.20778 v_acc: 0.70085 |  iteration: 12343 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1156 loss: 1.27408 acc: 0.70801 | v_loss: 1.17967 v_acc: 0.71680 |  iteration: 12344 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1157 loss: 1.26022 acc: 0.70703 | v_loss: 1.29044 v_acc: 0.71712 |  iteration: 12345 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1158 loss: 1.25166 acc: 0.70312 | v_loss: 1.43033 v_acc: 0.69564 |  iteration: 12346 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1159 loss: 1.28043 acc: 0.70085 | v_loss: 1.32139 v_acc: 0.70117 |  iteration: 12347 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1160 loss: 1.31180 acc: 0.70117 | v_loss: 1.16094 v_acc: 0.72363 |  iteration: 12348 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1161 loss: 1.24709 acc: 0.70345 | v_loss: 1.12083 v_acc: 0.70964 |  iteration: 12349 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1162 loss: 1.25834 acc: 0.70638 | v_loss: 1.10798 v_acc: 0.72526 |  iteration: 12350 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1163 loss: 1.37739 acc: 0.70085 | v_loss: 1.17328 v_acc: 0.70931 |  iteration: 12351 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1164 loss: 1.27137 acc: 0.70768 | v_loss: 1.21874 v_acc: 0.72038 |  iteration: 12352 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1165 loss: 1.27528 acc: 0.71419 | v_loss: 1.18443 v_acc: 0.73112 |  iteration: 12353 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1166 loss: 1.42841 acc: 0.68978 | v_loss: 1.20874 v_acc: 0.72135 |  iteration: 12354 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1167 loss: 1.31067 acc: 0.69141 | v_loss: 1.21175 v_acc: 0.71452 |  iteration: 12355 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1168 loss: 1.23556 acc: 0.70345 | v_loss: 1.13596 v_acc: 0.72461 |  iteration: 12356 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1169 loss: 1.24253 acc: 0.70312 | v_loss: 1.10463 v_acc: 0.72005 |  iteration: 12357 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1170 loss: 1.27163 acc: 0.70898 | v_loss: 1.41306 v_acc: 0.69238 |  iteration: 12358 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1171 loss: 1.22945 acc: 0.71484 | v_loss: 1.16878 v_acc: 0.71289 |  iteration: 12359 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1172 loss: 1.28452 acc: 0.69792 | v_loss: 1.18559 v_acc: 0.72135 |  iteration: 12360 teacher: 1 stage: sketch lr: 0.000398\n",
      "batch 1173 loss: 1.22665 acc: 0.71387 | v_loss: 1.19792 v_acc: 0.71322 |  iteration: 12361 teacher: 0 stage: sketch lr: 0.000398\n",
      "batch 1174 loss: 1.32076 acc: 0.70215 | v_loss: 1.23556 v_acc: 0.71029 |  iteration: 12362 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1175 loss: 1.22864 acc: 0.71387 | v_loss: 1.12282 v_acc: 0.73503 |  iteration: 12363 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1176 loss: 1.24293 acc: 0.70931 | v_loss: 1.33780 v_acc: 0.71517 |  iteration: 12364 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1177 loss: 1.24602 acc: 0.70443 | v_loss: 1.15649 v_acc: 0.69857 |  iteration: 12365 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1178 loss: 1.19203 acc: 0.71354 | v_loss: 1.16546 v_acc: 0.70605 |  iteration: 12366 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1179 loss: 1.21158 acc: 0.71582 | v_loss: 1.25915 v_acc: 0.70573 |  iteration: 12367 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1180 loss: 1.25681 acc: 0.70345 | v_loss: 1.23424 v_acc: 0.70573 |  iteration: 12368 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1181 loss: 1.18495 acc: 0.71484 | v_loss: 1.30402 v_acc: 0.69368 |  iteration: 12369 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1182 loss: 1.25282 acc: 0.71126 | v_loss: 1.34250 v_acc: 0.71029 |  iteration: 12370 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1183 loss: 1.22670 acc: 0.70996 | v_loss: 1.23764 v_acc: 0.70801 |  iteration: 12371 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1184 loss: 1.19249 acc: 0.70703 | v_loss: 1.14120 v_acc: 0.71615 |  iteration: 12372 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1185 loss: 1.28082 acc: 0.70866 | v_loss: 1.30466 v_acc: 0.70801 |  iteration: 12373 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1186 loss: 1.28795 acc: 0.70312 | v_loss: 1.20728 v_acc: 0.71452 |  iteration: 12374 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1187 loss: 1.25494 acc: 0.70605 | v_loss: 1.09210 v_acc: 0.73079 |  iteration: 12375 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1188 loss: 1.31404 acc: 0.70345 | v_loss: 1.10942 v_acc: 0.71257 |  iteration: 12376 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1189 loss: 1.27424 acc: 0.70638 | v_loss: 1.22335 v_acc: 0.70931 |  iteration: 12377 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1190 loss: 1.24516 acc: 0.71582 | v_loss: 1.26807 v_acc: 0.70085 |  iteration: 12378 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1191 loss: 1.16623 acc: 0.70573 | v_loss: 1.12331 v_acc: 0.70931 |  iteration: 12379 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1192 loss: 1.30552 acc: 0.70801 | v_loss: 1.17703 v_acc: 0.69824 |  iteration: 12380 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1193 loss: 1.25261 acc: 0.71224 | v_loss: 1.13694 v_acc: 0.71387 |  iteration: 12381 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1194 loss: 1.27203 acc: 0.70703 | v_loss: 1.17077 v_acc: 0.70605 |  iteration: 12382 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1195 loss: 1.23387 acc: 0.71973 | v_loss: 1.09543 v_acc: 0.73633 |  iteration: 12383 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1196 loss: 1.23422 acc: 0.70378 | v_loss: 1.13938 v_acc: 0.71484 |  iteration: 12384 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1197 loss: 1.28868 acc: 0.69596 | v_loss: 1.14515 v_acc: 0.71061 |  iteration: 12385 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1198 loss: 1.29327 acc: 0.70866 | v_loss: 1.10705 v_acc: 0.72949 |  iteration: 12386 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1199 loss: 1.25043 acc: 0.70182 | v_loss: 1.16977 v_acc: 0.72201 |  iteration: 12387 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1200 loss: 1.31912 acc: 0.70215 | v_loss: 1.16888 v_acc: 0.72266 |  iteration: 12388 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1201 loss: 1.27001 acc: 0.70443 | v_loss: 1.17205 v_acc: 0.73047 |  iteration: 12389 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1202 loss: 1.20958 acc: 0.71810 | v_loss: 1.37275 v_acc: 0.70215 |  iteration: 12390 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1203 loss: 1.23799 acc: 0.70345 | v_loss: 1.24060 v_acc: 0.72331 |  iteration: 12391 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1204 loss: 1.33793 acc: 0.70671 | v_loss: 1.01895 v_acc: 0.75065 |  iteration: 12392 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1205 loss: 1.26552 acc: 0.71224 | v_loss: 1.21996 v_acc: 0.70443 |  iteration: 12393 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1206 loss: 1.28128 acc: 0.70605 | v_loss: 1.20936 v_acc: 0.70671 |  iteration: 12394 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1207 loss: 1.31282 acc: 0.70280 | v_loss: 1.18056 v_acc: 0.70996 |  iteration: 12395 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1208 loss: 1.27645 acc: 0.70280 | v_loss: 1.20020 v_acc: 0.71517 |  iteration: 12396 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1209 loss: 1.27676 acc: 0.70378 | v_loss: 1.21571 v_acc: 0.69661 |  iteration: 12397 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1210 loss: 1.37738 acc: 0.69401 | v_loss: 1.17908 v_acc: 0.71354 |  iteration: 12398 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1211 loss: 1.30873 acc: 0.69661 | v_loss: 1.22971 v_acc: 0.69824 |  iteration: 12399 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1212 loss: 1.26122 acc: 0.71354 | v_loss: 1.16657 v_acc: 0.71452 |  iteration: 12400 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1213 loss: 1.22834 acc: 0.70443 | v_loss: 1.14150 v_acc: 0.72428 |  iteration: 12401 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1214 loss: 1.23225 acc: 0.70931 | v_loss: 1.17543 v_acc: 0.70573 |  iteration: 12402 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1215 loss: 1.26278 acc: 0.70280 | v_loss: 1.28096 v_acc: 0.70052 |  iteration: 12403 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1216 loss: 1.23216 acc: 0.71061 | v_loss: 1.11282 v_acc: 0.71224 |  iteration: 12404 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1217 loss: 1.25927 acc: 0.70671 | v_loss: 1.37623 v_acc: 0.68392 |  iteration: 12405 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1218 loss: 1.25188 acc: 0.71289 | v_loss: 1.12738 v_acc: 0.72038 |  iteration: 12406 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1219 loss: 1.28175 acc: 0.69661 | v_loss: 1.44386 v_acc: 0.68164 |  iteration: 12407 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1220 loss: 1.31610 acc: 0.69661 | v_loss: 1.31201 v_acc: 0.70247 |  iteration: 12408 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1221 loss: 1.25953 acc: 0.70833 | v_loss: 1.29066 v_acc: 0.69238 |  iteration: 12409 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1222 loss: 1.31419 acc: 0.70020 | v_loss: 1.27082 v_acc: 0.70312 |  iteration: 12410 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1223 loss: 1.27363 acc: 0.71126 | v_loss: 1.17385 v_acc: 0.70671 |  iteration: 12411 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1224 loss: 1.30697 acc: 0.70508 | v_loss: 1.23907 v_acc: 0.70443 |  iteration: 12412 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1225 loss: 1.21757 acc: 0.70931 | v_loss: 1.17372 v_acc: 0.71973 |  iteration: 12413 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1226 loss: 1.30521 acc: 0.70508 | v_loss: 1.37007 v_acc: 0.68848 |  iteration: 12414 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1227 loss: 1.19453 acc: 0.70833 | v_loss: 1.24564 v_acc: 0.70768 |  iteration: 12415 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1228 loss: 1.20174 acc: 0.71029 | v_loss: 1.12032 v_acc: 0.71647 |  iteration: 12416 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1229 loss: 1.30657 acc: 0.70410 | v_loss: 1.24410 v_acc: 0.71745 |  iteration: 12417 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1230 loss: 1.29114 acc: 0.70866 | v_loss: 1.12846 v_acc: 0.70768 |  iteration: 12418 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1231 loss: 1.30922 acc: 0.69531 | v_loss: 1.23644 v_acc: 0.70247 |  iteration: 12419 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1232 loss: 1.27735 acc: 0.70931 | v_loss: 1.22256 v_acc: 0.71354 |  iteration: 12420 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1233 loss: 1.22716 acc: 0.71973 | v_loss: 1.15832 v_acc: 0.71777 |  iteration: 12421 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1234 loss: 1.25826 acc: 0.70996 | v_loss: 1.16875 v_acc: 0.72298 |  iteration: 12422 teacher: 0 stage: sketch lr: 0.000397\n",
      "batch 1235 loss: 1.37351 acc: 0.69792 | v_loss: 1.27886 v_acc: 0.71647 |  iteration: 12423 teacher: 1 stage: sketch lr: 0.000397\n",
      "batch 1236 loss: 1.34753 acc: 0.70345 | v_loss: 1.27443 v_acc: 0.70345 |  iteration: 12424 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 1237 loss: 1.30730 acc: 0.70898 | v_loss: 1.26600 v_acc: 0.70964 |  iteration: 12425 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 1238 loss: 1.39147 acc: 0.68945 | v_loss: 1.07991 v_acc: 0.72526 |  iteration: 12426 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 1239 loss: 1.29114 acc: 0.70215 | v_loss: 1.23093 v_acc: 0.73568 |  iteration: 12427 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 1240 loss: 1.30686 acc: 0.69141 | v_loss: 1.28758 v_acc: 0.69727 |  iteration: 12428 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 1241 loss: 1.26793 acc: 0.70443 | v_loss: 1.25446 v_acc: 0.72656 |  iteration: 12429 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 1242 loss: 1.26837 acc: 0.71126 | v_loss: 1.13827 v_acc: 0.72266 |  iteration: 12430 teacher: 1 stage: sketch lr: 0.000396\n",
      "epoch 9 loss: 1.27435 acc: 0.70492 | v_loss: 1.20949 v_acc: 0.71187 \n",
      "epoch: 10\n",
      "__________________________________________\n",
      "batch 0 loss: 1.38494 acc: 0.70020 | v_loss: 1.26842 v_acc: 0.70801 |  iteration: 12431 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 1 loss: 1.28043 acc: 0.70443 | v_loss: 1.19530 v_acc: 0.70898 |  iteration: 12432 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 2 loss: 1.26489 acc: 0.70020 | v_loss: 1.27429 v_acc: 0.70671 |  iteration: 12433 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 3 loss: 1.29694 acc: 0.69987 | v_loss: 1.18408 v_acc: 0.71126 |  iteration: 12434 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 4 loss: 1.25073 acc: 0.71647 | v_loss: 1.16098 v_acc: 0.72428 |  iteration: 12435 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 5 loss: 1.34026 acc: 0.69531 | v_loss: 1.09612 v_acc: 0.70931 |  iteration: 12436 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 6 loss: 1.25026 acc: 0.70540 | v_loss: 1.24984 v_acc: 0.70443 |  iteration: 12437 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 7 loss: 1.27937 acc: 0.69987 | v_loss: 1.32617 v_acc: 0.69727 |  iteration: 12438 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 8 loss: 1.19464 acc: 0.70833 | v_loss: 1.17901 v_acc: 0.70508 |  iteration: 12439 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 9 loss: 1.26091 acc: 0.70345 | v_loss: 1.21583 v_acc: 0.70020 |  iteration: 12440 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 10 loss: 1.24951 acc: 0.70671 | v_loss: 1.15772 v_acc: 0.71354 |  iteration: 12441 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 11 loss: 1.22256 acc: 0.71452 | v_loss: 1.18072 v_acc: 0.70671 |  iteration: 12442 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 12 loss: 1.24143 acc: 0.70540 | v_loss: 1.08217 v_acc: 0.73535 |  iteration: 12443 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 13 loss: 1.20373 acc: 0.71289 | v_loss: 1.17841 v_acc: 0.71973 |  iteration: 12444 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 14 loss: 1.25506 acc: 0.70182 | v_loss: 1.18343 v_acc: 0.72559 |  iteration: 12445 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 15 loss: 1.30861 acc: 0.70475 | v_loss: 1.12534 v_acc: 0.72526 |  iteration: 12446 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 16 loss: 1.20999 acc: 0.70443 | v_loss: 1.20517 v_acc: 0.71680 |  iteration: 12447 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 17 loss: 1.37733 acc: 0.68522 | v_loss: 1.23315 v_acc: 0.71322 |  iteration: 12448 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 18 loss: 1.28115 acc: 0.69889 | v_loss: 1.21093 v_acc: 0.72201 |  iteration: 12449 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 19 loss: 1.29363 acc: 0.71029 | v_loss: 1.36995 v_acc: 0.70215 |  iteration: 12450 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 20 loss: 1.27846 acc: 0.70378 | v_loss: 1.27524 v_acc: 0.71712 |  iteration: 12451 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 21 loss: 1.25281 acc: 0.70475 | v_loss: 1.04608 v_acc: 0.74837 |  iteration: 12452 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 22 loss: 1.24364 acc: 0.70768 | v_loss: 1.18910 v_acc: 0.70443 |  iteration: 12453 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 23 loss: 1.23783 acc: 0.70768 | v_loss: 1.26261 v_acc: 0.69954 |  iteration: 12454 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 24 loss: 1.24743 acc: 0.71810 | v_loss: 1.17450 v_acc: 0.70801 |  iteration: 12455 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 25 loss: 1.31391 acc: 0.70280 | v_loss: 1.23869 v_acc: 0.71126 |  iteration: 12456 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 26 loss: 1.22125 acc: 0.71354 | v_loss: 1.24153 v_acc: 0.69108 |  iteration: 12457 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 27 loss: 1.23914 acc: 0.71029 | v_loss: 1.19936 v_acc: 0.70996 |  iteration: 12458 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 28 loss: 1.36360 acc: 0.69401 | v_loss: 1.22712 v_acc: 0.69564 |  iteration: 12459 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 29 loss: 1.27749 acc: 0.70605 | v_loss: 1.21458 v_acc: 0.71191 |  iteration: 12460 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 30 loss: 1.29895 acc: 0.70443 | v_loss: 1.18552 v_acc: 0.72363 |  iteration: 12461 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 31 loss: 1.30871 acc: 0.69954 | v_loss: 1.26562 v_acc: 0.70280 |  iteration: 12462 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 32 loss: 1.23420 acc: 0.70833 | v_loss: 1.30678 v_acc: 0.69922 |  iteration: 12463 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 33 loss: 1.29635 acc: 0.69466 | v_loss: 1.16516 v_acc: 0.70605 |  iteration: 12464 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 34 loss: 1.27436 acc: 0.71159 | v_loss: 1.39347 v_acc: 0.68913 |  iteration: 12465 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 35 loss: 1.25772 acc: 0.70443 | v_loss: 1.19299 v_acc: 0.71908 |  iteration: 12466 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 36 loss: 1.29495 acc: 0.70996 | v_loss: 1.45998 v_acc: 0.68197 |  iteration: 12467 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 37 loss: 1.38122 acc: 0.68913 | v_loss: 1.32575 v_acc: 0.69661 |  iteration: 12468 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 38 loss: 1.23617 acc: 0.71745 | v_loss: 1.34046 v_acc: 0.69173 |  iteration: 12469 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 39 loss: 1.26798 acc: 0.70573 | v_loss: 1.26727 v_acc: 0.70215 |  iteration: 12470 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 40 loss: 1.22548 acc: 0.70768 | v_loss: 1.20717 v_acc: 0.70931 |  iteration: 12471 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 41 loss: 1.25330 acc: 0.70508 | v_loss: 1.23140 v_acc: 0.70768 |  iteration: 12472 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 42 loss: 1.40680 acc: 0.68880 | v_loss: 1.19138 v_acc: 0.72298 |  iteration: 12473 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 43 loss: 1.26145 acc: 0.69727 | v_loss: 1.39003 v_acc: 0.69238 |  iteration: 12474 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 44 loss: 1.29742 acc: 0.70443 | v_loss: 1.27099 v_acc: 0.70768 |  iteration: 12475 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 45 loss: 1.21354 acc: 0.70996 | v_loss: 1.17842 v_acc: 0.71159 |  iteration: 12476 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 46 loss: 1.23387 acc: 0.70443 | v_loss: 1.23789 v_acc: 0.72038 |  iteration: 12477 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 47 loss: 1.29317 acc: 0.70573 | v_loss: 1.15011 v_acc: 0.70898 |  iteration: 12478 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 48 loss: 1.23610 acc: 0.70085 | v_loss: 1.26475 v_acc: 0.69727 |  iteration: 12479 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 49 loss: 1.31183 acc: 0.71029 | v_loss: 1.22439 v_acc: 0.71615 |  iteration: 12480 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 50 loss: 1.23491 acc: 0.70605 | v_loss: 1.14244 v_acc: 0.72070 |  iteration: 12481 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 51 loss: 1.15859 acc: 0.71224 | v_loss: 1.12106 v_acc: 0.72559 |  iteration: 12482 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 52 loss: 1.30720 acc: 0.69727 | v_loss: 1.25179 v_acc: 0.71940 |  iteration: 12483 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 53 loss: 1.21260 acc: 0.70247 | v_loss: 1.24944 v_acc: 0.70150 |  iteration: 12484 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 54 loss: 1.24951 acc: 0.70443 | v_loss: 1.25100 v_acc: 0.70964 |  iteration: 12485 teacher: 0 stage: sketch lr: 0.000396\n",
      "batch 55 loss: 1.32879 acc: 0.70052 | v_loss: 1.08591 v_acc: 0.72526 |  iteration: 12486 teacher: 1 stage: sketch lr: 0.000396\n",
      "batch 56 loss: 1.27023 acc: 0.70996 | v_loss: 1.26398 v_acc: 0.73112 |  iteration: 12487 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 57 loss: 1.31334 acc: 0.69792 | v_loss: 1.32008 v_acc: 0.69499 |  iteration: 12488 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 58 loss: 1.24951 acc: 0.70703 | v_loss: 1.32285 v_acc: 0.72070 |  iteration: 12489 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 59 loss: 1.26312 acc: 0.70020 | v_loss: 1.12997 v_acc: 0.72233 |  iteration: 12490 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 60 loss: 1.27429 acc: 0.69564 | v_loss: 1.09305 v_acc: 0.73926 |  iteration: 12491 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 61 loss: 1.29131 acc: 0.70768 | v_loss: 1.10147 v_acc: 0.72591 |  iteration: 12492 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 62 loss: 1.32829 acc: 0.69629 | v_loss: 1.17495 v_acc: 0.70964 |  iteration: 12493 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 63 loss: 1.33855 acc: 0.69466 | v_loss: 1.24524 v_acc: 0.69954 |  iteration: 12494 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 64 loss: 1.26992 acc: 0.70150 | v_loss: 1.19552 v_acc: 0.71484 |  iteration: 12495 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 65 loss: 1.28151 acc: 0.70443 | v_loss: 1.31123 v_acc: 0.69727 |  iteration: 12496 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 66 loss: 1.29469 acc: 0.70410 | v_loss: 1.46625 v_acc: 0.68880 |  iteration: 12497 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 67 loss: 1.20018 acc: 0.70736 | v_loss: 1.34370 v_acc: 0.69824 |  iteration: 12498 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 68 loss: 1.42026 acc: 0.69141 | v_loss: 1.19557 v_acc: 0.72233 |  iteration: 12499 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 69 loss: 1.29398 acc: 0.70247 | v_loss: 1.15781 v_acc: 0.70573 |  iteration: 12500 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 70 loss: 1.37210 acc: 0.69531 | v_loss: 1.13047 v_acc: 0.72135 |  iteration: 12501 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 71 loss: 1.23695 acc: 0.71354 | v_loss: 1.22957 v_acc: 0.70020 |  iteration: 12502 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 72 loss: 1.31260 acc: 0.70475 | v_loss: 1.23719 v_acc: 0.71484 |  iteration: 12503 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 73 loss: 1.25395 acc: 0.70247 | v_loss: 1.23532 v_acc: 0.72396 |  iteration: 12504 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 74 loss: 1.35902 acc: 0.70215 | v_loss: 1.26253 v_acc: 0.71484 |  iteration: 12505 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 75 loss: 1.35941 acc: 0.70345 | v_loss: 1.23198 v_acc: 0.71419 |  iteration: 12506 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 76 loss: 1.31191 acc: 0.70312 | v_loss: 1.15535 v_acc: 0.72526 |  iteration: 12507 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 77 loss: 1.29737 acc: 0.70182 | v_loss: 1.13767 v_acc: 0.72396 |  iteration: 12508 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 78 loss: 1.24315 acc: 0.71452 | v_loss: 1.41862 v_acc: 0.69206 |  iteration: 12509 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 79 loss: 1.29581 acc: 0.70443 | v_loss: 1.22624 v_acc: 0.70671 |  iteration: 12510 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 80 loss: 1.33883 acc: 0.69792 | v_loss: 1.19785 v_acc: 0.72005 |  iteration: 12511 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 81 loss: 1.37572 acc: 0.69434 | v_loss: 1.19889 v_acc: 0.71094 |  iteration: 12512 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 82 loss: 1.26712 acc: 0.70638 | v_loss: 1.25531 v_acc: 0.70768 |  iteration: 12513 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 83 loss: 1.23713 acc: 0.70540 | v_loss: 1.13024 v_acc: 0.73210 |  iteration: 12514 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 84 loss: 1.21653 acc: 0.71224 | v_loss: 1.34283 v_acc: 0.71712 |  iteration: 12515 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 85 loss: 1.33242 acc: 0.69922 | v_loss: 1.16652 v_acc: 0.70182 |  iteration: 12516 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 86 loss: 1.20798 acc: 0.71419 | v_loss: 1.18673 v_acc: 0.70508 |  iteration: 12517 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 87 loss: 1.27023 acc: 0.71908 | v_loss: 1.25635 v_acc: 0.70443 |  iteration: 12518 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 88 loss: 1.23176 acc: 0.69954 | v_loss: 1.26028 v_acc: 0.70508 |  iteration: 12519 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 89 loss: 1.21837 acc: 0.70215 | v_loss: 1.32183 v_acc: 0.69076 |  iteration: 12520 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 90 loss: 1.36353 acc: 0.69922 | v_loss: 1.35707 v_acc: 0.70736 |  iteration: 12521 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 91 loss: 1.32741 acc: 0.69824 | v_loss: 1.28403 v_acc: 0.70508 |  iteration: 12522 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 92 loss: 1.35414 acc: 0.69694 | v_loss: 1.16354 v_acc: 0.70833 |  iteration: 12523 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 93 loss: 1.29308 acc: 0.70736 | v_loss: 1.29231 v_acc: 0.70768 |  iteration: 12524 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 94 loss: 1.25012 acc: 0.71452 | v_loss: 1.18283 v_acc: 0.71582 |  iteration: 12525 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 95 loss: 1.18766 acc: 0.71615 | v_loss: 1.17126 v_acc: 0.71973 |  iteration: 12526 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 96 loss: 1.33083 acc: 0.70703 | v_loss: 1.09802 v_acc: 0.71126 |  iteration: 12527 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 97 loss: 1.25182 acc: 0.69727 | v_loss: 1.25468 v_acc: 0.70410 |  iteration: 12528 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 98 loss: 1.28010 acc: 0.70247 | v_loss: 1.34908 v_acc: 0.69727 |  iteration: 12529 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 99 loss: 1.24995 acc: 0.70768 | v_loss: 1.20459 v_acc: 0.70508 |  iteration: 12530 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 100 loss: 1.26963 acc: 0.71810 | v_loss: 1.23267 v_acc: 0.70052 |  iteration: 12531 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 101 loss: 1.28565 acc: 0.69857 | v_loss: 1.16771 v_acc: 0.71289 |  iteration: 12532 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 102 loss: 1.33005 acc: 0.70671 | v_loss: 1.17225 v_acc: 0.70768 |  iteration: 12533 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 103 loss: 1.25720 acc: 0.71582 | v_loss: 1.08206 v_acc: 0.73438 |  iteration: 12534 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 104 loss: 1.23219 acc: 0.70833 | v_loss: 1.16852 v_acc: 0.72103 |  iteration: 12535 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 105 loss: 1.42520 acc: 0.69076 | v_loss: 1.12991 v_acc: 0.72689 |  iteration: 12536 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 106 loss: 1.18102 acc: 0.71549 | v_loss: 1.11099 v_acc: 0.72428 |  iteration: 12537 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 107 loss: 1.27430 acc: 0.71191 | v_loss: 1.17164 v_acc: 0.72233 |  iteration: 12538 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 108 loss: 1.29319 acc: 0.70508 | v_loss: 1.19367 v_acc: 0.72103 |  iteration: 12539 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 109 loss: 1.26665 acc: 0.70638 | v_loss: 1.18671 v_acc: 0.72884 |  iteration: 12540 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 110 loss: 1.36375 acc: 0.69759 | v_loss: 1.36845 v_acc: 0.70020 |  iteration: 12541 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 111 loss: 1.35613 acc: 0.69759 | v_loss: 1.26943 v_acc: 0.71940 |  iteration: 12542 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 112 loss: 1.24923 acc: 0.70703 | v_loss: 1.05474 v_acc: 0.74447 |  iteration: 12543 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 113 loss: 1.22456 acc: 0.70410 | v_loss: 1.18272 v_acc: 0.70931 |  iteration: 12544 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 114 loss: 1.25900 acc: 0.70801 | v_loss: 1.28851 v_acc: 0.69954 |  iteration: 12545 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 115 loss: 1.31434 acc: 0.69727 | v_loss: 1.16789 v_acc: 0.69792 |  iteration: 12546 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 116 loss: 1.25946 acc: 0.70573 | v_loss: 1.24571 v_acc: 0.70801 |  iteration: 12547 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 117 loss: 1.30657 acc: 0.70964 | v_loss: 1.25419 v_acc: 0.69596 |  iteration: 12548 teacher: 0 stage: sketch lr: 0.000395\n",
      "batch 118 loss: 1.27441 acc: 0.70215 | v_loss: 1.18955 v_acc: 0.71810 |  iteration: 12549 teacher: 1 stage: sketch lr: 0.000395\n",
      "batch 119 loss: 1.29452 acc: 0.71159 | v_loss: 1.22240 v_acc: 0.70410 |  iteration: 12550 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 120 loss: 1.30907 acc: 0.70182 | v_loss: 1.17949 v_acc: 0.72201 |  iteration: 12551 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 121 loss: 1.18484 acc: 0.71224 | v_loss: 1.16791 v_acc: 0.72754 |  iteration: 12552 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 122 loss: 1.29901 acc: 0.70052 | v_loss: 1.20668 v_acc: 0.70312 |  iteration: 12553 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 123 loss: 1.30768 acc: 0.69824 | v_loss: 1.31013 v_acc: 0.70052 |  iteration: 12554 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 124 loss: 1.17731 acc: 0.72428 | v_loss: 1.14913 v_acc: 0.70768 |  iteration: 12555 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 125 loss: 1.30420 acc: 0.70703 | v_loss: 1.40213 v_acc: 0.68457 |  iteration: 12556 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 126 loss: 1.38050 acc: 0.69434 | v_loss: 1.15214 v_acc: 0.72363 |  iteration: 12557 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 127 loss: 1.19621 acc: 0.71647 | v_loss: 1.47101 v_acc: 0.67871 |  iteration: 12558 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 128 loss: 1.29472 acc: 0.70540 | v_loss: 1.33376 v_acc: 0.69629 |  iteration: 12559 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 129 loss: 1.34320 acc: 0.70931 | v_loss: 1.34691 v_acc: 0.69010 |  iteration: 12560 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 130 loss: 1.25814 acc: 0.70345 | v_loss: 1.27991 v_acc: 0.70508 |  iteration: 12561 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 131 loss: 1.34546 acc: 0.70247 | v_loss: 1.24011 v_acc: 0.70898 |  iteration: 12562 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 132 loss: 1.29460 acc: 0.69727 | v_loss: 1.25352 v_acc: 0.70671 |  iteration: 12563 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 133 loss: 1.30928 acc: 0.69336 | v_loss: 1.19506 v_acc: 0.72168 |  iteration: 12564 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 134 loss: 1.23851 acc: 0.70866 | v_loss: 1.41656 v_acc: 0.68815 |  iteration: 12565 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 135 loss: 1.19711 acc: 0.71647 | v_loss: 1.25262 v_acc: 0.71126 |  iteration: 12566 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 136 loss: 1.22736 acc: 0.71387 | v_loss: 1.20111 v_acc: 0.70931 |  iteration: 12567 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 137 loss: 1.29155 acc: 0.69759 | v_loss: 1.23089 v_acc: 0.71549 |  iteration: 12568 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 138 loss: 1.35075 acc: 0.69629 | v_loss: 1.16282 v_acc: 0.70801 |  iteration: 12569 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 139 loss: 1.27800 acc: 0.69922 | v_loss: 1.24807 v_acc: 0.69922 |  iteration: 12570 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 140 loss: 1.29821 acc: 0.70671 | v_loss: 1.23486 v_acc: 0.71354 |  iteration: 12571 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 141 loss: 1.23357 acc: 0.71842 | v_loss: 1.15032 v_acc: 0.72168 |  iteration: 12572 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 142 loss: 1.32107 acc: 0.70085 | v_loss: 1.14495 v_acc: 0.72526 |  iteration: 12573 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 143 loss: 1.32261 acc: 0.70345 | v_loss: 1.24941 v_acc: 0.71940 |  iteration: 12574 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 144 loss: 1.28940 acc: 0.70247 | v_loss: 1.24288 v_acc: 0.70312 |  iteration: 12575 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 145 loss: 1.23507 acc: 0.71257 | v_loss: 1.26139 v_acc: 0.70638 |  iteration: 12576 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 146 loss: 1.27766 acc: 0.70996 | v_loss: 1.08655 v_acc: 0.72070 |  iteration: 12577 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 147 loss: 1.32449 acc: 0.70605 | v_loss: 1.23988 v_acc: 0.73014 |  iteration: 12578 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 148 loss: 1.33780 acc: 0.70052 | v_loss: 1.29827 v_acc: 0.69954 |  iteration: 12579 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 149 loss: 1.27426 acc: 0.69987 | v_loss: 1.25274 v_acc: 0.72591 |  iteration: 12580 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 150 loss: 1.27134 acc: 0.70801 | v_loss: 1.12884 v_acc: 0.72396 |  iteration: 12581 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 151 loss: 1.28776 acc: 0.70768 | v_loss: 1.10368 v_acc: 0.73535 |  iteration: 12582 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 152 loss: 1.18580 acc: 0.70866 | v_loss: 1.10765 v_acc: 0.72428 |  iteration: 12583 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 153 loss: 1.29025 acc: 0.70964 | v_loss: 1.17591 v_acc: 0.70964 |  iteration: 12584 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 154 loss: 1.34596 acc: 0.69661 | v_loss: 1.26277 v_acc: 0.70150 |  iteration: 12585 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 155 loss: 1.24444 acc: 0.71322 | v_loss: 1.17233 v_acc: 0.71615 |  iteration: 12586 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 156 loss: 1.31302 acc: 0.70898 | v_loss: 1.29854 v_acc: 0.69954 |  iteration: 12587 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 157 loss: 1.19515 acc: 0.70703 | v_loss: 1.52059 v_acc: 0.68913 |  iteration: 12588 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 158 loss: 1.24037 acc: 0.70280 | v_loss: 1.37082 v_acc: 0.70020 |  iteration: 12589 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 159 loss: 1.18257 acc: 0.71061 | v_loss: 1.19805 v_acc: 0.72135 |  iteration: 12590 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 160 loss: 1.21785 acc: 0.71615 | v_loss: 1.16299 v_acc: 0.70801 |  iteration: 12591 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 161 loss: 1.30676 acc: 0.69759 | v_loss: 1.12452 v_acc: 0.72461 |  iteration: 12592 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 162 loss: 1.20984 acc: 0.70215 | v_loss: 1.23929 v_acc: 0.70475 |  iteration: 12593 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 163 loss: 1.29471 acc: 0.70020 | v_loss: 1.22439 v_acc: 0.72038 |  iteration: 12594 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 164 loss: 1.26004 acc: 0.70638 | v_loss: 1.20751 v_acc: 0.73014 |  iteration: 12595 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 165 loss: 1.25719 acc: 0.70573 | v_loss: 1.23303 v_acc: 0.71777 |  iteration: 12596 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 166 loss: 1.33673 acc: 0.70052 | v_loss: 1.20569 v_acc: 0.70996 |  iteration: 12597 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 167 loss: 1.31914 acc: 0.69596 | v_loss: 1.14884 v_acc: 0.72428 |  iteration: 12598 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 168 loss: 1.23653 acc: 0.71322 | v_loss: 1.11588 v_acc: 0.72168 |  iteration: 12599 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 169 loss: 1.23328 acc: 0.70508 | v_loss: 1.45603 v_acc: 0.69076 |  iteration: 12600 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 170 loss: 1.26012 acc: 0.70345 | v_loss: 1.20022 v_acc: 0.70898 |  iteration: 12601 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 171 loss: 1.31853 acc: 0.69857 | v_loss: 1.20161 v_acc: 0.71289 |  iteration: 12602 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 172 loss: 1.29702 acc: 0.69792 | v_loss: 1.21615 v_acc: 0.69954 |  iteration: 12603 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 173 loss: 1.39283 acc: 0.69401 | v_loss: 1.28164 v_acc: 0.69141 |  iteration: 12604 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 174 loss: 1.31626 acc: 0.70215 | v_loss: 1.14665 v_acc: 0.72917 |  iteration: 12605 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 175 loss: 1.29649 acc: 0.69499 | v_loss: 1.41447 v_acc: 0.70345 |  iteration: 12606 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 176 loss: 1.21748 acc: 0.71061 | v_loss: 1.18444 v_acc: 0.69922 |  iteration: 12607 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 177 loss: 1.24839 acc: 0.70540 | v_loss: 1.20541 v_acc: 0.70117 |  iteration: 12608 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 178 loss: 1.26619 acc: 0.70475 | v_loss: 1.33512 v_acc: 0.70117 |  iteration: 12609 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 179 loss: 1.29711 acc: 0.70345 | v_loss: 1.34012 v_acc: 0.69759 |  iteration: 12610 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 180 loss: 1.26451 acc: 0.70378 | v_loss: 1.37635 v_acc: 0.69108 |  iteration: 12611 teacher: 0 stage: sketch lr: 0.000394\n",
      "batch 181 loss: 1.31796 acc: 0.70182 | v_loss: 1.37130 v_acc: 0.70768 |  iteration: 12612 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 182 loss: 1.19402 acc: 0.71745 | v_loss: 1.29936 v_acc: 0.70215 |  iteration: 12613 teacher: 1 stage: sketch lr: 0.000394\n",
      "batch 183 loss: 1.27259 acc: 0.70573 | v_loss: 1.21824 v_acc: 0.70898 |  iteration: 12614 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 184 loss: 1.33432 acc: 0.69792 | v_loss: 1.27596 v_acc: 0.70671 |  iteration: 12615 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 185 loss: 1.27674 acc: 0.70703 | v_loss: 1.19652 v_acc: 0.71582 |  iteration: 12616 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 186 loss: 1.27992 acc: 0.71061 | v_loss: 1.14375 v_acc: 0.72331 |  iteration: 12617 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 187 loss: 1.32980 acc: 0.70605 | v_loss: 1.10182 v_acc: 0.70964 |  iteration: 12618 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 188 loss: 1.22309 acc: 0.71452 | v_loss: 1.22394 v_acc: 0.70443 |  iteration: 12619 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 189 loss: 1.31112 acc: 0.70215 | v_loss: 1.30342 v_acc: 0.69727 |  iteration: 12620 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 190 loss: 1.40259 acc: 0.69368 | v_loss: 1.17905 v_acc: 0.70540 |  iteration: 12621 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 191 loss: 1.31302 acc: 0.69727 | v_loss: 1.25899 v_acc: 0.69434 |  iteration: 12622 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 192 loss: 1.30966 acc: 0.70182 | v_loss: 1.16087 v_acc: 0.70964 |  iteration: 12623 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 193 loss: 1.30001 acc: 0.70280 | v_loss: 1.19779 v_acc: 0.70215 |  iteration: 12624 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 194 loss: 1.17737 acc: 0.71940 | v_loss: 1.15607 v_acc: 0.73210 |  iteration: 12625 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 195 loss: 1.22552 acc: 0.70182 | v_loss: 1.17938 v_acc: 0.71452 |  iteration: 12626 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 196 loss: 1.30023 acc: 0.70638 | v_loss: 1.21047 v_acc: 0.71973 |  iteration: 12627 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 197 loss: 1.35864 acc: 0.69173 | v_loss: 1.15119 v_acc: 0.72201 |  iteration: 12628 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 198 loss: 1.32969 acc: 0.69596 | v_loss: 1.24012 v_acc: 0.71159 |  iteration: 12629 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 199 loss: 1.46136 acc: 0.67806 | v_loss: 1.24631 v_acc: 0.71224 |  iteration: 12630 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 200 loss: 1.38921 acc: 0.69108 | v_loss: 1.23308 v_acc: 0.72168 |  iteration: 12631 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 201 loss: 1.23310 acc: 0.70833 | v_loss: 1.38314 v_acc: 0.70215 |  iteration: 12632 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 202 loss: 1.28195 acc: 0.70378 | v_loss: 1.30089 v_acc: 0.71452 |  iteration: 12633 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 203 loss: 1.32023 acc: 0.70117 | v_loss: 1.08282 v_acc: 0.74316 |  iteration: 12634 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 204 loss: 1.30666 acc: 0.71126 | v_loss: 1.17070 v_acc: 0.70768 |  iteration: 12635 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 205 loss: 1.33577 acc: 0.69466 | v_loss: 1.29961 v_acc: 0.70020 |  iteration: 12636 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 206 loss: 1.25150 acc: 0.70736 | v_loss: 1.17925 v_acc: 0.70573 |  iteration: 12637 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 207 loss: 1.37700 acc: 0.69954 | v_loss: 1.23593 v_acc: 0.71191 |  iteration: 12638 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 208 loss: 1.31730 acc: 0.70964 | v_loss: 1.23929 v_acc: 0.69694 |  iteration: 12639 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 209 loss: 1.31655 acc: 0.70085 | v_loss: 1.18745 v_acc: 0.71777 |  iteration: 12640 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 210 loss: 1.29888 acc: 0.69922 | v_loss: 1.22358 v_acc: 0.70215 |  iteration: 12641 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 211 loss: 1.31169 acc: 0.70052 | v_loss: 1.20366 v_acc: 0.71354 |  iteration: 12642 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 212 loss: 1.22216 acc: 0.70540 | v_loss: 1.17208 v_acc: 0.72721 |  iteration: 12643 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 213 loss: 1.32197 acc: 0.69629 | v_loss: 1.24233 v_acc: 0.70540 |  iteration: 12644 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 214 loss: 1.22962 acc: 0.70540 | v_loss: 1.31804 v_acc: 0.69857 |  iteration: 12645 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 215 loss: 1.36437 acc: 0.69857 | v_loss: 1.15023 v_acc: 0.70931 |  iteration: 12646 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 216 loss: 1.26728 acc: 0.70703 | v_loss: 1.39985 v_acc: 0.68327 |  iteration: 12647 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 217 loss: 1.27142 acc: 0.70052 | v_loss: 1.18380 v_acc: 0.72363 |  iteration: 12648 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 218 loss: 1.40778 acc: 0.69727 | v_loss: 1.46294 v_acc: 0.67839 |  iteration: 12649 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 219 loss: 1.27142 acc: 0.70182 | v_loss: 1.33776 v_acc: 0.70117 |  iteration: 12650 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 220 loss: 1.24146 acc: 0.70671 | v_loss: 1.36446 v_acc: 0.69238 |  iteration: 12651 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 221 loss: 1.29355 acc: 0.70247 | v_loss: 1.27020 v_acc: 0.70443 |  iteration: 12652 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 222 loss: 1.32762 acc: 0.70931 | v_loss: 1.23495 v_acc: 0.70801 |  iteration: 12653 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 223 loss: 1.24188 acc: 0.71615 | v_loss: 1.24290 v_acc: 0.70703 |  iteration: 12654 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 224 loss: 1.26427 acc: 0.69792 | v_loss: 1.20877 v_acc: 0.72363 |  iteration: 12655 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 225 loss: 1.30490 acc: 0.69759 | v_loss: 1.38768 v_acc: 0.68945 |  iteration: 12656 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 226 loss: 1.31740 acc: 0.70085 | v_loss: 1.26634 v_acc: 0.71289 |  iteration: 12657 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 227 loss: 1.24924 acc: 0.70052 | v_loss: 1.18630 v_acc: 0.71061 |  iteration: 12658 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 228 loss: 1.37826 acc: 0.69076 | v_loss: 1.24905 v_acc: 0.71452 |  iteration: 12659 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 229 loss: 1.34495 acc: 0.70247 | v_loss: 1.14827 v_acc: 0.70964 |  iteration: 12660 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 230 loss: 1.30443 acc: 0.70703 | v_loss: 1.25543 v_acc: 0.69987 |  iteration: 12661 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 231 loss: 1.29668 acc: 0.70182 | v_loss: 1.23923 v_acc: 0.71354 |  iteration: 12662 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 232 loss: 1.32092 acc: 0.70378 | v_loss: 1.18636 v_acc: 0.71940 |  iteration: 12663 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 233 loss: 1.26604 acc: 0.70801 | v_loss: 1.16101 v_acc: 0.72493 |  iteration: 12664 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 234 loss: 1.23122 acc: 0.71257 | v_loss: 1.25803 v_acc: 0.71582 |  iteration: 12665 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 235 loss: 1.35698 acc: 0.70085 | v_loss: 1.27802 v_acc: 0.70052 |  iteration: 12666 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 236 loss: 1.27161 acc: 0.70312 | v_loss: 1.27934 v_acc: 0.70703 |  iteration: 12667 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 237 loss: 1.29403 acc: 0.69792 | v_loss: 1.11092 v_acc: 0.72266 |  iteration: 12668 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 238 loss: 1.23622 acc: 0.71257 | v_loss: 1.26189 v_acc: 0.72917 |  iteration: 12669 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 239 loss: 1.30022 acc: 0.70345 | v_loss: 1.31700 v_acc: 0.69727 |  iteration: 12670 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 240 loss: 1.34220 acc: 0.69792 | v_loss: 1.29385 v_acc: 0.72201 |  iteration: 12671 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 241 loss: 1.26145 acc: 0.71419 | v_loss: 1.14677 v_acc: 0.72135 |  iteration: 12672 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 242 loss: 1.29563 acc: 0.70801 | v_loss: 1.08710 v_acc: 0.74284 |  iteration: 12673 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 243 loss: 1.23166 acc: 0.70703 | v_loss: 1.11191 v_acc: 0.72428 |  iteration: 12674 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 244 loss: 1.23487 acc: 0.71322 | v_loss: 1.17169 v_acc: 0.71322 |  iteration: 12675 teacher: 0 stage: sketch lr: 0.000393\n",
      "batch 245 loss: 1.27554 acc: 0.70475 | v_loss: 1.24470 v_acc: 0.70443 |  iteration: 12676 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 246 loss: 1.25607 acc: 0.70996 | v_loss: 1.17286 v_acc: 0.71680 |  iteration: 12677 teacher: 1 stage: sketch lr: 0.000393\n",
      "batch 247 loss: 1.27856 acc: 0.69792 | v_loss: 1.29285 v_acc: 0.70540 |  iteration: 12678 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 248 loss: 1.25911 acc: 0.71452 | v_loss: 1.50278 v_acc: 0.69108 |  iteration: 12679 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 249 loss: 1.40175 acc: 0.68880 | v_loss: 1.36438 v_acc: 0.69792 |  iteration: 12680 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 250 loss: 1.25671 acc: 0.70182 | v_loss: 1.19435 v_acc: 0.72396 |  iteration: 12681 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 251 loss: 1.29176 acc: 0.69596 | v_loss: 1.16256 v_acc: 0.70996 |  iteration: 12682 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 252 loss: 1.22499 acc: 0.71061 | v_loss: 1.13707 v_acc: 0.72298 |  iteration: 12683 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 253 loss: 1.26247 acc: 0.71061 | v_loss: 1.23849 v_acc: 0.70540 |  iteration: 12684 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 254 loss: 1.28151 acc: 0.70443 | v_loss: 1.24767 v_acc: 0.71810 |  iteration: 12685 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 255 loss: 1.29584 acc: 0.70410 | v_loss: 1.20892 v_acc: 0.73470 |  iteration: 12686 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 256 loss: 1.39792 acc: 0.69336 | v_loss: 1.23194 v_acc: 0.71777 |  iteration: 12687 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 257 loss: 1.33529 acc: 0.70182 | v_loss: 1.21791 v_acc: 0.71257 |  iteration: 12688 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 258 loss: 1.25352 acc: 0.70898 | v_loss: 1.14367 v_acc: 0.72591 |  iteration: 12689 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 259 loss: 1.22872 acc: 0.70996 | v_loss: 1.13638 v_acc: 0.72201 |  iteration: 12690 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 260 loss: 1.31592 acc: 0.69303 | v_loss: 1.43887 v_acc: 0.69206 |  iteration: 12691 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 261 loss: 1.28149 acc: 0.70638 | v_loss: 1.22679 v_acc: 0.70801 |  iteration: 12692 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 262 loss: 1.34862 acc: 0.69889 | v_loss: 1.20922 v_acc: 0.71387 |  iteration: 12693 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 263 loss: 1.26843 acc: 0.71582 | v_loss: 1.19629 v_acc: 0.70443 |  iteration: 12694 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 264 loss: 1.27500 acc: 0.70117 | v_loss: 1.26235 v_acc: 0.69954 |  iteration: 12695 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 265 loss: 1.20854 acc: 0.70931 | v_loss: 1.16039 v_acc: 0.73340 |  iteration: 12696 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 266 loss: 1.17107 acc: 0.72168 | v_loss: 1.39054 v_acc: 0.71224 |  iteration: 12697 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 267 loss: 1.39850 acc: 0.69076 | v_loss: 1.20238 v_acc: 0.70052 |  iteration: 12698 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 268 loss: 1.24467 acc: 0.70671 | v_loss: 1.19899 v_acc: 0.70671 |  iteration: 12699 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 269 loss: 1.25199 acc: 0.70898 | v_loss: 1.28659 v_acc: 0.70312 |  iteration: 12700 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 270 loss: 1.19380 acc: 0.70866 | v_loss: 1.29950 v_acc: 0.70247 |  iteration: 12701 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 271 loss: 1.32446 acc: 0.70312 | v_loss: 1.34943 v_acc: 0.69629 |  iteration: 12702 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 272 loss: 1.25575 acc: 0.71647 | v_loss: 1.35877 v_acc: 0.70898 |  iteration: 12703 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 273 loss: 1.37403 acc: 0.69694 | v_loss: 1.29788 v_acc: 0.69987 |  iteration: 12704 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 274 loss: 1.32285 acc: 0.70410 | v_loss: 1.21470 v_acc: 0.70898 |  iteration: 12705 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 275 loss: 1.29513 acc: 0.69564 | v_loss: 1.29539 v_acc: 0.70768 |  iteration: 12706 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 276 loss: 1.31075 acc: 0.69629 | v_loss: 1.18477 v_acc: 0.71745 |  iteration: 12707 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 277 loss: 1.20626 acc: 0.71452 | v_loss: 1.16286 v_acc: 0.72624 |  iteration: 12708 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 278 loss: 1.29674 acc: 0.71191 | v_loss: 1.10348 v_acc: 0.71061 |  iteration: 12709 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 279 loss: 1.29604 acc: 0.70117 | v_loss: 1.24414 v_acc: 0.70605 |  iteration: 12710 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 280 loss: 1.22878 acc: 0.70573 | v_loss: 1.33794 v_acc: 0.69694 |  iteration: 12711 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 281 loss: 1.28471 acc: 0.70443 | v_loss: 1.19935 v_acc: 0.70573 |  iteration: 12712 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 282 loss: 1.26325 acc: 0.70410 | v_loss: 1.24950 v_acc: 0.69564 |  iteration: 12713 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 283 loss: 1.23548 acc: 0.71094 | v_loss: 1.16167 v_acc: 0.71257 |  iteration: 12714 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 284 loss: 1.23039 acc: 0.70866 | v_loss: 1.18406 v_acc: 0.70638 |  iteration: 12715 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 285 loss: 1.25446 acc: 0.70703 | v_loss: 1.13033 v_acc: 0.73503 |  iteration: 12716 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 286 loss: 1.23539 acc: 0.71582 | v_loss: 1.17104 v_acc: 0.71842 |  iteration: 12717 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 287 loss: 1.23761 acc: 0.70475 | v_loss: 1.23194 v_acc: 0.71615 |  iteration: 12718 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 288 loss: 1.26269 acc: 0.70703 | v_loss: 1.15039 v_acc: 0.73307 |  iteration: 12719 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 289 loss: 1.24810 acc: 0.71322 | v_loss: 1.21935 v_acc: 0.71517 |  iteration: 12720 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 290 loss: 1.36237 acc: 0.69466 | v_loss: 1.25038 v_acc: 0.70833 |  iteration: 12721 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 291 loss: 1.25436 acc: 0.71257 | v_loss: 1.24054 v_acc: 0.71940 |  iteration: 12722 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 292 loss: 1.16248 acc: 0.71745 | v_loss: 1.37570 v_acc: 0.70475 |  iteration: 12723 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 293 loss: 1.26931 acc: 0.71029 | v_loss: 1.29166 v_acc: 0.71387 |  iteration: 12724 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 294 loss: 1.27716 acc: 0.70150 | v_loss: 1.06601 v_acc: 0.74056 |  iteration: 12725 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 295 loss: 1.21172 acc: 0.71061 | v_loss: 1.17461 v_acc: 0.70605 |  iteration: 12726 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 296 loss: 1.31459 acc: 0.69434 | v_loss: 1.27657 v_acc: 0.69043 |  iteration: 12727 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 297 loss: 1.18141 acc: 0.71354 | v_loss: 1.18443 v_acc: 0.69434 |  iteration: 12728 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 298 loss: 1.34804 acc: 0.69987 | v_loss: 1.24557 v_acc: 0.70280 |  iteration: 12729 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 299 loss: 1.30154 acc: 0.69792 | v_loss: 1.25475 v_acc: 0.68685 |  iteration: 12730 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 300 loss: 1.20357 acc: 0.71354 | v_loss: 1.18599 v_acc: 0.71940 |  iteration: 12731 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 301 loss: 1.30864 acc: 0.70117 | v_loss: 1.23244 v_acc: 0.70247 |  iteration: 12732 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 302 loss: 1.28793 acc: 0.71322 | v_loss: 1.20981 v_acc: 0.71224 |  iteration: 12733 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 303 loss: 1.21235 acc: 0.71484 | v_loss: 1.20602 v_acc: 0.72396 |  iteration: 12734 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 304 loss: 1.27184 acc: 0.71615 | v_loss: 1.26043 v_acc: 0.70117 |  iteration: 12735 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 305 loss: 1.23514 acc: 0.71745 | v_loss: 1.30952 v_acc: 0.69954 |  iteration: 12736 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 306 loss: 1.23676 acc: 0.70573 | v_loss: 1.14859 v_acc: 0.70833 |  iteration: 12737 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 307 loss: 1.17676 acc: 0.71549 | v_loss: 1.38867 v_acc: 0.68783 |  iteration: 12738 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 308 loss: 1.32070 acc: 0.70052 | v_loss: 1.17447 v_acc: 0.72135 |  iteration: 12739 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 309 loss: 1.29791 acc: 0.70410 | v_loss: 1.47743 v_acc: 0.68424 |  iteration: 12740 teacher: 0 stage: sketch lr: 0.000392\n",
      "batch 310 loss: 1.27853 acc: 0.71094 | v_loss: 1.32349 v_acc: 0.69987 |  iteration: 12741 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 311 loss: 1.22240 acc: 0.71322 | v_loss: 1.33527 v_acc: 0.69173 |  iteration: 12742 teacher: 1 stage: sketch lr: 0.000392\n",
      "batch 312 loss: 1.28305 acc: 0.70573 | v_loss: 1.29076 v_acc: 0.69954 |  iteration: 12743 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 313 loss: 1.22940 acc: 0.71387 | v_loss: 1.20741 v_acc: 0.70736 |  iteration: 12744 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 314 loss: 1.28680 acc: 0.70736 | v_loss: 1.23392 v_acc: 0.70801 |  iteration: 12745 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 315 loss: 1.27759 acc: 0.70280 | v_loss: 1.19180 v_acc: 0.72298 |  iteration: 12746 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 316 loss: 1.28067 acc: 0.70638 | v_loss: 1.39733 v_acc: 0.68783 |  iteration: 12747 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 317 loss: 1.29821 acc: 0.69922 | v_loss: 1.26755 v_acc: 0.70443 |  iteration: 12748 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 318 loss: 1.31464 acc: 0.69661 | v_loss: 1.23100 v_acc: 0.70703 |  iteration: 12749 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 319 loss: 1.25966 acc: 0.69954 | v_loss: 1.25451 v_acc: 0.71191 |  iteration: 12750 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 320 loss: 1.26550 acc: 0.71029 | v_loss: 1.16185 v_acc: 0.70508 |  iteration: 12751 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 321 loss: 1.38222 acc: 0.68750 | v_loss: 1.27419 v_acc: 0.69759 |  iteration: 12752 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 322 loss: 1.28001 acc: 0.69922 | v_loss: 1.25863 v_acc: 0.71973 |  iteration: 12753 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 323 loss: 1.28455 acc: 0.70182 | v_loss: 1.18288 v_acc: 0.71777 |  iteration: 12754 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 324 loss: 1.28690 acc: 0.69759 | v_loss: 1.16702 v_acc: 0.72461 |  iteration: 12755 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 325 loss: 1.27592 acc: 0.71257 | v_loss: 1.24704 v_acc: 0.71745 |  iteration: 12756 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 326 loss: 1.26014 acc: 0.70768 | v_loss: 1.24311 v_acc: 0.70378 |  iteration: 12757 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 327 loss: 1.24695 acc: 0.70475 | v_loss: 1.25220 v_acc: 0.70638 |  iteration: 12758 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 328 loss: 1.27930 acc: 0.70964 | v_loss: 1.09640 v_acc: 0.72070 |  iteration: 12759 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 329 loss: 1.38966 acc: 0.69271 | v_loss: 1.24360 v_acc: 0.73079 |  iteration: 12760 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 330 loss: 1.29329 acc: 0.70833 | v_loss: 1.31116 v_acc: 0.69564 |  iteration: 12761 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 331 loss: 1.30122 acc: 0.70801 | v_loss: 1.29861 v_acc: 0.72168 |  iteration: 12762 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 332 loss: 1.29807 acc: 0.70150 | v_loss: 1.14022 v_acc: 0.72266 |  iteration: 12763 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 333 loss: 1.30218 acc: 0.70508 | v_loss: 1.09677 v_acc: 0.73861 |  iteration: 12764 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 334 loss: 1.33940 acc: 0.69857 | v_loss: 1.11721 v_acc: 0.72591 |  iteration: 12765 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 335 loss: 1.25920 acc: 0.70475 | v_loss: 1.19764 v_acc: 0.71126 |  iteration: 12766 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 336 loss: 1.25810 acc: 0.69824 | v_loss: 1.26177 v_acc: 0.70345 |  iteration: 12767 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 337 loss: 1.24495 acc: 0.71159 | v_loss: 1.18648 v_acc: 0.71680 |  iteration: 12768 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 338 loss: 1.23721 acc: 0.70117 | v_loss: 1.30958 v_acc: 0.69043 |  iteration: 12769 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 339 loss: 1.23045 acc: 0.70573 | v_loss: 1.50646 v_acc: 0.68945 |  iteration: 12770 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 340 loss: 1.35313 acc: 0.70020 | v_loss: 1.37053 v_acc: 0.69629 |  iteration: 12771 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 341 loss: 1.26728 acc: 0.70247 | v_loss: 1.19992 v_acc: 0.72526 |  iteration: 12772 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 342 loss: 1.26359 acc: 0.70540 | v_loss: 1.17524 v_acc: 0.71029 |  iteration: 12773 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 343 loss: 1.21491 acc: 0.70638 | v_loss: 1.13616 v_acc: 0.71973 |  iteration: 12774 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 344 loss: 1.27906 acc: 0.69792 | v_loss: 1.23784 v_acc: 0.70508 |  iteration: 12775 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 345 loss: 1.31458 acc: 0.70345 | v_loss: 1.24058 v_acc: 0.71810 |  iteration: 12776 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 346 loss: 1.22092 acc: 0.70605 | v_loss: 1.21330 v_acc: 0.73014 |  iteration: 12777 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 347 loss: 1.34190 acc: 0.69564 | v_loss: 1.24470 v_acc: 0.71810 |  iteration: 12778 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 348 loss: 1.32306 acc: 0.70605 | v_loss: 1.23569 v_acc: 0.70768 |  iteration: 12779 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 349 loss: 1.31422 acc: 0.70312 | v_loss: 1.16497 v_acc: 0.72201 |  iteration: 12780 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 350 loss: 1.23911 acc: 0.70378 | v_loss: 1.14157 v_acc: 0.72201 |  iteration: 12781 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 351 loss: 1.18889 acc: 0.71582 | v_loss: 1.41834 v_acc: 0.69010 |  iteration: 12782 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 352 loss: 1.22054 acc: 0.70605 | v_loss: 1.20693 v_acc: 0.70768 |  iteration: 12783 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 353 loss: 1.27260 acc: 0.70898 | v_loss: 1.20212 v_acc: 0.71810 |  iteration: 12784 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 354 loss: 1.24265 acc: 0.71224 | v_loss: 1.19648 v_acc: 0.71875 |  iteration: 12785 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 355 loss: 1.33564 acc: 0.69694 | v_loss: 1.25067 v_acc: 0.70964 |  iteration: 12786 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 356 loss: 1.22082 acc: 0.71029 | v_loss: 1.13869 v_acc: 0.73340 |  iteration: 12787 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 357 loss: 1.25359 acc: 0.69987 | v_loss: 1.37337 v_acc: 0.71549 |  iteration: 12788 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 358 loss: 1.24614 acc: 0.69922 | v_loss: 1.16465 v_acc: 0.70312 |  iteration: 12789 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 359 loss: 1.32714 acc: 0.69368 | v_loss: 1.19124 v_acc: 0.70345 |  iteration: 12790 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 360 loss: 1.25474 acc: 0.70247 | v_loss: 1.28590 v_acc: 0.70378 |  iteration: 12791 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 361 loss: 1.28861 acc: 0.69206 | v_loss: 1.30066 v_acc: 0.70085 |  iteration: 12792 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 362 loss: 1.27221 acc: 0.70182 | v_loss: 1.35379 v_acc: 0.69173 |  iteration: 12793 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 363 loss: 1.23062 acc: 0.70605 | v_loss: 1.37336 v_acc: 0.70605 |  iteration: 12794 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 364 loss: 1.29921 acc: 0.70215 | v_loss: 1.30181 v_acc: 0.70215 |  iteration: 12795 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 365 loss: 1.29729 acc: 0.69922 | v_loss: 1.22476 v_acc: 0.70801 |  iteration: 12796 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 366 loss: 1.22937 acc: 0.70866 | v_loss: 1.29128 v_acc: 0.72038 |  iteration: 12797 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 367 loss: 1.30066 acc: 0.70182 | v_loss: 1.19295 v_acc: 0.71289 |  iteration: 12798 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 368 loss: 1.45043 acc: 0.68815 | v_loss: 1.17220 v_acc: 0.72005 |  iteration: 12799 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 369 loss: 1.31575 acc: 0.70443 | v_loss: 1.10469 v_acc: 0.71061 |  iteration: 12800 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 370 loss: 1.26870 acc: 0.70964 | v_loss: 1.24941 v_acc: 0.70573 |  iteration: 12801 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 371 loss: 1.23923 acc: 0.70801 | v_loss: 1.32827 v_acc: 0.69792 |  iteration: 12802 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 372 loss: 1.26397 acc: 0.70410 | v_loss: 1.17797 v_acc: 0.70573 |  iteration: 12803 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 373 loss: 1.40164 acc: 0.69954 | v_loss: 1.22622 v_acc: 0.69661 |  iteration: 12804 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 374 loss: 1.22162 acc: 0.70866 | v_loss: 1.17433 v_acc: 0.71126 |  iteration: 12805 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 375 loss: 1.30981 acc: 0.69694 | v_loss: 1.18853 v_acc: 0.70638 |  iteration: 12806 teacher: 0 stage: sketch lr: 0.000391\n",
      "batch 376 loss: 1.33177 acc: 0.70671 | v_loss: 1.10906 v_acc: 0.73470 |  iteration: 12807 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 377 loss: 1.31796 acc: 0.70085 | v_loss: 1.17519 v_acc: 0.71908 |  iteration: 12808 teacher: 1 stage: sketch lr: 0.000391\n",
      "batch 378 loss: 1.25639 acc: 0.71322 | v_loss: 1.18336 v_acc: 0.72591 |  iteration: 12809 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 379 loss: 1.30314 acc: 0.70085 | v_loss: 1.12795 v_acc: 0.72396 |  iteration: 12810 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 380 loss: 1.27403 acc: 0.69824 | v_loss: 1.21570 v_acc: 0.71810 |  iteration: 12811 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 381 loss: 1.27203 acc: 0.70605 | v_loss: 1.26030 v_acc: 0.71289 |  iteration: 12812 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 382 loss: 1.36340 acc: 0.69238 | v_loss: 1.22424 v_acc: 0.72233 |  iteration: 12813 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 383 loss: 1.30796 acc: 0.70801 | v_loss: 1.37257 v_acc: 0.70280 |  iteration: 12814 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 384 loss: 1.26320 acc: 0.70182 | v_loss: 1.29822 v_acc: 0.71745 |  iteration: 12815 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 385 loss: 1.23121 acc: 0.70833 | v_loss: 1.06503 v_acc: 0.74382 |  iteration: 12816 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 386 loss: 1.27578 acc: 0.69792 | v_loss: 1.18143 v_acc: 0.70638 |  iteration: 12817 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 387 loss: 1.21744 acc: 0.71517 | v_loss: 1.27903 v_acc: 0.70020 |  iteration: 12818 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 388 loss: 1.25882 acc: 0.71419 | v_loss: 1.16303 v_acc: 0.70833 |  iteration: 12819 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 389 loss: 1.29329 acc: 0.71387 | v_loss: 1.23677 v_acc: 0.71257 |  iteration: 12820 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 390 loss: 1.22123 acc: 0.70703 | v_loss: 1.24647 v_acc: 0.69173 |  iteration: 12821 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 391 loss: 1.22339 acc: 0.71159 | v_loss: 1.19274 v_acc: 0.71094 |  iteration: 12822 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 392 loss: 1.26949 acc: 0.71029 | v_loss: 1.23407 v_acc: 0.69629 |  iteration: 12823 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 393 loss: 1.47439 acc: 0.68685 | v_loss: 1.19700 v_acc: 0.71517 |  iteration: 12824 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 394 loss: 1.27304 acc: 0.70768 | v_loss: 1.16718 v_acc: 0.72526 |  iteration: 12825 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 395 loss: 1.22046 acc: 0.71029 | v_loss: 1.25499 v_acc: 0.70247 |  iteration: 12826 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 396 loss: 1.38482 acc: 0.70085 | v_loss: 1.31204 v_acc: 0.69661 |  iteration: 12827 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 397 loss: 1.29771 acc: 0.70898 | v_loss: 1.14934 v_acc: 0.70833 |  iteration: 12828 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 398 loss: 1.32868 acc: 0.69727 | v_loss: 1.40884 v_acc: 0.68229 |  iteration: 12829 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 399 loss: 1.22132 acc: 0.70964 | v_loss: 1.18809 v_acc: 0.72005 |  iteration: 12830 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 400 loss: 1.27896 acc: 0.70508 | v_loss: 1.46827 v_acc: 0.67480 |  iteration: 12831 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 401 loss: 1.27891 acc: 0.70215 | v_loss: 1.35041 v_acc: 0.69206 |  iteration: 12832 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 402 loss: 1.34904 acc: 0.70280 | v_loss: 1.35306 v_acc: 0.69173 |  iteration: 12833 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 403 loss: 1.34119 acc: 0.69531 | v_loss: 1.27941 v_acc: 0.70345 |  iteration: 12834 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 404 loss: 1.23027 acc: 0.70182 | v_loss: 1.23501 v_acc: 0.70898 |  iteration: 12835 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 405 loss: 1.36546 acc: 0.69368 | v_loss: 1.25039 v_acc: 0.70736 |  iteration: 12836 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 406 loss: 1.26155 acc: 0.70573 | v_loss: 1.20936 v_acc: 0.72168 |  iteration: 12837 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 407 loss: 1.27866 acc: 0.69564 | v_loss: 1.38662 v_acc: 0.68783 |  iteration: 12838 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 408 loss: 1.27889 acc: 0.70605 | v_loss: 1.27445 v_acc: 0.70638 |  iteration: 12839 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 409 loss: 1.32992 acc: 0.70020 | v_loss: 1.19394 v_acc: 0.71029 |  iteration: 12840 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 410 loss: 1.33004 acc: 0.69434 | v_loss: 1.24927 v_acc: 0.71810 |  iteration: 12841 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 411 loss: 1.25173 acc: 0.71322 | v_loss: 1.16516 v_acc: 0.70736 |  iteration: 12842 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 412 loss: 1.34315 acc: 0.70052 | v_loss: 1.25617 v_acc: 0.69629 |  iteration: 12843 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 413 loss: 1.27835 acc: 0.70182 | v_loss: 1.22851 v_acc: 0.71354 |  iteration: 12844 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 414 loss: 1.25949 acc: 0.70801 | v_loss: 1.16016 v_acc: 0.72005 |  iteration: 12845 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 415 loss: 1.35360 acc: 0.70182 | v_loss: 1.13613 v_acc: 0.72591 |  iteration: 12846 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 416 loss: 1.27045 acc: 0.70898 | v_loss: 1.25498 v_acc: 0.71908 |  iteration: 12847 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 417 loss: 1.34596 acc: 0.69108 | v_loss: 1.25587 v_acc: 0.70150 |  iteration: 12848 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 418 loss: 1.23382 acc: 0.70182 | v_loss: 1.27506 v_acc: 0.70866 |  iteration: 12849 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 419 loss: 1.31993 acc: 0.70345 | v_loss: 1.09420 v_acc: 0.72461 |  iteration: 12850 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 420 loss: 1.30087 acc: 0.69954 | v_loss: 1.26798 v_acc: 0.73307 |  iteration: 12851 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 421 loss: 1.37385 acc: 0.69303 | v_loss: 1.30433 v_acc: 0.69531 |  iteration: 12852 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 422 loss: 1.30752 acc: 0.70703 | v_loss: 1.30299 v_acc: 0.72070 |  iteration: 12853 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 423 loss: 1.26398 acc: 0.71159 | v_loss: 1.14678 v_acc: 0.72135 |  iteration: 12854 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 424 loss: 1.36677 acc: 0.70508 | v_loss: 1.10283 v_acc: 0.73763 |  iteration: 12855 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 425 loss: 1.28323 acc: 0.70931 | v_loss: 1.10279 v_acc: 0.72298 |  iteration: 12856 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 426 loss: 1.37371 acc: 0.68262 | v_loss: 1.18646 v_acc: 0.71191 |  iteration: 12857 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 427 loss: 1.25896 acc: 0.70931 | v_loss: 1.23011 v_acc: 0.69727 |  iteration: 12858 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 428 loss: 1.32584 acc: 0.70247 | v_loss: 1.18623 v_acc: 0.71517 |  iteration: 12859 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 429 loss: 1.24987 acc: 0.70671 | v_loss: 1.30507 v_acc: 0.70182 |  iteration: 12860 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 430 loss: 1.20410 acc: 0.71647 | v_loss: 1.46652 v_acc: 0.69141 |  iteration: 12861 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 431 loss: 1.28923 acc: 0.70475 | v_loss: 1.35190 v_acc: 0.69889 |  iteration: 12862 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 432 loss: 1.24568 acc: 0.70898 | v_loss: 1.19463 v_acc: 0.71908 |  iteration: 12863 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 433 loss: 1.17957 acc: 0.71810 | v_loss: 1.16877 v_acc: 0.70703 |  iteration: 12864 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 434 loss: 1.30373 acc: 0.70866 | v_loss: 1.14049 v_acc: 0.72363 |  iteration: 12865 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 435 loss: 1.26638 acc: 0.70801 | v_loss: 1.23045 v_acc: 0.70573 |  iteration: 12866 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 436 loss: 1.28389 acc: 0.70443 | v_loss: 1.22979 v_acc: 0.72363 |  iteration: 12867 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 437 loss: 1.26597 acc: 0.70671 | v_loss: 1.20709 v_acc: 0.72786 |  iteration: 12868 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 438 loss: 1.31452 acc: 0.70475 | v_loss: 1.22580 v_acc: 0.71908 |  iteration: 12869 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 439 loss: 1.20711 acc: 0.71094 | v_loss: 1.22726 v_acc: 0.71224 |  iteration: 12870 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 440 loss: 1.33030 acc: 0.69466 | v_loss: 1.16358 v_acc: 0.72493 |  iteration: 12871 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 441 loss: 1.35862 acc: 0.68978 | v_loss: 1.13022 v_acc: 0.72135 |  iteration: 12872 teacher: 1 stage: sketch lr: 0.000390\n",
      "batch 442 loss: 1.23819 acc: 0.70573 | v_loss: 1.44780 v_acc: 0.69238 |  iteration: 12873 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 443 loss: 1.25996 acc: 0.70280 | v_loss: 1.21040 v_acc: 0.71061 |  iteration: 12874 teacher: 0 stage: sketch lr: 0.000390\n",
      "batch 444 loss: 1.28016 acc: 0.70801 | v_loss: 1.20233 v_acc: 0.72038 |  iteration: 12875 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 445 loss: 1.24081 acc: 0.70085 | v_loss: 1.20340 v_acc: 0.71257 |  iteration: 12876 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 446 loss: 1.28774 acc: 0.69564 | v_loss: 1.25735 v_acc: 0.70898 |  iteration: 12877 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 447 loss: 1.29756 acc: 0.70215 | v_loss: 1.14949 v_acc: 0.73372 |  iteration: 12878 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 448 loss: 1.17582 acc: 0.71126 | v_loss: 1.37061 v_acc: 0.71029 |  iteration: 12879 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 449 loss: 1.29375 acc: 0.70117 | v_loss: 1.18111 v_acc: 0.69954 |  iteration: 12880 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 450 loss: 1.24957 acc: 0.70996 | v_loss: 1.18969 v_acc: 0.70345 |  iteration: 12881 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 451 loss: 1.37136 acc: 0.69564 | v_loss: 1.26355 v_acc: 0.70410 |  iteration: 12882 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 452 loss: 1.26045 acc: 0.70703 | v_loss: 1.26540 v_acc: 0.70150 |  iteration: 12883 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 453 loss: 1.30810 acc: 0.68880 | v_loss: 1.32469 v_acc: 0.69499 |  iteration: 12884 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 454 loss: 1.23275 acc: 0.70443 | v_loss: 1.35653 v_acc: 0.70768 |  iteration: 12885 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 455 loss: 1.34194 acc: 0.69271 | v_loss: 1.27670 v_acc: 0.70312 |  iteration: 12886 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 456 loss: 1.25938 acc: 0.70345 | v_loss: 1.18526 v_acc: 0.70931 |  iteration: 12887 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 457 loss: 1.19775 acc: 0.71061 | v_loss: 1.28979 v_acc: 0.70703 |  iteration: 12888 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 458 loss: 1.23008 acc: 0.70866 | v_loss: 1.20177 v_acc: 0.71289 |  iteration: 12889 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 459 loss: 1.16685 acc: 0.73405 | v_loss: 1.15139 v_acc: 0.72428 |  iteration: 12890 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 460 loss: 1.21605 acc: 0.71159 | v_loss: 1.10555 v_acc: 0.70964 |  iteration: 12891 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 461 loss: 1.28121 acc: 0.70378 | v_loss: 1.25764 v_acc: 0.70443 |  iteration: 12892 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 462 loss: 1.26611 acc: 0.70801 | v_loss: 1.32706 v_acc: 0.69792 |  iteration: 12893 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 463 loss: 1.22228 acc: 0.70768 | v_loss: 1.18437 v_acc: 0.70540 |  iteration: 12894 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 464 loss: 1.27148 acc: 0.70117 | v_loss: 1.23678 v_acc: 0.69499 |  iteration: 12895 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 465 loss: 1.26655 acc: 0.71257 | v_loss: 1.17557 v_acc: 0.70801 |  iteration: 12896 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 466 loss: 1.33839 acc: 0.69824 | v_loss: 1.19414 v_acc: 0.70508 |  iteration: 12897 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 467 loss: 1.24791 acc: 0.71191 | v_loss: 1.10185 v_acc: 0.73568 |  iteration: 12898 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 468 loss: 1.28953 acc: 0.70475 | v_loss: 1.16944 v_acc: 0.72005 |  iteration: 12899 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 469 loss: 1.22538 acc: 0.70801 | v_loss: 1.20117 v_acc: 0.72689 |  iteration: 12900 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 470 loss: 1.26598 acc: 0.71224 | v_loss: 1.12923 v_acc: 0.73275 |  iteration: 12901 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 471 loss: 1.30551 acc: 0.70085 | v_loss: 1.20162 v_acc: 0.71615 |  iteration: 12902 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 472 loss: 1.27979 acc: 0.70280 | v_loss: 1.25431 v_acc: 0.71061 |  iteration: 12903 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 473 loss: 1.28044 acc: 0.70312 | v_loss: 1.22719 v_acc: 0.72038 |  iteration: 12904 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 474 loss: 1.24387 acc: 0.70280 | v_loss: 1.37339 v_acc: 0.70117 |  iteration: 12905 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 475 loss: 1.30480 acc: 0.71289 | v_loss: 1.28936 v_acc: 0.71712 |  iteration: 12906 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 476 loss: 1.28354 acc: 0.70671 | v_loss: 1.06908 v_acc: 0.74642 |  iteration: 12907 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 477 loss: 1.26855 acc: 0.70475 | v_loss: 1.17963 v_acc: 0.70540 |  iteration: 12908 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 478 loss: 1.33008 acc: 0.70475 | v_loss: 1.28785 v_acc: 0.69694 |  iteration: 12909 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 479 loss: 1.33204 acc: 0.69857 | v_loss: 1.17049 v_acc: 0.69922 |  iteration: 12910 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 480 loss: 1.22857 acc: 0.71257 | v_loss: 1.25425 v_acc: 0.71191 |  iteration: 12911 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 481 loss: 1.22637 acc: 0.70801 | v_loss: 1.25579 v_acc: 0.69010 |  iteration: 12912 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 482 loss: 1.29398 acc: 0.69271 | v_loss: 1.19195 v_acc: 0.71452 |  iteration: 12913 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 483 loss: 1.29733 acc: 0.69922 | v_loss: 1.22043 v_acc: 0.70085 |  iteration: 12914 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 484 loss: 1.26795 acc: 0.70150 | v_loss: 1.22708 v_acc: 0.71680 |  iteration: 12915 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 485 loss: 1.34432 acc: 0.70117 | v_loss: 1.19598 v_acc: 0.72559 |  iteration: 12916 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 486 loss: 1.28842 acc: 0.70020 | v_loss: 1.27220 v_acc: 0.70312 |  iteration: 12917 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 487 loss: 1.22967 acc: 0.70736 | v_loss: 1.29965 v_acc: 0.69857 |  iteration: 12918 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 488 loss: 1.32996 acc: 0.70247 | v_loss: 1.14797 v_acc: 0.70671 |  iteration: 12919 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 489 loss: 1.29330 acc: 0.69206 | v_loss: 1.39768 v_acc: 0.68294 |  iteration: 12920 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 490 loss: 1.31094 acc: 0.69531 | v_loss: 1.18161 v_acc: 0.71973 |  iteration: 12921 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 491 loss: 1.24727 acc: 0.70378 | v_loss: 1.44550 v_acc: 0.68132 |  iteration: 12922 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 492 loss: 1.31359 acc: 0.70410 | v_loss: 1.33183 v_acc: 0.70085 |  iteration: 12923 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 493 loss: 1.25608 acc: 0.69954 | v_loss: 1.34274 v_acc: 0.69303 |  iteration: 12924 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 494 loss: 1.23869 acc: 0.71549 | v_loss: 1.27728 v_acc: 0.70443 |  iteration: 12925 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 495 loss: 1.30280 acc: 0.70703 | v_loss: 1.22682 v_acc: 0.70898 |  iteration: 12926 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 496 loss: 1.29244 acc: 0.70052 | v_loss: 1.23708 v_acc: 0.70736 |  iteration: 12927 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 497 loss: 1.27057 acc: 0.69889 | v_loss: 1.19874 v_acc: 0.72103 |  iteration: 12928 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 498 loss: 1.30293 acc: 0.70020 | v_loss: 1.39717 v_acc: 0.68099 |  iteration: 12929 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 499 loss: 1.27862 acc: 0.70215 | v_loss: 1.27073 v_acc: 0.71224 |  iteration: 12930 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 500 loss: 1.26528 acc: 0.71126 | v_loss: 1.18067 v_acc: 0.70703 |  iteration: 12931 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 501 loss: 1.30253 acc: 0.70605 | v_loss: 1.24871 v_acc: 0.71126 |  iteration: 12932 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 502 loss: 1.22623 acc: 0.70508 | v_loss: 1.15249 v_acc: 0.70833 |  iteration: 12933 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 503 loss: 1.24268 acc: 0.70605 | v_loss: 1.25478 v_acc: 0.69954 |  iteration: 12934 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 504 loss: 1.24197 acc: 0.70801 | v_loss: 1.22966 v_acc: 0.71354 |  iteration: 12935 teacher: 0 stage: sketch lr: 0.000389\n",
      "batch 505 loss: 1.35057 acc: 0.69661 | v_loss: 1.16362 v_acc: 0.71940 |  iteration: 12936 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 506 loss: 1.28763 acc: 0.71159 | v_loss: 1.12991 v_acc: 0.72526 |  iteration: 12937 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 507 loss: 1.28635 acc: 0.70508 | v_loss: 1.25135 v_acc: 0.71810 |  iteration: 12938 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 508 loss: 1.34793 acc: 0.70117 | v_loss: 1.24726 v_acc: 0.70150 |  iteration: 12939 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 509 loss: 1.17036 acc: 0.70573 | v_loss: 1.24816 v_acc: 0.70931 |  iteration: 12940 teacher: 1 stage: sketch lr: 0.000389\n",
      "batch 510 loss: 1.36984 acc: 0.70996 | v_loss: 1.09157 v_acc: 0.72428 |  iteration: 12941 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 511 loss: 1.25979 acc: 0.71126 | v_loss: 1.24609 v_acc: 0.72852 |  iteration: 12942 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 512 loss: 1.36966 acc: 0.70833 | v_loss: 1.29729 v_acc: 0.69564 |  iteration: 12943 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 513 loss: 1.37994 acc: 0.70052 | v_loss: 1.28819 v_acc: 0.72103 |  iteration: 12944 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 514 loss: 1.25109 acc: 0.70638 | v_loss: 1.14688 v_acc: 0.72168 |  iteration: 12945 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 515 loss: 1.34058 acc: 0.69857 | v_loss: 1.10564 v_acc: 0.73470 |  iteration: 12946 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 516 loss: 1.23135 acc: 0.71029 | v_loss: 1.09642 v_acc: 0.72591 |  iteration: 12947 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 517 loss: 1.24989 acc: 0.70475 | v_loss: 1.17851 v_acc: 0.70866 |  iteration: 12948 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 518 loss: 1.27160 acc: 0.70833 | v_loss: 1.23181 v_acc: 0.70345 |  iteration: 12949 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 519 loss: 1.23945 acc: 0.71061 | v_loss: 1.17192 v_acc: 0.71647 |  iteration: 12950 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 520 loss: 1.36240 acc: 0.69954 | v_loss: 1.30864 v_acc: 0.70410 |  iteration: 12951 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 521 loss: 1.22913 acc: 0.71061 | v_loss: 1.48705 v_acc: 0.69043 |  iteration: 12952 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 522 loss: 1.25071 acc: 0.70508 | v_loss: 1.36071 v_acc: 0.69727 |  iteration: 12953 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 523 loss: 1.34267 acc: 0.69173 | v_loss: 1.19759 v_acc: 0.72103 |  iteration: 12954 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 524 loss: 1.21299 acc: 0.71582 | v_loss: 1.17704 v_acc: 0.70964 |  iteration: 12955 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 525 loss: 1.31614 acc: 0.69759 | v_loss: 1.14612 v_acc: 0.72331 |  iteration: 12956 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 526 loss: 1.30463 acc: 0.69824 | v_loss: 1.24698 v_acc: 0.70508 |  iteration: 12957 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 527 loss: 1.27837 acc: 0.70540 | v_loss: 1.23981 v_acc: 0.72135 |  iteration: 12958 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 528 loss: 1.22296 acc: 0.70410 | v_loss: 1.22773 v_acc: 0.72754 |  iteration: 12959 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 529 loss: 1.29830 acc: 0.70182 | v_loss: 1.25071 v_acc: 0.71875 |  iteration: 12960 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 530 loss: 1.25561 acc: 0.70540 | v_loss: 1.22452 v_acc: 0.71322 |  iteration: 12961 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 531 loss: 1.44185 acc: 0.69303 | v_loss: 1.15105 v_acc: 0.72493 |  iteration: 12962 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 532 loss: 1.38502 acc: 0.69466 | v_loss: 1.11718 v_acc: 0.72070 |  iteration: 12963 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 533 loss: 1.27453 acc: 0.70898 | v_loss: 1.43553 v_acc: 0.69303 |  iteration: 12964 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 534 loss: 1.23760 acc: 0.70866 | v_loss: 1.18819 v_acc: 0.71061 |  iteration: 12965 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 535 loss: 1.13250 acc: 0.71354 | v_loss: 1.20184 v_acc: 0.72038 |  iteration: 12966 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 536 loss: 1.26970 acc: 0.69824 | v_loss: 1.20982 v_acc: 0.71322 |  iteration: 12967 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 537 loss: 1.32076 acc: 0.70703 | v_loss: 1.26155 v_acc: 0.70801 |  iteration: 12968 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 538 loss: 1.31905 acc: 0.70345 | v_loss: 1.12440 v_acc: 0.73340 |  iteration: 12969 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 539 loss: 1.22499 acc: 0.70768 | v_loss: 1.36226 v_acc: 0.71322 |  iteration: 12970 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 540 loss: 1.34063 acc: 0.69499 | v_loss: 1.17578 v_acc: 0.70150 |  iteration: 12971 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 541 loss: 1.31198 acc: 0.70215 | v_loss: 1.19474 v_acc: 0.70508 |  iteration: 12972 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 542 loss: 1.30330 acc: 0.70020 | v_loss: 1.28472 v_acc: 0.70475 |  iteration: 12973 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 543 loss: 1.30333 acc: 0.69531 | v_loss: 1.29336 v_acc: 0.69954 |  iteration: 12974 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 544 loss: 1.27122 acc: 0.70085 | v_loss: 1.35660 v_acc: 0.69238 |  iteration: 12975 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 545 loss: 1.19783 acc: 0.70866 | v_loss: 1.36318 v_acc: 0.70801 |  iteration: 12976 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 546 loss: 1.22645 acc: 0.71257 | v_loss: 1.29680 v_acc: 0.70215 |  iteration: 12977 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 547 loss: 1.29368 acc: 0.70573 | v_loss: 1.22682 v_acc: 0.70866 |  iteration: 12978 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 548 loss: 1.30997 acc: 0.69043 | v_loss: 1.28714 v_acc: 0.70866 |  iteration: 12979 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 549 loss: 1.34360 acc: 0.70605 | v_loss: 1.19107 v_acc: 0.71777 |  iteration: 12980 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 550 loss: 1.26924 acc: 0.70605 | v_loss: 1.14376 v_acc: 0.72396 |  iteration: 12981 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 551 loss: 1.37919 acc: 0.69206 | v_loss: 1.09825 v_acc: 0.70996 |  iteration: 12982 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 552 loss: 1.17281 acc: 0.71094 | v_loss: 1.23970 v_acc: 0.70508 |  iteration: 12983 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 553 loss: 1.26147 acc: 0.70540 | v_loss: 1.29667 v_acc: 0.70020 |  iteration: 12984 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 554 loss: 1.25266 acc: 0.70085 | v_loss: 1.14995 v_acc: 0.70540 |  iteration: 12985 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 555 loss: 1.23166 acc: 0.70573 | v_loss: 1.21709 v_acc: 0.69564 |  iteration: 12986 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 556 loss: 1.32618 acc: 0.70378 | v_loss: 1.17072 v_acc: 0.70833 |  iteration: 12987 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 557 loss: 1.28495 acc: 0.71257 | v_loss: 1.20382 v_acc: 0.70312 |  iteration: 12988 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 558 loss: 1.30664 acc: 0.70898 | v_loss: 1.08513 v_acc: 0.73503 |  iteration: 12989 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 559 loss: 1.18209 acc: 0.71777 | v_loss: 1.16548 v_acc: 0.71582 |  iteration: 12990 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 560 loss: 1.28147 acc: 0.71029 | v_loss: 1.18930 v_acc: 0.72819 |  iteration: 12991 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 561 loss: 1.18628 acc: 0.72428 | v_loss: 1.12683 v_acc: 0.72363 |  iteration: 12992 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 562 loss: 1.25378 acc: 0.69857 | v_loss: 1.21298 v_acc: 0.71647 |  iteration: 12993 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 563 loss: 1.27370 acc: 0.71094 | v_loss: 1.25561 v_acc: 0.71257 |  iteration: 12994 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 564 loss: 1.28993 acc: 0.70573 | v_loss: 1.22164 v_acc: 0.72363 |  iteration: 12995 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 565 loss: 1.33847 acc: 0.68978 | v_loss: 1.36443 v_acc: 0.70475 |  iteration: 12996 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 566 loss: 1.21336 acc: 0.71777 | v_loss: 1.28688 v_acc: 0.71452 |  iteration: 12997 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 567 loss: 1.33123 acc: 0.69531 | v_loss: 1.04546 v_acc: 0.74512 |  iteration: 12998 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 568 loss: 1.25279 acc: 0.70573 | v_loss: 1.17255 v_acc: 0.70898 |  iteration: 12999 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 569 loss: 1.25157 acc: 0.71322 | v_loss: 1.27644 v_acc: 0.69303 |  iteration: 13000 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 570 loss: 1.23722 acc: 0.70150 | v_loss: 1.16993 v_acc: 0.69401 |  iteration: 13001 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 571 loss: 1.30421 acc: 0.70443 | v_loss: 1.23896 v_acc: 0.70540 |  iteration: 13002 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 572 loss: 1.31154 acc: 0.69922 | v_loss: 1.24282 v_acc: 0.69271 |  iteration: 13003 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 573 loss: 1.25456 acc: 0.70540 | v_loss: 1.20103 v_acc: 0.71257 |  iteration: 13004 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 574 loss: 1.27915 acc: 0.70117 | v_loss: 1.22803 v_acc: 0.69499 |  iteration: 13005 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 575 loss: 1.18671 acc: 0.71452 | v_loss: 1.25576 v_acc: 0.70540 |  iteration: 13006 teacher: 1 stage: sketch lr: 0.000388\n",
      "batch 576 loss: 1.25518 acc: 0.70866 | v_loss: 1.20278 v_acc: 0.71842 |  iteration: 13007 teacher: 0 stage: sketch lr: 0.000388\n",
      "batch 577 loss: 1.27271 acc: 0.70378 | v_loss: 1.26347 v_acc: 0.70020 |  iteration: 13008 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 578 loss: 1.23814 acc: 0.71159 | v_loss: 1.31692 v_acc: 0.69596 |  iteration: 13009 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 579 loss: 1.30545 acc: 0.70605 | v_loss: 1.16295 v_acc: 0.71029 |  iteration: 13010 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 580 loss: 1.24310 acc: 0.70052 | v_loss: 1.39994 v_acc: 0.68001 |  iteration: 13011 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 581 loss: 1.37829 acc: 0.70605 | v_loss: 1.19225 v_acc: 0.72103 |  iteration: 13012 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 582 loss: 1.17169 acc: 0.71452 | v_loss: 1.44589 v_acc: 0.68034 |  iteration: 13013 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 583 loss: 1.21904 acc: 0.71094 | v_loss: 1.33183 v_acc: 0.69727 |  iteration: 13014 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 584 loss: 1.20763 acc: 0.71354 | v_loss: 1.35123 v_acc: 0.69238 |  iteration: 13015 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 585 loss: 1.32596 acc: 0.70085 | v_loss: 1.26073 v_acc: 0.70215 |  iteration: 13016 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 586 loss: 1.25132 acc: 0.70410 | v_loss: 1.21732 v_acc: 0.70768 |  iteration: 13017 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 587 loss: 1.16327 acc: 0.71549 | v_loss: 1.22992 v_acc: 0.70898 |  iteration: 13018 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 588 loss: 1.15081 acc: 0.72689 | v_loss: 1.20500 v_acc: 0.72266 |  iteration: 13019 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 589 loss: 1.29615 acc: 0.70312 | v_loss: 1.39230 v_acc: 0.68880 |  iteration: 13020 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 590 loss: 1.31792 acc: 0.70085 | v_loss: 1.27649 v_acc: 0.71159 |  iteration: 13021 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 591 loss: 1.23369 acc: 0.71257 | v_loss: 1.17588 v_acc: 0.71126 |  iteration: 13022 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 592 loss: 1.18095 acc: 0.70898 | v_loss: 1.22297 v_acc: 0.72070 |  iteration: 13023 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 593 loss: 1.29355 acc: 0.70117 | v_loss: 1.14577 v_acc: 0.70801 |  iteration: 13024 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 594 loss: 1.26094 acc: 0.70085 | v_loss: 1.25070 v_acc: 0.69824 |  iteration: 13025 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 595 loss: 1.20309 acc: 0.71517 | v_loss: 1.20683 v_acc: 0.71517 |  iteration: 13026 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 596 loss: 1.28516 acc: 0.70833 | v_loss: 1.13948 v_acc: 0.71875 |  iteration: 13027 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 597 loss: 1.22558 acc: 0.70540 | v_loss: 1.13935 v_acc: 0.72493 |  iteration: 13028 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 598 loss: 1.31409 acc: 0.70052 | v_loss: 1.24221 v_acc: 0.71387 |  iteration: 13029 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 599 loss: 1.24659 acc: 0.70117 | v_loss: 1.26662 v_acc: 0.69857 |  iteration: 13030 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 600 loss: 1.34296 acc: 0.69824 | v_loss: 1.26927 v_acc: 0.70573 |  iteration: 13031 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 601 loss: 1.33595 acc: 0.70052 | v_loss: 1.08979 v_acc: 0.71712 |  iteration: 13032 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 602 loss: 1.23383 acc: 0.71061 | v_loss: 1.28894 v_acc: 0.72428 |  iteration: 13033 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 603 loss: 1.28378 acc: 0.70964 | v_loss: 1.34567 v_acc: 0.69043 |  iteration: 13034 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 604 loss: 1.28038 acc: 0.70182 | v_loss: 1.30217 v_acc: 0.71842 |  iteration: 13035 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 605 loss: 1.30244 acc: 0.69076 | v_loss: 1.13834 v_acc: 0.71973 |  iteration: 13036 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 606 loss: 1.30569 acc: 0.70215 | v_loss: 1.09186 v_acc: 0.73926 |  iteration: 13037 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 607 loss: 1.17475 acc: 0.71354 | v_loss: 1.09215 v_acc: 0.72331 |  iteration: 13038 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 608 loss: 1.25453 acc: 0.70052 | v_loss: 1.18562 v_acc: 0.70996 |  iteration: 13039 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 609 loss: 1.21835 acc: 0.71061 | v_loss: 1.21216 v_acc: 0.70801 |  iteration: 13040 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 610 loss: 1.27881 acc: 0.70898 | v_loss: 1.18097 v_acc: 0.71452 |  iteration: 13041 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 611 loss: 1.23807 acc: 0.70671 | v_loss: 1.29213 v_acc: 0.70671 |  iteration: 13042 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 612 loss: 1.25912 acc: 0.70475 | v_loss: 1.44877 v_acc: 0.69336 |  iteration: 13043 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 613 loss: 1.28084 acc: 0.70150 | v_loss: 1.32711 v_acc: 0.70020 |  iteration: 13044 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 614 loss: 1.17954 acc: 0.70443 | v_loss: 1.18062 v_acc: 0.72331 |  iteration: 13045 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 615 loss: 1.25665 acc: 0.70117 | v_loss: 1.13860 v_acc: 0.70833 |  iteration: 13046 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 616 loss: 1.32738 acc: 0.70996 | v_loss: 1.12852 v_acc: 0.72428 |  iteration: 13047 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 617 loss: 1.18702 acc: 0.72266 | v_loss: 1.20096 v_acc: 0.70508 |  iteration: 13048 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 618 loss: 1.26154 acc: 0.70020 | v_loss: 1.22665 v_acc: 0.72070 |  iteration: 13049 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 619 loss: 1.25841 acc: 0.70410 | v_loss: 1.18826 v_acc: 0.72754 |  iteration: 13050 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 620 loss: 1.24074 acc: 0.72331 | v_loss: 1.22444 v_acc: 0.71908 |  iteration: 13051 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 621 loss: 1.33684 acc: 0.70085 | v_loss: 1.23255 v_acc: 0.71126 |  iteration: 13052 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 622 loss: 1.27793 acc: 0.71257 | v_loss: 1.14504 v_acc: 0.72233 |  iteration: 13053 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 623 loss: 1.32509 acc: 0.70117 | v_loss: 1.10889 v_acc: 0.72070 |  iteration: 13054 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 624 loss: 1.28653 acc: 0.70703 | v_loss: 1.40724 v_acc: 0.68945 |  iteration: 13055 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 625 loss: 1.20670 acc: 0.70573 | v_loss: 1.22374 v_acc: 0.70573 |  iteration: 13056 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 626 loss: 1.32018 acc: 0.69596 | v_loss: 1.19994 v_acc: 0.71582 |  iteration: 13057 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 627 loss: 1.25359 acc: 0.71126 | v_loss: 1.20755 v_acc: 0.69987 |  iteration: 13058 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 628 loss: 1.28463 acc: 0.70508 | v_loss: 1.25886 v_acc: 0.69727 |  iteration: 13059 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 629 loss: 1.28695 acc: 0.70605 | v_loss: 1.16105 v_acc: 0.72982 |  iteration: 13060 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 630 loss: 1.25778 acc: 0.70475 | v_loss: 1.37016 v_acc: 0.70866 |  iteration: 13061 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 631 loss: 1.25751 acc: 0.70378 | v_loss: 1.18253 v_acc: 0.70150 |  iteration: 13062 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 632 loss: 1.24184 acc: 0.70573 | v_loss: 1.19112 v_acc: 0.70671 |  iteration: 13063 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 633 loss: 1.32185 acc: 0.69531 | v_loss: 1.26536 v_acc: 0.70443 |  iteration: 13064 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 634 loss: 1.29707 acc: 0.71484 | v_loss: 1.27149 v_acc: 0.70085 |  iteration: 13065 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 635 loss: 1.30529 acc: 0.69759 | v_loss: 1.33648 v_acc: 0.69401 |  iteration: 13066 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 636 loss: 1.19877 acc: 0.71517 | v_loss: 1.36314 v_acc: 0.70833 |  iteration: 13067 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 637 loss: 1.35178 acc: 0.70508 | v_loss: 1.29472 v_acc: 0.70215 |  iteration: 13068 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 638 loss: 1.24654 acc: 0.70378 | v_loss: 1.18264 v_acc: 0.71224 |  iteration: 13069 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 639 loss: 1.30666 acc: 0.69954 | v_loss: 1.27653 v_acc: 0.70931 |  iteration: 13070 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 640 loss: 1.28916 acc: 0.70280 | v_loss: 1.17714 v_acc: 0.71777 |  iteration: 13071 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 641 loss: 1.25822 acc: 0.70540 | v_loss: 1.16151 v_acc: 0.72168 |  iteration: 13072 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 642 loss: 1.17782 acc: 0.71712 | v_loss: 1.09462 v_acc: 0.71289 |  iteration: 13073 teacher: 0 stage: sketch lr: 0.000387\n",
      "batch 643 loss: 1.34684 acc: 0.70312 | v_loss: 1.23927 v_acc: 0.70443 |  iteration: 13074 teacher: 1 stage: sketch lr: 0.000387\n",
      "batch 644 loss: 1.30941 acc: 0.69824 | v_loss: 1.31109 v_acc: 0.69466 |  iteration: 13075 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 645 loss: 1.27966 acc: 0.70573 | v_loss: 1.14587 v_acc: 0.70833 |  iteration: 13076 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 646 loss: 1.20008 acc: 0.71191 | v_loss: 1.20036 v_acc: 0.69727 |  iteration: 13077 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 647 loss: 1.16254 acc: 0.72363 | v_loss: 1.17777 v_acc: 0.71126 |  iteration: 13078 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 648 loss: 1.26280 acc: 0.71452 | v_loss: 1.20796 v_acc: 0.70540 |  iteration: 13079 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 649 loss: 1.28292 acc: 0.69336 | v_loss: 1.08082 v_acc: 0.73503 |  iteration: 13080 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 650 loss: 1.26380 acc: 0.70703 | v_loss: 1.16733 v_acc: 0.71875 |  iteration: 13081 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 651 loss: 1.25355 acc: 0.71322 | v_loss: 1.14747 v_acc: 0.72526 |  iteration: 13082 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 652 loss: 1.29569 acc: 0.69824 | v_loss: 1.13442 v_acc: 0.72526 |  iteration: 13083 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 653 loss: 1.26397 acc: 0.69889 | v_loss: 1.20153 v_acc: 0.71745 |  iteration: 13084 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 654 loss: 1.28351 acc: 0.71224 | v_loss: 1.23043 v_acc: 0.71159 |  iteration: 13085 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 655 loss: 1.24119 acc: 0.70703 | v_loss: 1.22574 v_acc: 0.72266 |  iteration: 13086 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 656 loss: 1.30424 acc: 0.69824 | v_loss: 1.37133 v_acc: 0.70150 |  iteration: 13087 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 657 loss: 1.28947 acc: 0.70150 | v_loss: 1.29277 v_acc: 0.71517 |  iteration: 13088 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 658 loss: 1.26765 acc: 0.70638 | v_loss: 1.05250 v_acc: 0.74056 |  iteration: 13089 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 659 loss: 1.31901 acc: 0.70833 | v_loss: 1.19452 v_acc: 0.70182 |  iteration: 13090 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 660 loss: 1.35631 acc: 0.69857 | v_loss: 1.28442 v_acc: 0.69368 |  iteration: 13091 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 661 loss: 1.32416 acc: 0.69922 | v_loss: 1.18610 v_acc: 0.69401 |  iteration: 13092 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 662 loss: 1.23140 acc: 0.71159 | v_loss: 1.23984 v_acc: 0.71387 |  iteration: 13093 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 663 loss: 1.21507 acc: 0.70996 | v_loss: 1.23311 v_acc: 0.69466 |  iteration: 13094 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 664 loss: 1.24337 acc: 0.71354 | v_loss: 1.19076 v_acc: 0.71224 |  iteration: 13095 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 665 loss: 1.43802 acc: 0.69076 | v_loss: 1.21712 v_acc: 0.69629 |  iteration: 13096 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 666 loss: 1.25938 acc: 0.70312 | v_loss: 1.17349 v_acc: 0.71517 |  iteration: 13097 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 667 loss: 1.38255 acc: 0.69596 | v_loss: 1.17512 v_acc: 0.72591 |  iteration: 13098 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 668 loss: 1.33418 acc: 0.69401 | v_loss: 1.22517 v_acc: 0.70312 |  iteration: 13099 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 669 loss: 1.26731 acc: 0.70736 | v_loss: 1.31000 v_acc: 0.69889 |  iteration: 13100 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 670 loss: 1.28574 acc: 0.69889 | v_loss: 1.14079 v_acc: 0.70573 |  iteration: 13101 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 671 loss: 1.28354 acc: 0.70475 | v_loss: 1.38898 v_acc: 0.68555 |  iteration: 13102 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 672 loss: 1.30008 acc: 0.69987 | v_loss: 1.16603 v_acc: 0.72201 |  iteration: 13103 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 673 loss: 1.36765 acc: 0.70215 | v_loss: 1.44076 v_acc: 0.68359 |  iteration: 13104 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 674 loss: 1.29656 acc: 0.69629 | v_loss: 1.31066 v_acc: 0.70117 |  iteration: 13105 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 675 loss: 1.26155 acc: 0.69857 | v_loss: 1.33778 v_acc: 0.69303 |  iteration: 13106 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 676 loss: 1.31724 acc: 0.69629 | v_loss: 1.27049 v_acc: 0.70215 |  iteration: 13107 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 677 loss: 1.22070 acc: 0.71159 | v_loss: 1.23491 v_acc: 0.70866 |  iteration: 13108 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 678 loss: 1.27796 acc: 0.71191 | v_loss: 1.23721 v_acc: 0.70898 |  iteration: 13109 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 679 loss: 1.30346 acc: 0.69889 | v_loss: 1.19197 v_acc: 0.72103 |  iteration: 13110 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 680 loss: 1.32418 acc: 0.70671 | v_loss: 1.37098 v_acc: 0.69076 |  iteration: 13111 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 681 loss: 1.25609 acc: 0.70866 | v_loss: 1.25645 v_acc: 0.71191 |  iteration: 13112 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 682 loss: 1.24789 acc: 0.69499 | v_loss: 1.16002 v_acc: 0.70801 |  iteration: 13113 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 683 loss: 1.37367 acc: 0.69824 | v_loss: 1.23028 v_acc: 0.71354 |  iteration: 13114 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 684 loss: 1.23427 acc: 0.71126 | v_loss: 1.13855 v_acc: 0.71257 |  iteration: 13115 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 685 loss: 1.38425 acc: 0.68913 | v_loss: 1.24963 v_acc: 0.70150 |  iteration: 13116 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 686 loss: 1.28330 acc: 0.70964 | v_loss: 1.20982 v_acc: 0.71582 |  iteration: 13117 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 687 loss: 1.31242 acc: 0.70085 | v_loss: 1.15890 v_acc: 0.71745 |  iteration: 13118 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 688 loss: 1.28357 acc: 0.70052 | v_loss: 1.14316 v_acc: 0.72624 |  iteration: 13119 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 689 loss: 1.28446 acc: 0.70312 | v_loss: 1.24853 v_acc: 0.71615 |  iteration: 13120 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 690 loss: 1.21455 acc: 0.71484 | v_loss: 1.25447 v_acc: 0.69857 |  iteration: 13121 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 691 loss: 1.29355 acc: 0.69792 | v_loss: 1.27815 v_acc: 0.70345 |  iteration: 13122 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 692 loss: 1.26112 acc: 0.69889 | v_loss: 1.08505 v_acc: 0.71908 |  iteration: 13123 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 693 loss: 1.31036 acc: 0.70312 | v_loss: 1.25568 v_acc: 0.72819 |  iteration: 13124 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 694 loss: 1.27212 acc: 0.70671 | v_loss: 1.30657 v_acc: 0.69531 |  iteration: 13125 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 695 loss: 1.19770 acc: 0.70736 | v_loss: 1.28952 v_acc: 0.72135 |  iteration: 13126 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 696 loss: 1.30298 acc: 0.70540 | v_loss: 1.11295 v_acc: 0.72168 |  iteration: 13127 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 697 loss: 1.18958 acc: 0.71289 | v_loss: 1.06896 v_acc: 0.74219 |  iteration: 13128 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 698 loss: 1.27313 acc: 0.70345 | v_loss: 1.07042 v_acc: 0.72103 |  iteration: 13129 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 699 loss: 1.20293 acc: 0.71419 | v_loss: 1.17422 v_acc: 0.70540 |  iteration: 13130 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 700 loss: 1.29057 acc: 0.69661 | v_loss: 1.21065 v_acc: 0.70964 |  iteration: 13131 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 701 loss: 1.23379 acc: 0.71029 | v_loss: 1.19869 v_acc: 0.71484 |  iteration: 13132 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 702 loss: 1.34829 acc: 0.70638 | v_loss: 1.31126 v_acc: 0.69303 |  iteration: 13133 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 703 loss: 1.25691 acc: 0.71191 | v_loss: 1.46225 v_acc: 0.68978 |  iteration: 13134 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 704 loss: 1.35038 acc: 0.70247 | v_loss: 1.34453 v_acc: 0.69922 |  iteration: 13135 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 705 loss: 1.24552 acc: 0.70768 | v_loss: 1.19230 v_acc: 0.71908 |  iteration: 13136 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 706 loss: 1.20975 acc: 0.71159 | v_loss: 1.15966 v_acc: 0.70866 |  iteration: 13137 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 707 loss: 1.29266 acc: 0.70931 | v_loss: 1.13689 v_acc: 0.72266 |  iteration: 13138 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 708 loss: 1.28243 acc: 0.70768 | v_loss: 1.22073 v_acc: 0.70280 |  iteration: 13139 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 709 loss: 1.28373 acc: 0.69922 | v_loss: 1.23110 v_acc: 0.71387 |  iteration: 13140 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 710 loss: 1.23315 acc: 0.71126 | v_loss: 1.20505 v_acc: 0.72721 |  iteration: 13141 teacher: 1 stage: sketch lr: 0.000386\n",
      "batch 711 loss: 1.27735 acc: 0.71061 | v_loss: 1.24612 v_acc: 0.71908 |  iteration: 13142 teacher: 0 stage: sketch lr: 0.000386\n",
      "batch 712 loss: 1.28805 acc: 0.70117 | v_loss: 1.22423 v_acc: 0.71224 |  iteration: 13143 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 713 loss: 1.23140 acc: 0.71387 | v_loss: 1.13826 v_acc: 0.72689 |  iteration: 13144 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 714 loss: 1.18134 acc: 0.71517 | v_loss: 1.11734 v_acc: 0.72070 |  iteration: 13145 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 715 loss: 1.38275 acc: 0.70085 | v_loss: 1.43289 v_acc: 0.69401 |  iteration: 13146 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 716 loss: 1.24610 acc: 0.70898 | v_loss: 1.18008 v_acc: 0.71257 |  iteration: 13147 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 717 loss: 1.20877 acc: 0.72396 | v_loss: 1.20832 v_acc: 0.71940 |  iteration: 13148 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 718 loss: 1.19957 acc: 0.71419 | v_loss: 1.21379 v_acc: 0.71029 |  iteration: 13149 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 719 loss: 1.30281 acc: 0.70117 | v_loss: 1.24977 v_acc: 0.70768 |  iteration: 13150 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 720 loss: 1.34471 acc: 0.69629 | v_loss: 1.13187 v_acc: 0.73372 |  iteration: 13151 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 721 loss: 1.31788 acc: 0.70150 | v_loss: 1.34812 v_acc: 0.71484 |  iteration: 13152 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 722 loss: 1.21239 acc: 0.70475 | v_loss: 1.18703 v_acc: 0.70117 |  iteration: 13153 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 723 loss: 1.29879 acc: 0.70573 | v_loss: 1.20813 v_acc: 0.70150 |  iteration: 13154 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 724 loss: 1.37326 acc: 0.69987 | v_loss: 1.25918 v_acc: 0.70540 |  iteration: 13155 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 725 loss: 1.27861 acc: 0.72201 | v_loss: 1.26830 v_acc: 0.69922 |  iteration: 13156 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 726 loss: 1.26658 acc: 0.70540 | v_loss: 1.34107 v_acc: 0.68750 |  iteration: 13157 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 727 loss: 1.23585 acc: 0.71354 | v_loss: 1.36674 v_acc: 0.70280 |  iteration: 13158 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 728 loss: 1.24814 acc: 0.70703 | v_loss: 1.28350 v_acc: 0.70540 |  iteration: 13159 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 729 loss: 1.23982 acc: 0.71224 | v_loss: 1.19506 v_acc: 0.70801 |  iteration: 13160 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 730 loss: 1.34330 acc: 0.69596 | v_loss: 1.29293 v_acc: 0.70605 |  iteration: 13161 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 731 loss: 1.31094 acc: 0.70410 | v_loss: 1.20423 v_acc: 0.71191 |  iteration: 13162 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 732 loss: 1.20320 acc: 0.71745 | v_loss: 1.12112 v_acc: 0.72298 |  iteration: 13163 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 733 loss: 1.24868 acc: 0.70931 | v_loss: 1.13107 v_acc: 0.70638 |  iteration: 13164 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 734 loss: 1.35825 acc: 0.70182 | v_loss: 1.23360 v_acc: 0.70703 |  iteration: 13165 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 735 loss: 1.16478 acc: 0.71647 | v_loss: 1.31467 v_acc: 0.69954 |  iteration: 13166 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 736 loss: 1.26415 acc: 0.70768 | v_loss: 1.14410 v_acc: 0.71777 |  iteration: 13167 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 737 loss: 1.35962 acc: 0.70052 | v_loss: 1.18518 v_acc: 0.70117 |  iteration: 13168 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 738 loss: 1.27242 acc: 0.71029 | v_loss: 1.19746 v_acc: 0.70573 |  iteration: 13169 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 739 loss: 1.29809 acc: 0.70671 | v_loss: 1.20584 v_acc: 0.70280 |  iteration: 13170 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 740 loss: 1.22200 acc: 0.72038 | v_loss: 1.04741 v_acc: 0.73828 |  iteration: 13171 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 741 loss: 1.29621 acc: 0.71419 | v_loss: 1.16008 v_acc: 0.71842 |  iteration: 13172 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 742 loss: 1.29578 acc: 0.69824 | v_loss: 1.15929 v_acc: 0.72331 |  iteration: 13173 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 743 loss: 1.26627 acc: 0.70931 | v_loss: 1.12797 v_acc: 0.71712 |  iteration: 13174 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 744 loss: 1.26030 acc: 0.70540 | v_loss: 1.19739 v_acc: 0.71615 |  iteration: 13175 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 745 loss: 1.28210 acc: 0.70964 | v_loss: 1.20990 v_acc: 0.71777 |  iteration: 13176 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 746 loss: 1.30580 acc: 0.69727 | v_loss: 1.20716 v_acc: 0.71875 |  iteration: 13177 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 747 loss: 1.25842 acc: 0.71094 | v_loss: 1.36718 v_acc: 0.69922 |  iteration: 13178 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 748 loss: 1.35617 acc: 0.69466 | v_loss: 1.27620 v_acc: 0.71712 |  iteration: 13179 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 749 loss: 1.32361 acc: 0.70573 | v_loss: 1.03584 v_acc: 0.74479 |  iteration: 13180 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 750 loss: 1.20165 acc: 0.71387 | v_loss: 1.19220 v_acc: 0.70898 |  iteration: 13181 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 751 loss: 1.27576 acc: 0.69824 | v_loss: 1.24775 v_acc: 0.69629 |  iteration: 13182 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 752 loss: 1.31256 acc: 0.69499 | v_loss: 1.19760 v_acc: 0.70703 |  iteration: 13183 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 753 loss: 1.36786 acc: 0.69792 | v_loss: 1.22766 v_acc: 0.71289 |  iteration: 13184 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 754 loss: 1.26223 acc: 0.70703 | v_loss: 1.23200 v_acc: 0.69759 |  iteration: 13185 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 755 loss: 1.28183 acc: 0.69629 | v_loss: 1.20610 v_acc: 0.71842 |  iteration: 13186 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 756 loss: 1.35621 acc: 0.70508 | v_loss: 1.24006 v_acc: 0.70182 |  iteration: 13187 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 757 loss: 1.28814 acc: 0.71126 | v_loss: 1.19326 v_acc: 0.71745 |  iteration: 13188 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 758 loss: 1.33627 acc: 0.70508 | v_loss: 1.17561 v_acc: 0.72526 |  iteration: 13189 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 759 loss: 1.33704 acc: 0.70052 | v_loss: 1.24242 v_acc: 0.70247 |  iteration: 13190 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 760 loss: 1.28913 acc: 0.70345 | v_loss: 1.31546 v_acc: 0.69987 |  iteration: 13191 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 761 loss: 1.31942 acc: 0.69889 | v_loss: 1.15511 v_acc: 0.70638 |  iteration: 13192 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 762 loss: 1.28179 acc: 0.70508 | v_loss: 1.38002 v_acc: 0.68717 |  iteration: 13193 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 763 loss: 1.34362 acc: 0.70866 | v_loss: 1.15954 v_acc: 0.72135 |  iteration: 13194 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 764 loss: 1.30326 acc: 0.71061 | v_loss: 1.43795 v_acc: 0.68294 |  iteration: 13195 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 765 loss: 1.27684 acc: 0.71094 | v_loss: 1.33992 v_acc: 0.70215 |  iteration: 13196 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 766 loss: 1.25950 acc: 0.70638 | v_loss: 1.31692 v_acc: 0.69368 |  iteration: 13197 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 767 loss: 1.28127 acc: 0.70996 | v_loss: 1.28937 v_acc: 0.70378 |  iteration: 13198 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 768 loss: 1.33825 acc: 0.69401 | v_loss: 1.21126 v_acc: 0.70508 |  iteration: 13199 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 769 loss: 1.26708 acc: 0.70215 | v_loss: 1.25879 v_acc: 0.70312 |  iteration: 13200 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 770 loss: 1.22611 acc: 0.72135 | v_loss: 1.19343 v_acc: 0.72038 |  iteration: 13201 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 771 loss: 1.28574 acc: 0.70312 | v_loss: 1.40282 v_acc: 0.69141 |  iteration: 13202 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 772 loss: 1.23765 acc: 0.70768 | v_loss: 1.30086 v_acc: 0.71159 |  iteration: 13203 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 773 loss: 1.26114 acc: 0.70898 | v_loss: 1.18369 v_acc: 0.71159 |  iteration: 13204 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 774 loss: 1.31275 acc: 0.69792 | v_loss: 1.22731 v_acc: 0.71745 |  iteration: 13205 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 775 loss: 1.30462 acc: 0.71029 | v_loss: 1.14119 v_acc: 0.70833 |  iteration: 13206 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 776 loss: 1.31599 acc: 0.70378 | v_loss: 1.25702 v_acc: 0.69824 |  iteration: 13207 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 777 loss: 1.33461 acc: 0.70931 | v_loss: 1.20939 v_acc: 0.71549 |  iteration: 13208 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 778 loss: 1.28103 acc: 0.69596 | v_loss: 1.15247 v_acc: 0.71712 |  iteration: 13209 teacher: 1 stage: sketch lr: 0.000385\n",
      "batch 779 loss: 1.16377 acc: 0.71973 | v_loss: 1.12110 v_acc: 0.72786 |  iteration: 13210 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 780 loss: 1.29873 acc: 0.69531 | v_loss: 1.23746 v_acc: 0.71712 |  iteration: 13211 teacher: 0 stage: sketch lr: 0.000385\n",
      "batch 781 loss: 1.29369 acc: 0.70898 | v_loss: 1.25088 v_acc: 0.70182 |  iteration: 13212 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 782 loss: 1.28401 acc: 0.70345 | v_loss: 1.25731 v_acc: 0.70638 |  iteration: 13213 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 783 loss: 1.32321 acc: 0.69954 | v_loss: 1.09562 v_acc: 0.72396 |  iteration: 13214 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 784 loss: 1.31459 acc: 0.71126 | v_loss: 1.23013 v_acc: 0.72721 |  iteration: 13215 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 785 loss: 1.21664 acc: 0.70085 | v_loss: 1.27811 v_acc: 0.69889 |  iteration: 13216 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 786 loss: 1.35597 acc: 0.69954 | v_loss: 1.30432 v_acc: 0.72363 |  iteration: 13217 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 787 loss: 1.24247 acc: 0.70964 | v_loss: 1.15004 v_acc: 0.71973 |  iteration: 13218 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 788 loss: 1.23531 acc: 0.71419 | v_loss: 1.10465 v_acc: 0.73275 |  iteration: 13219 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 789 loss: 1.27707 acc: 0.70475 | v_loss: 1.08380 v_acc: 0.72526 |  iteration: 13220 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 790 loss: 1.20403 acc: 0.71680 | v_loss: 1.17512 v_acc: 0.70671 |  iteration: 13221 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 791 loss: 1.24189 acc: 0.70443 | v_loss: 1.21684 v_acc: 0.70052 |  iteration: 13222 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 792 loss: 1.36384 acc: 0.69564 | v_loss: 1.18619 v_acc: 0.71549 |  iteration: 13223 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 793 loss: 1.36723 acc: 0.69922 | v_loss: 1.27907 v_acc: 0.70410 |  iteration: 13224 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 794 loss: 1.34711 acc: 0.69954 | v_loss: 1.49278 v_acc: 0.69076 |  iteration: 13225 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 795 loss: 1.32273 acc: 0.69824 | v_loss: 1.36977 v_acc: 0.69727 |  iteration: 13226 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 796 loss: 1.30933 acc: 0.70410 | v_loss: 1.20081 v_acc: 0.72070 |  iteration: 13227 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 797 loss: 1.28256 acc: 0.70117 | v_loss: 1.17538 v_acc: 0.70801 |  iteration: 13228 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 798 loss: 1.32246 acc: 0.69531 | v_loss: 1.12848 v_acc: 0.72103 |  iteration: 13229 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 799 loss: 1.30369 acc: 0.71061 | v_loss: 1.21466 v_acc: 0.70345 |  iteration: 13230 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 800 loss: 1.31376 acc: 0.70280 | v_loss: 1.23538 v_acc: 0.72005 |  iteration: 13231 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 801 loss: 1.29973 acc: 0.69336 | v_loss: 1.20882 v_acc: 0.73047 |  iteration: 13232 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 802 loss: 1.28986 acc: 0.70801 | v_loss: 1.21999 v_acc: 0.72298 |  iteration: 13233 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 803 loss: 1.26429 acc: 0.70671 | v_loss: 1.22051 v_acc: 0.71224 |  iteration: 13234 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 804 loss: 1.34882 acc: 0.69727 | v_loss: 1.14460 v_acc: 0.72559 |  iteration: 13235 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 805 loss: 1.25148 acc: 0.70833 | v_loss: 1.11754 v_acc: 0.72396 |  iteration: 13236 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 806 loss: 1.23195 acc: 0.69824 | v_loss: 1.46445 v_acc: 0.69173 |  iteration: 13237 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 807 loss: 1.32832 acc: 0.71387 | v_loss: 1.18851 v_acc: 0.71061 |  iteration: 13238 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 808 loss: 1.26666 acc: 0.70605 | v_loss: 1.21045 v_acc: 0.71940 |  iteration: 13239 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 809 loss: 1.24402 acc: 0.71191 | v_loss: 1.20310 v_acc: 0.71908 |  iteration: 13240 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 810 loss: 1.31399 acc: 0.70410 | v_loss: 1.25832 v_acc: 0.70866 |  iteration: 13241 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 811 loss: 1.28482 acc: 0.70736 | v_loss: 1.12182 v_acc: 0.73470 |  iteration: 13242 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 812 loss: 1.28681 acc: 0.71126 | v_loss: 1.34426 v_acc: 0.71452 |  iteration: 13243 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 813 loss: 1.22866 acc: 0.70150 | v_loss: 1.17841 v_acc: 0.69857 |  iteration: 13244 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 814 loss: 1.28109 acc: 0.70573 | v_loss: 1.18934 v_acc: 0.70671 |  iteration: 13245 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 815 loss: 1.25841 acc: 0.70085 | v_loss: 1.24357 v_acc: 0.70410 |  iteration: 13246 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 816 loss: 1.24771 acc: 0.70801 | v_loss: 1.25069 v_acc: 0.70150 |  iteration: 13247 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 817 loss: 1.35348 acc: 0.69596 | v_loss: 1.33349 v_acc: 0.69368 |  iteration: 13248 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 818 loss: 1.30610 acc: 0.69303 | v_loss: 1.36671 v_acc: 0.70801 |  iteration: 13249 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 819 loss: 1.22634 acc: 0.70215 | v_loss: 1.26567 v_acc: 0.70410 |  iteration: 13250 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 820 loss: 1.22059 acc: 0.71224 | v_loss: 1.16841 v_acc: 0.71126 |  iteration: 13251 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 821 loss: 1.23281 acc: 0.70605 | v_loss: 1.29073 v_acc: 0.70931 |  iteration: 13252 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 822 loss: 1.25744 acc: 0.70866 | v_loss: 1.19592 v_acc: 0.71810 |  iteration: 13253 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 823 loss: 1.26510 acc: 0.70540 | v_loss: 1.13578 v_acc: 0.72656 |  iteration: 13254 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 824 loss: 1.31812 acc: 0.69857 | v_loss: 1.13318 v_acc: 0.71094 |  iteration: 13255 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 825 loss: 1.30910 acc: 0.70671 | v_loss: 1.24307 v_acc: 0.70508 |  iteration: 13256 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 826 loss: 1.31540 acc: 0.70280 | v_loss: 1.30161 v_acc: 0.70085 |  iteration: 13257 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 827 loss: 1.26116 acc: 0.70736 | v_loss: 1.14095 v_acc: 0.71257 |  iteration: 13258 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 828 loss: 1.22827 acc: 0.70801 | v_loss: 1.19001 v_acc: 0.69596 |  iteration: 13259 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 829 loss: 1.20357 acc: 0.70996 | v_loss: 1.18723 v_acc: 0.71061 |  iteration: 13260 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 830 loss: 1.31141 acc: 0.70866 | v_loss: 1.20517 v_acc: 0.70410 |  iteration: 13261 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 831 loss: 1.18848 acc: 0.71224 | v_loss: 1.05039 v_acc: 0.73861 |  iteration: 13262 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 832 loss: 1.42309 acc: 0.68685 | v_loss: 1.15593 v_acc: 0.71973 |  iteration: 13263 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 833 loss: 1.29959 acc: 0.69824 | v_loss: 1.14178 v_acc: 0.72624 |  iteration: 13264 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 834 loss: 1.28362 acc: 0.70443 | v_loss: 1.12557 v_acc: 0.72103 |  iteration: 13265 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 835 loss: 1.26148 acc: 0.70410 | v_loss: 1.19035 v_acc: 0.71712 |  iteration: 13266 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 836 loss: 1.32589 acc: 0.70150 | v_loss: 1.22650 v_acc: 0.71615 |  iteration: 13267 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 837 loss: 1.30172 acc: 0.69889 | v_loss: 1.22732 v_acc: 0.71745 |  iteration: 13268 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 838 loss: 1.24914 acc: 0.71289 | v_loss: 1.38505 v_acc: 0.69889 |  iteration: 13269 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 839 loss: 1.28824 acc: 0.70508 | v_loss: 1.28777 v_acc: 0.71647 |  iteration: 13270 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 840 loss: 1.24368 acc: 0.70866 | v_loss: 1.06193 v_acc: 0.74349 |  iteration: 13271 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 841 loss: 1.27814 acc: 0.70671 | v_loss: 1.19364 v_acc: 0.70378 |  iteration: 13272 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 842 loss: 1.21851 acc: 0.70150 | v_loss: 1.26139 v_acc: 0.69694 |  iteration: 13273 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 843 loss: 1.21199 acc: 0.70866 | v_loss: 1.18380 v_acc: 0.70638 |  iteration: 13274 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 844 loss: 1.26657 acc: 0.70898 | v_loss: 1.22708 v_acc: 0.71354 |  iteration: 13275 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 845 loss: 1.32825 acc: 0.69727 | v_loss: 1.22188 v_acc: 0.69727 |  iteration: 13276 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 846 loss: 1.36885 acc: 0.69108 | v_loss: 1.19585 v_acc: 0.71712 |  iteration: 13277 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 847 loss: 1.22373 acc: 0.71484 | v_loss: 1.22741 v_acc: 0.70378 |  iteration: 13278 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 848 loss: 1.29425 acc: 0.70508 | v_loss: 1.16748 v_acc: 0.72201 |  iteration: 13279 teacher: 0 stage: sketch lr: 0.000384\n",
      "batch 849 loss: 1.39809 acc: 0.69694 | v_loss: 1.16291 v_acc: 0.73145 |  iteration: 13280 teacher: 1 stage: sketch lr: 0.000384\n",
      "batch 850 loss: 1.29968 acc: 0.70052 | v_loss: 1.22337 v_acc: 0.70605 |  iteration: 13281 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 851 loss: 1.36657 acc: 0.68815 | v_loss: 1.32172 v_acc: 0.69173 |  iteration: 13282 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 852 loss: 1.28496 acc: 0.69596 | v_loss: 1.15215 v_acc: 0.70378 |  iteration: 13283 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 853 loss: 1.28603 acc: 0.70085 | v_loss: 1.40167 v_acc: 0.68262 |  iteration: 13284 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 854 loss: 1.21637 acc: 0.70703 | v_loss: 1.16194 v_acc: 0.71973 |  iteration: 13285 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 855 loss: 1.30542 acc: 0.70020 | v_loss: 1.44803 v_acc: 0.67513 |  iteration: 13286 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 856 loss: 1.25028 acc: 0.70508 | v_loss: 1.34692 v_acc: 0.69238 |  iteration: 13287 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 857 loss: 1.31146 acc: 0.69564 | v_loss: 1.35623 v_acc: 0.69076 |  iteration: 13288 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 858 loss: 1.21772 acc: 0.70605 | v_loss: 1.27708 v_acc: 0.70247 |  iteration: 13289 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 859 loss: 1.24588 acc: 0.70312 | v_loss: 1.23585 v_acc: 0.70833 |  iteration: 13290 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 860 loss: 1.28788 acc: 0.70150 | v_loss: 1.24121 v_acc: 0.70833 |  iteration: 13291 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 861 loss: 1.29727 acc: 0.70671 | v_loss: 1.19346 v_acc: 0.72493 |  iteration: 13292 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 862 loss: 1.29189 acc: 0.70866 | v_loss: 1.39058 v_acc: 0.69238 |  iteration: 13293 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 863 loss: 1.29126 acc: 0.70020 | v_loss: 1.27358 v_acc: 0.71029 |  iteration: 13294 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 864 loss: 1.25755 acc: 0.71549 | v_loss: 1.17811 v_acc: 0.71126 |  iteration: 13295 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 865 loss: 1.25693 acc: 0.70280 | v_loss: 1.23492 v_acc: 0.71842 |  iteration: 13296 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 866 loss: 1.26267 acc: 0.69922 | v_loss: 1.13759 v_acc: 0.70833 |  iteration: 13297 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 867 loss: 1.35045 acc: 0.70345 | v_loss: 1.25614 v_acc: 0.69857 |  iteration: 13298 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 868 loss: 1.21539 acc: 0.71810 | v_loss: 1.21260 v_acc: 0.71484 |  iteration: 13299 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 869 loss: 1.39635 acc: 0.69759 | v_loss: 1.14769 v_acc: 0.72038 |  iteration: 13300 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 870 loss: 1.30827 acc: 0.70410 | v_loss: 1.14200 v_acc: 0.72428 |  iteration: 13301 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 871 loss: 1.28147 acc: 0.70833 | v_loss: 1.24140 v_acc: 0.71875 |  iteration: 13302 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 872 loss: 1.17542 acc: 0.71061 | v_loss: 1.25278 v_acc: 0.70215 |  iteration: 13303 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 873 loss: 1.21151 acc: 0.71126 | v_loss: 1.24012 v_acc: 0.70964 |  iteration: 13304 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 874 loss: 1.31482 acc: 0.70605 | v_loss: 1.09587 v_acc: 0.72363 |  iteration: 13305 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 875 loss: 1.32235 acc: 0.69303 | v_loss: 1.24393 v_acc: 0.73047 |  iteration: 13306 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 876 loss: 1.28303 acc: 0.71908 | v_loss: 1.28574 v_acc: 0.69759 |  iteration: 13307 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 877 loss: 1.26979 acc: 0.70736 | v_loss: 1.27579 v_acc: 0.72201 |  iteration: 13308 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 878 loss: 1.36479 acc: 0.69564 | v_loss: 1.13738 v_acc: 0.72103 |  iteration: 13309 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 879 loss: 1.29380 acc: 0.70671 | v_loss: 1.09645 v_acc: 0.73730 |  iteration: 13310 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 880 loss: 1.27195 acc: 0.70671 | v_loss: 1.09174 v_acc: 0.72266 |  iteration: 13311 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 881 loss: 1.32567 acc: 0.70052 | v_loss: 1.18240 v_acc: 0.71094 |  iteration: 13312 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 882 loss: 1.26777 acc: 0.70801 | v_loss: 1.21260 v_acc: 0.70508 |  iteration: 13313 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 883 loss: 1.44278 acc: 0.68717 | v_loss: 1.17887 v_acc: 0.71354 |  iteration: 13314 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 884 loss: 1.27362 acc: 0.70247 | v_loss: 1.31451 v_acc: 0.70312 |  iteration: 13315 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 885 loss: 1.30838 acc: 0.69661 | v_loss: 1.46736 v_acc: 0.69141 |  iteration: 13316 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 886 loss: 1.25495 acc: 0.71354 | v_loss: 1.34867 v_acc: 0.69824 |  iteration: 13317 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 887 loss: 1.29966 acc: 0.70931 | v_loss: 1.19447 v_acc: 0.72070 |  iteration: 13318 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 888 loss: 1.27667 acc: 0.71094 | v_loss: 1.16626 v_acc: 0.70475 |  iteration: 13319 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 889 loss: 1.35114 acc: 0.69954 | v_loss: 1.14375 v_acc: 0.72103 |  iteration: 13320 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 890 loss: 1.30020 acc: 0.70703 | v_loss: 1.23600 v_acc: 0.70312 |  iteration: 13321 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 891 loss: 1.26633 acc: 0.70964 | v_loss: 1.21947 v_acc: 0.71419 |  iteration: 13322 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 892 loss: 1.15285 acc: 0.72721 | v_loss: 1.20722 v_acc: 0.73079 |  iteration: 13323 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 893 loss: 1.33778 acc: 0.69889 | v_loss: 1.21928 v_acc: 0.71875 |  iteration: 13324 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 894 loss: 1.35435 acc: 0.69727 | v_loss: 1.21231 v_acc: 0.70768 |  iteration: 13325 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 895 loss: 1.18449 acc: 0.72070 | v_loss: 1.14193 v_acc: 0.72786 |  iteration: 13326 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 896 loss: 1.32090 acc: 0.69206 | v_loss: 1.11185 v_acc: 0.72233 |  iteration: 13327 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 897 loss: 1.36443 acc: 0.69466 | v_loss: 1.43922 v_acc: 0.69141 |  iteration: 13328 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 898 loss: 1.18802 acc: 0.71126 | v_loss: 1.18227 v_acc: 0.70866 |  iteration: 13329 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 899 loss: 1.21465 acc: 0.70996 | v_loss: 1.20146 v_acc: 0.71908 |  iteration: 13330 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 900 loss: 1.29483 acc: 0.69922 | v_loss: 1.19504 v_acc: 0.70996 |  iteration: 13331 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 901 loss: 1.23004 acc: 0.71159 | v_loss: 1.26730 v_acc: 0.70671 |  iteration: 13332 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 902 loss: 1.15536 acc: 0.72103 | v_loss: 1.12376 v_acc: 0.73438 |  iteration: 13333 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 903 loss: 1.24522 acc: 0.71289 | v_loss: 1.37223 v_acc: 0.71419 |  iteration: 13334 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 904 loss: 1.28663 acc: 0.70280 | v_loss: 1.16159 v_acc: 0.70150 |  iteration: 13335 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 905 loss: 1.22562 acc: 0.71419 | v_loss: 1.18100 v_acc: 0.70443 |  iteration: 13336 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 906 loss: 1.22065 acc: 0.70215 | v_loss: 1.25844 v_acc: 0.70410 |  iteration: 13337 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 907 loss: 1.20910 acc: 0.71029 | v_loss: 1.24230 v_acc: 0.70280 |  iteration: 13338 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 908 loss: 1.27628 acc: 0.69792 | v_loss: 1.31007 v_acc: 0.70117 |  iteration: 13339 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 909 loss: 1.19245 acc: 0.70833 | v_loss: 1.36245 v_acc: 0.70801 |  iteration: 13340 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 910 loss: 1.28945 acc: 0.70280 | v_loss: 1.28493 v_acc: 0.70117 |  iteration: 13341 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 911 loss: 1.18549 acc: 0.71257 | v_loss: 1.15723 v_acc: 0.71419 |  iteration: 13342 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 912 loss: 1.31641 acc: 0.70833 | v_loss: 1.29013 v_acc: 0.70931 |  iteration: 13343 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 913 loss: 1.22325 acc: 0.71354 | v_loss: 1.20584 v_acc: 0.71354 |  iteration: 13344 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 914 loss: 1.20548 acc: 0.71322 | v_loss: 1.13369 v_acc: 0.72754 |  iteration: 13345 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 915 loss: 1.29902 acc: 0.70052 | v_loss: 1.11939 v_acc: 0.70964 |  iteration: 13346 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 916 loss: 1.30377 acc: 0.70736 | v_loss: 1.25106 v_acc: 0.70378 |  iteration: 13347 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 917 loss: 1.29007 acc: 0.70540 | v_loss: 1.28382 v_acc: 0.69434 |  iteration: 13348 teacher: 1 stage: sketch lr: 0.000383\n",
      "batch 918 loss: 1.21697 acc: 0.71452 | v_loss: 1.17685 v_acc: 0.70378 |  iteration: 13349 teacher: 0 stage: sketch lr: 0.000383\n",
      "batch 919 loss: 1.32010 acc: 0.70280 | v_loss: 1.20392 v_acc: 0.69434 |  iteration: 13350 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 920 loss: 1.20870 acc: 0.71615 | v_loss: 1.18569 v_acc: 0.70736 |  iteration: 13351 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 921 loss: 1.31557 acc: 0.69336 | v_loss: 1.18746 v_acc: 0.70671 |  iteration: 13352 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 922 loss: 1.23247 acc: 0.70964 | v_loss: 1.06292 v_acc: 0.73698 |  iteration: 13353 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 923 loss: 1.27551 acc: 0.70215 | v_loss: 1.13938 v_acc: 0.71973 |  iteration: 13354 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 924 loss: 1.32843 acc: 0.70085 | v_loss: 1.15641 v_acc: 0.72689 |  iteration: 13355 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 925 loss: 1.30338 acc: 0.69759 | v_loss: 1.11272 v_acc: 0.72591 |  iteration: 13356 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 926 loss: 1.21009 acc: 0.71094 | v_loss: 1.18489 v_acc: 0.72624 |  iteration: 13357 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 927 loss: 1.22608 acc: 0.70768 | v_loss: 1.20323 v_acc: 0.71712 |  iteration: 13358 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 928 loss: 1.30208 acc: 0.70540 | v_loss: 1.21855 v_acc: 0.72428 |  iteration: 13359 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 929 loss: 1.25727 acc: 0.71354 | v_loss: 1.37464 v_acc: 0.70247 |  iteration: 13360 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 930 loss: 1.26007 acc: 0.70671 | v_loss: 1.28762 v_acc: 0.71712 |  iteration: 13361 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 931 loss: 1.23732 acc: 0.70345 | v_loss: 1.05893 v_acc: 0.74479 |  iteration: 13362 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 932 loss: 1.24874 acc: 0.70215 | v_loss: 1.18145 v_acc: 0.70508 |  iteration: 13363 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 933 loss: 1.25439 acc: 0.70378 | v_loss: 1.30192 v_acc: 0.69629 |  iteration: 13364 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 934 loss: 1.27488 acc: 0.70020 | v_loss: 1.16336 v_acc: 0.70573 |  iteration: 13365 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 935 loss: 1.26554 acc: 0.70703 | v_loss: 1.23250 v_acc: 0.71615 |  iteration: 13366 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 936 loss: 1.15809 acc: 0.71615 | v_loss: 1.24924 v_acc: 0.69108 |  iteration: 13367 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 937 loss: 1.24709 acc: 0.70931 | v_loss: 1.19306 v_acc: 0.71745 |  iteration: 13368 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 938 loss: 1.23194 acc: 0.70736 | v_loss: 1.23264 v_acc: 0.70247 |  iteration: 13369 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 939 loss: 1.38301 acc: 0.69303 | v_loss: 1.18158 v_acc: 0.71810 |  iteration: 13370 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 940 loss: 1.27589 acc: 0.69889 | v_loss: 1.15919 v_acc: 0.72982 |  iteration: 13371 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 941 loss: 1.31202 acc: 0.69954 | v_loss: 1.20491 v_acc: 0.70508 |  iteration: 13372 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 942 loss: 1.24993 acc: 0.70833 | v_loss: 1.31004 v_acc: 0.69889 |  iteration: 13373 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 943 loss: 1.26625 acc: 0.71549 | v_loss: 1.13714 v_acc: 0.70964 |  iteration: 13374 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 944 loss: 1.27525 acc: 0.69466 | v_loss: 1.39100 v_acc: 0.68750 |  iteration: 13375 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 945 loss: 1.35413 acc: 0.68815 | v_loss: 1.14823 v_acc: 0.72298 |  iteration: 13376 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 946 loss: 1.26584 acc: 0.70410 | v_loss: 1.44585 v_acc: 0.68490 |  iteration: 13377 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 947 loss: 1.29519 acc: 0.70703 | v_loss: 1.32602 v_acc: 0.70345 |  iteration: 13378 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 948 loss: 1.22307 acc: 0.71029 | v_loss: 1.31283 v_acc: 0.69336 |  iteration: 13379 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 949 loss: 1.25624 acc: 0.70280 | v_loss: 1.26626 v_acc: 0.70085 |  iteration: 13380 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 950 loss: 1.30473 acc: 0.70345 | v_loss: 1.21411 v_acc: 0.70768 |  iteration: 13381 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 951 loss: 1.27510 acc: 0.71126 | v_loss: 1.25169 v_acc: 0.70508 |  iteration: 13382 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 952 loss: 1.21456 acc: 0.71159 | v_loss: 1.19311 v_acc: 0.72201 |  iteration: 13383 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 953 loss: 1.26115 acc: 0.71094 | v_loss: 1.38137 v_acc: 0.69141 |  iteration: 13384 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 954 loss: 1.35176 acc: 0.69596 | v_loss: 1.27370 v_acc: 0.70996 |  iteration: 13385 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 955 loss: 1.24666 acc: 0.70085 | v_loss: 1.17312 v_acc: 0.71126 |  iteration: 13386 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 956 loss: 1.30396 acc: 0.69629 | v_loss: 1.23868 v_acc: 0.71647 |  iteration: 13387 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 957 loss: 1.27278 acc: 0.70215 | v_loss: 1.14334 v_acc: 0.70768 |  iteration: 13388 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 958 loss: 1.24775 acc: 0.70247 | v_loss: 1.25633 v_acc: 0.69954 |  iteration: 13389 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 959 loss: 1.23986 acc: 0.70931 | v_loss: 1.21940 v_acc: 0.71094 |  iteration: 13390 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 960 loss: 1.26655 acc: 0.70866 | v_loss: 1.13567 v_acc: 0.72363 |  iteration: 13391 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 961 loss: 1.27478 acc: 0.69857 | v_loss: 1.13586 v_acc: 0.72266 |  iteration: 13392 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 962 loss: 1.35754 acc: 0.69661 | v_loss: 1.24289 v_acc: 0.72168 |  iteration: 13393 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 963 loss: 1.24586 acc: 0.71224 | v_loss: 1.22777 v_acc: 0.70312 |  iteration: 13394 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 964 loss: 1.21911 acc: 0.71452 | v_loss: 1.22939 v_acc: 0.70964 |  iteration: 13395 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 965 loss: 1.26959 acc: 0.69727 | v_loss: 1.08297 v_acc: 0.72493 |  iteration: 13396 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 966 loss: 1.23202 acc: 0.70573 | v_loss: 1.22226 v_acc: 0.73503 |  iteration: 13397 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 967 loss: 1.27443 acc: 0.69889 | v_loss: 1.28706 v_acc: 0.69792 |  iteration: 13398 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 968 loss: 1.28351 acc: 0.70443 | v_loss: 1.28895 v_acc: 0.72363 |  iteration: 13399 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 969 loss: 1.24061 acc: 0.70247 | v_loss: 1.13205 v_acc: 0.72266 |  iteration: 13400 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 970 loss: 1.25005 acc: 0.70540 | v_loss: 1.08591 v_acc: 0.73991 |  iteration: 13401 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 971 loss: 1.28532 acc: 0.69531 | v_loss: 1.09279 v_acc: 0.72363 |  iteration: 13402 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 972 loss: 1.38258 acc: 0.69727 | v_loss: 1.16277 v_acc: 0.71191 |  iteration: 13403 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 973 loss: 1.21173 acc: 0.70540 | v_loss: 1.23035 v_acc: 0.70410 |  iteration: 13404 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 974 loss: 1.31507 acc: 0.69694 | v_loss: 1.17515 v_acc: 0.71647 |  iteration: 13405 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 975 loss: 1.33340 acc: 0.70443 | v_loss: 1.29178 v_acc: 0.70866 |  iteration: 13406 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 976 loss: 1.30006 acc: 0.69922 | v_loss: 1.44374 v_acc: 0.69531 |  iteration: 13407 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 977 loss: 1.31420 acc: 0.69922 | v_loss: 1.34049 v_acc: 0.69987 |  iteration: 13408 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 978 loss: 1.22152 acc: 0.71191 | v_loss: 1.18767 v_acc: 0.72168 |  iteration: 13409 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 979 loss: 1.20961 acc: 0.71289 | v_loss: 1.14333 v_acc: 0.70996 |  iteration: 13410 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 980 loss: 1.21096 acc: 0.71419 | v_loss: 1.13554 v_acc: 0.72396 |  iteration: 13411 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 981 loss: 1.20614 acc: 0.71517 | v_loss: 1.21140 v_acc: 0.70573 |  iteration: 13412 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 982 loss: 1.23929 acc: 0.70475 | v_loss: 1.23045 v_acc: 0.71419 |  iteration: 13413 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 983 loss: 1.29743 acc: 0.70150 | v_loss: 1.21016 v_acc: 0.72982 |  iteration: 13414 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 984 loss: 1.29518 acc: 0.70410 | v_loss: 1.24431 v_acc: 0.71712 |  iteration: 13415 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 985 loss: 1.21042 acc: 0.72396 | v_loss: 1.21533 v_acc: 0.70736 |  iteration: 13416 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 986 loss: 1.27327 acc: 0.70866 | v_loss: 1.12731 v_acc: 0.72233 |  iteration: 13417 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 987 loss: 1.23433 acc: 0.70964 | v_loss: 1.10246 v_acc: 0.72103 |  iteration: 13418 teacher: 0 stage: sketch lr: 0.000382\n",
      "batch 988 loss: 1.23674 acc: 0.70182 | v_loss: 1.44814 v_acc: 0.69206 |  iteration: 13419 teacher: 1 stage: sketch lr: 0.000382\n",
      "batch 989 loss: 1.31821 acc: 0.69824 | v_loss: 1.17977 v_acc: 0.70833 |  iteration: 13420 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 990 loss: 1.25238 acc: 0.70605 | v_loss: 1.19515 v_acc: 0.72168 |  iteration: 13421 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 991 loss: 1.28167 acc: 0.69954 | v_loss: 1.18909 v_acc: 0.71354 |  iteration: 13422 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 992 loss: 1.39125 acc: 0.68978 | v_loss: 1.25881 v_acc: 0.70443 |  iteration: 13423 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 993 loss: 1.34140 acc: 0.69694 | v_loss: 1.13969 v_acc: 0.73242 |  iteration: 13424 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 994 loss: 1.31428 acc: 0.69108 | v_loss: 1.37967 v_acc: 0.71191 |  iteration: 13425 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 995 loss: 1.29869 acc: 0.69922 | v_loss: 1.16210 v_acc: 0.70117 |  iteration: 13426 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 996 loss: 1.32552 acc: 0.70085 | v_loss: 1.18751 v_acc: 0.70345 |  iteration: 13427 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 997 loss: 1.24804 acc: 0.70638 | v_loss: 1.23264 v_acc: 0.70312 |  iteration: 13428 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 998 loss: 1.24253 acc: 0.71094 | v_loss: 1.25182 v_acc: 0.70443 |  iteration: 13429 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 999 loss: 1.31509 acc: 0.69922 | v_loss: 1.32056 v_acc: 0.69368 |  iteration: 13430 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1000 loss: 1.31157 acc: 0.70345 | v_loss: 1.34741 v_acc: 0.70638 |  iteration: 13431 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1001 loss: 1.29042 acc: 0.69922 | v_loss: 1.26509 v_acc: 0.70638 |  iteration: 13432 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1002 loss: 1.22216 acc: 0.70996 | v_loss: 1.17210 v_acc: 0.71061 |  iteration: 13433 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1003 loss: 1.29887 acc: 0.70247 | v_loss: 1.28375 v_acc: 0.70703 |  iteration: 13434 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1004 loss: 1.23472 acc: 0.71582 | v_loss: 1.19751 v_acc: 0.71354 |  iteration: 13435 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1005 loss: 1.37794 acc: 0.70638 | v_loss: 1.14173 v_acc: 0.72461 |  iteration: 13436 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1006 loss: 1.28424 acc: 0.69954 | v_loss: 1.11814 v_acc: 0.70931 |  iteration: 13437 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1007 loss: 1.20577 acc: 0.70833 | v_loss: 1.24292 v_acc: 0.70443 |  iteration: 13438 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1008 loss: 1.24985 acc: 0.70671 | v_loss: 1.28317 v_acc: 0.69889 |  iteration: 13439 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1009 loss: 1.27018 acc: 0.70996 | v_loss: 1.14494 v_acc: 0.70638 |  iteration: 13440 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1010 loss: 1.21305 acc: 0.71289 | v_loss: 1.19692 v_acc: 0.69466 |  iteration: 13441 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1011 loss: 1.27258 acc: 0.70768 | v_loss: 1.17801 v_acc: 0.70898 |  iteration: 13442 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1012 loss: 1.20221 acc: 0.71354 | v_loss: 1.18189 v_acc: 0.70443 |  iteration: 13443 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1013 loss: 1.30805 acc: 0.70573 | v_loss: 1.07014 v_acc: 0.73893 |  iteration: 13444 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1014 loss: 1.16529 acc: 0.71908 | v_loss: 1.16514 v_acc: 0.71810 |  iteration: 13445 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1015 loss: 1.29085 acc: 0.71126 | v_loss: 1.17174 v_acc: 0.72656 |  iteration: 13446 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1016 loss: 1.28292 acc: 0.70898 | v_loss: 1.11553 v_acc: 0.72103 |  iteration: 13447 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1017 loss: 1.19389 acc: 0.71712 | v_loss: 1.18563 v_acc: 0.71875 |  iteration: 13448 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1018 loss: 1.22395 acc: 0.70573 | v_loss: 1.19696 v_acc: 0.71582 |  iteration: 13449 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1019 loss: 1.30554 acc: 0.69792 | v_loss: 1.20103 v_acc: 0.71875 |  iteration: 13450 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1020 loss: 1.28741 acc: 0.70638 | v_loss: 1.35788 v_acc: 0.70182 |  iteration: 13451 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1021 loss: 1.27705 acc: 0.70736 | v_loss: 1.27308 v_acc: 0.71712 |  iteration: 13452 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1022 loss: 1.24031 acc: 0.71842 | v_loss: 1.04751 v_acc: 0.74414 |  iteration: 13453 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1023 loss: 1.32109 acc: 0.69629 | v_loss: 1.19424 v_acc: 0.70280 |  iteration: 13454 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1024 loss: 1.25086 acc: 0.71094 | v_loss: 1.25643 v_acc: 0.70085 |  iteration: 13455 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1025 loss: 1.24872 acc: 0.70671 | v_loss: 1.15859 v_acc: 0.70996 |  iteration: 13456 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1026 loss: 1.22129 acc: 0.71126 | v_loss: 1.23104 v_acc: 0.71257 |  iteration: 13457 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1027 loss: 1.19616 acc: 0.71029 | v_loss: 1.23144 v_acc: 0.69531 |  iteration: 13458 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1028 loss: 1.31798 acc: 0.70573 | v_loss: 1.17704 v_acc: 0.71777 |  iteration: 13459 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1029 loss: 1.16189 acc: 0.72461 | v_loss: 1.21817 v_acc: 0.70215 |  iteration: 13460 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1030 loss: 1.17101 acc: 0.71191 | v_loss: 1.18816 v_acc: 0.72038 |  iteration: 13461 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1031 loss: 1.18315 acc: 0.71354 | v_loss: 1.16791 v_acc: 0.72786 |  iteration: 13462 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1032 loss: 1.22279 acc: 0.71549 | v_loss: 1.21291 v_acc: 0.70573 |  iteration: 13463 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1033 loss: 1.33331 acc: 0.69727 | v_loss: 1.30975 v_acc: 0.69661 |  iteration: 13464 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1034 loss: 1.23171 acc: 0.70703 | v_loss: 1.13580 v_acc: 0.71159 |  iteration: 13465 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1035 loss: 1.21888 acc: 0.70410 | v_loss: 1.37277 v_acc: 0.68522 |  iteration: 13466 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1036 loss: 1.31045 acc: 0.70378 | v_loss: 1.14827 v_acc: 0.72396 |  iteration: 13467 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1037 loss: 1.27086 acc: 0.70703 | v_loss: 1.45986 v_acc: 0.67936 |  iteration: 13468 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1038 loss: 1.20989 acc: 0.71354 | v_loss: 1.32928 v_acc: 0.69857 |  iteration: 13469 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1039 loss: 1.24417 acc: 0.70052 | v_loss: 1.33660 v_acc: 0.69238 |  iteration: 13470 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1040 loss: 1.30213 acc: 0.70475 | v_loss: 1.26161 v_acc: 0.70540 |  iteration: 13471 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1041 loss: 1.29051 acc: 0.69824 | v_loss: 1.24372 v_acc: 0.70443 |  iteration: 13472 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1042 loss: 1.22684 acc: 0.70931 | v_loss: 1.25016 v_acc: 0.70768 |  iteration: 13473 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1043 loss: 1.26588 acc: 0.70345 | v_loss: 1.19251 v_acc: 0.72038 |  iteration: 13474 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1044 loss: 1.15887 acc: 0.71680 | v_loss: 1.37063 v_acc: 0.68945 |  iteration: 13475 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1045 loss: 1.32956 acc: 0.70280 | v_loss: 1.27599 v_acc: 0.70573 |  iteration: 13476 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1046 loss: 1.30393 acc: 0.70312 | v_loss: 1.16388 v_acc: 0.71061 |  iteration: 13477 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1047 loss: 1.25221 acc: 0.70866 | v_loss: 1.22185 v_acc: 0.72135 |  iteration: 13478 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1048 loss: 1.30030 acc: 0.70410 | v_loss: 1.12553 v_acc: 0.71094 |  iteration: 13479 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1049 loss: 1.19020 acc: 0.70345 | v_loss: 1.25303 v_acc: 0.69824 |  iteration: 13480 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1050 loss: 1.30146 acc: 0.70020 | v_loss: 1.21479 v_acc: 0.71452 |  iteration: 13481 teacher: 1 stage: sketch lr: 0.000381\n",
      "batch 1051 loss: 1.29469 acc: 0.70898 | v_loss: 1.14902 v_acc: 0.72038 |  iteration: 13482 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1052 loss: 1.27428 acc: 0.70671 | v_loss: 1.12813 v_acc: 0.72526 |  iteration: 13483 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1053 loss: 1.24922 acc: 0.70703 | v_loss: 1.25055 v_acc: 0.71712 |  iteration: 13484 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1054 loss: 1.22435 acc: 0.71029 | v_loss: 1.23989 v_acc: 0.70150 |  iteration: 13485 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1055 loss: 1.29162 acc: 0.70703 | v_loss: 1.25689 v_acc: 0.70801 |  iteration: 13486 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1056 loss: 1.33846 acc: 0.70964 | v_loss: 1.08784 v_acc: 0.72721 |  iteration: 13487 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1057 loss: 1.20783 acc: 0.71517 | v_loss: 1.24403 v_acc: 0.73145 |  iteration: 13488 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1058 loss: 1.26498 acc: 0.69629 | v_loss: 1.27542 v_acc: 0.69792 |  iteration: 13489 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1059 loss: 1.24922 acc: 0.71094 | v_loss: 1.26768 v_acc: 0.72331 |  iteration: 13490 teacher: 0 stage: sketch lr: 0.000381\n",
      "batch 1060 loss: 1.25343 acc: 0.70280 | v_loss: 1.13969 v_acc: 0.72233 |  iteration: 13491 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1061 loss: 1.34501 acc: 0.69596 | v_loss: 1.10484 v_acc: 0.73763 |  iteration: 13492 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1062 loss: 1.30983 acc: 0.70215 | v_loss: 1.07573 v_acc: 0.72689 |  iteration: 13493 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1063 loss: 1.29577 acc: 0.69792 | v_loss: 1.18126 v_acc: 0.71029 |  iteration: 13494 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1064 loss: 1.20882 acc: 0.71224 | v_loss: 1.20640 v_acc: 0.70540 |  iteration: 13495 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1065 loss: 1.27987 acc: 0.70931 | v_loss: 1.18065 v_acc: 0.71810 |  iteration: 13496 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1066 loss: 1.21503 acc: 0.70964 | v_loss: 1.30172 v_acc: 0.71419 |  iteration: 13497 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1067 loss: 1.19842 acc: 0.71680 | v_loss: 1.44372 v_acc: 0.69531 |  iteration: 13498 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1068 loss: 1.19809 acc: 0.70443 | v_loss: 1.34830 v_acc: 0.69954 |  iteration: 13499 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1069 loss: 1.21740 acc: 0.70410 | v_loss: 1.18591 v_acc: 0.72005 |  iteration: 13500 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1070 loss: 1.27513 acc: 0.70182 | v_loss: 1.14386 v_acc: 0.70540 |  iteration: 13501 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1071 loss: 1.20982 acc: 0.71647 | v_loss: 1.13397 v_acc: 0.72201 |  iteration: 13502 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1072 loss: 1.21743 acc: 0.71354 | v_loss: 1.23376 v_acc: 0.70345 |  iteration: 13503 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1073 loss: 1.19927 acc: 0.70638 | v_loss: 1.23670 v_acc: 0.72005 |  iteration: 13504 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1074 loss: 1.21950 acc: 0.71191 | v_loss: 1.20550 v_acc: 0.73145 |  iteration: 13505 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1075 loss: 1.33997 acc: 0.69694 | v_loss: 1.22798 v_acc: 0.72266 |  iteration: 13506 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1076 loss: 1.23463 acc: 0.71061 | v_loss: 1.21036 v_acc: 0.70996 |  iteration: 13507 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1077 loss: 1.28359 acc: 0.69987 | v_loss: 1.14093 v_acc: 0.72917 |  iteration: 13508 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1078 loss: 1.22047 acc: 0.70703 | v_loss: 1.09027 v_acc: 0.71875 |  iteration: 13509 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1079 loss: 1.24186 acc: 0.70475 | v_loss: 1.43052 v_acc: 0.69141 |  iteration: 13510 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1080 loss: 1.25966 acc: 0.69531 | v_loss: 1.21687 v_acc: 0.70703 |  iteration: 13511 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1081 loss: 1.33770 acc: 0.70280 | v_loss: 1.19055 v_acc: 0.71712 |  iteration: 13512 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1082 loss: 1.19293 acc: 0.71419 | v_loss: 1.20853 v_acc: 0.70475 |  iteration: 13513 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1083 loss: 1.23790 acc: 0.70573 | v_loss: 1.26291 v_acc: 0.69499 |  iteration: 13514 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1084 loss: 1.27168 acc: 0.70280 | v_loss: 1.16951 v_acc: 0.72982 |  iteration: 13515 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1085 loss: 1.35833 acc: 0.69596 | v_loss: 1.39355 v_acc: 0.70703 |  iteration: 13516 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1086 loss: 1.26455 acc: 0.70345 | v_loss: 1.16850 v_acc: 0.70052 |  iteration: 13517 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1087 loss: 1.19083 acc: 0.72168 | v_loss: 1.17439 v_acc: 0.70378 |  iteration: 13518 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1088 loss: 1.22530 acc: 0.70768 | v_loss: 1.26409 v_acc: 0.70475 |  iteration: 13519 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1089 loss: 1.26690 acc: 0.70475 | v_loss: 1.26655 v_acc: 0.70117 |  iteration: 13520 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1090 loss: 1.22319 acc: 0.71191 | v_loss: 1.30979 v_acc: 0.69629 |  iteration: 13521 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1091 loss: 1.29205 acc: 0.70312 | v_loss: 1.36217 v_acc: 0.70801 |  iteration: 13522 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1092 loss: 1.25600 acc: 0.71517 | v_loss: 1.26113 v_acc: 0.70150 |  iteration: 13523 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1093 loss: 1.34051 acc: 0.69531 | v_loss: 1.14187 v_acc: 0.71191 |  iteration: 13524 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1094 loss: 1.24908 acc: 0.70150 | v_loss: 1.31572 v_acc: 0.70671 |  iteration: 13525 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1095 loss: 1.36765 acc: 0.69922 | v_loss: 1.20898 v_acc: 0.71810 |  iteration: 13526 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1096 loss: 1.28903 acc: 0.70671 | v_loss: 1.11627 v_acc: 0.72461 |  iteration: 13527 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1097 loss: 1.38362 acc: 0.69303 | v_loss: 1.12452 v_acc: 0.70866 |  iteration: 13528 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1098 loss: 1.18025 acc: 0.71126 | v_loss: 1.21919 v_acc: 0.70573 |  iteration: 13529 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1099 loss: 1.37390 acc: 0.70280 | v_loss: 1.30257 v_acc: 0.69596 |  iteration: 13530 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1100 loss: 1.24714 acc: 0.70085 | v_loss: 1.16388 v_acc: 0.70475 |  iteration: 13531 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1101 loss: 1.32134 acc: 0.69238 | v_loss: 1.21380 v_acc: 0.69531 |  iteration: 13532 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1102 loss: 1.31723 acc: 0.70931 | v_loss: 1.18249 v_acc: 0.70866 |  iteration: 13533 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1103 loss: 1.31692 acc: 0.69466 | v_loss: 1.19615 v_acc: 0.70378 |  iteration: 13534 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1104 loss: 1.21656 acc: 0.71387 | v_loss: 1.10510 v_acc: 0.73438 |  iteration: 13535 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1105 loss: 1.35756 acc: 0.70247 | v_loss: 1.16228 v_acc: 0.71712 |  iteration: 13536 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1106 loss: 1.31751 acc: 0.70801 | v_loss: 1.16448 v_acc: 0.72298 |  iteration: 13537 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1107 loss: 1.23851 acc: 0.71224 | v_loss: 1.11383 v_acc: 0.72396 |  iteration: 13538 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1108 loss: 1.32494 acc: 0.70020 | v_loss: 1.17722 v_acc: 0.72396 |  iteration: 13539 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1109 loss: 1.35086 acc: 0.70117 | v_loss: 1.20649 v_acc: 0.71484 |  iteration: 13540 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1110 loss: 1.21044 acc: 0.71224 | v_loss: 1.19686 v_acc: 0.72298 |  iteration: 13541 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1111 loss: 1.23861 acc: 0.70866 | v_loss: 1.37259 v_acc: 0.70150 |  iteration: 13542 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1112 loss: 1.22466 acc: 0.71029 | v_loss: 1.26022 v_acc: 0.71810 |  iteration: 13543 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1113 loss: 1.27310 acc: 0.70247 | v_loss: 1.04001 v_acc: 0.74414 |  iteration: 13544 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1114 loss: 1.33545 acc: 0.70996 | v_loss: 1.19928 v_acc: 0.71126 |  iteration: 13545 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1115 loss: 1.30951 acc: 0.70182 | v_loss: 1.24389 v_acc: 0.70020 |  iteration: 13546 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1116 loss: 1.25795 acc: 0.70605 | v_loss: 1.18677 v_acc: 0.70508 |  iteration: 13547 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1117 loss: 1.24167 acc: 0.72135 | v_loss: 1.24226 v_acc: 0.71289 |  iteration: 13548 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1118 loss: 1.34651 acc: 0.70345 | v_loss: 1.23691 v_acc: 0.69303 |  iteration: 13549 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1119 loss: 1.33986 acc: 0.70410 | v_loss: 1.19025 v_acc: 0.71647 |  iteration: 13550 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1120 loss: 1.33742 acc: 0.70150 | v_loss: 1.21852 v_acc: 0.70020 |  iteration: 13551 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1121 loss: 1.24922 acc: 0.70540 | v_loss: 1.20462 v_acc: 0.70671 |  iteration: 13552 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1122 loss: 1.45006 acc: 0.69076 | v_loss: 1.18038 v_acc: 0.72005 |  iteration: 13553 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1123 loss: 1.26558 acc: 0.69954 | v_loss: 1.26189 v_acc: 0.70020 |  iteration: 13554 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1124 loss: 1.32168 acc: 0.70182 | v_loss: 1.31261 v_acc: 0.69043 |  iteration: 13555 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1125 loss: 1.30299 acc: 0.70150 | v_loss: 1.16652 v_acc: 0.70801 |  iteration: 13556 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1126 loss: 1.17169 acc: 0.71875 | v_loss: 1.39025 v_acc: 0.68750 |  iteration: 13557 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1127 loss: 1.22218 acc: 0.70964 | v_loss: 1.12213 v_acc: 0.72754 |  iteration: 13558 teacher: 1 stage: sketch lr: 0.000380\n",
      "batch 1128 loss: 1.25660 acc: 0.71159 | v_loss: 1.45534 v_acc: 0.68490 |  iteration: 13559 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1129 loss: 1.26783 acc: 0.70573 | v_loss: 1.32124 v_acc: 0.70150 |  iteration: 13560 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1130 loss: 1.26663 acc: 0.71061 | v_loss: 1.30853 v_acc: 0.69141 |  iteration: 13561 teacher: 0 stage: sketch lr: 0.000380\n",
      "batch 1131 loss: 1.21776 acc: 0.72005 | v_loss: 1.28585 v_acc: 0.70020 |  iteration: 13562 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1132 loss: 1.27112 acc: 0.69824 | v_loss: 1.20738 v_acc: 0.70508 |  iteration: 13563 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1133 loss: 1.41072 acc: 0.69108 | v_loss: 1.23725 v_acc: 0.70573 |  iteration: 13564 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1134 loss: 1.37181 acc: 0.70020 | v_loss: 1.18648 v_acc: 0.72070 |  iteration: 13565 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1135 loss: 1.31044 acc: 0.70573 | v_loss: 1.37864 v_acc: 0.68880 |  iteration: 13566 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1136 loss: 1.23966 acc: 0.71061 | v_loss: 1.27295 v_acc: 0.71159 |  iteration: 13567 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1137 loss: 1.20901 acc: 0.71061 | v_loss: 1.16720 v_acc: 0.71029 |  iteration: 13568 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1138 loss: 1.31170 acc: 0.69108 | v_loss: 1.22587 v_acc: 0.71745 |  iteration: 13569 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1139 loss: 1.15879 acc: 0.72070 | v_loss: 1.13156 v_acc: 0.71029 |  iteration: 13570 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1140 loss: 1.26317 acc: 0.71354 | v_loss: 1.26551 v_acc: 0.69792 |  iteration: 13571 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1141 loss: 1.29736 acc: 0.70052 | v_loss: 1.22277 v_acc: 0.71875 |  iteration: 13572 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1142 loss: 1.28438 acc: 0.70736 | v_loss: 1.12690 v_acc: 0.72363 |  iteration: 13573 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1143 loss: 1.38670 acc: 0.70020 | v_loss: 1.13766 v_acc: 0.72591 |  iteration: 13574 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1144 loss: 1.31694 acc: 0.69694 | v_loss: 1.24627 v_acc: 0.71875 |  iteration: 13575 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1145 loss: 1.31108 acc: 0.69596 | v_loss: 1.23096 v_acc: 0.70182 |  iteration: 13576 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1146 loss: 1.31548 acc: 0.70215 | v_loss: 1.23524 v_acc: 0.70996 |  iteration: 13577 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1147 loss: 1.20638 acc: 0.71582 | v_loss: 1.07106 v_acc: 0.72591 |  iteration: 13578 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1148 loss: 1.32721 acc: 0.69010 | v_loss: 1.22483 v_acc: 0.73177 |  iteration: 13579 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1149 loss: 1.29148 acc: 0.70345 | v_loss: 1.27134 v_acc: 0.69954 |  iteration: 13580 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1150 loss: 1.26627 acc: 0.69954 | v_loss: 1.26383 v_acc: 0.72005 |  iteration: 13581 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1151 loss: 1.31270 acc: 0.69987 | v_loss: 1.14099 v_acc: 0.71842 |  iteration: 13582 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1152 loss: 1.30845 acc: 0.69987 | v_loss: 1.10036 v_acc: 0.73958 |  iteration: 13583 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1153 loss: 1.29086 acc: 0.69889 | v_loss: 1.08923 v_acc: 0.72428 |  iteration: 13584 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1154 loss: 1.25422 acc: 0.70996 | v_loss: 1.16138 v_acc: 0.71029 |  iteration: 13585 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1155 loss: 1.30064 acc: 0.70085 | v_loss: 1.21640 v_acc: 0.70052 |  iteration: 13586 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1156 loss: 1.20651 acc: 0.71094 | v_loss: 1.16003 v_acc: 0.71582 |  iteration: 13587 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1157 loss: 1.26107 acc: 0.70736 | v_loss: 1.25685 v_acc: 0.71745 |  iteration: 13588 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1158 loss: 1.33358 acc: 0.70052 | v_loss: 1.44981 v_acc: 0.69368 |  iteration: 13589 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1159 loss: 1.27369 acc: 0.70768 | v_loss: 1.33924 v_acc: 0.70052 |  iteration: 13590 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1160 loss: 1.25454 acc: 0.69792 | v_loss: 1.18191 v_acc: 0.72233 |  iteration: 13591 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1161 loss: 1.34619 acc: 0.70573 | v_loss: 1.14333 v_acc: 0.70508 |  iteration: 13592 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1162 loss: 1.28299 acc: 0.70540 | v_loss: 1.11576 v_acc: 0.72559 |  iteration: 13593 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1163 loss: 1.30605 acc: 0.69889 | v_loss: 1.19355 v_acc: 0.71191 |  iteration: 13594 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1164 loss: 1.31173 acc: 0.70312 | v_loss: 1.22882 v_acc: 0.72168 |  iteration: 13595 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1165 loss: 1.19625 acc: 0.70833 | v_loss: 1.20073 v_acc: 0.72852 |  iteration: 13596 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1166 loss: 1.20449 acc: 0.70247 | v_loss: 1.21713 v_acc: 0.72103 |  iteration: 13597 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1167 loss: 1.30262 acc: 0.70605 | v_loss: 1.18540 v_acc: 0.71842 |  iteration: 13598 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1168 loss: 1.29186 acc: 0.70638 | v_loss: 1.13201 v_acc: 0.72786 |  iteration: 13599 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1169 loss: 1.34077 acc: 0.69857 | v_loss: 1.09773 v_acc: 0.72103 |  iteration: 13600 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1170 loss: 1.31292 acc: 0.69727 | v_loss: 1.43019 v_acc: 0.69238 |  iteration: 13601 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1171 loss: 1.19463 acc: 0.71517 | v_loss: 1.20017 v_acc: 0.70801 |  iteration: 13602 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1172 loss: 1.25485 acc: 0.69922 | v_loss: 1.19708 v_acc: 0.71549 |  iteration: 13603 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1173 loss: 1.26850 acc: 0.70215 | v_loss: 1.21211 v_acc: 0.70964 |  iteration: 13604 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1174 loss: 1.17749 acc: 0.71517 | v_loss: 1.23251 v_acc: 0.70410 |  iteration: 13605 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1175 loss: 1.31436 acc: 0.69954 | v_loss: 1.13926 v_acc: 0.73177 |  iteration: 13606 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1176 loss: 1.28208 acc: 0.70931 | v_loss: 1.33715 v_acc: 0.71322 |  iteration: 13607 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1177 loss: 1.31147 acc: 0.69629 | v_loss: 1.18167 v_acc: 0.69759 |  iteration: 13608 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1178 loss: 1.18424 acc: 0.70964 | v_loss: 1.18701 v_acc: 0.70410 |  iteration: 13609 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1179 loss: 1.24456 acc: 0.70182 | v_loss: 1.23631 v_acc: 0.70508 |  iteration: 13610 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1180 loss: 1.32623 acc: 0.69043 | v_loss: 1.22933 v_acc: 0.70605 |  iteration: 13611 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1181 loss: 1.27862 acc: 0.69531 | v_loss: 1.31823 v_acc: 0.69596 |  iteration: 13612 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1182 loss: 1.37306 acc: 0.68424 | v_loss: 1.35675 v_acc: 0.70801 |  iteration: 13613 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1183 loss: 1.24313 acc: 0.70312 | v_loss: 1.26019 v_acc: 0.70052 |  iteration: 13614 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1184 loss: 1.26820 acc: 0.70378 | v_loss: 1.14907 v_acc: 0.71354 |  iteration: 13615 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1185 loss: 1.24917 acc: 0.70443 | v_loss: 1.26063 v_acc: 0.70768 |  iteration: 13616 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1186 loss: 1.25041 acc: 0.71517 | v_loss: 1.18198 v_acc: 0.71419 |  iteration: 13617 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1187 loss: 1.28361 acc: 0.70443 | v_loss: 1.14765 v_acc: 0.72428 |  iteration: 13618 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1188 loss: 1.28631 acc: 0.69922 | v_loss: 1.09012 v_acc: 0.70931 |  iteration: 13619 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1189 loss: 1.29892 acc: 0.70085 | v_loss: 1.21729 v_acc: 0.70540 |  iteration: 13620 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1190 loss: 1.22117 acc: 0.70801 | v_loss: 1.28876 v_acc: 0.70182 |  iteration: 13621 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1191 loss: 1.38270 acc: 0.68880 | v_loss: 1.14817 v_acc: 0.70964 |  iteration: 13622 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1192 loss: 1.35020 acc: 0.69824 | v_loss: 1.20651 v_acc: 0.69596 |  iteration: 13623 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1193 loss: 1.24333 acc: 0.71257 | v_loss: 1.16728 v_acc: 0.70931 |  iteration: 13624 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1194 loss: 1.17753 acc: 0.71647 | v_loss: 1.18786 v_acc: 0.70736 |  iteration: 13625 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1195 loss: 1.29797 acc: 0.69889 | v_loss: 1.05884 v_acc: 0.73861 |  iteration: 13626 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1196 loss: 1.23734 acc: 0.70052 | v_loss: 1.16060 v_acc: 0.71940 |  iteration: 13627 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 1197 loss: 1.21034 acc: 0.70605 | v_loss: 1.11334 v_acc: 0.72493 |  iteration: 13628 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1198 loss: 1.20765 acc: 0.71094 | v_loss: 1.09939 v_acc: 0.72689 |  iteration: 13629 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1199 loss: 1.22099 acc: 0.70443 | v_loss: 1.17355 v_acc: 0.72070 |  iteration: 13630 teacher: 1 stage: sketch lr: 0.000379\n",
      "batch 1200 loss: 1.34323 acc: 0.69661 | v_loss: 1.17067 v_acc: 0.71712 |  iteration: 13631 teacher: 0 stage: sketch lr: 0.000379\n",
      "batch 123 loss: 1.27562 acc: 0.70150 | v_loss: 1.29629 v_acc: 0.69922 |  iteration: 13797 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 124 loss: 1.24037 acc: 0.71452 | v_loss: 1.12524 v_acc: 0.71029 |  iteration: 13798 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 125 loss: 1.22979 acc: 0.71322 | v_loss: 1.37570 v_acc: 0.68490 |  iteration: 13799 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 126 loss: 1.23356 acc: 0.70898 | v_loss: 1.13320 v_acc: 0.72559 |  iteration: 13800 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 127 loss: 1.33633 acc: 0.69564 | v_loss: 1.44906 v_acc: 0.67806 |  iteration: 13801 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 128 loss: 1.32217 acc: 0.69954 | v_loss: 1.31587 v_acc: 0.70280 |  iteration: 13802 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 129 loss: 1.21428 acc: 0.70866 | v_loss: 1.32704 v_acc: 0.69368 |  iteration: 13803 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 130 loss: 1.24092 acc: 0.70573 | v_loss: 1.25513 v_acc: 0.70540 |  iteration: 13804 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 131 loss: 1.25019 acc: 0.70378 | v_loss: 1.20845 v_acc: 0.71094 |  iteration: 13805 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 132 loss: 1.26835 acc: 0.70182 | v_loss: 1.22887 v_acc: 0.70964 |  iteration: 13806 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 133 loss: 1.23331 acc: 0.71159 | v_loss: 1.19293 v_acc: 0.72038 |  iteration: 13807 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 134 loss: 1.29161 acc: 0.70312 | v_loss: 1.37632 v_acc: 0.68587 |  iteration: 13808 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 135 loss: 1.30751 acc: 0.69987 | v_loss: 1.25562 v_acc: 0.70605 |  iteration: 13809 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 136 loss: 1.27083 acc: 0.70410 | v_loss: 1.16934 v_acc: 0.71224 |  iteration: 13810 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 137 loss: 1.26000 acc: 0.69954 | v_loss: 1.20865 v_acc: 0.71940 |  iteration: 13811 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 138 loss: 1.22840 acc: 0.71159 | v_loss: 1.13560 v_acc: 0.70996 |  iteration: 13812 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 139 loss: 1.26616 acc: 0.70931 | v_loss: 1.24813 v_acc: 0.69889 |  iteration: 13813 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 140 loss: 1.24946 acc: 0.69596 | v_loss: 1.22007 v_acc: 0.71224 |  iteration: 13814 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 141 loss: 1.28521 acc: 0.69434 | v_loss: 1.12838 v_acc: 0.72103 |  iteration: 13815 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 142 loss: 1.26601 acc: 0.70671 | v_loss: 1.09246 v_acc: 0.72591 |  iteration: 13816 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 143 loss: 1.28203 acc: 0.69889 | v_loss: 1.25371 v_acc: 0.71810 |  iteration: 13817 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 144 loss: 1.27519 acc: 0.70573 | v_loss: 1.22953 v_acc: 0.70638 |  iteration: 13818 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 145 loss: 1.20957 acc: 0.70508 | v_loss: 1.22825 v_acc: 0.70931 |  iteration: 13819 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 146 loss: 1.29629 acc: 0.69564 | v_loss: 1.06885 v_acc: 0.72461 |  iteration: 13820 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 147 loss: 1.24564 acc: 0.70540 | v_loss: 1.22491 v_acc: 0.73210 |  iteration: 13821 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 148 loss: 1.20053 acc: 0.70801 | v_loss: 1.27717 v_acc: 0.69759 |  iteration: 13822 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 149 loss: 1.31482 acc: 0.70638 | v_loss: 1.27566 v_acc: 0.72852 |  iteration: 13823 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 150 loss: 1.29988 acc: 0.69759 | v_loss: 1.12190 v_acc: 0.71908 |  iteration: 13824 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 151 loss: 1.21778 acc: 0.70312 | v_loss: 1.07540 v_acc: 0.73405 |  iteration: 13825 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 152 loss: 1.23441 acc: 0.71224 | v_loss: 1.07708 v_acc: 0.72103 |  iteration: 13826 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 153 loss: 1.34868 acc: 0.68848 | v_loss: 1.15002 v_acc: 0.70768 |  iteration: 13827 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 154 loss: 1.31699 acc: 0.69727 | v_loss: 1.16839 v_acc: 0.71094 |  iteration: 13828 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 155 loss: 1.22604 acc: 0.70801 | v_loss: 1.17865 v_acc: 0.71647 |  iteration: 13829 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 156 loss: 1.27929 acc: 0.71029 | v_loss: 1.31172 v_acc: 0.69922 |  iteration: 13830 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 157 loss: 1.29791 acc: 0.69401 | v_loss: 1.42556 v_acc: 0.69694 |  iteration: 13831 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 158 loss: 1.25866 acc: 0.70085 | v_loss: 1.32306 v_acc: 0.69824 |  iteration: 13832 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 159 loss: 1.22417 acc: 0.70117 | v_loss: 1.16572 v_acc: 0.72396 |  iteration: 13833 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 160 loss: 1.22173 acc: 0.70703 | v_loss: 1.13120 v_acc: 0.71191 |  iteration: 13834 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 161 loss: 1.34691 acc: 0.69336 | v_loss: 1.11288 v_acc: 0.72396 |  iteration: 13835 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 162 loss: 1.25798 acc: 0.70117 | v_loss: 1.17008 v_acc: 0.70508 |  iteration: 13836 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 163 loss: 1.32320 acc: 0.69499 | v_loss: 1.24625 v_acc: 0.72038 |  iteration: 13837 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 164 loss: 1.21997 acc: 0.70020 | v_loss: 1.19529 v_acc: 0.72917 |  iteration: 13838 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 165 loss: 1.28872 acc: 0.70150 | v_loss: 1.20050 v_acc: 0.72168 |  iteration: 13839 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 166 loss: 1.22784 acc: 0.70150 | v_loss: 1.19120 v_acc: 0.71484 |  iteration: 13840 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 167 loss: 1.32221 acc: 0.69564 | v_loss: 1.13354 v_acc: 0.72363 |  iteration: 13841 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 168 loss: 1.26082 acc: 0.70833 | v_loss: 1.11169 v_acc: 0.72233 |  iteration: 13842 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 169 loss: 1.42374 acc: 0.68555 | v_loss: 1.45624 v_acc: 0.69336 |  iteration: 13843 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 170 loss: 1.28378 acc: 0.70020 | v_loss: 1.17378 v_acc: 0.71126 |  iteration: 13844 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 171 loss: 1.28109 acc: 0.70378 | v_loss: 1.19232 v_acc: 0.72103 |  iteration: 13845 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 172 loss: 1.20568 acc: 0.70996 | v_loss: 1.19782 v_acc: 0.71452 |  iteration: 13846 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 173 loss: 1.29418 acc: 0.69792 | v_loss: 1.25572 v_acc: 0.70280 |  iteration: 13847 teacher: 0 stage: sketch lr: 0.000376\n",
      "batch 174 loss: 1.18399 acc: 0.71549 | v_loss: 1.11149 v_acc: 0.73535 |  iteration: 13848 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 175 loss: 1.19326 acc: 0.71257 | v_loss: 1.33150 v_acc: 0.71745 |  iteration: 13849 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 176 loss: 1.22275 acc: 0.71257 | v_loss: 1.21580 v_acc: 0.70280 |  iteration: 13850 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 177 loss: 1.24327 acc: 0.70410 | v_loss: 1.22203 v_acc: 0.70378 |  iteration: 13851 teacher: 1 stage: sketch lr: 0.000376\n",
      "batch 178 loss: 1.30131 acc: 0.71322 | v_loss: 1.24868 v_acc: 0.70475 |  iteration: 13852 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 179 loss: 1.26588 acc: 0.70020 | v_loss: 1.24392 v_acc: 0.70247 |  iteration: 13853 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 180 loss: 1.29743 acc: 0.69987 | v_loss: 1.31768 v_acc: 0.69629 |  iteration: 13854 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 181 loss: 1.29847 acc: 0.70898 | v_loss: 1.36106 v_acc: 0.71029 |  iteration: 13855 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 182 loss: 1.32958 acc: 0.70736 | v_loss: 1.26665 v_acc: 0.70215 |  iteration: 13856 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 183 loss: 1.33692 acc: 0.69954 | v_loss: 1.16487 v_acc: 0.71191 |  iteration: 13857 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 184 loss: 1.34220 acc: 0.70736 | v_loss: 1.28934 v_acc: 0.70736 |  iteration: 13858 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 185 loss: 1.31079 acc: 0.70345 | v_loss: 1.21439 v_acc: 0.71842 |  iteration: 13859 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 186 loss: 1.20816 acc: 0.71029 | v_loss: 1.12514 v_acc: 0.72559 |  iteration: 13860 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 187 loss: 1.37159 acc: 0.69857 | v_loss: 1.12704 v_acc: 0.70801 |  iteration: 13861 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 188 loss: 1.23968 acc: 0.70964 | v_loss: 1.24037 v_acc: 0.70703 |  iteration: 13862 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 189 loss: 1.32815 acc: 0.71126 | v_loss: 1.29842 v_acc: 0.69401 |  iteration: 13863 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 190 loss: 1.26537 acc: 0.71094 | v_loss: 1.12108 v_acc: 0.71484 |  iteration: 13864 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 191 loss: 1.24867 acc: 0.70768 | v_loss: 1.21765 v_acc: 0.69759 |  iteration: 13865 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 192 loss: 1.27129 acc: 0.70052 | v_loss: 1.17095 v_acc: 0.71159 |  iteration: 13866 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 193 loss: 1.28957 acc: 0.70182 | v_loss: 1.20086 v_acc: 0.70736 |  iteration: 13867 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 194 loss: 1.27872 acc: 0.70508 | v_loss: 1.04251 v_acc: 0.74447 |  iteration: 13868 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 195 loss: 1.28751 acc: 0.70020 | v_loss: 1.17992 v_acc: 0.71745 |  iteration: 13869 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 196 loss: 1.18761 acc: 0.71289 | v_loss: 1.09982 v_acc: 0.72526 |  iteration: 13870 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 197 loss: 1.20907 acc: 0.71061 | v_loss: 1.12197 v_acc: 0.72331 |  iteration: 13871 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 198 loss: 1.28685 acc: 0.70020 | v_loss: 1.18154 v_acc: 0.72103 |  iteration: 13872 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 199 loss: 1.19572 acc: 0.71419 | v_loss: 1.18129 v_acc: 0.71712 |  iteration: 13873 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 200 loss: 1.19881 acc: 0.71387 | v_loss: 1.18066 v_acc: 0.72428 |  iteration: 13874 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 201 loss: 1.32940 acc: 0.69531 | v_loss: 1.38594 v_acc: 0.69889 |  iteration: 13875 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 202 loss: 1.20984 acc: 0.71061 | v_loss: 1.25683 v_acc: 0.72168 |  iteration: 13876 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 203 loss: 1.28239 acc: 0.70085 | v_loss: 1.03728 v_acc: 0.74544 |  iteration: 13877 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 204 loss: 1.25904 acc: 0.71126 | v_loss: 1.20017 v_acc: 0.70866 |  iteration: 13878 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 205 loss: 1.27642 acc: 0.70117 | v_loss: 1.25251 v_acc: 0.70182 |  iteration: 13879 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 206 loss: 1.22777 acc: 0.71712 | v_loss: 1.20841 v_acc: 0.70508 |  iteration: 13880 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 207 loss: 1.23119 acc: 0.70931 | v_loss: 1.22730 v_acc: 0.71224 |  iteration: 13881 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 208 loss: 1.22899 acc: 0.71061 | v_loss: 1.22707 v_acc: 0.69336 |  iteration: 13882 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 209 loss: 1.36221 acc: 0.68848 | v_loss: 1.19253 v_acc: 0.71810 |  iteration: 13883 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 210 loss: 1.35745 acc: 0.69759 | v_loss: 1.24060 v_acc: 0.70182 |  iteration: 13884 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 211 loss: 1.27524 acc: 0.70247 | v_loss: 1.15929 v_acc: 0.71875 |  iteration: 13885 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 212 loss: 1.31751 acc: 0.70247 | v_loss: 1.17287 v_acc: 0.72656 |  iteration: 13886 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 213 loss: 1.27961 acc: 0.70898 | v_loss: 1.18613 v_acc: 0.70671 |  iteration: 13887 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 214 loss: 1.33691 acc: 0.69401 | v_loss: 1.32336 v_acc: 0.70052 |  iteration: 13888 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 215 loss: 1.23009 acc: 0.70247 | v_loss: 1.15033 v_acc: 0.70964 |  iteration: 13889 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 216 loss: 1.21394 acc: 0.71094 | v_loss: 1.37477 v_acc: 0.68945 |  iteration: 13890 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 217 loss: 1.32673 acc: 0.69954 | v_loss: 1.12813 v_acc: 0.72526 |  iteration: 13891 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 218 loss: 1.31518 acc: 0.71029 | v_loss: 1.46212 v_acc: 0.68229 |  iteration: 13892 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 219 loss: 1.17084 acc: 0.71842 | v_loss: 1.35653 v_acc: 0.69922 |  iteration: 13893 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 220 loss: 1.24914 acc: 0.70345 | v_loss: 1.30192 v_acc: 0.69368 |  iteration: 13894 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 221 loss: 1.29290 acc: 0.70443 | v_loss: 1.30023 v_acc: 0.70215 |  iteration: 13895 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 222 loss: 1.23224 acc: 0.71094 | v_loss: 1.21064 v_acc: 0.70443 |  iteration: 13896 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 223 loss: 1.26629 acc: 0.69596 | v_loss: 1.25604 v_acc: 0.70280 |  iteration: 13897 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 224 loss: 1.25162 acc: 0.70247 | v_loss: 1.19695 v_acc: 0.71875 |  iteration: 13898 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 225 loss: 1.21430 acc: 0.71191 | v_loss: 1.38858 v_acc: 0.68913 |  iteration: 13899 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 226 loss: 1.25347 acc: 0.70703 | v_loss: 1.27405 v_acc: 0.71159 |  iteration: 13900 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 227 loss: 1.32942 acc: 0.69759 | v_loss: 1.16823 v_acc: 0.71159 |  iteration: 13901 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 228 loss: 1.34026 acc: 0.69922 | v_loss: 1.21757 v_acc: 0.71973 |  iteration: 13902 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 229 loss: 1.17190 acc: 0.71419 | v_loss: 1.13497 v_acc: 0.70996 |  iteration: 13903 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 230 loss: 1.27501 acc: 0.70671 | v_loss: 1.27207 v_acc: 0.69824 |  iteration: 13904 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 231 loss: 1.18419 acc: 0.72298 | v_loss: 1.21534 v_acc: 0.71387 |  iteration: 13905 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 232 loss: 1.26145 acc: 0.70866 | v_loss: 1.12865 v_acc: 0.71810 |  iteration: 13906 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 233 loss: 1.22161 acc: 0.70931 | v_loss: 1.11652 v_acc: 0.72786 |  iteration: 13907 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 234 loss: 1.17364 acc: 0.71680 | v_loss: 1.26004 v_acc: 0.71517 |  iteration: 13908 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 235 loss: 1.22536 acc: 0.70378 | v_loss: 1.22768 v_acc: 0.70215 |  iteration: 13909 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 236 loss: 1.20977 acc: 0.69889 | v_loss: 1.22181 v_acc: 0.70573 |  iteration: 13910 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 237 loss: 1.25592 acc: 0.70247 | v_loss: 1.08566 v_acc: 0.71777 |  iteration: 13911 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 238 loss: 1.26588 acc: 0.70801 | v_loss: 1.22564 v_acc: 0.73014 |  iteration: 13912 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 239 loss: 1.27992 acc: 0.70605 | v_loss: 1.27825 v_acc: 0.69727 |  iteration: 13913 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 240 loss: 1.22120 acc: 0.71322 | v_loss: 1.27263 v_acc: 0.72135 |  iteration: 13914 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 241 loss: 1.30341 acc: 0.69727 | v_loss: 1.14807 v_acc: 0.71940 |  iteration: 13915 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 242 loss: 1.25998 acc: 0.70475 | v_loss: 1.11420 v_acc: 0.73210 |  iteration: 13916 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 243 loss: 1.31569 acc: 0.70117 | v_loss: 1.09445 v_acc: 0.72428 |  iteration: 13917 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 244 loss: 1.16522 acc: 0.70475 | v_loss: 1.18269 v_acc: 0.70833 |  iteration: 13918 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 245 loss: 1.21347 acc: 0.70898 | v_loss: 1.20313 v_acc: 0.70443 |  iteration: 13919 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 246 loss: 1.28091 acc: 0.70605 | v_loss: 1.20029 v_acc: 0.71354 |  iteration: 13920 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 247 loss: 1.26625 acc: 0.69922 | v_loss: 1.31569 v_acc: 0.70508 |  iteration: 13921 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 248 loss: 1.28480 acc: 0.69661 | v_loss: 1.44502 v_acc: 0.69759 |  iteration: 13922 teacher: 0 stage: sketch lr: 0.000375\n",
      "batch 249 loss: 1.28350 acc: 0.70736 | v_loss: 1.33390 v_acc: 0.69922 |  iteration: 13923 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 250 loss: 1.29364 acc: 0.70475 | v_loss: 1.17692 v_acc: 0.72005 |  iteration: 13924 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 251 loss: 1.26074 acc: 0.69759 | v_loss: 1.14393 v_acc: 0.71061 |  iteration: 13925 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 252 loss: 1.33819 acc: 0.69824 | v_loss: 1.15044 v_acc: 0.72233 |  iteration: 13926 teacher: 1 stage: sketch lr: 0.000375\n",
      "batch 253 loss: 1.30067 acc: 0.69824 | v_loss: 1.18343 v_acc: 0.70671 |  iteration: 13927 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 254 loss: 1.29028 acc: 0.70085 | v_loss: 1.25195 v_acc: 0.71842 |  iteration: 13928 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 255 loss: 1.29778 acc: 0.69401 | v_loss: 1.18094 v_acc: 0.72884 |  iteration: 13929 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 256 loss: 1.28322 acc: 0.70052 | v_loss: 1.21784 v_acc: 0.72526 |  iteration: 13930 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 257 loss: 1.26922 acc: 0.71061 | v_loss: 1.21627 v_acc: 0.71680 |  iteration: 13931 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 258 loss: 1.25311 acc: 0.70182 | v_loss: 1.13964 v_acc: 0.72559 |  iteration: 13932 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 259 loss: 1.24556 acc: 0.70312 | v_loss: 1.10990 v_acc: 0.72005 |  iteration: 13933 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 260 loss: 1.26049 acc: 0.69954 | v_loss: 1.46022 v_acc: 0.69173 |  iteration: 13934 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 261 loss: 1.21209 acc: 0.70833 | v_loss: 1.17760 v_acc: 0.71029 |  iteration: 13935 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 262 loss: 1.21826 acc: 0.71029 | v_loss: 1.21504 v_acc: 0.71810 |  iteration: 13936 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 263 loss: 1.25017 acc: 0.70247 | v_loss: 1.21375 v_acc: 0.70801 |  iteration: 13937 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 264 loss: 1.24504 acc: 0.70605 | v_loss: 1.26333 v_acc: 0.70573 |  iteration: 13938 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 265 loss: 1.20225 acc: 0.71061 | v_loss: 1.14170 v_acc: 0.73470 |  iteration: 13939 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 266 loss: 1.29310 acc: 0.70768 | v_loss: 1.33587 v_acc: 0.71647 |  iteration: 13940 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 267 loss: 1.22250 acc: 0.71094 | v_loss: 1.16616 v_acc: 0.70280 |  iteration: 13941 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 268 loss: 1.34034 acc: 0.70182 | v_loss: 1.19993 v_acc: 0.70150 |  iteration: 13942 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 269 loss: 1.28147 acc: 0.70052 | v_loss: 1.23887 v_acc: 0.70540 |  iteration: 13943 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 270 loss: 1.31767 acc: 0.70508 | v_loss: 1.22366 v_acc: 0.70475 |  iteration: 13944 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 271 loss: 1.21154 acc: 0.70573 | v_loss: 1.31740 v_acc: 0.69466 |  iteration: 13945 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 272 loss: 1.24754 acc: 0.70964 | v_loss: 1.34861 v_acc: 0.70638 |  iteration: 13946 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 273 loss: 1.17570 acc: 0.71908 | v_loss: 1.24519 v_acc: 0.70475 |  iteration: 13947 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 274 loss: 1.37046 acc: 0.69694 | v_loss: 1.15605 v_acc: 0.71061 |  iteration: 13948 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 275 loss: 1.27488 acc: 0.69596 | v_loss: 1.27334 v_acc: 0.71387 |  iteration: 13949 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 276 loss: 1.21189 acc: 0.70215 | v_loss: 1.19898 v_acc: 0.71582 |  iteration: 13950 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 277 loss: 1.28972 acc: 0.70638 | v_loss: 1.13305 v_acc: 0.72786 |  iteration: 13951 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 278 loss: 1.30524 acc: 0.69954 | v_loss: 1.11613 v_acc: 0.71094 |  iteration: 13952 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 279 loss: 1.27592 acc: 0.69922 | v_loss: 1.23850 v_acc: 0.70605 |  iteration: 13953 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 280 loss: 1.25411 acc: 0.70736 | v_loss: 1.25801 v_acc: 0.70345 |  iteration: 13954 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 281 loss: 1.29462 acc: 0.71029 | v_loss: 1.12583 v_acc: 0.71257 |  iteration: 13955 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 282 loss: 1.15418 acc: 0.71419 | v_loss: 1.17737 v_acc: 0.70215 |  iteration: 13956 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 283 loss: 1.25071 acc: 0.70573 | v_loss: 1.16904 v_acc: 0.71680 |  iteration: 13957 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 284 loss: 1.22118 acc: 0.71712 | v_loss: 1.18644 v_acc: 0.70736 |  iteration: 13958 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 285 loss: 1.23178 acc: 0.71191 | v_loss: 1.03534 v_acc: 0.74056 |  iteration: 13959 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 286 loss: 1.27594 acc: 0.69499 | v_loss: 1.17396 v_acc: 0.71842 |  iteration: 13960 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 287 loss: 1.22636 acc: 0.70378 | v_loss: 1.05779 v_acc: 0.72298 |  iteration: 13961 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 288 loss: 1.21592 acc: 0.71615 | v_loss: 1.08931 v_acc: 0.72363 |  iteration: 13962 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 289 loss: 1.30288 acc: 0.70443 | v_loss: 1.16803 v_acc: 0.72168 |  iteration: 13963 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 290 loss: 1.19495 acc: 0.72070 | v_loss: 1.16913 v_acc: 0.72005 |  iteration: 13964 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 291 loss: 1.27669 acc: 0.71029 | v_loss: 1.17826 v_acc: 0.72363 |  iteration: 13965 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 292 loss: 1.21348 acc: 0.70508 | v_loss: 1.37804 v_acc: 0.69987 |  iteration: 13966 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 293 loss: 1.19915 acc: 0.71777 | v_loss: 1.25756 v_acc: 0.71842 |  iteration: 13967 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 294 loss: 1.23892 acc: 0.70866 | v_loss: 1.01823 v_acc: 0.74902 |  iteration: 13968 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 295 loss: 1.35907 acc: 0.68978 | v_loss: 1.16074 v_acc: 0.70508 |  iteration: 13969 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 296 loss: 1.23783 acc: 0.70247 | v_loss: 1.23001 v_acc: 0.70215 |  iteration: 13970 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 297 loss: 1.42507 acc: 0.69629 | v_loss: 1.16623 v_acc: 0.70931 |  iteration: 13971 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 298 loss: 1.33025 acc: 0.69922 | v_loss: 1.19512 v_acc: 0.71322 |  iteration: 13972 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 299 loss: 1.20181 acc: 0.71842 | v_loss: 1.20323 v_acc: 0.69759 |  iteration: 13973 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 300 loss: 1.40142 acc: 0.68848 | v_loss: 1.18669 v_acc: 0.71289 |  iteration: 13974 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 301 loss: 1.27741 acc: 0.70508 | v_loss: 1.20591 v_acc: 0.69954 |  iteration: 13975 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 302 loss: 1.20174 acc: 0.71289 | v_loss: 1.14538 v_acc: 0.71973 |  iteration: 13976 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 303 loss: 1.27866 acc: 0.70671 | v_loss: 1.13443 v_acc: 0.72786 |  iteration: 13977 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 304 loss: 1.24411 acc: 0.71191 | v_loss: 1.16060 v_acc: 0.70833 |  iteration: 13978 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 305 loss: 1.30664 acc: 0.70215 | v_loss: 1.28303 v_acc: 0.69889 |  iteration: 13979 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 306 loss: 1.26263 acc: 0.70605 | v_loss: 1.13917 v_acc: 0.71387 |  iteration: 13980 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 307 loss: 1.20693 acc: 0.70540 | v_loss: 1.36214 v_acc: 0.68620 |  iteration: 13981 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 308 loss: 1.29078 acc: 0.70801 | v_loss: 1.11067 v_acc: 0.72526 |  iteration: 13982 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 309 loss: 1.18151 acc: 0.71810 | v_loss: 1.44002 v_acc: 0.68066 |  iteration: 13983 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 310 loss: 1.25795 acc: 0.70247 | v_loss: 1.30820 v_acc: 0.70182 |  iteration: 13984 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 311 loss: 1.17247 acc: 0.70573 | v_loss: 1.29475 v_acc: 0.69661 |  iteration: 13985 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 312 loss: 1.27832 acc: 0.70182 | v_loss: 1.26909 v_acc: 0.70150 |  iteration: 13986 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 313 loss: 1.28935 acc: 0.69434 | v_loss: 1.16718 v_acc: 0.71126 |  iteration: 13987 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 314 loss: 1.20186 acc: 0.71615 | v_loss: 1.21877 v_acc: 0.70866 |  iteration: 13988 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 315 loss: 1.30826 acc: 0.70312 | v_loss: 1.18300 v_acc: 0.72201 |  iteration: 13989 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 316 loss: 1.26292 acc: 0.69531 | v_loss: 1.36435 v_acc: 0.69108 |  iteration: 13990 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 317 loss: 1.25834 acc: 0.70573 | v_loss: 1.26394 v_acc: 0.70671 |  iteration: 13991 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 318 loss: 1.35374 acc: 0.69401 | v_loss: 1.15014 v_acc: 0.71224 |  iteration: 13992 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 319 loss: 1.19711 acc: 0.70671 | v_loss: 1.21495 v_acc: 0.71940 |  iteration: 13993 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 320 loss: 1.27557 acc: 0.70085 | v_loss: 1.15226 v_acc: 0.70508 |  iteration: 13994 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 321 loss: 1.25132 acc: 0.70736 | v_loss: 1.25211 v_acc: 0.69759 |  iteration: 13995 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 322 loss: 1.21976 acc: 0.71159 | v_loss: 1.20933 v_acc: 0.71615 |  iteration: 13996 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 323 loss: 1.33147 acc: 0.69759 | v_loss: 1.12662 v_acc: 0.72005 |  iteration: 13997 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 324 loss: 1.24796 acc: 0.70671 | v_loss: 1.11128 v_acc: 0.72396 |  iteration: 13998 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 325 loss: 1.37175 acc: 0.69596 | v_loss: 1.25232 v_acc: 0.71549 |  iteration: 13999 teacher: 0 stage: sketch lr: 0.000374\n",
      "batch 326 loss: 1.28780 acc: 0.70573 | v_loss: 1.21775 v_acc: 0.70508 |  iteration: 14000 teacher: 1 stage: sketch lr: 0.000374\n",
      "batch 327 loss: 1.28182 acc: 0.69694 | v_loss: 1.21382 v_acc: 0.70508 |  iteration: 14001 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 328 loss: 1.16831 acc: 0.72656 | v_loss: 1.07037 v_acc: 0.72168 |  iteration: 14002 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 329 loss: 1.24892 acc: 0.71615 | v_loss: 1.22236 v_acc: 0.73145 |  iteration: 14003 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 330 loss: 1.32892 acc: 0.69596 | v_loss: 1.25198 v_acc: 0.70085 |  iteration: 14004 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 331 loss: 1.26365 acc: 0.70280 | v_loss: 1.24547 v_acc: 0.72819 |  iteration: 14005 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 332 loss: 1.23657 acc: 0.70052 | v_loss: 1.12961 v_acc: 0.71908 |  iteration: 14006 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 333 loss: 1.29661 acc: 0.69922 | v_loss: 1.08736 v_acc: 0.74219 |  iteration: 14007 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 334 loss: 1.28177 acc: 0.70215 | v_loss: 1.05884 v_acc: 0.72298 |  iteration: 14008 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 335 loss: 1.23896 acc: 0.70443 | v_loss: 1.14356 v_acc: 0.71061 |  iteration: 14009 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 336 loss: 1.23392 acc: 0.70150 | v_loss: 1.19582 v_acc: 0.70540 |  iteration: 14010 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 337 loss: 1.29179 acc: 0.71419 | v_loss: 1.15468 v_acc: 0.71647 |  iteration: 14011 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 338 loss: 1.24636 acc: 0.71126 | v_loss: 1.25320 v_acc: 0.70410 |  iteration: 14012 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 339 loss: 1.23773 acc: 0.71549 | v_loss: 1.43165 v_acc: 0.69499 |  iteration: 14013 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 340 loss: 1.20319 acc: 0.71159 | v_loss: 1.31756 v_acc: 0.69889 |  iteration: 14014 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 341 loss: 1.32365 acc: 0.70085 | v_loss: 1.14919 v_acc: 0.72493 |  iteration: 14015 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 342 loss: 1.21491 acc: 0.70410 | v_loss: 1.13112 v_acc: 0.70768 |  iteration: 14016 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 343 loss: 1.34333 acc: 0.69987 | v_loss: 1.09309 v_acc: 0.72428 |  iteration: 14017 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 344 loss: 1.25012 acc: 0.70605 | v_loss: 1.18808 v_acc: 0.70247 |  iteration: 14018 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 345 loss: 1.19967 acc: 0.71159 | v_loss: 1.24139 v_acc: 0.71159 |  iteration: 14019 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 346 loss: 1.20029 acc: 0.70866 | v_loss: 1.17920 v_acc: 0.72526 |  iteration: 14020 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 347 loss: 1.27496 acc: 0.70150 | v_loss: 1.21275 v_acc: 0.72526 |  iteration: 14021 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 348 loss: 1.30822 acc: 0.70020 | v_loss: 1.20612 v_acc: 0.71322 |  iteration: 14022 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 349 loss: 1.24811 acc: 0.70443 | v_loss: 1.14075 v_acc: 0.72461 |  iteration: 14023 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 350 loss: 1.26509 acc: 0.70833 | v_loss: 1.09396 v_acc: 0.72233 |  iteration: 14024 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 351 loss: 1.26355 acc: 0.70280 | v_loss: 1.43891 v_acc: 0.69206 |  iteration: 14025 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 352 loss: 1.20812 acc: 0.71289 | v_loss: 1.16145 v_acc: 0.71159 |  iteration: 14026 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 353 loss: 1.30860 acc: 0.69629 | v_loss: 1.17261 v_acc: 0.72038 |  iteration: 14027 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 354 loss: 1.21572 acc: 0.70410 | v_loss: 1.17719 v_acc: 0.71940 |  iteration: 14028 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 355 loss: 1.18002 acc: 0.71354 | v_loss: 1.19895 v_acc: 0.70964 |  iteration: 14029 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 356 loss: 1.27931 acc: 0.70378 | v_loss: 1.11403 v_acc: 0.73470 |  iteration: 14030 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 357 loss: 1.25525 acc: 0.71094 | v_loss: 1.31694 v_acc: 0.71745 |  iteration: 14031 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 358 loss: 1.15864 acc: 0.71257 | v_loss: 1.15231 v_acc: 0.70182 |  iteration: 14032 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 359 loss: 1.29453 acc: 0.69661 | v_loss: 1.15291 v_acc: 0.70605 |  iteration: 14033 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 360 loss: 1.18075 acc: 0.72103 | v_loss: 1.21735 v_acc: 0.70573 |  iteration: 14034 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 361 loss: 1.35393 acc: 0.71061 | v_loss: 1.20363 v_acc: 0.70280 |  iteration: 14035 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 362 loss: 1.12308 acc: 0.71224 | v_loss: 1.29558 v_acc: 0.69727 |  iteration: 14036 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 363 loss: 1.27837 acc: 0.70312 | v_loss: 1.33307 v_acc: 0.70996 |  iteration: 14037 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 364 loss: 1.29481 acc: 0.70703 | v_loss: 1.24527 v_acc: 0.70475 |  iteration: 14038 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 365 loss: 1.18779 acc: 0.71257 | v_loss: 1.11715 v_acc: 0.71908 |  iteration: 14039 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 366 loss: 1.27281 acc: 0.70475 | v_loss: 1.28538 v_acc: 0.70931 |  iteration: 14040 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 367 loss: 1.29159 acc: 0.69661 | v_loss: 1.22623 v_acc: 0.71582 |  iteration: 14041 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 368 loss: 1.17541 acc: 0.70443 | v_loss: 1.10552 v_acc: 0.72917 |  iteration: 14042 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 369 loss: 1.24746 acc: 0.70573 | v_loss: 1.09827 v_acc: 0.71322 |  iteration: 14043 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 370 loss: 1.26843 acc: 0.69889 | v_loss: 1.21091 v_acc: 0.70833 |  iteration: 14044 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 371 loss: 1.26969 acc: 0.71061 | v_loss: 1.26884 v_acc: 0.69694 |  iteration: 14045 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 372 loss: 1.26962 acc: 0.70540 | v_loss: 1.10665 v_acc: 0.71777 |  iteration: 14046 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 373 loss: 1.36624 acc: 0.69271 | v_loss: 1.16029 v_acc: 0.70443 |  iteration: 14047 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 374 loss: 1.23598 acc: 0.70247 | v_loss: 1.13578 v_acc: 0.71549 |  iteration: 14048 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 375 loss: 1.28033 acc: 0.71452 | v_loss: 1.16837 v_acc: 0.70964 |  iteration: 14049 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 376 loss: 1.35749 acc: 0.69824 | v_loss: 1.03397 v_acc: 0.74642 |  iteration: 14050 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 377 loss: 1.19081 acc: 0.71061 | v_loss: 1.15144 v_acc: 0.72005 |  iteration: 14051 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 378 loss: 1.21367 acc: 0.71354 | v_loss: 1.08810 v_acc: 0.72168 |  iteration: 14052 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 379 loss: 1.19021 acc: 0.71257 | v_loss: 1.07908 v_acc: 0.72721 |  iteration: 14053 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 380 loss: 1.22081 acc: 0.71452 | v_loss: 1.15421 v_acc: 0.72070 |  iteration: 14054 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 381 loss: 1.34445 acc: 0.70703 | v_loss: 1.14012 v_acc: 0.72298 |  iteration: 14055 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 382 loss: 1.28617 acc: 0.70215 | v_loss: 1.14927 v_acc: 0.72526 |  iteration: 14056 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 383 loss: 1.23004 acc: 0.70215 | v_loss: 1.37571 v_acc: 0.70215 |  iteration: 14057 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 384 loss: 1.15928 acc: 0.72428 | v_loss: 1.23257 v_acc: 0.72298 |  iteration: 14058 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 385 loss: 1.30488 acc: 0.68913 | v_loss: 1.01528 v_acc: 0.74577 |  iteration: 14059 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 386 loss: 1.32632 acc: 0.69368 | v_loss: 1.22243 v_acc: 0.70996 |  iteration: 14060 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 387 loss: 1.19834 acc: 0.71484 | v_loss: 1.21380 v_acc: 0.70215 |  iteration: 14061 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 388 loss: 1.24342 acc: 0.72331 | v_loss: 1.17188 v_acc: 0.70703 |  iteration: 14062 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 389 loss: 1.18200 acc: 0.71191 | v_loss: 1.20769 v_acc: 0.71452 |  iteration: 14063 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 390 loss: 1.31038 acc: 0.70020 | v_loss: 1.19763 v_acc: 0.69531 |  iteration: 14064 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 391 loss: 1.25965 acc: 0.70931 | v_loss: 1.19851 v_acc: 0.71191 |  iteration: 14065 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 392 loss: 1.26429 acc: 0.69564 | v_loss: 1.19677 v_acc: 0.69727 |  iteration: 14066 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 393 loss: 1.19380 acc: 0.70898 | v_loss: 1.13803 v_acc: 0.71712 |  iteration: 14067 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 394 loss: 1.22576 acc: 0.70443 | v_loss: 1.15113 v_acc: 0.72884 |  iteration: 14068 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 395 loss: 1.24828 acc: 0.70833 | v_loss: 1.16105 v_acc: 0.70443 |  iteration: 14069 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 396 loss: 1.15775 acc: 0.72331 | v_loss: 1.28145 v_acc: 0.69889 |  iteration: 14070 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 397 loss: 1.23557 acc: 0.71061 | v_loss: 1.11531 v_acc: 0.71061 |  iteration: 14071 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 398 loss: 1.20657 acc: 0.71484 | v_loss: 1.36470 v_acc: 0.68457 |  iteration: 14072 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 399 loss: 1.21997 acc: 0.70443 | v_loss: 1.14528 v_acc: 0.72396 |  iteration: 14073 teacher: 0 stage: sketch lr: 0.000373\n",
      "batch 400 loss: 1.20741 acc: 0.70573 | v_loss: 1.40271 v_acc: 0.68197 |  iteration: 14074 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 401 loss: 1.24958 acc: 0.71094 | v_loss: 1.31818 v_acc: 0.70117 |  iteration: 14075 teacher: 1 stage: sketch lr: 0.000373\n",
      "batch 402 loss: 1.12740 acc: 0.72559 | v_loss: 1.28482 v_acc: 0.69499 |  iteration: 14076 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 403 loss: 1.28199 acc: 0.69661 | v_loss: 1.27915 v_acc: 0.70247 |  iteration: 14077 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 404 loss: 1.31416 acc: 0.69987 | v_loss: 1.17512 v_acc: 0.71061 |  iteration: 14078 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 405 loss: 1.18925 acc: 0.71549 | v_loss: 1.25500 v_acc: 0.70540 |  iteration: 14079 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 406 loss: 1.19469 acc: 0.70182 | v_loss: 1.18759 v_acc: 0.71842 |  iteration: 14080 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 407 loss: 1.23308 acc: 0.70443 | v_loss: 1.38379 v_acc: 0.68945 |  iteration: 14081 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 408 loss: 1.37770 acc: 0.69499 | v_loss: 1.29019 v_acc: 0.70671 |  iteration: 14082 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 409 loss: 1.28382 acc: 0.69857 | v_loss: 1.12952 v_acc: 0.71257 |  iteration: 14083 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 410 loss: 1.21484 acc: 0.71419 | v_loss: 1.22326 v_acc: 0.72363 |  iteration: 14084 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 411 loss: 1.19529 acc: 0.71094 | v_loss: 1.13369 v_acc: 0.70866 |  iteration: 14085 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 412 loss: 1.24919 acc: 0.70638 | v_loss: 1.20761 v_acc: 0.69987 |  iteration: 14086 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 413 loss: 1.24958 acc: 0.70638 | v_loss: 1.18199 v_acc: 0.71159 |  iteration: 14087 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 414 loss: 1.23777 acc: 0.70150 | v_loss: 1.13097 v_acc: 0.71940 |  iteration: 14088 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 415 loss: 1.26328 acc: 0.70280 | v_loss: 1.07301 v_acc: 0.72689 |  iteration: 14089 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 416 loss: 1.24532 acc: 0.71029 | v_loss: 1.22035 v_acc: 0.71973 |  iteration: 14090 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 417 loss: 1.31875 acc: 0.70508 | v_loss: 1.22117 v_acc: 0.70508 |  iteration: 14091 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 418 loss: 1.49214 acc: 0.67448 | v_loss: 1.20592 v_acc: 0.70931 |  iteration: 14092 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 419 loss: 1.20923 acc: 0.70736 | v_loss: 1.07191 v_acc: 0.72038 |  iteration: 14093 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 420 loss: 1.21887 acc: 0.71029 | v_loss: 1.20488 v_acc: 0.73112 |  iteration: 14094 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 421 loss: 1.41084 acc: 0.69206 | v_loss: 1.25236 v_acc: 0.70117 |  iteration: 14095 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 422 loss: 1.20279 acc: 0.72005 | v_loss: 1.26133 v_acc: 0.72559 |  iteration: 14096 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 423 loss: 1.16436 acc: 0.72168 | v_loss: 1.13235 v_acc: 0.72168 |  iteration: 14097 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 424 loss: 1.20734 acc: 0.71810 | v_loss: 1.10673 v_acc: 0.72819 |  iteration: 14098 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 425 loss: 1.28128 acc: 0.70671 | v_loss: 1.07257 v_acc: 0.72689 |  iteration: 14099 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 426 loss: 1.19454 acc: 0.71647 | v_loss: 1.16510 v_acc: 0.70540 |  iteration: 14100 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 427 loss: 1.26975 acc: 0.70345 | v_loss: 1.18553 v_acc: 0.70345 |  iteration: 14101 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 428 loss: 1.23915 acc: 0.71126 | v_loss: 1.14957 v_acc: 0.71647 |  iteration: 14102 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 429 loss: 1.24590 acc: 0.70378 | v_loss: 1.28872 v_acc: 0.70671 |  iteration: 14103 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 430 loss: 1.20103 acc: 0.70768 | v_loss: 1.40435 v_acc: 0.70052 |  iteration: 14104 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 431 loss: 1.28709 acc: 0.71224 | v_loss: 1.29922 v_acc: 0.69857 |  iteration: 14105 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 432 loss: 1.22641 acc: 0.70475 | v_loss: 1.14139 v_acc: 0.72135 |  iteration: 14106 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 433 loss: 1.17387 acc: 0.71191 | v_loss: 1.14033 v_acc: 0.70898 |  iteration: 14107 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 434 loss: 1.32477 acc: 0.70312 | v_loss: 1.12867 v_acc: 0.72559 |  iteration: 14108 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 435 loss: 1.21862 acc: 0.70085 | v_loss: 1.15920 v_acc: 0.70964 |  iteration: 14109 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 436 loss: 1.21914 acc: 0.70573 | v_loss: 1.21721 v_acc: 0.71810 |  iteration: 14110 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 437 loss: 1.17134 acc: 0.70996 | v_loss: 1.18029 v_acc: 0.72949 |  iteration: 14111 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 438 loss: 1.25244 acc: 0.70215 | v_loss: 1.19773 v_acc: 0.72428 |  iteration: 14112 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 439 loss: 1.24632 acc: 0.70573 | v_loss: 1.20563 v_acc: 0.70964 |  iteration: 14113 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 440 loss: 1.28520 acc: 0.70443 | v_loss: 1.11970 v_acc: 0.72754 |  iteration: 14114 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 441 loss: 1.24322 acc: 0.71712 | v_loss: 1.08551 v_acc: 0.72363 |  iteration: 14115 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 442 loss: 1.22830 acc: 0.71224 | v_loss: 1.45926 v_acc: 0.69303 |  iteration: 14116 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 443 loss: 1.20276 acc: 0.70638 | v_loss: 1.19150 v_acc: 0.71224 |  iteration: 14117 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 444 loss: 1.29821 acc: 0.70280 | v_loss: 1.17321 v_acc: 0.71940 |  iteration: 14118 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 445 loss: 1.21296 acc: 0.70833 | v_loss: 1.19394 v_acc: 0.71061 |  iteration: 14119 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 446 loss: 1.14410 acc: 0.72428 | v_loss: 1.23478 v_acc: 0.70345 |  iteration: 14120 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 447 loss: 1.34655 acc: 0.70475 | v_loss: 1.11432 v_acc: 0.73600 |  iteration: 14121 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 448 loss: 1.26131 acc: 0.69987 | v_loss: 1.32190 v_acc: 0.71940 |  iteration: 14122 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 449 loss: 1.34373 acc: 0.69824 | v_loss: 1.15149 v_acc: 0.70247 |  iteration: 14123 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 450 loss: 1.20763 acc: 0.70410 | v_loss: 1.17935 v_acc: 0.70475 |  iteration: 14124 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 451 loss: 1.21915 acc: 0.71029 | v_loss: 1.24553 v_acc: 0.70345 |  iteration: 14125 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 452 loss: 1.24771 acc: 0.71094 | v_loss: 1.22979 v_acc: 0.70247 |  iteration: 14126 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 453 loss: 1.24511 acc: 0.70671 | v_loss: 1.29035 v_acc: 0.69889 |  iteration: 14127 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 454 loss: 1.20264 acc: 0.70573 | v_loss: 1.33291 v_acc: 0.71257 |  iteration: 14128 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 455 loss: 1.32849 acc: 0.69141 | v_loss: 1.22975 v_acc: 0.70638 |  iteration: 14129 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 456 loss: 1.25317 acc: 0.70410 | v_loss: 1.13433 v_acc: 0.71745 |  iteration: 14130 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 457 loss: 1.20698 acc: 0.71126 | v_loss: 1.29141 v_acc: 0.70736 |  iteration: 14131 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 458 loss: 1.32024 acc: 0.69824 | v_loss: 1.22677 v_acc: 0.71940 |  iteration: 14132 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 459 loss: 1.32037 acc: 0.69629 | v_loss: 1.09280 v_acc: 0.73079 |  iteration: 14133 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 460 loss: 1.26106 acc: 0.70215 | v_loss: 1.12620 v_acc: 0.71061 |  iteration: 14134 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 461 loss: 1.27021 acc: 0.70085 | v_loss: 1.20711 v_acc: 0.70703 |  iteration: 14135 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 462 loss: 1.27932 acc: 0.70671 | v_loss: 1.27776 v_acc: 0.69727 |  iteration: 14136 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 463 loss: 1.18749 acc: 0.70801 | v_loss: 1.13373 v_acc: 0.71289 |  iteration: 14137 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 464 loss: 1.21804 acc: 0.70573 | v_loss: 1.15612 v_acc: 0.69596 |  iteration: 14138 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 465 loss: 1.32390 acc: 0.69954 | v_loss: 1.17360 v_acc: 0.70964 |  iteration: 14139 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 466 loss: 1.23528 acc: 0.71387 | v_loss: 1.22947 v_acc: 0.70508 |  iteration: 14140 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 467 loss: 1.27829 acc: 0.70573 | v_loss: 1.01432 v_acc: 0.74284 |  iteration: 14141 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 468 loss: 1.30719 acc: 0.70052 | v_loss: 1.15848 v_acc: 0.71940 |  iteration: 14142 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 469 loss: 1.28586 acc: 0.69857 | v_loss: 1.06608 v_acc: 0.72884 |  iteration: 14143 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 470 loss: 1.23607 acc: 0.70247 | v_loss: 1.08710 v_acc: 0.72721 |  iteration: 14144 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 471 loss: 1.16366 acc: 0.71517 | v_loss: 1.14989 v_acc: 0.72461 |  iteration: 14145 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 472 loss: 1.19869 acc: 0.70605 | v_loss: 1.13875 v_acc: 0.72135 |  iteration: 14146 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 473 loss: 1.23461 acc: 0.70443 | v_loss: 1.15725 v_acc: 0.73014 |  iteration: 14147 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 474 loss: 1.26886 acc: 0.69889 | v_loss: 1.39446 v_acc: 0.70182 |  iteration: 14148 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 475 loss: 1.12622 acc: 0.72298 | v_loss: 1.25651 v_acc: 0.72103 |  iteration: 14149 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 476 loss: 1.23361 acc: 0.70931 | v_loss: 1.01867 v_acc: 0.74414 |  iteration: 14150 teacher: 0 stage: sketch lr: 0.000372\n",
      "batch 477 loss: 1.20442 acc: 0.70573 | v_loss: 1.21544 v_acc: 0.70833 |  iteration: 14151 teacher: 1 stage: sketch lr: 0.000372\n",
      "batch 478 loss: 1.37349 acc: 0.69889 | v_loss: 1.21474 v_acc: 0.70020 |  iteration: 14152 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 479 loss: 1.30129 acc: 0.69922 | v_loss: 1.18978 v_acc: 0.70703 |  iteration: 14153 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 480 loss: 1.21719 acc: 0.71322 | v_loss: 1.22746 v_acc: 0.71354 |  iteration: 14154 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 481 loss: 1.18091 acc: 0.71810 | v_loss: 1.19200 v_acc: 0.69727 |  iteration: 14155 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 482 loss: 1.15127 acc: 0.71387 | v_loss: 1.17591 v_acc: 0.71322 |  iteration: 14156 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 483 loss: 1.21940 acc: 0.70247 | v_loss: 1.20181 v_acc: 0.69727 |  iteration: 14157 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 484 loss: 1.21217 acc: 0.70964 | v_loss: 1.14900 v_acc: 0.71777 |  iteration: 14158 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 485 loss: 1.27782 acc: 0.70801 | v_loss: 1.13965 v_acc: 0.72786 |  iteration: 14159 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 486 loss: 1.30454 acc: 0.70768 | v_loss: 1.14946 v_acc: 0.70605 |  iteration: 14160 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 487 loss: 1.27714 acc: 0.70573 | v_loss: 1.29164 v_acc: 0.70117 |  iteration: 14161 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 488 loss: 1.28896 acc: 0.70638 | v_loss: 1.11306 v_acc: 0.71126 |  iteration: 14162 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 489 loss: 1.24316 acc: 0.71159 | v_loss: 1.36062 v_acc: 0.68815 |  iteration: 14163 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 490 loss: 1.23293 acc: 0.70898 | v_loss: 1.11304 v_acc: 0.72493 |  iteration: 14164 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 491 loss: 1.29700 acc: 0.70638 | v_loss: 1.47287 v_acc: 0.67839 |  iteration: 14165 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 492 loss: 1.31667 acc: 0.70345 | v_loss: 1.36218 v_acc: 0.68783 |  iteration: 14166 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 493 loss: 1.21508 acc: 0.71289 | v_loss: 1.27779 v_acc: 0.69596 |  iteration: 14167 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 494 loss: 1.29107 acc: 0.70085 | v_loss: 1.31166 v_acc: 0.69792 |  iteration: 14168 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 495 loss: 1.27847 acc: 0.70312 | v_loss: 1.19316 v_acc: 0.71387 |  iteration: 14169 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 496 loss: 1.30244 acc: 0.68848 | v_loss: 1.21358 v_acc: 0.71615 |  iteration: 14170 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 497 loss: 1.16809 acc: 0.71257 | v_loss: 1.18542 v_acc: 0.72624 |  iteration: 14171 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 498 loss: 1.24561 acc: 0.70996 | v_loss: 1.35001 v_acc: 0.68652 |  iteration: 14172 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 499 loss: 1.32563 acc: 0.69857 | v_loss: 1.23678 v_acc: 0.71354 |  iteration: 14173 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 500 loss: 1.30430 acc: 0.70182 | v_loss: 1.13253 v_acc: 0.71452 |  iteration: 14174 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 501 loss: 1.42651 acc: 0.68717 | v_loss: 1.18906 v_acc: 0.71647 |  iteration: 14175 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 502 loss: 1.38493 acc: 0.69401 | v_loss: 1.12287 v_acc: 0.71159 |  iteration: 14176 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 503 loss: 1.21047 acc: 0.70378 | v_loss: 1.20991 v_acc: 0.70345 |  iteration: 14177 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 504 loss: 1.30108 acc: 0.69596 | v_loss: 1.18602 v_acc: 0.71712 |  iteration: 14178 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 505 loss: 1.19325 acc: 0.71257 | v_loss: 1.11192 v_acc: 0.72201 |  iteration: 14179 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 506 loss: 1.17513 acc: 0.71452 | v_loss: 1.09171 v_acc: 0.73014 |  iteration: 14180 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 507 loss: 1.21988 acc: 0.71484 | v_loss: 1.21943 v_acc: 0.71810 |  iteration: 14181 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 508 loss: 1.24730 acc: 0.70573 | v_loss: 1.23914 v_acc: 0.70280 |  iteration: 14182 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 509 loss: 1.27581 acc: 0.69596 | v_loss: 1.21908 v_acc: 0.70540 |  iteration: 14183 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 510 loss: 1.28818 acc: 0.69727 | v_loss: 1.05710 v_acc: 0.72070 |  iteration: 14184 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 511 loss: 1.29190 acc: 0.69141 | v_loss: 1.19241 v_acc: 0.73210 |  iteration: 14185 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 512 loss: 1.31955 acc: 0.69206 | v_loss: 1.25316 v_acc: 0.70117 |  iteration: 14186 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 513 loss: 1.25232 acc: 0.70605 | v_loss: 1.21893 v_acc: 0.72721 |  iteration: 14187 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 514 loss: 1.28508 acc: 0.69661 | v_loss: 1.11779 v_acc: 0.71875 |  iteration: 14188 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 515 loss: 1.22436 acc: 0.70703 | v_loss: 1.06035 v_acc: 0.72949 |  iteration: 14189 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 516 loss: 1.20442 acc: 0.71061 | v_loss: 1.04571 v_acc: 0.72689 |  iteration: 14190 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 517 loss: 1.30254 acc: 0.70150 | v_loss: 1.16685 v_acc: 0.70736 |  iteration: 14191 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 518 loss: 1.28427 acc: 0.70280 | v_loss: 1.15944 v_acc: 0.70247 |  iteration: 14192 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 519 loss: 1.36617 acc: 0.69108 | v_loss: 1.15640 v_acc: 0.71615 |  iteration: 14193 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 520 loss: 1.22890 acc: 0.70475 | v_loss: 1.26341 v_acc: 0.71484 |  iteration: 14194 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 521 loss: 1.28324 acc: 0.71061 | v_loss: 1.38207 v_acc: 0.69824 |  iteration: 14195 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 522 loss: 1.24650 acc: 0.70964 | v_loss: 1.28917 v_acc: 0.70410 |  iteration: 14196 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 523 loss: 1.21282 acc: 0.70573 | v_loss: 1.16218 v_acc: 0.72461 |  iteration: 14197 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 524 loss: 1.28817 acc: 0.69954 | v_loss: 1.13070 v_acc: 0.70736 |  iteration: 14198 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 525 loss: 1.24304 acc: 0.71061 | v_loss: 1.10765 v_acc: 0.72461 |  iteration: 14199 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 526 loss: 1.26318 acc: 0.71647 | v_loss: 1.17179 v_acc: 0.70801 |  iteration: 14200 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 527 loss: 1.38339 acc: 0.68848 | v_loss: 1.19824 v_acc: 0.72201 |  iteration: 14201 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 528 loss: 1.34912 acc: 0.69857 | v_loss: 1.16625 v_acc: 0.73145 |  iteration: 14202 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 529 loss: 1.13595 acc: 0.71484 | v_loss: 1.19777 v_acc: 0.72266 |  iteration: 14203 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 530 loss: 1.21042 acc: 0.71191 | v_loss: 1.18021 v_acc: 0.71061 |  iteration: 14204 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 531 loss: 1.26146 acc: 0.70312 | v_loss: 1.12405 v_acc: 0.72949 |  iteration: 14205 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 532 loss: 1.21717 acc: 0.70215 | v_loss: 1.06898 v_acc: 0.72428 |  iteration: 14206 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 533 loss: 1.14149 acc: 0.71517 | v_loss: 1.42930 v_acc: 0.69173 |  iteration: 14207 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 534 loss: 1.28507 acc: 0.70768 | v_loss: 1.17041 v_acc: 0.71224 |  iteration: 14208 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 535 loss: 1.26388 acc: 0.71549 | v_loss: 1.17283 v_acc: 0.72168 |  iteration: 14209 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 536 loss: 1.21006 acc: 0.71387 | v_loss: 1.18669 v_acc: 0.71582 |  iteration: 14210 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 537 loss: 1.19101 acc: 0.70508 | v_loss: 1.19698 v_acc: 0.71842 |  iteration: 14211 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 538 loss: 1.19679 acc: 0.71940 | v_loss: 1.10994 v_acc: 0.73796 |  iteration: 14212 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 539 loss: 1.24356 acc: 0.71387 | v_loss: 1.29320 v_acc: 0.71712 |  iteration: 14213 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 540 loss: 1.25042 acc: 0.70312 | v_loss: 1.17990 v_acc: 0.70052 |  iteration: 14214 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 541 loss: 1.22017 acc: 0.71549 | v_loss: 1.20541 v_acc: 0.70247 |  iteration: 14215 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 542 loss: 1.24043 acc: 0.70768 | v_loss: 1.22257 v_acc: 0.70312 |  iteration: 14216 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 543 loss: 1.20233 acc: 0.70866 | v_loss: 1.17680 v_acc: 0.70475 |  iteration: 14217 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 544 loss: 1.22485 acc: 0.69564 | v_loss: 1.29257 v_acc: 0.69564 |  iteration: 14218 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 545 loss: 1.30238 acc: 0.70638 | v_loss: 1.32048 v_acc: 0.70866 |  iteration: 14219 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 546 loss: 1.26370 acc: 0.71615 | v_loss: 1.22388 v_acc: 0.70540 |  iteration: 14220 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 547 loss: 1.25452 acc: 0.70540 | v_loss: 1.11361 v_acc: 0.71159 |  iteration: 14221 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 548 loss: 1.27737 acc: 0.69727 | v_loss: 1.26319 v_acc: 0.70540 |  iteration: 14222 teacher: 1 stage: sketch lr: 0.000371\n",
      "batch 549 loss: 1.32998 acc: 0.69661 | v_loss: 1.20824 v_acc: 0.71224 |  iteration: 14223 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 550 loss: 1.26369 acc: 0.70638 | v_loss: 1.07724 v_acc: 0.73014 |  iteration: 14224 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 551 loss: 1.17233 acc: 0.71289 | v_loss: 1.12129 v_acc: 0.70768 |  iteration: 14225 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 552 loss: 1.24505 acc: 0.69824 | v_loss: 1.20308 v_acc: 0.70964 |  iteration: 14226 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 553 loss: 1.23170 acc: 0.70052 | v_loss: 1.23046 v_acc: 0.70312 |  iteration: 14227 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 554 loss: 1.26736 acc: 0.70052 | v_loss: 1.10956 v_acc: 0.71908 |  iteration: 14228 teacher: 0 stage: sketch lr: 0.000371\n",
      "batch 555 loss: 1.27201 acc: 0.69824 | v_loss: 1.15316 v_acc: 0.70247 |  iteration: 14229 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 556 loss: 1.24567 acc: 0.70117 | v_loss: 1.14064 v_acc: 0.71647 |  iteration: 14230 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 557 loss: 1.25875 acc: 0.70540 | v_loss: 1.17666 v_acc: 0.70964 |  iteration: 14231 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 558 loss: 1.24588 acc: 0.69792 | v_loss: 1.03904 v_acc: 0.74414 |  iteration: 14232 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 559 loss: 1.38149 acc: 0.69759 | v_loss: 1.14801 v_acc: 0.71810 |  iteration: 14233 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 560 loss: 1.31712 acc: 0.69824 | v_loss: 1.09334 v_acc: 0.70736 |  iteration: 14234 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 561 loss: 1.18270 acc: 0.71257 | v_loss: 1.06792 v_acc: 0.73079 |  iteration: 14235 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 562 loss: 1.29409 acc: 0.70247 | v_loss: 1.15948 v_acc: 0.71647 |  iteration: 14236 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 563 loss: 1.27969 acc: 0.70605 | v_loss: 1.16893 v_acc: 0.71940 |  iteration: 14237 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 564 loss: 1.22061 acc: 0.70703 | v_loss: 1.16966 v_acc: 0.72949 |  iteration: 14238 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 565 loss: 1.20737 acc: 0.71549 | v_loss: 1.36189 v_acc: 0.70215 |  iteration: 14239 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 566 loss: 1.33980 acc: 0.69661 | v_loss: 1.23267 v_acc: 0.72201 |  iteration: 14240 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 567 loss: 1.21287 acc: 0.70768 | v_loss: 1.01490 v_acc: 0.74577 |  iteration: 14241 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 568 loss: 1.27328 acc: 0.70443 | v_loss: 1.18722 v_acc: 0.70931 |  iteration: 14242 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 569 loss: 1.22788 acc: 0.70703 | v_loss: 1.21219 v_acc: 0.70312 |  iteration: 14243 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 570 loss: 1.27943 acc: 0.70573 | v_loss: 1.17323 v_acc: 0.70768 |  iteration: 14244 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 571 loss: 1.17884 acc: 0.71354 | v_loss: 1.19166 v_acc: 0.71322 |  iteration: 14245 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 572 loss: 1.20142 acc: 0.70866 | v_loss: 1.20554 v_acc: 0.69759 |  iteration: 14246 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 573 loss: 1.23493 acc: 0.70573 | v_loss: 1.19249 v_acc: 0.71094 |  iteration: 14247 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 574 loss: 1.21202 acc: 0.70605 | v_loss: 1.18883 v_acc: 0.69824 |  iteration: 14248 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 575 loss: 1.19140 acc: 0.71419 | v_loss: 1.11373 v_acc: 0.71810 |  iteration: 14249 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 576 loss: 1.28009 acc: 0.69792 | v_loss: 1.11259 v_acc: 0.72884 |  iteration: 14250 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 577 loss: 1.21001 acc: 0.70182 | v_loss: 1.13949 v_acc: 0.70540 |  iteration: 14251 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 578 loss: 1.32182 acc: 0.69889 | v_loss: 1.28515 v_acc: 0.70280 |  iteration: 14252 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 579 loss: 1.17786 acc: 0.71029 | v_loss: 1.11260 v_acc: 0.71680 |  iteration: 14253 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 580 loss: 1.26735 acc: 0.70605 | v_loss: 1.35719 v_acc: 0.68848 |  iteration: 14254 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 581 loss: 1.25676 acc: 0.70605 | v_loss: 1.10041 v_acc: 0.72689 |  iteration: 14255 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 582 loss: 1.22510 acc: 0.71126 | v_loss: 1.47552 v_acc: 0.67969 |  iteration: 14256 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 583 loss: 1.22228 acc: 0.70345 | v_loss: 1.37636 v_acc: 0.69010 |  iteration: 14257 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 584 loss: 1.19599 acc: 0.71061 | v_loss: 1.26685 v_acc: 0.69889 |  iteration: 14258 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 585 loss: 1.26926 acc: 0.70312 | v_loss: 1.33050 v_acc: 0.69206 |  iteration: 14259 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 586 loss: 1.26161 acc: 0.70345 | v_loss: 1.17773 v_acc: 0.71289 |  iteration: 14260 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 587 loss: 1.20159 acc: 0.70508 | v_loss: 1.25207 v_acc: 0.70801 |  iteration: 14261 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 588 loss: 1.19538 acc: 0.70964 | v_loss: 1.18401 v_acc: 0.72591 |  iteration: 14262 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 589 loss: 1.25559 acc: 0.70410 | v_loss: 1.38257 v_acc: 0.68294 |  iteration: 14263 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 590 loss: 1.33849 acc: 0.69596 | v_loss: 1.25127 v_acc: 0.71452 |  iteration: 14264 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 591 loss: 1.18654 acc: 0.70540 | v_loss: 1.15498 v_acc: 0.71126 |  iteration: 14265 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 592 loss: 1.29455 acc: 0.70801 | v_loss: 1.22985 v_acc: 0.70964 |  iteration: 14266 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 593 loss: 1.26564 acc: 0.69889 | v_loss: 1.13589 v_acc: 0.70866 |  iteration: 14267 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 594 loss: 1.14468 acc: 0.71387 | v_loss: 1.21107 v_acc: 0.70671 |  iteration: 14268 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 595 loss: 1.25030 acc: 0.69824 | v_loss: 1.18347 v_acc: 0.71810 |  iteration: 14269 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 596 loss: 1.32289 acc: 0.69466 | v_loss: 1.11999 v_acc: 0.72396 |  iteration: 14270 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 597 loss: 1.22334 acc: 0.71061 | v_loss: 1.07985 v_acc: 0.72884 |  iteration: 14271 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 598 loss: 1.24337 acc: 0.70443 | v_loss: 1.22150 v_acc: 0.71712 |  iteration: 14272 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 599 loss: 1.21323 acc: 0.70540 | v_loss: 1.20494 v_acc: 0.70833 |  iteration: 14273 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 600 loss: 1.20994 acc: 0.70247 | v_loss: 1.17373 v_acc: 0.71322 |  iteration: 14274 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 601 loss: 1.26077 acc: 0.69889 | v_loss: 1.06427 v_acc: 0.72689 |  iteration: 14275 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 602 loss: 1.20369 acc: 0.70117 | v_loss: 1.21825 v_acc: 0.73405 |  iteration: 14276 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 603 loss: 1.26412 acc: 0.69922 | v_loss: 1.26278 v_acc: 0.70117 |  iteration: 14277 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 604 loss: 1.31557 acc: 0.69759 | v_loss: 1.24457 v_acc: 0.72819 |  iteration: 14278 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 605 loss: 1.28200 acc: 0.69954 | v_loss: 1.10777 v_acc: 0.72070 |  iteration: 14279 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 606 loss: 1.27822 acc: 0.70280 | v_loss: 1.08546 v_acc: 0.73275 |  iteration: 14280 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 607 loss: 1.21343 acc: 0.70508 | v_loss: 1.05899 v_acc: 0.72591 |  iteration: 14281 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 608 loss: 1.16112 acc: 0.71029 | v_loss: 1.16589 v_acc: 0.70996 |  iteration: 14282 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 609 loss: 1.20037 acc: 0.70410 | v_loss: 1.17882 v_acc: 0.70540 |  iteration: 14283 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 610 loss: 1.22323 acc: 0.71094 | v_loss: 1.13829 v_acc: 0.71810 |  iteration: 14284 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 611 loss: 1.17999 acc: 0.71061 | v_loss: 1.25893 v_acc: 0.70443 |  iteration: 14285 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 612 loss: 1.31328 acc: 0.69466 | v_loss: 1.41049 v_acc: 0.69499 |  iteration: 14286 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 613 loss: 1.21604 acc: 0.70703 | v_loss: 1.30150 v_acc: 0.70475 |  iteration: 14287 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 614 loss: 1.26444 acc: 0.70345 | v_loss: 1.13902 v_acc: 0.72884 |  iteration: 14288 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 615 loss: 1.18638 acc: 0.70833 | v_loss: 1.13086 v_acc: 0.70931 |  iteration: 14289 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 616 loss: 1.34953 acc: 0.69271 | v_loss: 1.09363 v_acc: 0.72298 |  iteration: 14290 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 617 loss: 1.20840 acc: 0.71289 | v_loss: 1.16107 v_acc: 0.70898 |  iteration: 14291 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 618 loss: 1.21910 acc: 0.71094 | v_loss: 1.20370 v_acc: 0.72038 |  iteration: 14292 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 619 loss: 1.19377 acc: 0.71322 | v_loss: 1.16170 v_acc: 0.73112 |  iteration: 14293 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 620 loss: 1.31901 acc: 0.69792 | v_loss: 1.20063 v_acc: 0.72656 |  iteration: 14294 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 621 loss: 1.25129 acc: 0.69857 | v_loss: 1.16987 v_acc: 0.72168 |  iteration: 14295 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 622 loss: 1.39463 acc: 0.69043 | v_loss: 1.12363 v_acc: 0.72852 |  iteration: 14296 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 623 loss: 1.24549 acc: 0.70215 | v_loss: 1.08640 v_acc: 0.72233 |  iteration: 14297 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 624 loss: 1.24118 acc: 0.71549 | v_loss: 1.43450 v_acc: 0.68978 |  iteration: 14298 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 625 loss: 1.21728 acc: 0.70801 | v_loss: 1.18645 v_acc: 0.71419 |  iteration: 14299 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 626 loss: 1.25010 acc: 0.70378 | v_loss: 1.21806 v_acc: 0.71745 |  iteration: 14300 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 627 loss: 1.20265 acc: 0.70605 | v_loss: 1.21790 v_acc: 0.71940 |  iteration: 14301 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 628 loss: 1.20413 acc: 0.71126 | v_loss: 1.21191 v_acc: 0.71257 |  iteration: 14302 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 629 loss: 1.25578 acc: 0.72070 | v_loss: 1.09166 v_acc: 0.73926 |  iteration: 14303 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 630 loss: 1.27500 acc: 0.70508 | v_loss: 1.30494 v_acc: 0.71680 |  iteration: 14304 teacher: 1 stage: sketch lr: 0.000370\n",
      "batch 631 loss: 1.23685 acc: 0.71322 | v_loss: 1.14876 v_acc: 0.69922 |  iteration: 14305 teacher: 0 stage: sketch lr: 0.000370\n",
      "batch 632 loss: 1.28770 acc: 0.70247 | v_loss: 1.14388 v_acc: 0.70703 |  iteration: 14306 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 633 loss: 1.20648 acc: 0.71094 | v_loss: 1.22842 v_acc: 0.70638 |  iteration: 14307 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 634 loss: 1.18884 acc: 0.70768 | v_loss: 1.23831 v_acc: 0.70117 |  iteration: 14308 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 635 loss: 1.27289 acc: 0.69792 | v_loss: 1.33073 v_acc: 0.69173 |  iteration: 14309 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 636 loss: 1.15969 acc: 0.71777 | v_loss: 1.33565 v_acc: 0.70573 |  iteration: 14310 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 637 loss: 1.22443 acc: 0.70117 | v_loss: 1.23050 v_acc: 0.70508 |  iteration: 14311 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 638 loss: 1.24353 acc: 0.70247 | v_loss: 1.13841 v_acc: 0.70964 |  iteration: 14312 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 639 loss: 1.25133 acc: 0.70736 | v_loss: 1.27872 v_acc: 0.70508 |  iteration: 14313 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 640 loss: 1.19626 acc: 0.71810 | v_loss: 1.17599 v_acc: 0.71647 |  iteration: 14314 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 641 loss: 1.23150 acc: 0.69954 | v_loss: 1.08299 v_acc: 0.73112 |  iteration: 14315 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 642 loss: 1.22646 acc: 0.70215 | v_loss: 1.10486 v_acc: 0.71191 |  iteration: 14316 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 643 loss: 1.22977 acc: 0.70996 | v_loss: 1.22054 v_acc: 0.70768 |  iteration: 14317 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 644 loss: 1.23089 acc: 0.71387 | v_loss: 1.26436 v_acc: 0.69401 |  iteration: 14318 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 645 loss: 1.27275 acc: 0.69303 | v_loss: 1.11115 v_acc: 0.71712 |  iteration: 14319 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 646 loss: 1.22628 acc: 0.70573 | v_loss: 1.15751 v_acc: 0.69954 |  iteration: 14320 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 647 loss: 1.25585 acc: 0.71029 | v_loss: 1.15226 v_acc: 0.71517 |  iteration: 14321 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 648 loss: 1.21476 acc: 0.70931 | v_loss: 1.17470 v_acc: 0.70703 |  iteration: 14322 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 649 loss: 1.20058 acc: 0.72201 | v_loss: 1.02442 v_acc: 0.74056 |  iteration: 14323 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 650 loss: 1.20108 acc: 0.71810 | v_loss: 1.14228 v_acc: 0.71745 |  iteration: 14324 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 651 loss: 1.30415 acc: 0.69531 | v_loss: 1.07390 v_acc: 0.70703 |  iteration: 14325 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 652 loss: 1.18780 acc: 0.70833 | v_loss: 1.06438 v_acc: 0.72754 |  iteration: 14326 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 653 loss: 1.24313 acc: 0.70182 | v_loss: 1.14149 v_acc: 0.72331 |  iteration: 14327 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 654 loss: 1.16934 acc: 0.71680 | v_loss: 1.12159 v_acc: 0.72396 |  iteration: 14328 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 655 loss: 1.24367 acc: 0.70117 | v_loss: 1.13094 v_acc: 0.72949 |  iteration: 14329 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 656 loss: 1.14207 acc: 0.71191 | v_loss: 1.33902 v_acc: 0.70605 |  iteration: 14330 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 657 loss: 1.31469 acc: 0.69141 | v_loss: 1.23391 v_acc: 0.72070 |  iteration: 14331 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 658 loss: 1.28575 acc: 0.70508 | v_loss: 0.97468 v_acc: 0.74577 |  iteration: 14332 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 659 loss: 1.26323 acc: 0.69596 | v_loss: 1.17080 v_acc: 0.70866 |  iteration: 14333 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 660 loss: 1.16441 acc: 0.70605 | v_loss: 1.21723 v_acc: 0.70280 |  iteration: 14334 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 661 loss: 1.28753 acc: 0.70215 | v_loss: 1.13416 v_acc: 0.71126 |  iteration: 14335 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 662 loss: 1.26835 acc: 0.70020 | v_loss: 1.22604 v_acc: 0.71126 |  iteration: 14336 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 663 loss: 1.24324 acc: 0.70312 | v_loss: 1.18000 v_acc: 0.69824 |  iteration: 14337 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 664 loss: 1.26862 acc: 0.70020 | v_loss: 1.14317 v_acc: 0.71582 |  iteration: 14338 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 665 loss: 1.29417 acc: 0.70182 | v_loss: 1.19208 v_acc: 0.70540 |  iteration: 14339 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 666 loss: 1.26700 acc: 0.70833 | v_loss: 1.11358 v_acc: 0.72266 |  iteration: 14340 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 667 loss: 1.24448 acc: 0.70833 | v_loss: 1.13374 v_acc: 0.72884 |  iteration: 14341 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 668 loss: 1.21148 acc: 0.70443 | v_loss: 1.12188 v_acc: 0.71029 |  iteration: 14342 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 669 loss: 1.35285 acc: 0.69792 | v_loss: 1.28043 v_acc: 0.70215 |  iteration: 14343 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 670 loss: 1.26788 acc: 0.70345 | v_loss: 1.14018 v_acc: 0.71159 |  iteration: 14344 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 671 loss: 1.27198 acc: 0.70768 | v_loss: 1.36206 v_acc: 0.68750 |  iteration: 14345 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 672 loss: 1.19539 acc: 0.70703 | v_loss: 1.09267 v_acc: 0.72819 |  iteration: 14346 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 673 loss: 1.15045 acc: 0.71191 | v_loss: 1.42894 v_acc: 0.68327 |  iteration: 14347 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 674 loss: 1.25437 acc: 0.70833 | v_loss: 1.31360 v_acc: 0.70475 |  iteration: 14348 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 675 loss: 1.36911 acc: 0.69922 | v_loss: 1.26621 v_acc: 0.69727 |  iteration: 14349 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 676 loss: 1.20471 acc: 0.70898 | v_loss: 1.24992 v_acc: 0.70508 |  iteration: 14350 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 677 loss: 1.23138 acc: 0.70247 | v_loss: 1.15603 v_acc: 0.71387 |  iteration: 14351 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 678 loss: 1.18915 acc: 0.70801 | v_loss: 1.20125 v_acc: 0.70703 |  iteration: 14352 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 679 loss: 1.24141 acc: 0.69954 | v_loss: 1.17027 v_acc: 0.72070 |  iteration: 14353 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 680 loss: 1.20588 acc: 0.69889 | v_loss: 1.33069 v_acc: 0.68880 |  iteration: 14354 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 681 loss: 1.23798 acc: 0.70117 | v_loss: 1.23682 v_acc: 0.70996 |  iteration: 14355 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 682 loss: 1.16842 acc: 0.70898 | v_loss: 1.10591 v_acc: 0.71615 |  iteration: 14356 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 683 loss: 1.24513 acc: 0.70671 | v_loss: 1.18367 v_acc: 0.71712 |  iteration: 14357 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 684 loss: 1.33664 acc: 0.69076 | v_loss: 1.10652 v_acc: 0.70964 |  iteration: 14358 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 685 loss: 1.17895 acc: 0.69889 | v_loss: 1.23452 v_acc: 0.70508 |  iteration: 14359 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 686 loss: 1.27983 acc: 0.70410 | v_loss: 1.16784 v_acc: 0.71322 |  iteration: 14360 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 687 loss: 1.21558 acc: 0.71973 | v_loss: 1.11473 v_acc: 0.72298 |  iteration: 14361 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 688 loss: 1.18543 acc: 0.71257 | v_loss: 1.06116 v_acc: 0.73210 |  iteration: 14362 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 689 loss: 1.25318 acc: 0.70573 | v_loss: 1.21903 v_acc: 0.71712 |  iteration: 14363 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 690 loss: 1.22000 acc: 0.70378 | v_loss: 1.18145 v_acc: 0.70866 |  iteration: 14364 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 691 loss: 1.25031 acc: 0.70996 | v_loss: 1.16995 v_acc: 0.71191 |  iteration: 14365 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 692 loss: 1.18447 acc: 0.70638 | v_loss: 1.01791 v_acc: 0.72721 |  iteration: 14366 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 693 loss: 1.29759 acc: 0.70117 | v_loss: 1.17946 v_acc: 0.73535 |  iteration: 14367 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 694 loss: 1.21315 acc: 0.70182 | v_loss: 1.24148 v_acc: 0.70020 |  iteration: 14368 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 695 loss: 1.17223 acc: 0.71908 | v_loss: 1.23736 v_acc: 0.72656 |  iteration: 14369 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 696 loss: 1.21662 acc: 0.70573 | v_loss: 1.10082 v_acc: 0.72363 |  iteration: 14370 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 697 loss: 1.26475 acc: 0.69499 | v_loss: 1.08403 v_acc: 0.74186 |  iteration: 14371 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 698 loss: 1.32197 acc: 0.69434 | v_loss: 1.04703 v_acc: 0.72754 |  iteration: 14372 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 699 loss: 1.17274 acc: 0.71712 | v_loss: 1.14533 v_acc: 0.71061 |  iteration: 14373 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 700 loss: 1.23821 acc: 0.70931 | v_loss: 1.12733 v_acc: 0.70866 |  iteration: 14374 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 701 loss: 1.26894 acc: 0.70378 | v_loss: 1.10400 v_acc: 0.72201 |  iteration: 14375 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 702 loss: 1.23522 acc: 0.70833 | v_loss: 1.28328 v_acc: 0.70312 |  iteration: 14376 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 703 loss: 1.26158 acc: 0.70410 | v_loss: 1.37364 v_acc: 0.69303 |  iteration: 14377 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 704 loss: 1.29734 acc: 0.70801 | v_loss: 1.26269 v_acc: 0.70410 |  iteration: 14378 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 705 loss: 1.15097 acc: 0.70768 | v_loss: 1.13372 v_acc: 0.72493 |  iteration: 14379 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 706 loss: 1.13613 acc: 0.71289 | v_loss: 1.11395 v_acc: 0.70996 |  iteration: 14380 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 707 loss: 1.24100 acc: 0.71517 | v_loss: 1.06903 v_acc: 0.72786 |  iteration: 14381 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 708 loss: 1.17278 acc: 0.71875 | v_loss: 1.13901 v_acc: 0.71452 |  iteration: 14382 teacher: 1 stage: sketch lr: 0.000369\n",
      "batch 709 loss: 1.22638 acc: 0.70866 | v_loss: 1.18219 v_acc: 0.72721 |  iteration: 14383 teacher: 0 stage: sketch lr: 0.000369\n",
      "batch 710 loss: 1.27778 acc: 0.70215 | v_loss: 1.15947 v_acc: 0.73047 |  iteration: 14384 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 711 loss: 1.14608 acc: 0.70964 | v_loss: 1.18715 v_acc: 0.72624 |  iteration: 14385 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 712 loss: 1.24116 acc: 0.71061 | v_loss: 1.17788 v_acc: 0.71419 |  iteration: 14386 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 713 loss: 1.27924 acc: 0.70605 | v_loss: 1.10068 v_acc: 0.72819 |  iteration: 14387 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 714 loss: 1.12466 acc: 0.71908 | v_loss: 1.05531 v_acc: 0.72331 |  iteration: 14388 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 715 loss: 1.32695 acc: 0.70345 | v_loss: 1.43162 v_acc: 0.69173 |  iteration: 14389 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 716 loss: 1.19208 acc: 0.71224 | v_loss: 1.16334 v_acc: 0.71191 |  iteration: 14390 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 717 loss: 1.32657 acc: 0.69954 | v_loss: 1.16636 v_acc: 0.71712 |  iteration: 14391 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 718 loss: 1.24792 acc: 0.69889 | v_loss: 1.16778 v_acc: 0.71582 |  iteration: 14392 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 719 loss: 1.22115 acc: 0.70996 | v_loss: 1.21591 v_acc: 0.70508 |  iteration: 14393 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 720 loss: 1.18515 acc: 0.70182 | v_loss: 1.10615 v_acc: 0.73307 |  iteration: 14394 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 721 loss: 1.21536 acc: 0.71517 | v_loss: 1.28196 v_acc: 0.71647 |  iteration: 14395 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 722 loss: 1.17372 acc: 0.70280 | v_loss: 1.11182 v_acc: 0.69987 |  iteration: 14396 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 723 loss: 1.13898 acc: 0.71582 | v_loss: 1.13069 v_acc: 0.70605 |  iteration: 14397 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 724 loss: 1.19367 acc: 0.70736 | v_loss: 1.22633 v_acc: 0.70508 |  iteration: 14398 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 725 loss: 1.29119 acc: 0.70866 | v_loss: 1.18540 v_acc: 0.70182 |  iteration: 14399 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 726 loss: 1.21986 acc: 0.70215 | v_loss: 1.28000 v_acc: 0.69857 |  iteration: 14400 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 727 loss: 1.24364 acc: 0.70410 | v_loss: 1.32318 v_acc: 0.71289 |  iteration: 14401 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 728 loss: 1.25601 acc: 0.70150 | v_loss: 1.21575 v_acc: 0.70508 |  iteration: 14402 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 729 loss: 1.21423 acc: 0.70475 | v_loss: 1.11796 v_acc: 0.71810 |  iteration: 14403 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 730 loss: 1.15594 acc: 0.69694 | v_loss: 1.23912 v_acc: 0.70996 |  iteration: 14404 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 731 loss: 1.21340 acc: 0.71517 | v_loss: 1.15748 v_acc: 0.72103 |  iteration: 14405 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 732 loss: 1.22749 acc: 0.70964 | v_loss: 1.07977 v_acc: 0.72689 |  iteration: 14406 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 733 loss: 1.22884 acc: 0.70801 | v_loss: 1.07560 v_acc: 0.71126 |  iteration: 14407 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 734 loss: 1.19879 acc: 0.71875 | v_loss: 1.21789 v_acc: 0.70703 |  iteration: 14408 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 735 loss: 1.19957 acc: 0.70671 | v_loss: 1.22789 v_acc: 0.69792 |  iteration: 14409 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 736 loss: 1.28898 acc: 0.70540 | v_loss: 1.07169 v_acc: 0.71810 |  iteration: 14410 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 737 loss: 1.27501 acc: 0.71191 | v_loss: 1.16612 v_acc: 0.69857 |  iteration: 14411 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 738 loss: 1.27622 acc: 0.70182 | v_loss: 1.12805 v_acc: 0.71387 |  iteration: 14412 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 739 loss: 1.26859 acc: 0.70378 | v_loss: 1.13261 v_acc: 0.70801 |  iteration: 14413 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 740 loss: 1.25322 acc: 0.70182 | v_loss: 1.04433 v_acc: 0.73730 |  iteration: 14414 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 741 loss: 1.33493 acc: 0.69661 | v_loss: 1.13993 v_acc: 0.71842 |  iteration: 14415 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 742 loss: 1.31347 acc: 0.68294 | v_loss: 1.08072 v_acc: 0.72786 |  iteration: 14416 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 743 loss: 1.33768 acc: 0.69629 | v_loss: 1.08288 v_acc: 0.72363 |  iteration: 14417 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 744 loss: 1.29508 acc: 0.70410 | v_loss: 1.15691 v_acc: 0.71777 |  iteration: 14418 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 745 loss: 1.24854 acc: 0.71191 | v_loss: 1.21718 v_acc: 0.71484 |  iteration: 14419 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 746 loss: 1.33933 acc: 0.69531 | v_loss: 1.21160 v_acc: 0.72103 |  iteration: 14420 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 747 loss: 1.28134 acc: 0.70150 | v_loss: 1.37588 v_acc: 0.69889 |  iteration: 14421 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 748 loss: 1.32370 acc: 0.69303 | v_loss: 1.26696 v_acc: 0.72038 |  iteration: 14422 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 749 loss: 1.29578 acc: 0.69889 | v_loss: 1.02661 v_acc: 0.74349 |  iteration: 14423 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 750 loss: 1.15573 acc: 0.71029 | v_loss: 1.14960 v_acc: 0.70833 |  iteration: 14424 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 751 loss: 1.29480 acc: 0.70996 | v_loss: 1.25074 v_acc: 0.69792 |  iteration: 14425 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 752 loss: 1.22046 acc: 0.71224 | v_loss: 1.13014 v_acc: 0.69792 |  iteration: 14426 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 753 loss: 1.29353 acc: 0.70150 | v_loss: 1.19956 v_acc: 0.70801 |  iteration: 14427 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 754 loss: 1.27518 acc: 0.71452 | v_loss: 1.22124 v_acc: 0.69141 |  iteration: 14428 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 755 loss: 1.22312 acc: 0.70475 | v_loss: 1.15861 v_acc: 0.71712 |  iteration: 14429 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 756 loss: 1.29656 acc: 0.71126 | v_loss: 1.19801 v_acc: 0.70280 |  iteration: 14430 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 757 loss: 1.29045 acc: 0.69499 | v_loss: 1.14110 v_acc: 0.71940 |  iteration: 14431 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 758 loss: 1.20731 acc: 0.70475 | v_loss: 1.12885 v_acc: 0.72786 |  iteration: 14432 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 759 loss: 1.25429 acc: 0.70671 | v_loss: 1.14168 v_acc: 0.70410 |  iteration: 14433 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 760 loss: 1.22706 acc: 0.70378 | v_loss: 1.28342 v_acc: 0.70020 |  iteration: 14434 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 761 loss: 1.25293 acc: 0.70768 | v_loss: 1.12548 v_acc: 0.70996 |  iteration: 14435 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 762 loss: 1.16887 acc: 0.71875 | v_loss: 1.33017 v_acc: 0.68815 |  iteration: 14436 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 763 loss: 1.17323 acc: 0.72135 | v_loss: 1.11776 v_acc: 0.72493 |  iteration: 14437 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 764 loss: 1.31353 acc: 0.70117 | v_loss: 1.41602 v_acc: 0.68978 |  iteration: 14438 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 765 loss: 1.22857 acc: 0.70833 | v_loss: 1.27238 v_acc: 0.70605 |  iteration: 14439 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 766 loss: 1.20346 acc: 0.70605 | v_loss: 1.28949 v_acc: 0.69434 |  iteration: 14440 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 767 loss: 1.25840 acc: 0.70280 | v_loss: 1.24605 v_acc: 0.69987 |  iteration: 14441 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 768 loss: 1.25173 acc: 0.70443 | v_loss: 1.15339 v_acc: 0.70736 |  iteration: 14442 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 769 loss: 1.19445 acc: 0.71257 | v_loss: 1.20708 v_acc: 0.70312 |  iteration: 14443 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 770 loss: 1.24592 acc: 0.70703 | v_loss: 1.16712 v_acc: 0.71875 |  iteration: 14444 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 771 loss: 1.25779 acc: 0.70475 | v_loss: 1.39048 v_acc: 0.69108 |  iteration: 14445 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 772 loss: 1.25985 acc: 0.70508 | v_loss: 1.24064 v_acc: 0.71549 |  iteration: 14446 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 773 loss: 1.33688 acc: 0.69759 | v_loss: 1.14811 v_acc: 0.71387 |  iteration: 14447 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 774 loss: 1.23618 acc: 0.70931 | v_loss: 1.20145 v_acc: 0.71875 |  iteration: 14448 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 775 loss: 1.25078 acc: 0.70312 | v_loss: 1.09028 v_acc: 0.71257 |  iteration: 14449 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 776 loss: 1.20590 acc: 0.70410 | v_loss: 1.20673 v_acc: 0.70215 |  iteration: 14450 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 777 loss: 1.21999 acc: 0.70378 | v_loss: 1.20006 v_acc: 0.71810 |  iteration: 14451 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 778 loss: 1.31850 acc: 0.69564 | v_loss: 1.09461 v_acc: 0.71908 |  iteration: 14452 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 779 loss: 1.18869 acc: 0.70443 | v_loss: 1.08571 v_acc: 0.73079 |  iteration: 14453 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 780 loss: 1.25954 acc: 0.70215 | v_loss: 1.21558 v_acc: 0.71745 |  iteration: 14454 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 781 loss: 1.22932 acc: 0.70508 | v_loss: 1.21225 v_acc: 0.70475 |  iteration: 14455 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 782 loss: 1.23224 acc: 0.71191 | v_loss: 1.20046 v_acc: 0.71224 |  iteration: 14456 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 783 loss: 1.25823 acc: 0.70638 | v_loss: 1.04278 v_acc: 0.72591 |  iteration: 14457 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 784 loss: 1.24993 acc: 0.70898 | v_loss: 1.21143 v_acc: 0.73405 |  iteration: 14458 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 785 loss: 1.29846 acc: 0.68815 | v_loss: 1.28334 v_acc: 0.69792 |  iteration: 14459 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 786 loss: 1.21366 acc: 0.70801 | v_loss: 1.23600 v_acc: 0.72559 |  iteration: 14460 teacher: 0 stage: sketch lr: 0.000368\n",
      "batch 787 loss: 1.25689 acc: 0.70931 | v_loss: 1.09318 v_acc: 0.72461 |  iteration: 14461 teacher: 1 stage: sketch lr: 0.000368\n",
      "batch 788 loss: 1.27725 acc: 0.70345 | v_loss: 1.05979 v_acc: 0.73763 |  iteration: 14462 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 789 loss: 1.17328 acc: 0.71061 | v_loss: 1.07228 v_acc: 0.72721 |  iteration: 14463 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 790 loss: 1.24741 acc: 0.70736 | v_loss: 1.15414 v_acc: 0.71094 |  iteration: 14464 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 791 loss: 1.30761 acc: 0.70410 | v_loss: 1.20348 v_acc: 0.70605 |  iteration: 14465 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 792 loss: 1.28412 acc: 0.71094 | v_loss: 1.12632 v_acc: 0.72070 |  iteration: 14466 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 793 loss: 1.28211 acc: 0.71224 | v_loss: 1.26849 v_acc: 0.70345 |  iteration: 14467 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 794 loss: 1.19750 acc: 0.71159 | v_loss: 1.43249 v_acc: 0.69401 |  iteration: 14468 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 795 loss: 1.24655 acc: 0.71159 | v_loss: 1.33280 v_acc: 0.69954 |  iteration: 14469 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 796 loss: 1.24338 acc: 0.70052 | v_loss: 1.13504 v_acc: 0.72233 |  iteration: 14470 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 797 loss: 1.31991 acc: 0.70182 | v_loss: 1.12411 v_acc: 0.71419 |  iteration: 14471 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 798 loss: 1.27264 acc: 0.69954 | v_loss: 1.09130 v_acc: 0.72493 |  iteration: 14472 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 799 loss: 1.20558 acc: 0.70312 | v_loss: 1.16962 v_acc: 0.71061 |  iteration: 14473 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 800 loss: 1.18655 acc: 0.70833 | v_loss: 1.20606 v_acc: 0.72493 |  iteration: 14474 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 801 loss: 1.24587 acc: 0.70052 | v_loss: 1.16001 v_acc: 0.73210 |  iteration: 14475 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 802 loss: 1.23498 acc: 0.70117 | v_loss: 1.20441 v_acc: 0.71973 |  iteration: 14476 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 803 loss: 1.42501 acc: 0.68457 | v_loss: 1.19197 v_acc: 0.71745 |  iteration: 14477 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 804 loss: 1.26808 acc: 0.70866 | v_loss: 1.08827 v_acc: 0.72982 |  iteration: 14478 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 805 loss: 1.33194 acc: 0.69401 | v_loss: 1.07583 v_acc: 0.72168 |  iteration: 14479 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 806 loss: 1.20270 acc: 0.70703 | v_loss: 1.38507 v_acc: 0.69303 |  iteration: 14480 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 807 loss: 1.30111 acc: 0.70540 | v_loss: 1.15832 v_acc: 0.71061 |  iteration: 14481 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 808 loss: 1.18403 acc: 0.71647 | v_loss: 1.15624 v_acc: 0.72331 |  iteration: 14482 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 809 loss: 1.26645 acc: 0.69889 | v_loss: 1.15515 v_acc: 0.71517 |  iteration: 14483 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 810 loss: 1.14784 acc: 0.70638 | v_loss: 1.19187 v_acc: 0.71126 |  iteration: 14484 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 811 loss: 1.23045 acc: 0.70703 | v_loss: 1.11791 v_acc: 0.73340 |  iteration: 14485 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 812 loss: 1.28490 acc: 0.70020 | v_loss: 1.30208 v_acc: 0.71354 |  iteration: 14486 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 813 loss: 1.23310 acc: 0.70378 | v_loss: 1.11932 v_acc: 0.69922 |  iteration: 14487 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 814 loss: 1.32951 acc: 0.69531 | v_loss: 1.14687 v_acc: 0.70378 |  iteration: 14488 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 815 loss: 1.22718 acc: 0.71126 | v_loss: 1.25544 v_acc: 0.70312 |  iteration: 14489 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 816 loss: 1.22590 acc: 0.70866 | v_loss: 1.21150 v_acc: 0.70671 |  iteration: 14490 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 817 loss: 1.22219 acc: 0.70605 | v_loss: 1.28816 v_acc: 0.69010 |  iteration: 14491 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 818 loss: 1.16302 acc: 0.71582 | v_loss: 1.31135 v_acc: 0.70964 |  iteration: 14492 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 819 loss: 1.27645 acc: 0.70378 | v_loss: 1.23911 v_acc: 0.70410 |  iteration: 14493 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 820 loss: 1.25829 acc: 0.70605 | v_loss: 1.10394 v_acc: 0.71517 |  iteration: 14494 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 821 loss: 1.28232 acc: 0.70378 | v_loss: 1.26104 v_acc: 0.70833 |  iteration: 14495 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 822 loss: 1.22229 acc: 0.71159 | v_loss: 1.15612 v_acc: 0.72135 |  iteration: 14496 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 823 loss: 1.22180 acc: 0.70898 | v_loss: 1.09154 v_acc: 0.72852 |  iteration: 14497 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 824 loss: 1.35515 acc: 0.69792 | v_loss: 1.06182 v_acc: 0.71257 |  iteration: 14498 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 825 loss: 1.25763 acc: 0.69987 | v_loss: 1.17335 v_acc: 0.70768 |  iteration: 14499 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 826 loss: 1.23917 acc: 0.70605 | v_loss: 1.30650 v_acc: 0.69661 |  iteration: 14500 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 827 loss: 1.19262 acc: 0.71126 | v_loss: 1.13439 v_acc: 0.71257 |  iteration: 14501 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 828 loss: 1.24464 acc: 0.70085 | v_loss: 1.17127 v_acc: 0.70215 |  iteration: 14502 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 829 loss: 1.28340 acc: 0.70345 | v_loss: 1.11118 v_acc: 0.71484 |  iteration: 14503 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 830 loss: 1.26944 acc: 0.71029 | v_loss: 1.13367 v_acc: 0.70703 |  iteration: 14504 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 831 loss: 1.25616 acc: 0.71224 | v_loss: 1.03568 v_acc: 0.74349 |  iteration: 14505 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 832 loss: 1.17229 acc: 0.71061 | v_loss: 1.11126 v_acc: 0.72168 |  iteration: 14506 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 833 loss: 1.32915 acc: 0.69499 | v_loss: 1.06292 v_acc: 0.70931 |  iteration: 14507 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 834 loss: 1.18054 acc: 0.70671 | v_loss: 1.06695 v_acc: 0.72917 |  iteration: 14508 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 835 loss: 1.25735 acc: 0.70508 | v_loss: 1.12911 v_acc: 0.71745 |  iteration: 14509 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 836 loss: 1.26094 acc: 0.69792 | v_loss: 1.12243 v_acc: 0.72070 |  iteration: 14510 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 837 loss: 1.27254 acc: 0.69987 | v_loss: 1.12168 v_acc: 0.72884 |  iteration: 14511 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 838 loss: 1.18878 acc: 0.70703 | v_loss: 1.32829 v_acc: 0.70540 |  iteration: 14512 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 839 loss: 1.19321 acc: 0.70117 | v_loss: 1.23773 v_acc: 0.71875 |  iteration: 14513 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 840 loss: 1.19188 acc: 0.70508 | v_loss: 0.98436 v_acc: 0.74479 |  iteration: 14514 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 841 loss: 1.24502 acc: 0.70508 | v_loss: 1.15148 v_acc: 0.70573 |  iteration: 14515 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 842 loss: 1.23370 acc: 0.70280 | v_loss: 1.18429 v_acc: 0.70540 |  iteration: 14516 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 843 loss: 1.22483 acc: 0.70801 | v_loss: 1.15469 v_acc: 0.70085 |  iteration: 14517 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 844 loss: 1.21379 acc: 0.70931 | v_loss: 1.14952 v_acc: 0.71029 |  iteration: 14518 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 845 loss: 1.27441 acc: 0.70020 | v_loss: 1.15584 v_acc: 0.70020 |  iteration: 14519 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 846 loss: 1.17116 acc: 0.70768 | v_loss: 1.12407 v_acc: 0.71549 |  iteration: 14520 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 847 loss: 1.27114 acc: 0.69987 | v_loss: 1.15133 v_acc: 0.70378 |  iteration: 14521 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 848 loss: 1.23242 acc: 0.69824 | v_loss: 1.13716 v_acc: 0.71712 |  iteration: 14522 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 849 loss: 1.17778 acc: 0.70475 | v_loss: 1.12382 v_acc: 0.72428 |  iteration: 14523 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 850 loss: 1.27547 acc: 0.70410 | v_loss: 1.10889 v_acc: 0.70671 |  iteration: 14524 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 851 loss: 1.18853 acc: 0.71126 | v_loss: 1.22148 v_acc: 0.70573 |  iteration: 14525 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 852 loss: 1.18866 acc: 0.70638 | v_loss: 1.08014 v_acc: 0.71647 |  iteration: 14526 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 853 loss: 1.24336 acc: 0.70378 | v_loss: 1.33325 v_acc: 0.68359 |  iteration: 14527 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 854 loss: 1.16161 acc: 0.71257 | v_loss: 1.05384 v_acc: 0.72819 |  iteration: 14528 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 855 loss: 1.12545 acc: 0.70736 | v_loss: 1.40588 v_acc: 0.68490 |  iteration: 14529 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 856 loss: 1.18295 acc: 0.70378 | v_loss: 1.25959 v_acc: 0.69889 |  iteration: 14530 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 857 loss: 1.16985 acc: 0.71289 | v_loss: 1.23242 v_acc: 0.70052 |  iteration: 14531 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 858 loss: 1.26447 acc: 0.69727 | v_loss: 1.20441 v_acc: 0.70378 |  iteration: 14532 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 859 loss: 1.26495 acc: 0.70182 | v_loss: 1.10754 v_acc: 0.71289 |  iteration: 14533 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 860 loss: 1.13486 acc: 0.71061 | v_loss: 1.15441 v_acc: 0.71126 |  iteration: 14534 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 861 loss: 1.22318 acc: 0.70312 | v_loss: 1.12369 v_acc: 0.72493 |  iteration: 14535 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 862 loss: 1.20840 acc: 0.70605 | v_loss: 1.32337 v_acc: 0.69076 |  iteration: 14536 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 863 loss: 1.27678 acc: 0.70833 | v_loss: 1.19018 v_acc: 0.71419 |  iteration: 14537 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 864 loss: 1.16106 acc: 0.71484 | v_loss: 1.10757 v_acc: 0.71126 |  iteration: 14538 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 865 loss: 1.29289 acc: 0.69922 | v_loss: 1.17121 v_acc: 0.71973 |  iteration: 14539 teacher: 1 stage: sketch lr: 0.000367\n",
      "batch 866 loss: 1.24322 acc: 0.70345 | v_loss: 1.08846 v_acc: 0.71224 |  iteration: 14540 teacher: 0 stage: sketch lr: 0.000367\n",
      "batch 867 loss: 1.17295 acc: 0.71647 | v_loss: 1.20564 v_acc: 0.70150 |  iteration: 14541 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 868 loss: 1.15973 acc: 0.70801 | v_loss: 1.15898 v_acc: 0.71777 |  iteration: 14542 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 869 loss: 1.15437 acc: 0.70703 | v_loss: 1.05441 v_acc: 0.72526 |  iteration: 14543 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 870 loss: 1.18625 acc: 0.70312 | v_loss: 1.02508 v_acc: 0.72982 |  iteration: 14544 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 871 loss: 1.20726 acc: 0.70475 | v_loss: 1.18770 v_acc: 0.71549 |  iteration: 14545 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 872 loss: 1.16968 acc: 0.70736 | v_loss: 1.17190 v_acc: 0.70703 |  iteration: 14546 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 873 loss: 1.10933 acc: 0.72624 | v_loss: 1.14650 v_acc: 0.71094 |  iteration: 14547 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 874 loss: 1.22502 acc: 0.71419 | v_loss: 0.98428 v_acc: 0.72526 |  iteration: 14548 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 875 loss: 1.25827 acc: 0.70378 | v_loss: 1.19061 v_acc: 0.73177 |  iteration: 14549 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 876 loss: 1.16323 acc: 0.71354 | v_loss: 1.22798 v_acc: 0.70052 |  iteration: 14550 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 877 loss: 1.23011 acc: 0.70768 | v_loss: 1.20924 v_acc: 0.72298 |  iteration: 14551 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 878 loss: 1.16131 acc: 0.71289 | v_loss: 1.04363 v_acc: 0.72363 |  iteration: 14552 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 879 loss: 1.14384 acc: 0.71191 | v_loss: 1.02582 v_acc: 0.73861 |  iteration: 14553 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 880 loss: 1.31928 acc: 0.70247 | v_loss: 1.00056 v_acc: 0.72559 |  iteration: 14554 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 881 loss: 1.20846 acc: 0.70671 | v_loss: 1.10098 v_acc: 0.71615 |  iteration: 14555 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 882 loss: 1.25582 acc: 0.70280 | v_loss: 1.09353 v_acc: 0.71452 |  iteration: 14556 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 883 loss: 1.26199 acc: 0.70020 | v_loss: 1.10999 v_acc: 0.70996 |  iteration: 14557 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 884 loss: 1.11269 acc: 0.71680 | v_loss: 1.27580 v_acc: 0.70182 |  iteration: 14558 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 885 loss: 1.26902 acc: 0.70508 | v_loss: 1.38816 v_acc: 0.69792 |  iteration: 14559 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 886 loss: 1.18901 acc: 0.71549 | v_loss: 1.28920 v_acc: 0.69759 |  iteration: 14560 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 887 loss: 1.29756 acc: 0.68424 | v_loss: 1.14291 v_acc: 0.72526 |  iteration: 14561 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 888 loss: 1.21718 acc: 0.70117 | v_loss: 1.10470 v_acc: 0.71029 |  iteration: 14562 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 889 loss: 1.14046 acc: 0.71875 | v_loss: 1.05421 v_acc: 0.72689 |  iteration: 14563 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 890 loss: 1.26890 acc: 0.69824 | v_loss: 1.13464 v_acc: 0.70540 |  iteration: 14564 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 891 loss: 1.24545 acc: 0.69792 | v_loss: 1.16359 v_acc: 0.71615 |  iteration: 14565 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 892 loss: 1.21543 acc: 0.70443 | v_loss: 1.14301 v_acc: 0.73047 |  iteration: 14566 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 893 loss: 1.21174 acc: 0.70475 | v_loss: 1.18145 v_acc: 0.72266 |  iteration: 14567 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 894 loss: 1.13438 acc: 0.71224 | v_loss: 1.12996 v_acc: 0.71289 |  iteration: 14568 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 895 loss: 1.23345 acc: 0.71940 | v_loss: 1.06437 v_acc: 0.72982 |  iteration: 14569 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 896 loss: 1.25265 acc: 0.69759 | v_loss: 1.03793 v_acc: 0.72461 |  iteration: 14570 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 897 loss: 1.21027 acc: 0.70312 | v_loss: 1.42827 v_acc: 0.69206 |  iteration: 14571 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 898 loss: 1.28403 acc: 0.69043 | v_loss: 1.11493 v_acc: 0.71257 |  iteration: 14572 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 899 loss: 1.22443 acc: 0.70020 | v_loss: 1.11342 v_acc: 0.72266 |  iteration: 14573 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 900 loss: 1.24975 acc: 0.70833 | v_loss: 1.19714 v_acc: 0.70410 |  iteration: 14574 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 901 loss: 1.22585 acc: 0.70866 | v_loss: 1.18304 v_acc: 0.70150 |  iteration: 14575 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 902 loss: 1.19166 acc: 0.70605 | v_loss: 1.07431 v_acc: 0.73665 |  iteration: 14576 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 903 loss: 1.11059 acc: 0.72201 | v_loss: 1.25451 v_acc: 0.71257 |  iteration: 14577 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 904 loss: 1.16749 acc: 0.71875 | v_loss: 1.09366 v_acc: 0.70312 |  iteration: 14578 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 905 loss: 1.18010 acc: 0.70833 | v_loss: 1.12451 v_acc: 0.70736 |  iteration: 14579 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 906 loss: 1.14657 acc: 0.71191 | v_loss: 1.22761 v_acc: 0.70540 |  iteration: 14580 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 907 loss: 1.20225 acc: 0.71061 | v_loss: 1.17367 v_acc: 0.70996 |  iteration: 14581 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 908 loss: 1.14401 acc: 0.71582 | v_loss: 1.27437 v_acc: 0.69368 |  iteration: 14582 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 909 loss: 1.14248 acc: 0.71061 | v_loss: 1.31562 v_acc: 0.70768 |  iteration: 14583 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 910 loss: 1.12914 acc: 0.71842 | v_loss: 1.19508 v_acc: 0.70443 |  iteration: 14584 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 911 loss: 1.20355 acc: 0.71549 | v_loss: 1.09687 v_acc: 0.71940 |  iteration: 14585 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 912 loss: 1.26586 acc: 0.71224 | v_loss: 1.21476 v_acc: 0.70898 |  iteration: 14586 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 913 loss: 1.26666 acc: 0.69727 | v_loss: 1.11258 v_acc: 0.72298 |  iteration: 14587 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 914 loss: 1.18761 acc: 0.70540 | v_loss: 1.02850 v_acc: 0.73145 |  iteration: 14588 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 915 loss: 1.25761 acc: 0.70703 | v_loss: 1.03500 v_acc: 0.71419 |  iteration: 14589 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 916 loss: 1.32093 acc: 0.70150 | v_loss: 1.16918 v_acc: 0.71224 |  iteration: 14590 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 917 loss: 1.26941 acc: 0.70508 | v_loss: 1.19380 v_acc: 0.70150 |  iteration: 14591 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 918 loss: 1.21611 acc: 0.70410 | v_loss: 1.05671 v_acc: 0.72070 |  iteration: 14592 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 919 loss: 1.13489 acc: 0.71061 | v_loss: 1.12408 v_acc: 0.70182 |  iteration: 14593 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 920 loss: 1.30296 acc: 0.69303 | v_loss: 1.09293 v_acc: 0.71224 |  iteration: 14594 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 921 loss: 1.23496 acc: 0.70475 | v_loss: 1.11025 v_acc: 0.71061 |  iteration: 14595 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 922 loss: 1.13668 acc: 0.71094 | v_loss: 1.00278 v_acc: 0.74382 |  iteration: 14596 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 923 loss: 1.17408 acc: 0.71126 | v_loss: 1.13570 v_acc: 0.71777 |  iteration: 14597 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 924 loss: 1.25071 acc: 0.69987 | v_loss: 1.03380 v_acc: 0.72428 |  iteration: 14598 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 925 loss: 1.12483 acc: 0.71419 | v_loss: 1.02262 v_acc: 0.72754 |  iteration: 14599 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 926 loss: 1.21949 acc: 0.69922 | v_loss: 1.12212 v_acc: 0.71810 |  iteration: 14600 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 927 loss: 1.18552 acc: 0.71094 | v_loss: 1.08583 v_acc: 0.72428 |  iteration: 14601 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 928 loss: 1.23401 acc: 0.70280 | v_loss: 1.09648 v_acc: 0.73177 |  iteration: 14602 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 929 loss: 1.27154 acc: 0.69922 | v_loss: 1.29910 v_acc: 0.70833 |  iteration: 14603 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 930 loss: 1.18765 acc: 0.71029 | v_loss: 1.21557 v_acc: 0.72396 |  iteration: 14604 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 931 loss: 1.24585 acc: 0.69954 | v_loss: 0.95597 v_acc: 0.75098 |  iteration: 14605 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 932 loss: 1.20360 acc: 0.70052 | v_loss: 1.13149 v_acc: 0.71029 |  iteration: 14606 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 933 loss: 1.17427 acc: 0.70540 | v_loss: 1.14895 v_acc: 0.70410 |  iteration: 14607 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 934 loss: 1.23184 acc: 0.70150 | v_loss: 1.09523 v_acc: 0.70085 |  iteration: 14608 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 935 loss: 1.19814 acc: 0.71094 | v_loss: 1.16249 v_acc: 0.71061 |  iteration: 14609 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 936 loss: 1.22869 acc: 0.70020 | v_loss: 1.14497 v_acc: 0.69564 |  iteration: 14610 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 937 loss: 1.22190 acc: 0.71322 | v_loss: 1.11724 v_acc: 0.72005 |  iteration: 14611 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 938 loss: 1.25914 acc: 0.69759 | v_loss: 1.14800 v_acc: 0.70833 |  iteration: 14612 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 939 loss: 1.19361 acc: 0.70508 | v_loss: 1.11330 v_acc: 0.72428 |  iteration: 14613 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 940 loss: 1.23252 acc: 0.70638 | v_loss: 1.08354 v_acc: 0.73210 |  iteration: 14614 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 941 loss: 1.26595 acc: 0.69954 | v_loss: 1.10413 v_acc: 0.70931 |  iteration: 14615 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 942 loss: 1.23523 acc: 0.70378 | v_loss: 1.21315 v_acc: 0.69727 |  iteration: 14616 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 943 loss: 1.19343 acc: 0.70638 | v_loss: 1.08522 v_acc: 0.71029 |  iteration: 14617 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 944 loss: 1.19495 acc: 0.71517 | v_loss: 1.31636 v_acc: 0.68587 |  iteration: 14618 teacher: 1 stage: sketch lr: 0.000366\n",
      "batch 945 loss: 1.22995 acc: 0.70605 | v_loss: 1.09248 v_acc: 0.72721 |  iteration: 14619 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 946 loss: 1.25345 acc: 0.69466 | v_loss: 1.40658 v_acc: 0.68457 |  iteration: 14620 teacher: 0 stage: sketch lr: 0.000366\n",
      "batch 947 loss: 1.25799 acc: 0.70605 | v_loss: 1.25223 v_acc: 0.70247 |  iteration: 14621 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 948 loss: 1.17075 acc: 0.70573 | v_loss: 1.24509 v_acc: 0.69857 |  iteration: 14622 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 949 loss: 1.21448 acc: 0.70898 | v_loss: 1.18636 v_acc: 0.70475 |  iteration: 14623 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 950 loss: 1.30550 acc: 0.69466 | v_loss: 1.11549 v_acc: 0.71191 |  iteration: 14624 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 951 loss: 1.21646 acc: 0.70443 | v_loss: 1.17253 v_acc: 0.71159 |  iteration: 14625 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 952 loss: 1.20508 acc: 0.70866 | v_loss: 1.13752 v_acc: 0.72689 |  iteration: 14626 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 953 loss: 1.17095 acc: 0.71094 | v_loss: 1.30346 v_acc: 0.69206 |  iteration: 14627 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 954 loss: 1.19205 acc: 0.70736 | v_loss: 1.22301 v_acc: 0.71419 |  iteration: 14628 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 955 loss: 1.24326 acc: 0.70475 | v_loss: 1.08955 v_acc: 0.71387 |  iteration: 14629 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 956 loss: 1.19154 acc: 0.70833 | v_loss: 1.16420 v_acc: 0.71973 |  iteration: 14630 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 957 loss: 1.11768 acc: 0.72363 | v_loss: 1.05314 v_acc: 0.71257 |  iteration: 14631 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 958 loss: 1.17354 acc: 0.70866 | v_loss: 1.16899 v_acc: 0.70085 |  iteration: 14632 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 959 loss: 1.24433 acc: 0.70312 | v_loss: 1.14009 v_acc: 0.72070 |  iteration: 14633 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 960 loss: 1.34071 acc: 0.69564 | v_loss: 1.06585 v_acc: 0.71777 |  iteration: 14634 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 961 loss: 1.18344 acc: 0.71224 | v_loss: 1.05080 v_acc: 0.72949 |  iteration: 14635 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 962 loss: 1.20872 acc: 0.71224 | v_loss: 1.19946 v_acc: 0.71680 |  iteration: 14636 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 963 loss: 1.19856 acc: 0.70866 | v_loss: 1.16667 v_acc: 0.70768 |  iteration: 14637 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 964 loss: 1.27855 acc: 0.69889 | v_loss: 1.15037 v_acc: 0.71289 |  iteration: 14638 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 965 loss: 1.24197 acc: 0.69889 | v_loss: 1.00294 v_acc: 0.72754 |  iteration: 14639 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 966 loss: 1.23027 acc: 0.70964 | v_loss: 1.18925 v_acc: 0.73568 |  iteration: 14640 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 967 loss: 1.19464 acc: 0.70378 | v_loss: 1.21738 v_acc: 0.70410 |  iteration: 14641 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 968 loss: 1.19781 acc: 0.69954 | v_loss: 1.18323 v_acc: 0.72786 |  iteration: 14642 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 969 loss: 1.15986 acc: 0.70312 | v_loss: 1.05089 v_acc: 0.72103 |  iteration: 14643 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 970 loss: 1.16501 acc: 0.71257 | v_loss: 1.05077 v_acc: 0.73633 |  iteration: 14644 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 971 loss: 1.16559 acc: 0.70443 | v_loss: 1.01553 v_acc: 0.73079 |  iteration: 14645 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 972 loss: 1.18009 acc: 0.70475 | v_loss: 1.11192 v_acc: 0.71159 |  iteration: 14646 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 973 loss: 1.19349 acc: 0.69792 | v_loss: 1.11981 v_acc: 0.71191 |  iteration: 14647 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 974 loss: 1.20898 acc: 0.71126 | v_loss: 1.13004 v_acc: 0.71810 |  iteration: 14648 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 975 loss: 1.20902 acc: 0.70475 | v_loss: 1.23925 v_acc: 0.69824 |  iteration: 14649 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 976 loss: 1.22635 acc: 0.69922 | v_loss: 1.37984 v_acc: 0.69889 |  iteration: 14650 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 977 loss: 1.14093 acc: 0.70801 | v_loss: 1.29178 v_acc: 0.69987 |  iteration: 14651 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 978 loss: 1.16021 acc: 0.71289 | v_loss: 1.11556 v_acc: 0.72201 |  iteration: 14652 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 979 loss: 1.20864 acc: 0.70508 | v_loss: 1.08781 v_acc: 0.71484 |  iteration: 14653 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 980 loss: 1.22127 acc: 0.69531 | v_loss: 1.04266 v_acc: 0.72721 |  iteration: 14654 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 981 loss: 1.22775 acc: 0.69434 | v_loss: 1.11182 v_acc: 0.71257 |  iteration: 14655 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 982 loss: 1.16963 acc: 0.69857 | v_loss: 1.16535 v_acc: 0.71973 |  iteration: 14656 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 983 loss: 1.18849 acc: 0.70638 | v_loss: 1.14736 v_acc: 0.73470 |  iteration: 14657 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 984 loss: 1.33856 acc: 0.69857 | v_loss: 1.19028 v_acc: 0.71973 |  iteration: 14658 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 985 loss: 1.16390 acc: 0.71061 | v_loss: 1.11250 v_acc: 0.70801 |  iteration: 14659 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 986 loss: 1.17533 acc: 0.70736 | v_loss: 1.12379 v_acc: 0.72493 |  iteration: 14660 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 987 loss: 1.19259 acc: 0.69596 | v_loss: 1.07114 v_acc: 0.72201 |  iteration: 14661 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 988 loss: 1.15562 acc: 0.70020 | v_loss: 1.44725 v_acc: 0.68913 |  iteration: 14662 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 989 loss: 1.13898 acc: 0.70931 | v_loss: 1.11776 v_acc: 0.71582 |  iteration: 14663 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 990 loss: 1.16442 acc: 0.72038 | v_loss: 1.14285 v_acc: 0.71582 |  iteration: 14664 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 991 loss: 1.21277 acc: 0.69727 | v_loss: 1.18556 v_acc: 0.70085 |  iteration: 14665 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 992 loss: 1.25883 acc: 0.70996 | v_loss: 1.18318 v_acc: 0.69727 |  iteration: 14666 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 993 loss: 1.31516 acc: 0.69954 | v_loss: 1.06821 v_acc: 0.73828 |  iteration: 14667 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 994 loss: 1.20034 acc: 0.70996 | v_loss: 1.26235 v_acc: 0.71875 |  iteration: 14668 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 995 loss: 1.26306 acc: 0.69466 | v_loss: 1.08735 v_acc: 0.70898 |  iteration: 14669 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 996 loss: 1.23149 acc: 0.70345 | v_loss: 1.13160 v_acc: 0.70540 |  iteration: 14670 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 997 loss: 1.10071 acc: 0.72168 | v_loss: 1.18532 v_acc: 0.70866 |  iteration: 14671 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 998 loss: 1.29916 acc: 0.70378 | v_loss: 1.17231 v_acc: 0.70638 |  iteration: 14672 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 999 loss: 1.25048 acc: 0.69531 | v_loss: 1.26674 v_acc: 0.69889 |  iteration: 14673 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 1000 loss: 1.24362 acc: 0.70898 | v_loss: 1.26683 v_acc: 0.70931 |  iteration: 14674 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 1001 loss: 1.21695 acc: 0.70833 | v_loss: 1.20428 v_acc: 0.70573 |  iteration: 14675 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 1002 loss: 1.18357 acc: 0.71387 | v_loss: 1.13851 v_acc: 0.71810 |  iteration: 14676 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 1003 loss: 1.15046 acc: 0.71126 | v_loss: 1.21730 v_acc: 0.70931 |  iteration: 14677 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 1004 loss: 1.27248 acc: 0.70801 | v_loss: 1.14358 v_acc: 0.71973 |  iteration: 14678 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 1005 loss: 1.16724 acc: 0.71517 | v_loss: 1.08605 v_acc: 0.72884 |  iteration: 14679 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 1006 loss: 1.21441 acc: 0.70150 | v_loss: 1.02128 v_acc: 0.71387 |  iteration: 14680 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 1007 loss: 1.20497 acc: 0.70150 | v_loss: 1.15567 v_acc: 0.71094 |  iteration: 14681 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 1008 loss: 1.26949 acc: 0.70573 | v_loss: 1.22164 v_acc: 0.69987 |  iteration: 14682 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 1009 loss: 1.21227 acc: 0.71126 | v_loss: 1.05972 v_acc: 0.72266 |  iteration: 14683 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 1010 loss: 1.22965 acc: 0.69824 | v_loss: 1.14909 v_acc: 0.70215 |  iteration: 14684 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 1011 loss: 1.18732 acc: 0.70117 | v_loss: 1.09562 v_acc: 0.71908 |  iteration: 14685 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 1012 loss: 1.23982 acc: 0.69792 | v_loss: 1.10616 v_acc: 0.71094 |  iteration: 14686 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 1013 loss: 1.20658 acc: 0.70866 | v_loss: 1.01663 v_acc: 0.74219 |  iteration: 14687 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 1014 loss: 1.14915 acc: 0.71257 | v_loss: 1.11645 v_acc: 0.71810 |  iteration: 14688 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 1015 loss: 1.21479 acc: 0.71322 | v_loss: 1.00029 v_acc: 0.71094 |  iteration: 14689 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 1016 loss: 1.30878 acc: 0.69238 | v_loss: 1.00845 v_acc: 0.72949 |  iteration: 14690 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 1017 loss: 1.19726 acc: 0.71712 | v_loss: 1.11321 v_acc: 0.72103 |  iteration: 14691 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 1018 loss: 1.21694 acc: 0.71745 | v_loss: 1.10367 v_acc: 0.72461 |  iteration: 14692 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 1019 loss: 1.21015 acc: 0.72526 | v_loss: 1.11041 v_acc: 0.72526 |  iteration: 14693 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 1020 loss: 1.28510 acc: 0.69108 | v_loss: 1.31253 v_acc: 0.70280 |  iteration: 14694 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 1021 loss: 1.27669 acc: 0.69954 | v_loss: 1.21775 v_acc: 0.72331 |  iteration: 14695 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 1022 loss: 1.18345 acc: 0.70540 | v_loss: 0.98772 v_acc: 0.75163 |  iteration: 14696 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 1023 loss: 1.18113 acc: 0.71224 | v_loss: 1.12308 v_acc: 0.71322 |  iteration: 14697 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 1024 loss: 1.13835 acc: 0.72135 | v_loss: 1.17613 v_acc: 0.71029 |  iteration: 14698 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 1025 loss: 1.14736 acc: 0.71289 | v_loss: 1.13960 v_acc: 0.69629 |  iteration: 14699 teacher: 1 stage: sketch lr: 0.000365\n",
      "batch 1026 loss: 1.19265 acc: 0.70996 | v_loss: 1.14889 v_acc: 0.71224 |  iteration: 14700 teacher: 0 stage: sketch lr: 0.000365\n",
      "batch 1027 loss: 1.15063 acc: 0.71322 | v_loss: 1.14554 v_acc: 0.69889 |  iteration: 14701 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1028 loss: 1.20649 acc: 0.71159 | v_loss: 1.12895 v_acc: 0.71484 |  iteration: 14702 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1029 loss: 1.18634 acc: 0.70378 | v_loss: 1.14333 v_acc: 0.70996 |  iteration: 14703 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1030 loss: 1.19934 acc: 0.70703 | v_loss: 1.11230 v_acc: 0.72526 |  iteration: 14704 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1031 loss: 1.25085 acc: 0.69824 | v_loss: 1.11762 v_acc: 0.72917 |  iteration: 14705 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1032 loss: 1.27769 acc: 0.69434 | v_loss: 1.09413 v_acc: 0.70768 |  iteration: 14706 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1033 loss: 1.13036 acc: 0.71387 | v_loss: 1.20985 v_acc: 0.70182 |  iteration: 14707 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1034 loss: 1.13018 acc: 0.71419 | v_loss: 1.08921 v_acc: 0.71582 |  iteration: 14708 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1035 loss: 1.16027 acc: 0.71354 | v_loss: 1.33680 v_acc: 0.68978 |  iteration: 14709 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1036 loss: 1.20351 acc: 0.70540 | v_loss: 1.04893 v_acc: 0.72721 |  iteration: 14710 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1037 loss: 1.21145 acc: 0.70020 | v_loss: 1.38070 v_acc: 0.68848 |  iteration: 14711 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1038 loss: 1.13515 acc: 0.72135 | v_loss: 1.23799 v_acc: 0.69531 |  iteration: 14712 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1039 loss: 1.24322 acc: 0.70247 | v_loss: 1.22805 v_acc: 0.69792 |  iteration: 14713 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1040 loss: 1.24194 acc: 0.70182 | v_loss: 1.21892 v_acc: 0.70052 |  iteration: 14714 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1041 loss: 1.16049 acc: 0.71484 | v_loss: 1.13393 v_acc: 0.70931 |  iteration: 14715 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1042 loss: 1.20461 acc: 0.70410 | v_loss: 1.16430 v_acc: 0.69954 |  iteration: 14716 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1043 loss: 1.29708 acc: 0.69303 | v_loss: 1.13858 v_acc: 0.72038 |  iteration: 14717 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1044 loss: 1.21883 acc: 0.70573 | v_loss: 1.30381 v_acc: 0.68848 |  iteration: 14718 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1045 loss: 1.23527 acc: 0.69401 | v_loss: 1.19710 v_acc: 0.71094 |  iteration: 14719 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1046 loss: 1.16509 acc: 0.71452 | v_loss: 1.10111 v_acc: 0.71452 |  iteration: 14720 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1047 loss: 1.16741 acc: 0.70703 | v_loss: 1.13243 v_acc: 0.72493 |  iteration: 14721 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1048 loss: 1.22058 acc: 0.69922 | v_loss: 1.07827 v_acc: 0.71257 |  iteration: 14722 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1049 loss: 1.18176 acc: 0.71094 | v_loss: 1.16810 v_acc: 0.70150 |  iteration: 14723 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1050 loss: 1.17625 acc: 0.70671 | v_loss: 1.15786 v_acc: 0.71712 |  iteration: 14724 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1051 loss: 1.24112 acc: 0.69889 | v_loss: 1.05614 v_acc: 0.71842 |  iteration: 14725 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1052 loss: 1.19664 acc: 0.71159 | v_loss: 1.06938 v_acc: 0.72591 |  iteration: 14726 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1053 loss: 1.13949 acc: 0.71191 | v_loss: 1.21110 v_acc: 0.71745 |  iteration: 14727 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1054 loss: 1.18977 acc: 0.71191 | v_loss: 1.14266 v_acc: 0.70703 |  iteration: 14728 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1055 loss: 1.17783 acc: 0.70898 | v_loss: 1.13362 v_acc: 0.71224 |  iteration: 14729 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1056 loss: 1.25926 acc: 0.69889 | v_loss: 0.99362 v_acc: 0.72624 |  iteration: 14730 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1057 loss: 1.27401 acc: 0.70605 | v_loss: 1.19850 v_acc: 0.73177 |  iteration: 14731 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1058 loss: 1.14944 acc: 0.71257 | v_loss: 1.22049 v_acc: 0.70345 |  iteration: 14732 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1059 loss: 1.28092 acc: 0.70117 | v_loss: 1.16781 v_acc: 0.73014 |  iteration: 14733 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1060 loss: 1.12500 acc: 0.71582 | v_loss: 1.04943 v_acc: 0.72005 |  iteration: 14734 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1061 loss: 1.07441 acc: 0.72656 | v_loss: 1.07658 v_acc: 0.73633 |  iteration: 14735 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1062 loss: 1.20973 acc: 0.70833 | v_loss: 1.00953 v_acc: 0.72819 |  iteration: 14736 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1063 loss: 1.25663 acc: 0.70410 | v_loss: 1.10612 v_acc: 0.70573 |  iteration: 14737 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1064 loss: 1.26586 acc: 0.69727 | v_loss: 1.14660 v_acc: 0.70996 |  iteration: 14738 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1065 loss: 1.16186 acc: 0.71354 | v_loss: 1.11389 v_acc: 0.71875 |  iteration: 14739 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1066 loss: 1.18599 acc: 0.71094 | v_loss: 1.25376 v_acc: 0.70964 |  iteration: 14740 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1067 loss: 1.27501 acc: 0.70280 | v_loss: 1.36996 v_acc: 0.69857 |  iteration: 14741 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1068 loss: 1.09111 acc: 0.71615 | v_loss: 1.26370 v_acc: 0.70150 |  iteration: 14742 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1069 loss: 1.23055 acc: 0.70378 | v_loss: 1.11007 v_acc: 0.72168 |  iteration: 14743 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1070 loss: 1.17592 acc: 0.69824 | v_loss: 1.11135 v_acc: 0.71387 |  iteration: 14744 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1071 loss: 1.14759 acc: 0.70768 | v_loss: 1.03948 v_acc: 0.72526 |  iteration: 14745 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1072 loss: 1.19390 acc: 0.70247 | v_loss: 1.11391 v_acc: 0.70931 |  iteration: 14746 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1073 loss: 1.15657 acc: 0.70312 | v_loss: 1.16950 v_acc: 0.72005 |  iteration: 14747 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1074 loss: 1.18925 acc: 0.70638 | v_loss: 1.13093 v_acc: 0.73112 |  iteration: 14748 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1075 loss: 1.24139 acc: 0.70312 | v_loss: 1.14115 v_acc: 0.72819 |  iteration: 14749 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1076 loss: 1.22938 acc: 0.71159 | v_loss: 1.12329 v_acc: 0.71712 |  iteration: 14750 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1077 loss: 1.29827 acc: 0.69499 | v_loss: 1.08105 v_acc: 0.73210 |  iteration: 14751 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1078 loss: 1.17086 acc: 0.70410 | v_loss: 1.03468 v_acc: 0.72201 |  iteration: 14752 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1079 loss: 1.13109 acc: 0.70964 | v_loss: 1.39608 v_acc: 0.69303 |  iteration: 14753 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1080 loss: 1.17907 acc: 0.70052 | v_loss: 1.10918 v_acc: 0.71322 |  iteration: 14754 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1081 loss: 1.12622 acc: 0.71257 | v_loss: 1.10156 v_acc: 0.71680 |  iteration: 14755 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1082 loss: 1.26420 acc: 0.69922 | v_loss: 1.15914 v_acc: 0.70898 |  iteration: 14756 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1083 loss: 1.18607 acc: 0.70801 | v_loss: 1.16370 v_acc: 0.70508 |  iteration: 14757 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1084 loss: 1.19088 acc: 0.71224 | v_loss: 1.07117 v_acc: 0.73828 |  iteration: 14758 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1085 loss: 1.23852 acc: 0.70931 | v_loss: 1.25707 v_acc: 0.71257 |  iteration: 14759 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1086 loss: 1.27192 acc: 0.70378 | v_loss: 1.08468 v_acc: 0.70215 |  iteration: 14760 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1087 loss: 1.21311 acc: 0.70605 | v_loss: 1.10778 v_acc: 0.70378 |  iteration: 14761 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1088 loss: 1.23603 acc: 0.70215 | v_loss: 1.21505 v_acc: 0.70605 |  iteration: 14762 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1089 loss: 1.24802 acc: 0.69629 | v_loss: 1.18879 v_acc: 0.70605 |  iteration: 14763 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1090 loss: 1.20003 acc: 0.70671 | v_loss: 1.28382 v_acc: 0.70052 |  iteration: 14764 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1091 loss: 1.12454 acc: 0.71680 | v_loss: 1.28881 v_acc: 0.71191 |  iteration: 14765 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1092 loss: 1.26427 acc: 0.69824 | v_loss: 1.18968 v_acc: 0.70410 |  iteration: 14766 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1093 loss: 1.20244 acc: 0.69954 | v_loss: 1.07955 v_acc: 0.71712 |  iteration: 14767 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1094 loss: 1.24908 acc: 0.70508 | v_loss: 1.21157 v_acc: 0.71582 |  iteration: 14768 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1095 loss: 1.17675 acc: 0.71647 | v_loss: 1.10755 v_acc: 0.72168 |  iteration: 14769 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1096 loss: 1.25700 acc: 0.69141 | v_loss: 1.06115 v_acc: 0.73210 |  iteration: 14770 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1097 loss: 1.21767 acc: 0.69954 | v_loss: 1.06376 v_acc: 0.70866 |  iteration: 14771 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1098 loss: 1.16776 acc: 0.71517 | v_loss: 1.14255 v_acc: 0.70671 |  iteration: 14772 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1099 loss: 1.13969 acc: 0.70996 | v_loss: 1.21807 v_acc: 0.69596 |  iteration: 14773 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1100 loss: 1.20116 acc: 0.71387 | v_loss: 1.04700 v_acc: 0.72233 |  iteration: 14774 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1101 loss: 1.33179 acc: 0.69401 | v_loss: 1.12186 v_acc: 0.70312 |  iteration: 14775 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1102 loss: 1.13672 acc: 0.71387 | v_loss: 1.07823 v_acc: 0.71875 |  iteration: 14776 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1103 loss: 1.19317 acc: 0.70833 | v_loss: 1.11341 v_acc: 0.70866 |  iteration: 14777 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1104 loss: 1.22332 acc: 0.69922 | v_loss: 1.00719 v_acc: 0.74154 |  iteration: 14778 teacher: 1 stage: sketch lr: 0.000364\n",
      "batch 1105 loss: 1.17025 acc: 0.70833 | v_loss: 1.09026 v_acc: 0.72070 |  iteration: 14779 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1106 loss: 1.25384 acc: 0.70020 | v_loss: 1.03598 v_acc: 0.71615 |  iteration: 14780 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1107 loss: 1.15728 acc: 0.71159 | v_loss: 1.04654 v_acc: 0.73145 |  iteration: 14781 teacher: 0 stage: sketch lr: 0.000364\n",
      "batch 1108 loss: 1.21652 acc: 0.70443 | v_loss: 1.13088 v_acc: 0.71940 |  iteration: 14782 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1109 loss: 1.12659 acc: 0.71680 | v_loss: 1.11779 v_acc: 0.71973 |  iteration: 14783 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1110 loss: 1.18214 acc: 0.71322 | v_loss: 1.11346 v_acc: 0.72624 |  iteration: 14784 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1111 loss: 1.16444 acc: 0.71484 | v_loss: 1.29942 v_acc: 0.70312 |  iteration: 14785 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1112 loss: 1.11220 acc: 0.71647 | v_loss: 1.22414 v_acc: 0.72103 |  iteration: 14786 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1113 loss: 1.20801 acc: 0.70378 | v_loss: 0.97720 v_acc: 0.74674 |  iteration: 14787 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1114 loss: 1.17731 acc: 0.71419 | v_loss: 1.13675 v_acc: 0.70638 |  iteration: 14788 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1115 loss: 1.29263 acc: 0.71159 | v_loss: 1.15937 v_acc: 0.70605 |  iteration: 14789 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1116 loss: 1.12262 acc: 0.71419 | v_loss: 1.12803 v_acc: 0.69694 |  iteration: 14790 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1117 loss: 1.16503 acc: 0.70247 | v_loss: 1.15450 v_acc: 0.71224 |  iteration: 14791 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1118 loss: 1.17092 acc: 0.71159 | v_loss: 1.15630 v_acc: 0.70573 |  iteration: 14792 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1119 loss: 1.20574 acc: 0.70768 | v_loss: 1.14685 v_acc: 0.71615 |  iteration: 14793 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1120 loss: 1.21267 acc: 0.70508 | v_loss: 1.15818 v_acc: 0.70540 |  iteration: 14794 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1121 loss: 1.19683 acc: 0.69694 | v_loss: 1.09955 v_acc: 0.72363 |  iteration: 14795 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1122 loss: 1.25180 acc: 0.69922 | v_loss: 1.08760 v_acc: 0.72363 |  iteration: 14796 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1123 loss: 1.15897 acc: 0.71126 | v_loss: 1.12500 v_acc: 0.70540 |  iteration: 14797 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1124 loss: 1.26249 acc: 0.71419 | v_loss: 1.22178 v_acc: 0.69596 |  iteration: 14798 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1125 loss: 1.27157 acc: 0.71061 | v_loss: 1.09766 v_acc: 0.71322 |  iteration: 14799 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1126 loss: 1.21773 acc: 0.70866 | v_loss: 1.32666 v_acc: 0.69206 |  iteration: 14800 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1127 loss: 1.15703 acc: 0.71615 | v_loss: 1.10737 v_acc: 0.72982 |  iteration: 14801 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1128 loss: 1.17872 acc: 0.71061 | v_loss: 1.38905 v_acc: 0.68880 |  iteration: 14802 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1129 loss: 1.12638 acc: 0.70964 | v_loss: 1.27530 v_acc: 0.70280 |  iteration: 14803 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1130 loss: 1.18950 acc: 0.71777 | v_loss: 1.27586 v_acc: 0.69596 |  iteration: 14804 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1131 loss: 1.16692 acc: 0.70508 | v_loss: 1.20391 v_acc: 0.70638 |  iteration: 14805 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1132 loss: 1.22030 acc: 0.70117 | v_loss: 1.14854 v_acc: 0.71224 |  iteration: 14806 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1133 loss: 1.15193 acc: 0.70671 | v_loss: 1.17039 v_acc: 0.70996 |  iteration: 14807 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1134 loss: 1.26292 acc: 0.70215 | v_loss: 1.16342 v_acc: 0.71875 |  iteration: 14808 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1135 loss: 1.30809 acc: 0.69368 | v_loss: 1.31003 v_acc: 0.68815 |  iteration: 14809 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1136 loss: 1.18316 acc: 0.70280 | v_loss: 1.20439 v_acc: 0.71224 |  iteration: 14810 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1137 loss: 1.17219 acc: 0.71061 | v_loss: 1.10337 v_acc: 0.71354 |  iteration: 14811 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1138 loss: 1.20178 acc: 0.70052 | v_loss: 1.17551 v_acc: 0.71322 |  iteration: 14812 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1139 loss: 1.10713 acc: 0.71094 | v_loss: 1.07383 v_acc: 0.71647 |  iteration: 14813 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1140 loss: 1.22549 acc: 0.70345 | v_loss: 1.15258 v_acc: 0.70801 |  iteration: 14814 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1141 loss: 1.19340 acc: 0.70605 | v_loss: 1.12326 v_acc: 0.71875 |  iteration: 14815 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1142 loss: 1.13632 acc: 0.72005 | v_loss: 1.05815 v_acc: 0.72493 |  iteration: 14816 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1143 loss: 1.20323 acc: 0.70736 | v_loss: 1.04015 v_acc: 0.72949 |  iteration: 14817 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1144 loss: 1.22289 acc: 0.70540 | v_loss: 1.19893 v_acc: 0.71745 |  iteration: 14818 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1145 loss: 1.16621 acc: 0.71842 | v_loss: 1.17376 v_acc: 0.70508 |  iteration: 14819 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1146 loss: 1.19050 acc: 0.70996 | v_loss: 1.15350 v_acc: 0.70866 |  iteration: 14820 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1147 loss: 1.18450 acc: 0.70345 | v_loss: 1.00046 v_acc: 0.72493 |  iteration: 14821 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1148 loss: 1.18639 acc: 0.70638 | v_loss: 1.18585 v_acc: 0.73470 |  iteration: 14822 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1149 loss: 1.24261 acc: 0.70736 | v_loss: 1.24715 v_acc: 0.70150 |  iteration: 14823 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1150 loss: 1.17353 acc: 0.70508 | v_loss: 1.20429 v_acc: 0.72819 |  iteration: 14824 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1151 loss: 1.26234 acc: 0.70443 | v_loss: 1.05496 v_acc: 0.72493 |  iteration: 14825 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1152 loss: 1.14368 acc: 0.71973 | v_loss: 1.03559 v_acc: 0.73828 |  iteration: 14826 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1153 loss: 1.25413 acc: 0.70410 | v_loss: 1.03481 v_acc: 0.72461 |  iteration: 14827 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1154 loss: 1.15431 acc: 0.71126 | v_loss: 1.13503 v_acc: 0.70508 |  iteration: 14828 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1155 loss: 1.23607 acc: 0.70508 | v_loss: 1.10080 v_acc: 0.71322 |  iteration: 14829 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1156 loss: 1.25105 acc: 0.70736 | v_loss: 1.11727 v_acc: 0.71582 |  iteration: 14830 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1157 loss: 1.16019 acc: 0.70996 | v_loss: 1.27188 v_acc: 0.69336 |  iteration: 14831 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1158 loss: 1.28393 acc: 0.69922 | v_loss: 1.39292 v_acc: 0.69727 |  iteration: 14832 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1159 loss: 1.29769 acc: 0.69824 | v_loss: 1.27984 v_acc: 0.70150 |  iteration: 14833 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1160 loss: 1.21854 acc: 0.70866 | v_loss: 1.12975 v_acc: 0.72689 |  iteration: 14834 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1161 loss: 1.17787 acc: 0.71257 | v_loss: 1.11199 v_acc: 0.71289 |  iteration: 14835 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1162 loss: 1.16069 acc: 0.70247 | v_loss: 1.07688 v_acc: 0.72233 |  iteration: 14836 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1163 loss: 1.34438 acc: 0.69206 | v_loss: 1.16235 v_acc: 0.70020 |  iteration: 14837 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1164 loss: 1.25334 acc: 0.70020 | v_loss: 1.18211 v_acc: 0.71289 |  iteration: 14838 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1165 loss: 1.20898 acc: 0.70475 | v_loss: 1.16553 v_acc: 0.73503 |  iteration: 14839 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1166 loss: 1.19629 acc: 0.70117 | v_loss: 1.15109 v_acc: 0.72298 |  iteration: 14840 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1167 loss: 1.22991 acc: 0.71159 | v_loss: 1.11077 v_acc: 0.71126 |  iteration: 14841 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1168 loss: 1.12294 acc: 0.71452 | v_loss: 1.07420 v_acc: 0.72786 |  iteration: 14842 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1169 loss: 1.28347 acc: 0.69238 | v_loss: 1.03542 v_acc: 0.72656 |  iteration: 14843 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1170 loss: 1.25962 acc: 0.69889 | v_loss: 1.42926 v_acc: 0.69401 |  iteration: 14844 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1171 loss: 1.19485 acc: 0.70833 | v_loss: 1.12790 v_acc: 0.71029 |  iteration: 14845 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1172 loss: 1.21950 acc: 0.69987 | v_loss: 1.13079 v_acc: 0.72656 |  iteration: 14846 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1173 loss: 1.15316 acc: 0.71549 | v_loss: 1.16686 v_acc: 0.71419 |  iteration: 14847 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1174 loss: 1.29503 acc: 0.69824 | v_loss: 1.16758 v_acc: 0.71517 |  iteration: 14848 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1175 loss: 1.27710 acc: 0.69759 | v_loss: 1.08317 v_acc: 0.74089 |  iteration: 14849 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1176 loss: 1.20941 acc: 0.70247 | v_loss: 1.26307 v_acc: 0.71549 |  iteration: 14850 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1177 loss: 1.31942 acc: 0.68913 | v_loss: 1.12065 v_acc: 0.70410 |  iteration: 14851 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1178 loss: 1.22222 acc: 0.70703 | v_loss: 1.14320 v_acc: 0.70540 |  iteration: 14852 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1179 loss: 1.23087 acc: 0.70443 | v_loss: 1.19621 v_acc: 0.70671 |  iteration: 14853 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1180 loss: 1.19920 acc: 0.69727 | v_loss: 1.18365 v_acc: 0.70443 |  iteration: 14854 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1181 loss: 1.22127 acc: 0.70833 | v_loss: 1.26204 v_acc: 0.69824 |  iteration: 14855 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1182 loss: 1.26172 acc: 0.69271 | v_loss: 1.31131 v_acc: 0.70931 |  iteration: 14856 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1183 loss: 1.23904 acc: 0.70573 | v_loss: 1.18392 v_acc: 0.70573 |  iteration: 14857 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1184 loss: 1.17190 acc: 0.70605 | v_loss: 1.06906 v_acc: 0.71875 |  iteration: 14858 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1185 loss: 1.13781 acc: 0.70964 | v_loss: 1.24783 v_acc: 0.70671 |  iteration: 14859 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1186 loss: 1.23582 acc: 0.69889 | v_loss: 1.15033 v_acc: 0.71973 |  iteration: 14860 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1187 loss: 1.28404 acc: 0.69629 | v_loss: 1.06930 v_acc: 0.72786 |  iteration: 14861 teacher: 0 stage: sketch lr: 0.000363\n",
      "batch 1188 loss: 1.25197 acc: 0.70801 | v_loss: 1.06595 v_acc: 0.71191 |  iteration: 14862 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1189 loss: 1.16606 acc: 0.70638 | v_loss: 1.15106 v_acc: 0.71322 |  iteration: 14863 teacher: 1 stage: sketch lr: 0.000363\n",
      "batch 1190 loss: 1.15573 acc: 0.71094 | v_loss: 1.18964 v_acc: 0.70085 |  iteration: 14864 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1191 loss: 1.20694 acc: 0.70964 | v_loss: 1.07551 v_acc: 0.71745 |  iteration: 14865 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1192 loss: 1.16016 acc: 0.70378 | v_loss: 1.12629 v_acc: 0.70182 |  iteration: 14866 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1193 loss: 1.23360 acc: 0.70508 | v_loss: 1.11193 v_acc: 0.71257 |  iteration: 14867 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1194 loss: 1.18831 acc: 0.71159 | v_loss: 1.13441 v_acc: 0.70898 |  iteration: 14868 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1195 loss: 1.20476 acc: 0.70247 | v_loss: 1.03351 v_acc: 0.74186 |  iteration: 14869 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1196 loss: 1.24354 acc: 0.70801 | v_loss: 1.10161 v_acc: 0.72363 |  iteration: 14870 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1197 loss: 1.16477 acc: 0.71745 | v_loss: 1.04354 v_acc: 0.72786 |  iteration: 14871 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1198 loss: 1.23521 acc: 0.70280 | v_loss: 1.03454 v_acc: 0.72689 |  iteration: 14872 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1199 loss: 1.23251 acc: 0.71094 | v_loss: 1.13787 v_acc: 0.71940 |  iteration: 14873 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1200 loss: 1.17230 acc: 0.72038 | v_loss: 1.11851 v_acc: 0.72005 |  iteration: 14874 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1201 loss: 1.28826 acc: 0.70117 | v_loss: 1.14292 v_acc: 0.72461 |  iteration: 14875 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1202 loss: 1.19429 acc: 0.71484 | v_loss: 1.32084 v_acc: 0.69824 |  iteration: 14876 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1203 loss: 1.18364 acc: 0.70833 | v_loss: 1.23815 v_acc: 0.72038 |  iteration: 14877 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1204 loss: 1.22138 acc: 0.69499 | v_loss: 0.96915 v_acc: 0.75065 |  iteration: 14878 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1205 loss: 1.14877 acc: 0.70052 | v_loss: 1.14552 v_acc: 0.70931 |  iteration: 14879 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1206 loss: 1.20032 acc: 0.71061 | v_loss: 1.18351 v_acc: 0.70443 |  iteration: 14880 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1207 loss: 1.29167 acc: 0.68815 | v_loss: 1.15805 v_acc: 0.69824 |  iteration: 14881 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1208 loss: 1.17607 acc: 0.70085 | v_loss: 1.12448 v_acc: 0.71224 |  iteration: 14882 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1209 loss: 1.19827 acc: 0.70833 | v_loss: 1.14249 v_acc: 0.70475 |  iteration: 14883 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1210 loss: 1.26668 acc: 0.70573 | v_loss: 1.12985 v_acc: 0.71159 |  iteration: 14884 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1211 loss: 1.23222 acc: 0.70638 | v_loss: 1.13288 v_acc: 0.71257 |  iteration: 14885 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1212 loss: 1.21485 acc: 0.70378 | v_loss: 1.11381 v_acc: 0.71973 |  iteration: 14886 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1213 loss: 1.25066 acc: 0.69434 | v_loss: 1.08281 v_acc: 0.73145 |  iteration: 14887 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1214 loss: 1.28725 acc: 0.69401 | v_loss: 1.11413 v_acc: 0.70280 |  iteration: 14888 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1215 loss: 1.17128 acc: 0.69922 | v_loss: 1.19377 v_acc: 0.69857 |  iteration: 14889 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1216 loss: 1.19527 acc: 0.71387 | v_loss: 1.05805 v_acc: 0.71354 |  iteration: 14890 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1217 loss: 1.26248 acc: 0.70964 | v_loss: 1.32163 v_acc: 0.68848 |  iteration: 14891 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1218 loss: 1.27457 acc: 0.69987 | v_loss: 1.07185 v_acc: 0.72786 |  iteration: 14892 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1219 loss: 1.22922 acc: 0.69922 | v_loss: 1.38659 v_acc: 0.68490 |  iteration: 14893 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1220 loss: 1.22071 acc: 0.71257 | v_loss: 1.22837 v_acc: 0.69661 |  iteration: 14894 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1221 loss: 1.23884 acc: 0.70247 | v_loss: 1.25338 v_acc: 0.69759 |  iteration: 14895 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1222 loss: 1.23427 acc: 0.70768 | v_loss: 1.18891 v_acc: 0.70215 |  iteration: 14896 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1223 loss: 1.28129 acc: 0.70540 | v_loss: 1.10479 v_acc: 0.71159 |  iteration: 14897 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1224 loss: 1.24800 acc: 0.70736 | v_loss: 1.16962 v_acc: 0.70475 |  iteration: 14898 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1225 loss: 1.16332 acc: 0.70182 | v_loss: 1.13420 v_acc: 0.72135 |  iteration: 14899 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1226 loss: 1.21103 acc: 0.70182 | v_loss: 1.32244 v_acc: 0.68652 |  iteration: 14900 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1227 loss: 1.19140 acc: 0.70280 | v_loss: 1.19968 v_acc: 0.70768 |  iteration: 14901 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1228 loss: 1.20844 acc: 0.70638 | v_loss: 1.09030 v_acc: 0.71126 |  iteration: 14902 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1229 loss: 1.14449 acc: 0.70605 | v_loss: 1.16405 v_acc: 0.72103 |  iteration: 14903 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1230 loss: 1.18655 acc: 0.71061 | v_loss: 1.09382 v_acc: 0.70996 |  iteration: 14904 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1231 loss: 1.10538 acc: 0.72786 | v_loss: 1.15192 v_acc: 0.70801 |  iteration: 14905 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1232 loss: 1.16438 acc: 0.71289 | v_loss: 1.17065 v_acc: 0.72624 |  iteration: 14906 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1233 loss: 1.22799 acc: 0.70931 | v_loss: 1.04044 v_acc: 0.72721 |  iteration: 14907 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1234 loss: 1.23453 acc: 0.71029 | v_loss: 1.06232 v_acc: 0.73145 |  iteration: 14908 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1235 loss: 1.21883 acc: 0.70768 | v_loss: 1.21798 v_acc: 0.71680 |  iteration: 14909 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1236 loss: 1.31199 acc: 0.69661 | v_loss: 1.16076 v_acc: 0.71354 |  iteration: 14910 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1237 loss: 1.22869 acc: 0.71973 | v_loss: 1.19165 v_acc: 0.71061 |  iteration: 14911 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1238 loss: 1.23093 acc: 0.70768 | v_loss: 1.04308 v_acc: 0.72559 |  iteration: 14912 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1239 loss: 1.15324 acc: 0.71289 | v_loss: 1.18751 v_acc: 0.73372 |  iteration: 14913 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1240 loss: 1.16992 acc: 0.70605 | v_loss: 1.21553 v_acc: 0.70150 |  iteration: 14914 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 1241 loss: 1.19334 acc: 0.70443 | v_loss: 1.19098 v_acc: 0.72852 |  iteration: 14915 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1242 loss: 1.16853 acc: 0.71484 | v_loss: 1.04713 v_acc: 0.72070 |  iteration: 14916 teacher: 0 stage: sketch lr: 0.000362\n",
      "epoch 11 loss: 1.23937 acc: 0.70567 | v_loss: 1.18119 v_acc: 0.71307 \n",
      "epoch: 12\n",
      "__________________________________________\n",
      "batch 0 loss: 1.18096 acc: 0.72168 | v_loss: 1.19570 v_acc: 0.70312 |  iteration: 14917 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 1 loss: 1.20589 acc: 0.70508 | v_loss: 1.10231 v_acc: 0.71289 |  iteration: 14918 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 2 loss: 1.22548 acc: 0.70703 | v_loss: 1.23196 v_acc: 0.70605 |  iteration: 14919 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 3 loss: 1.24773 acc: 0.70215 | v_loss: 1.16527 v_acc: 0.72070 |  iteration: 14920 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 4 loss: 1.19616 acc: 0.71419 | v_loss: 1.05377 v_acc: 0.73079 |  iteration: 14921 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 5 loss: 1.13446 acc: 0.70573 | v_loss: 1.04714 v_acc: 0.71322 |  iteration: 14922 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 6 loss: 1.16428 acc: 0.70703 | v_loss: 1.13995 v_acc: 0.70898 |  iteration: 14923 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 7 loss: 1.16916 acc: 0.69824 | v_loss: 1.21001 v_acc: 0.69759 |  iteration: 14924 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 8 loss: 1.26118 acc: 0.70215 | v_loss: 1.05809 v_acc: 0.72070 |  iteration: 14925 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 9 loss: 1.20098 acc: 0.71647 | v_loss: 1.10590 v_acc: 0.70508 |  iteration: 14926 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 10 loss: 1.22596 acc: 0.70247 | v_loss: 1.08963 v_acc: 0.71647 |  iteration: 14927 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 11 loss: 1.14955 acc: 0.71191 | v_loss: 1.09037 v_acc: 0.71387 |  iteration: 14928 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 12 loss: 1.19460 acc: 0.71061 | v_loss: 0.98678 v_acc: 0.74414 |  iteration: 14929 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 13 loss: 1.27911 acc: 0.70085 | v_loss: 1.10282 v_acc: 0.71842 |  iteration: 14930 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 14 loss: 1.15066 acc: 0.71419 | v_loss: 1.02542 v_acc: 0.70898 |  iteration: 14931 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 15 loss: 1.21841 acc: 0.70866 | v_loss: 1.03043 v_acc: 0.72949 |  iteration: 14932 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 16 loss: 1.16443 acc: 0.70931 | v_loss: 1.10842 v_acc: 0.72201 |  iteration: 14933 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 17 loss: 1.18400 acc: 0.69727 | v_loss: 1.10566 v_acc: 0.72331 |  iteration: 14934 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 18 loss: 1.17446 acc: 0.70866 | v_loss: 1.13726 v_acc: 0.72624 |  iteration: 14935 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 19 loss: 1.12579 acc: 0.70801 | v_loss: 1.31537 v_acc: 0.70117 |  iteration: 14936 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 20 loss: 1.24739 acc: 0.70443 | v_loss: 1.24384 v_acc: 0.72461 |  iteration: 14937 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 21 loss: 1.19729 acc: 0.69987 | v_loss: 0.98700 v_acc: 0.74251 |  iteration: 14938 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 22 loss: 1.22611 acc: 0.69922 | v_loss: 1.16237 v_acc: 0.70931 |  iteration: 14939 teacher: 1 stage: sketch lr: 0.000362\n",
      "batch 23 loss: 1.29892 acc: 0.69010 | v_loss: 1.18350 v_acc: 0.69987 |  iteration: 14940 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 24 loss: 1.13488 acc: 0.71973 | v_loss: 1.11893 v_acc: 0.70247 |  iteration: 14941 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 25 loss: 1.20179 acc: 0.70247 | v_loss: 1.13768 v_acc: 0.71387 |  iteration: 14942 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 26 loss: 1.21803 acc: 0.70801 | v_loss: 1.14199 v_acc: 0.70150 |  iteration: 14943 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 27 loss: 1.21309 acc: 0.70703 | v_loss: 1.12698 v_acc: 0.71875 |  iteration: 14944 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 28 loss: 1.22981 acc: 0.70345 | v_loss: 1.14913 v_acc: 0.70508 |  iteration: 14945 teacher: 0 stage: sketch lr: 0.000362\n",
      "batch 29 loss: 1.19660 acc: 0.70931 | v_loss: 1.08701 v_acc: 0.71257 |  iteration: 14946 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 30 loss: 1.14389 acc: 0.72103 | v_loss: 1.08149 v_acc: 0.72884 |  iteration: 14947 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 31 loss: 1.23398 acc: 0.69727 | v_loss: 1.10385 v_acc: 0.70410 |  iteration: 14948 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 32 loss: 1.27366 acc: 0.69401 | v_loss: 1.17676 v_acc: 0.69759 |  iteration: 14949 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 33 loss: 1.26745 acc: 0.69434 | v_loss: 1.07295 v_acc: 0.70898 |  iteration: 14950 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 34 loss: 1.19856 acc: 0.70736 | v_loss: 1.32200 v_acc: 0.68783 |  iteration: 14951 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 35 loss: 1.14266 acc: 0.70443 | v_loss: 1.07044 v_acc: 0.72917 |  iteration: 14952 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 36 loss: 1.15984 acc: 0.70866 | v_loss: 1.35611 v_acc: 0.68262 |  iteration: 14953 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 37 loss: 1.16216 acc: 0.70540 | v_loss: 1.26856 v_acc: 0.69629 |  iteration: 14954 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 38 loss: 1.15763 acc: 0.71257 | v_loss: 1.24502 v_acc: 0.70117 |  iteration: 14955 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 39 loss: 1.15010 acc: 0.70996 | v_loss: 1.17784 v_acc: 0.70475 |  iteration: 14956 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 40 loss: 1.14775 acc: 0.71289 | v_loss: 1.12109 v_acc: 0.71582 |  iteration: 14957 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 41 loss: 1.11919 acc: 0.71257 | v_loss: 1.15678 v_acc: 0.71387 |  iteration: 14958 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 42 loss: 1.18255 acc: 0.70345 | v_loss: 1.09979 v_acc: 0.72786 |  iteration: 14959 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 43 loss: 1.29769 acc: 0.69824 | v_loss: 1.34519 v_acc: 0.68424 |  iteration: 14960 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 44 loss: 1.23834 acc: 0.69824 | v_loss: 1.22686 v_acc: 0.71029 |  iteration: 14961 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 45 loss: 1.12116 acc: 0.71842 | v_loss: 1.08442 v_acc: 0.71549 |  iteration: 14962 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 46 loss: 1.22129 acc: 0.71126 | v_loss: 1.16340 v_acc: 0.71452 |  iteration: 14963 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 47 loss: 1.27531 acc: 0.69857 | v_loss: 1.07535 v_acc: 0.71712 |  iteration: 14964 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 48 loss: 1.23803 acc: 0.70703 | v_loss: 1.14271 v_acc: 0.70508 |  iteration: 14965 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 49 loss: 1.06952 acc: 0.72526 | v_loss: 1.13497 v_acc: 0.72201 |  iteration: 14966 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 50 loss: 1.22714 acc: 0.69727 | v_loss: 1.05943 v_acc: 0.71842 |  iteration: 14967 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 51 loss: 1.18202 acc: 0.70540 | v_loss: 1.05955 v_acc: 0.72982 |  iteration: 14968 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 52 loss: 1.14566 acc: 0.70443 | v_loss: 1.20457 v_acc: 0.71549 |  iteration: 14969 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 53 loss: 1.16931 acc: 0.70085 | v_loss: 1.16720 v_acc: 0.70410 |  iteration: 14970 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 54 loss: 1.23538 acc: 0.69922 | v_loss: 1.12809 v_acc: 0.71094 |  iteration: 14971 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 55 loss: 1.15798 acc: 0.71615 | v_loss: 1.00385 v_acc: 0.72201 |  iteration: 14972 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 56 loss: 1.26418 acc: 0.70671 | v_loss: 1.19167 v_acc: 0.73340 |  iteration: 14973 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 57 loss: 1.26273 acc: 0.69531 | v_loss: 1.19870 v_acc: 0.70247 |  iteration: 14974 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 58 loss: 1.19120 acc: 0.70182 | v_loss: 1.16328 v_acc: 0.72786 |  iteration: 14975 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 59 loss: 1.20962 acc: 0.71191 | v_loss: 1.03638 v_acc: 0.72852 |  iteration: 14976 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 60 loss: 1.24720 acc: 0.70703 | v_loss: 1.01989 v_acc: 0.73893 |  iteration: 14977 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 61 loss: 1.18902 acc: 0.70475 | v_loss: 1.02198 v_acc: 0.72266 |  iteration: 14978 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 62 loss: 1.16905 acc: 0.70736 | v_loss: 1.09442 v_acc: 0.70996 |  iteration: 14979 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 63 loss: 1.36011 acc: 0.69043 | v_loss: 1.10641 v_acc: 0.71289 |  iteration: 14980 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 64 loss: 1.23876 acc: 0.69434 | v_loss: 1.12683 v_acc: 0.71680 |  iteration: 14981 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 65 loss: 1.11050 acc: 0.70931 | v_loss: 1.25013 v_acc: 0.69596 |  iteration: 14982 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 66 loss: 1.20845 acc: 0.70703 | v_loss: 1.37663 v_acc: 0.69759 |  iteration: 14983 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 67 loss: 1.18710 acc: 0.70540 | v_loss: 1.25531 v_acc: 0.70312 |  iteration: 14984 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 68 loss: 1.23402 acc: 0.69824 | v_loss: 1.11711 v_acc: 0.72754 |  iteration: 14985 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 69 loss: 1.25991 acc: 0.69694 | v_loss: 1.09867 v_acc: 0.70736 |  iteration: 14986 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 70 loss: 1.24586 acc: 0.69271 | v_loss: 1.05646 v_acc: 0.72624 |  iteration: 14987 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 71 loss: 1.20017 acc: 0.70247 | v_loss: 1.14936 v_acc: 0.70378 |  iteration: 14988 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 72 loss: 1.20890 acc: 0.69987 | v_loss: 1.16946 v_acc: 0.71517 |  iteration: 14989 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 73 loss: 1.13382 acc: 0.71517 | v_loss: 1.14979 v_acc: 0.73242 |  iteration: 14990 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 74 loss: 1.20911 acc: 0.70247 | v_loss: 1.18038 v_acc: 0.72233 |  iteration: 14991 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 75 loss: 1.27224 acc: 0.69954 | v_loss: 1.11660 v_acc: 0.70638 |  iteration: 14992 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 76 loss: 1.13718 acc: 0.71387 | v_loss: 1.09202 v_acc: 0.72526 |  iteration: 14993 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 77 loss: 1.17381 acc: 0.71419 | v_loss: 1.07626 v_acc: 0.72070 |  iteration: 14994 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 78 loss: 1.18836 acc: 0.70996 | v_loss: 1.44993 v_acc: 0.68913 |  iteration: 14995 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 79 loss: 1.20054 acc: 0.71419 | v_loss: 1.11346 v_acc: 0.71322 |  iteration: 14996 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 80 loss: 1.25044 acc: 0.70150 | v_loss: 1.14062 v_acc: 0.72038 |  iteration: 14997 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 81 loss: 1.12975 acc: 0.71094 | v_loss: 1.13557 v_acc: 0.70964 |  iteration: 14998 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 82 loss: 1.26209 acc: 0.70410 | v_loss: 1.18923 v_acc: 0.70020 |  iteration: 14999 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 83 loss: 1.19967 acc: 0.70866 | v_loss: 1.08583 v_acc: 0.73698 |  iteration: 15000 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 84 loss: 1.20750 acc: 0.70996 | v_loss: 1.30129 v_acc: 0.71875 |  iteration: 15001 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 85 loss: 1.19162 acc: 0.69727 | v_loss: 1.10201 v_acc: 0.70280 |  iteration: 15002 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 86 loss: 1.16060 acc: 0.71257 | v_loss: 1.14503 v_acc: 0.70085 |  iteration: 15003 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 87 loss: 1.20417 acc: 0.70736 | v_loss: 1.22448 v_acc: 0.70443 |  iteration: 15004 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 88 loss: 1.20812 acc: 0.70833 | v_loss: 1.19207 v_acc: 0.70768 |  iteration: 15005 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 89 loss: 1.17653 acc: 0.71126 | v_loss: 1.26707 v_acc: 0.69857 |  iteration: 15006 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 90 loss: 1.18719 acc: 0.70150 | v_loss: 1.27099 v_acc: 0.71582 |  iteration: 15007 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 91 loss: 1.27630 acc: 0.69857 | v_loss: 1.21232 v_acc: 0.70833 |  iteration: 15008 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 92 loss: 1.19085 acc: 0.70801 | v_loss: 1.06607 v_acc: 0.72168 |  iteration: 15009 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 93 loss: 1.20360 acc: 0.70605 | v_loss: 1.25411 v_acc: 0.70996 |  iteration: 15010 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 94 loss: 1.19002 acc: 0.71322 | v_loss: 1.15213 v_acc: 0.71940 |  iteration: 15011 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 95 loss: 1.25871 acc: 0.70085 | v_loss: 1.06865 v_acc: 0.72949 |  iteration: 15012 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 96 loss: 1.28629 acc: 0.69759 | v_loss: 1.04060 v_acc: 0.71191 |  iteration: 15013 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 97 loss: 1.19110 acc: 0.70117 | v_loss: 1.13425 v_acc: 0.70898 |  iteration: 15014 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 98 loss: 1.14219 acc: 0.71224 | v_loss: 1.18966 v_acc: 0.70052 |  iteration: 15015 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 99 loss: 1.22431 acc: 0.70345 | v_loss: 1.08785 v_acc: 0.71582 |  iteration: 15016 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 100 loss: 1.13731 acc: 0.70931 | v_loss: 1.12757 v_acc: 0.69889 |  iteration: 15017 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 101 loss: 1.21411 acc: 0.70671 | v_loss: 1.10348 v_acc: 0.70964 |  iteration: 15018 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 102 loss: 1.35321 acc: 0.68457 | v_loss: 1.08445 v_acc: 0.71126 |  iteration: 15019 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 103 loss: 1.17131 acc: 0.69889 | v_loss: 1.05008 v_acc: 0.73633 |  iteration: 15020 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 104 loss: 1.19857 acc: 0.69987 | v_loss: 1.09860 v_acc: 0.72070 |  iteration: 15021 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 105 loss: 1.16797 acc: 0.70996 | v_loss: 1.05550 v_acc: 0.72852 |  iteration: 15022 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 106 loss: 1.21397 acc: 0.70117 | v_loss: 1.03125 v_acc: 0.73014 |  iteration: 15023 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 107 loss: 1.24784 acc: 0.69466 | v_loss: 1.14305 v_acc: 0.71680 |  iteration: 15024 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 108 loss: 1.17099 acc: 0.71126 | v_loss: 1.11351 v_acc: 0.72038 |  iteration: 15025 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 109 loss: 1.27662 acc: 0.69824 | v_loss: 1.15226 v_acc: 0.72396 |  iteration: 15026 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 110 loss: 1.27714 acc: 0.69694 | v_loss: 1.33316 v_acc: 0.69987 |  iteration: 15027 teacher: 0 stage: sketch lr: 0.000361\n",
      "batch 111 loss: 1.25417 acc: 0.69531 | v_loss: 1.24117 v_acc: 0.72493 |  iteration: 15028 teacher: 1 stage: sketch lr: 0.000361\n",
      "batch 112 loss: 1.12673 acc: 0.71224 | v_loss: 0.98663 v_acc: 0.74251 |  iteration: 15029 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 113 loss: 1.24651 acc: 0.69759 | v_loss: 1.15061 v_acc: 0.70540 |  iteration: 15030 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 114 loss: 1.33005 acc: 0.70117 | v_loss: 1.18150 v_acc: 0.70150 |  iteration: 15031 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 115 loss: 1.23075 acc: 0.69596 | v_loss: 1.16816 v_acc: 0.69173 |  iteration: 15032 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 116 loss: 1.27547 acc: 0.69857 | v_loss: 1.14207 v_acc: 0.71094 |  iteration: 15033 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 117 loss: 1.20286 acc: 0.70768 | v_loss: 1.13171 v_acc: 0.70475 |  iteration: 15034 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 118 loss: 1.25300 acc: 0.70150 | v_loss: 1.12815 v_acc: 0.71517 |  iteration: 15035 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 119 loss: 1.20860 acc: 0.70508 | v_loss: 1.14449 v_acc: 0.70475 |  iteration: 15036 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 120 loss: 1.27184 acc: 0.69759 | v_loss: 1.13832 v_acc: 0.71452 |  iteration: 15037 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 121 loss: 1.16763 acc: 0.72005 | v_loss: 1.06779 v_acc: 0.72884 |  iteration: 15038 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 122 loss: 1.08051 acc: 0.71973 | v_loss: 1.09288 v_acc: 0.70768 |  iteration: 15039 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 123 loss: 1.20394 acc: 0.70573 | v_loss: 1.17130 v_acc: 0.70345 |  iteration: 15040 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 124 loss: 1.15484 acc: 0.72005 | v_loss: 1.08607 v_acc: 0.71159 |  iteration: 15041 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 125 loss: 1.31485 acc: 0.69564 | v_loss: 1.38639 v_acc: 0.68620 |  iteration: 15042 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 126 loss: 1.19016 acc: 0.70964 | v_loss: 1.05943 v_acc: 0.73014 |  iteration: 15043 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 127 loss: 1.23519 acc: 0.70150 | v_loss: 1.40765 v_acc: 0.68327 |  iteration: 15044 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 128 loss: 1.26184 acc: 0.70085 | v_loss: 1.25789 v_acc: 0.69987 |  iteration: 15045 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 129 loss: 1.13862 acc: 0.71452 | v_loss: 1.23300 v_acc: 0.69922 |  iteration: 15046 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 130 loss: 1.27537 acc: 0.70052 | v_loss: 1.19558 v_acc: 0.70378 |  iteration: 15047 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 131 loss: 1.33617 acc: 0.68848 | v_loss: 1.11885 v_acc: 0.71940 |  iteration: 15048 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 132 loss: 1.18862 acc: 0.70117 | v_loss: 1.18528 v_acc: 0.70801 |  iteration: 15049 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 133 loss: 1.14825 acc: 0.71387 | v_loss: 1.12586 v_acc: 0.72461 |  iteration: 15050 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 134 loss: 1.16096 acc: 0.70996 | v_loss: 1.26957 v_acc: 0.68945 |  iteration: 15051 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 135 loss: 1.25158 acc: 0.69401 | v_loss: 1.18670 v_acc: 0.71061 |  iteration: 15052 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 136 loss: 1.17487 acc: 0.70443 | v_loss: 1.08557 v_acc: 0.71582 |  iteration: 15053 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 137 loss: 1.28340 acc: 0.69336 | v_loss: 1.13379 v_acc: 0.71810 |  iteration: 15054 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 138 loss: 1.24184 acc: 0.70312 | v_loss: 1.09295 v_acc: 0.71289 |  iteration: 15055 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 139 loss: 1.16208 acc: 0.71094 | v_loss: 1.16594 v_acc: 0.70703 |  iteration: 15056 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 140 loss: 1.29791 acc: 0.71549 | v_loss: 1.11825 v_acc: 0.72070 |  iteration: 15057 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 141 loss: 1.23044 acc: 0.71029 | v_loss: 1.10043 v_acc: 0.72103 |  iteration: 15058 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 142 loss: 1.16620 acc: 0.71517 | v_loss: 1.05724 v_acc: 0.72721 |  iteration: 15059 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 143 loss: 1.21003 acc: 0.70638 | v_loss: 1.19666 v_acc: 0.71582 |  iteration: 15060 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 144 loss: 1.23643 acc: 0.70540 | v_loss: 1.13519 v_acc: 0.71191 |  iteration: 15061 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 145 loss: 1.21599 acc: 0.71061 | v_loss: 1.16671 v_acc: 0.71191 |  iteration: 15062 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 146 loss: 1.17029 acc: 0.70573 | v_loss: 0.98862 v_acc: 0.72754 |  iteration: 15063 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 147 loss: 1.17130 acc: 0.71517 | v_loss: 1.18940 v_acc: 0.73372 |  iteration: 15064 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 148 loss: 1.17602 acc: 0.71322 | v_loss: 1.17514 v_acc: 0.70475 |  iteration: 15065 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 149 loss: 1.23143 acc: 0.69954 | v_loss: 1.20998 v_acc: 0.72754 |  iteration: 15066 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 150 loss: 1.21632 acc: 0.70020 | v_loss: 1.04141 v_acc: 0.71875 |  iteration: 15067 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 151 loss: 1.24801 acc: 0.70638 | v_loss: 1.04156 v_acc: 0.73405 |  iteration: 15068 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 152 loss: 1.28255 acc: 0.69076 | v_loss: 0.99462 v_acc: 0.72754 |  iteration: 15069 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 153 loss: 1.23673 acc: 0.71061 | v_loss: 1.10813 v_acc: 0.70638 |  iteration: 15070 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 154 loss: 1.26813 acc: 0.69824 | v_loss: 1.10116 v_acc: 0.71289 |  iteration: 15071 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 155 loss: 1.16695 acc: 0.70540 | v_loss: 1.10602 v_acc: 0.71322 |  iteration: 15072 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 156 loss: 1.27207 acc: 0.70671 | v_loss: 1.25595 v_acc: 0.68880 |  iteration: 15073 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 157 loss: 1.24180 acc: 0.69368 | v_loss: 1.39539 v_acc: 0.69792 |  iteration: 15074 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 158 loss: 1.27323 acc: 0.69759 | v_loss: 1.25201 v_acc: 0.70312 |  iteration: 15075 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 159 loss: 1.17022 acc: 0.70931 | v_loss: 1.07505 v_acc: 0.72917 |  iteration: 15076 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 160 loss: 1.19474 acc: 0.70182 | v_loss: 1.07064 v_acc: 0.71257 |  iteration: 15077 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 161 loss: 1.25830 acc: 0.70410 | v_loss: 1.02755 v_acc: 0.72721 |  iteration: 15078 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 162 loss: 1.20961 acc: 0.70345 | v_loss: 1.09130 v_acc: 0.70410 |  iteration: 15079 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 163 loss: 1.13457 acc: 0.71094 | v_loss: 1.15825 v_acc: 0.71452 |  iteration: 15080 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 164 loss: 1.18813 acc: 0.70508 | v_loss: 1.15665 v_acc: 0.73210 |  iteration: 15081 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 165 loss: 1.16083 acc: 0.70475 | v_loss: 1.14082 v_acc: 0.72005 |  iteration: 15082 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 166 loss: 1.24800 acc: 0.69857 | v_loss: 1.10466 v_acc: 0.71680 |  iteration: 15083 teacher: 1 stage: sketch lr: 0.000360\n",
      "batch 167 loss: 1.20158 acc: 0.70443 | v_loss: 1.10154 v_acc: 0.72982 |  iteration: 15084 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 168 loss: 1.17500 acc: 0.70378 | v_loss: 1.07536 v_acc: 0.72624 |  iteration: 15085 teacher: 0 stage: sketch lr: 0.000360\n",
      "batch 169 loss: 1.12552 acc: 0.71354 | v_loss: 1.45791 v_acc: 0.69010 |  iteration: 15086 teacher: 0 stage: sketch lr: 0.000360\n"
     ]
    }
   ],
   "source": [
    "def process_raw_x(raw_x, n_past, n_inpaint, n_future):\n",
    "    raw_px, raw_rx, raw_len_x, raw_nrx, raw_gd = raw_x\n",
    "    past_px = raw_px[:,:n_past,:]\n",
    "    inpaint_px = raw_px[:,n_past:n_past + n_inpaint,:]\n",
    "    future_px = raw_px[:,n_future:,:]\n",
    "    past_rx = raw_rx[:,:n_past,:]\n",
    "    inpaint_rx = raw_rx[:,n_past:n_past + n_inpaint,:]\n",
    "    future_rx = raw_rx[:,n_future:,:]\n",
    "    past_len_x = raw_len_x[:,:n_past]\n",
    "    inpaint_len_x = raw_len_x[:,n_past:n_past + n_inpaint]\n",
    "    future_len_x = raw_len_x[:,n_future:]\n",
    "    past_nrx = raw_nrx[:,:n_past,:]\n",
    "    inpaint_nrx = raw_nrx[:,n_past:n_past + n_inpaint,:]\n",
    "    future_nrx = raw_nrx[:,n_future:,:]\n",
    "    past_gd = raw_gd[:,:n_past,:]\n",
    "    inpaint_gd = raw_gd[:,n_past:n_past + n_inpaint,:]\n",
    "    future_gd = raw_gd[:,n_future:,:]\n",
    "    re = [\n",
    "        past_px, past_rx, past_len_x, past_nrx, past_gd,\n",
    "        inpaint_px, inpaint_rx, inpaint_len_x, inpaint_nrx, inpaint_gd,\n",
    "        future_px, future_rx, future_len_x, future_nrx, future_gd,\n",
    "    ]\n",
    "    return re\n",
    "def get_acc(recon, gd):\n",
    "    recon = recon.cpu().detach().numpy()\n",
    "    gd = gd.cpu().detach().numpy()\n",
    "    return np.sum(recon == gd) / recon.size\n",
    "# stage-2 training\n",
    "model.set_stage(\"sketch\")\n",
    "device = torch.device(torch.cuda.current_device())\n",
    "losses = []\n",
    "step = 0\n",
    "n_past = 6\n",
    "n_future = 10\n",
    "n_inpaint = 4\n",
    "iteration = 0\n",
    "# save_period = 200\n",
    "print(vae_model.training)\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    print(\"epoch: %d\\n__________________________________________\" % (epoch), flush = True)\n",
    "    mean_loss = 0.0\n",
    "    mean_acc = 0.0\n",
    "    v_mean_loss = 0.0\n",
    "    v_mean_acc = 0.0\n",
    "    total = 0\n",
    "    for i,tr_data in enumerate(train_loader):\n",
    "        model.train()\n",
    "#         print(\"begin_time\", time.process_time())\n",
    "        j = i % len(validate_data)\n",
    "        raw_x = process_raw_x(tr_data, n_past, n_inpaint, n_future)\n",
    "        for k in range(len(raw_x)):\n",
    "            raw_x[k] = raw_x[k].to(device = device,non_blocking = True)\n",
    "        past_px, past_rx, past_len_x, past_nrx, past_gd, \\\n",
    "        inpaint_px, inpaint_rx, inpaint_len_x, inpaint_nrx, inpaint_gd,\\\n",
    "        future_px, future_rx, future_len_x, future_nrx, future_gd = raw_x\n",
    "        inpaint_gd_whole = inpaint_gd.contiguous().view(-1)\n",
    "        past_x = [past_px, past_rx, past_len_x, past_nrx, past_gd]\n",
    "        inpaint_x = [inpaint_px, inpaint_rx, inpaint_len_x, inpaint_nrx, inpaint_gd]\n",
    "        future_x = [future_px, future_rx, future_len_x, future_nrx, future_gd]\n",
    "        \n",
    "        # validate\n",
    "        v_raw_x = process_raw_x(validate_data[j], n_past, n_inpaint, n_future)\n",
    "        for k in range(len(v_raw_x)):\n",
    "            v_raw_x[k] = v_raw_x[k].to(device = device,non_blocking = True)\n",
    "        v_past_px, v_past_rx, v_past_len_x, v_past_nrx, v_past_gd, \\\n",
    "        v_inpaint_px, v_inpaint_rx, v_inpaint_len_x, v_inpaint_nrx, v_inpaint_gd,\\\n",
    "        v_future_px, v_future_rx, v_future_len_x, v_future_nrx, v_future_gd = v_raw_x\n",
    "        v_inpaint_gd_whole = v_inpaint_gd.contiguous().view(-1)\n",
    "        v_past_x = [v_past_px, v_past_rx, v_past_len_x, v_past_nrx, v_past_gd]\n",
    "        v_inpaint_x = [v_inpaint_px, v_inpaint_rx, v_inpaint_len_x, v_inpaint_nrx, v_inpaint_gd]\n",
    "        v_future_x = [v_future_px, v_future_rx, v_future_len_x, v_future_nrx, v_future_gd]\n",
    "        \n",
    "        scheduler.optimizer.zero_grad()\n",
    "        \n",
    "        recon_x, iteration, use_teacher, stage = model(past_x, future_x, inpaint_x)\n",
    "        \n",
    "        loss = F.cross_entropy(recon_x.view(-1, recon_x.size(-1)), inpaint_gd_whole, reduction = \"mean\") \n",
    "        acc = get_acc(recon_x.view(-1, recon_x.size(-1)).argmax(-1), inpaint_gd_whole)\n",
    "        loss.backward()\n",
    "        scheduler.step()    \n",
    "        total += 1\n",
    "        mean_loss += loss.item()\n",
    "        mean_acc += acc\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            v_recon_x, _,_,_ = model(v_past_x, v_future_x, v_inpaint_x)\n",
    "            v_loss = F.cross_entropy(v_recon_x.view(-1, v_recon_x.size(-1)), v_inpaint_gd_whole, reduction = \"mean\") \n",
    "            v_acc = get_acc(v_recon_x.view(-1, v_recon_x.size(-1)).argmax(-1), v_inpaint_gd_whole)\n",
    "            v_mean_loss += v_loss.item()\n",
    "            v_mean_acc += v_acc\n",
    "        print(\"batch %d loss: %.5f acc: %.5f | v_loss: %.5f v_acc: %.5f |  iteration: %d teacher: %d stage: %s lr: %f\" \\\n",
    "              % (i,loss.item(), acc, v_loss.item(), v_acc, iteration, use_teacher, stage, scheduler.rate()),flush = True)\n",
    "    mean_loss /= total\n",
    "    mean_acc /= total\n",
    "    v_mean_loss /= total\n",
    "    v_mean_acc /= total\n",
    "    print(\"epoch %d loss: %.5f acc: %.5f | v_loss: %.5f v_acc: %.5f \"  % (epoch,mean_loss, mean_acc, v_mean_loss, v_mean_acc),flush = True)\n",
    "    losses.append([mean_loss, v_mean_loss])\n",
    "    if (epoch + 1) % save_period == 0:\n",
    "        filename = \"sketchnet-\" + 'loss_' + str(v_mean_loss) + \"_acc_\" + str(v_mean_acc) + \"_epoch_\" +  str(epoch+1) + '_it_' + str(iteration) + \".pt\"\n",
    "        torch.save(model.cpu().state_dict(),os.path.join(save_path,filename))\n",
    "        model.cuda()\n",
    "    np.save(os.path.join(s_dir, \"sketchnet_log.npy\"),losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}