{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "You can skip this if you only want to test the SketchNet\n",
    "In this file, we train the MeasureVAE \"Learning to Traverse Latent Spaces for Musical Score Inpainting\", published in ISMIR 2019\n",
    "The core model code and training code are from their releasing codes.\n",
    "'''\n",
    "from MeasureVAE.measure_vae import MeasureVAE\n",
    "from utils.helpers import *\n",
    "from loader.dataloader import DataLoader\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "\n",
    "data_path = [\n",
    "    \"data/irish_train.npy\",\n",
    "    \"data/irish_validate.npy\",\n",
    "    \"data/irish_test.npy\"\n",
    "]\n",
    "# paramters initialization\n",
    "num_notes = 130\n",
    "note_embedding_dim=10\n",
    "metadata_embedding_dim=2\n",
    "num_encoder_layers=2\n",
    "encoder_hidden_size=512\n",
    "encoder_dropout_prob=0.5\n",
    "has_metadata=False\n",
    "latent_space_dim=256\n",
    "num_decoder_layers=2\n",
    "decoder_hidden_size=512\n",
    "decoder_dropout_prob=0.5\n",
    "batch_size=256\n",
    "num_epochs=30\n",
    "train=True\n",
    "plot=False\n",
    "log=True\n",
    "lr=1e-4\n",
    "seq_len = 6 * 4\n",
    "n_epochs = 50\n",
    "save_period = 2\n",
    "save_path = \"model_backup\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "train_x = np.load(data_path[0],allow_pickle=True)\n",
    "validate_x = np.load(data_path[1],allow_pickle=True)\n",
    "test_x = np.load(data_path[2],allow_pickle=True)\n",
    "dl = DataLoader(train = train_x, validate = validate_x, test = test_x)\n",
    "dl.process_split(split_size = seq_len)\n",
    "print(len(dl.train_set),len(dl.validate_set),len(dl.test_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "def compute_kld_loss(z_dist, prior_dist, beta=0.001):\n",
    "    \"\"\"\n",
    "\n",
    "    :param z_dist: torch.nn.distributions object\n",
    "    :param prior_dist: torch.nn.distributions\n",
    "    :param beta:\n",
    "    :return: kl divergence loss\n",
    "    \"\"\"\n",
    "    kld = torch.distributions.kl.kl_divergence(z_dist, prior_dist)\n",
    "    kld = beta * kld.sum(1).mean()\n",
    "    return kld\n",
    "\n",
    "def mean_crossentropy_loss(weights, targets):\n",
    "    \"\"\"\n",
    "    Evaluates the cross entropy loss\n",
    "    :param weights: torch Variable,\n",
    "            (batch_size, seq_len, num_notes)\n",
    "    :param targets: torch Variable,\n",
    "            (batch_size, seq_len)\n",
    "    :return: float, loss\n",
    "    \"\"\"\n",
    "    criteria = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "    batch_size, seq_len, num_notes = weights.size()\n",
    "    weights = weights.contiguous().view(-1, num_notes)\n",
    "    targets = targets.contiguous().view(-1)\n",
    "    loss = criteria(weights, targets)\n",
    "    return loss\n",
    "\n",
    "def mean_accuracy(weights, targets):\n",
    "    \"\"\"\n",
    "    Evaluates the mean accuracy in prediction\n",
    "    :param weights: torch Variable,\n",
    "            (batch_size, seq_len, num_notes)\n",
    "    :param targets: torch Variable,\n",
    "            (batch_size, seq_len)\n",
    "    :return float, accuracy\n",
    "    \"\"\"\n",
    "    _, _, num_notes = weights.size()\n",
    "    weights = weights.contiguous().view(-1, num_notes)\n",
    "    targets = targets.contiguous().view(-1)\n",
    "\n",
    "    _, max_indices = weights.max(1)\n",
    "    correct = max_indices == targets\n",
    "    return torch.sum(correct.float()) / targets.size(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import measureVAE\n",
    "model = MeasureVAE(\n",
    "    num_notes = num_notes,\n",
    "    note_embedding_dim=note_embedding_dim,\n",
    "    metadata_embedding_dim=metadata_embedding_dim,\n",
    "    num_encoder_layers=num_encoder_layers,\n",
    "    encoder_hidden_size=encoder_hidden_size,\n",
    "    encoder_dropout_prob=encoder_dropout_prob,\n",
    "    latent_space_dim=latent_space_dim,\n",
    "    num_decoder_layers=num_decoder_layers,\n",
    "    decoder_hidden_size=decoder_hidden_size,\n",
    "    decoder_dropout_prob=decoder_dropout_prob,\n",
    "    has_metadata=has_metadata\n",
    ")\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "if torch.cuda.is_available():\n",
    "    print('Using: ', torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "    model.cuda()\n",
    "else:\n",
    "    print('Using: CPU')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "model.train()\n",
    "step = 0\n",
    "for epoch in range(n_epochs):\n",
    "    print(\"epoch: %d\\n__________________________________________\" % (epoch), flush = True)\n",
    "    train_batches, validate_batches = dl.start_new_epoch(batch_size = batch_size)\n",
    "    for i in range(len(train_batches)):\n",
    "        model.train()\n",
    "        # validate display\n",
    "        j = i % len(validate_batches)\n",
    "        raw_x = train_batches[i]\n",
    "        raw_vx = validate_batches[j]\n",
    "        x = torch.from_numpy(raw_x).long()\n",
    "        target = x.view(-1)\n",
    "        v_x = torch.from_numpy(raw_vx).long()\n",
    "        v_target = v_x.view(-1)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "            target = target.cuda()\n",
    "            v_x = v_x.cuda()\n",
    "            v_target = v_target.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        weights, samples, z_dist, prior_dist, z_tilde, z_prior = model(measure_score_tensor=x,train=True)\n",
    "        recons_loss = mean_crossentropy_loss(weights=weights, targets=target)\n",
    "        dist_loss = compute_kld_loss(z_dist, prior_dist)\n",
    "        loss = recons_loss + dist_loss\n",
    "        accuracy = mean_accuracy(weights=weights,targets=target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        v_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            v_weights, v_samples, v_z_dist, v_prior_dist, v_z_tilde, v_z_prior = model(measure_score_tensor=v_x,train=False)\n",
    "            v_recons_loss = mean_crossentropy_loss(weights=v_weights, targets=v_target)\n",
    "            v_dist_loss = compute_kld_loss(v_z_dist, v_prior_dist)\n",
    "            v_loss = v_recons_loss + v_dist_loss\n",
    "            v_accuracy = mean_accuracy(weights=v_weights,targets=v_target)\n",
    "        print(\"batch %d loss: %.5f acc: %.5f| val loss %.5f acc: %.5f \"  \n",
    "              % (i,loss.item(), accuracy.item(),v_loss.item(),v_accuracy.item()),flush = True)\n",
    "    if (epoch + 1) % save_period == 0:\n",
    "        filename = \"measure-vae-\" + 'loss_' + str(v_loss.item()) + \"_acc_\" + str(v_accuracy.item()) + \"_epoch_\" + str(epoch+1) + \".pt\"\n",
    "        torch.save(model.cpu().state_dict(),os.path.join(save_path,filename))\n",
    "        model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
